{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import threading\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.logger.set_level(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'CartPole-v0'\n",
    "input_dim = 4\n",
    "action_list = [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A3C(nn.Module):\n",
    "    def __init__(self, input_dim, action_dim, max_ep=0, is_global=False):\n",
    "        super(A3C, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.max_ep = max_ep\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.ep_counter = 0\n",
    "        self.ep_returns = []\n",
    "        self.average_returns = []\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        Q = self.fc3(x)\n",
    "        V = self.fc4(x)\n",
    "        return Q, V\n",
    "    \n",
    "    def log_episode(self, ep_return):\n",
    "        c = self.ep_counter\n",
    "        self.ep_returns.append(ep_return)\n",
    "        self.average_returns.append(np.mean(self.ep_returns[max(0, c-99):c+1]))\n",
    "        self.ep_counter += 1\n",
    "        return self.ep_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 8\n",
    "\n",
    "#T_max = 10000\n",
    "MAX_EP = 20000\n",
    "t_max = 5\n",
    "print_freq = 1000\n",
    "\n",
    "beta = 0.01   # entropy regularization\n",
    "gamma = 0.99\n",
    "alpha = 0.99   # RMSProb decay factor\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 0.996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lock, globalNet, optimizer, tmax, tid):\n",
    "    t = 0\n",
    "    done = False\n",
    "    ep_return = 0\n",
    "    log_episode_return = []\n",
    "    cur_ep = 0\n",
    "    \n",
    "    localNet = A3C(input_dim, len(action_list))\n",
    "    localNet.load_state_dict(globalNet.state_dict())\n",
    "    env = gym.make(ENV_NAME)\n",
    "    obs = env.reset()\n",
    "    \n",
    "    while globalNet.ep_counter < MAX_EP:\n",
    "        t_start = t\n",
    "        buff_value = []\n",
    "        buff_q = []\n",
    "        buff_reward = []\n",
    "        buff_logp = []\n",
    "        buff_entropy = []\n",
    "\n",
    "        while t_start-t < t_max:\n",
    "            Q, V = localNet(torch.tensor(obs.astype(np.float32)))\n",
    "            prob = F.softmax(Q, dim=0).data\n",
    "            [a] = np.random.choice(localNet.action_dim, 1, p=prob.detach().numpy())\n",
    "            log_prob = F.log_softmax(Q, dim=0)\n",
    "\n",
    "            obs, reward, done, _ = env.step(action_list[a])\n",
    "            ep_return += reward\n",
    "            entropy = -log_prob*prob.sum()\n",
    "\n",
    "            buff_q.append(Q)\n",
    "            buff_value.append(V)\n",
    "            buff_reward.append(reward)\n",
    "            buff_logp.append(log_prob[a])\n",
    "            buff_entropy.append(entropy)\n",
    "            t += 1\n",
    "            \n",
    "            if done:\n",
    "                cur_ep = globalNet.log_episode(ep_return)\n",
    "                obs = env.reset()\n",
    "                ep_return = 0\n",
    "                break\n",
    "\n",
    "        R = V if not done else 0\n",
    "        policy_loss = 0\n",
    "        value_loss = 0\n",
    "        entropy_loss = 0\n",
    "        for i in range(-1, -(t-t_start)-1, -1): #range(t-1, t_start-1, -1):\n",
    "            R = buff_reward[i] + gamma*R\n",
    "            TD = R - buff_value[i]\n",
    "            policy_loss += buff_logp[i] * TD.detach()\n",
    "            value_loss += torch.pow(TD, 2)\n",
    "            entropy_loss += buff_entropy[i].sum()\n",
    "        loss = - policy_loss + value_loss - beta*entropy_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        lock.acquire()\n",
    "        try:\n",
    "            for local_param, global_param in zip(localNet.parameters(), globalNet.parameters()):\n",
    "                global_param.grad = local_param.grad\n",
    "            optimizer.step()\n",
    "        finally:\n",
    "            lock.release()\n",
    "        localNet.load_state_dict(globalNet.state_dict())\n",
    "        \n",
    "        if cur_ep%print_freq==0: #globalNet.ep_counter.value%100==0:\n",
    "            print('[%d] Thread'%tid)\n",
    "            print('%d/%d episodes. (%.2f%%)'%(cur_ep, MAX_EP, cur_ep/MAX_EP*100))\n",
    "            #print(globalNet.ep_counter.value-1, 'episodes.')\n",
    "            print('Total loss:\\t', loss.data.numpy()[0])\n",
    "            print('Entropy\\t\\tPolicy\\t\\tValue')\n",
    "            print('%.2f\\t\\t%.2f\\t\\t%.2f'%(entropy_loss.data.numpy(), policy_loss.data.numpy()[0], \\\n",
    "                  value_loss.data.numpy()[0]))\n",
    "            print('Epside Return: [%.1f]'%globalNet.average_returns[globalNet.ep_counter-1])\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583591895.1710887\n",
      "10.155836582183838\n",
      "\n",
      "[2] Thread\n",
      "1000/20000 episodes. (5.00%)\n",
      "Total loss:\t 1481.8181\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "35.52\t\t55.96\t\t1538.13\n",
      "Epside Return: [32.8]\n",
      "\n",
      "1583591905.3269253\n",
      "14.60524034500122\n",
      "\n",
      "[2] Thread\n",
      "2000/20000 episodes. (10.00%)\n",
      "Total loss:\t 21027.176\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "122.52\t\t-247.05\t\t20781.35\n",
      "Epside Return: [53.1]\n",
      "\n",
      "1583591919.9321656\n",
      "19.61437153816223\n",
      "\n",
      "[1] Thread\n",
      "3000/20000 episodes. (15.00%)\n",
      "Total loss:\t 22294.602\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "161.96\t\t-376.18\t\t21920.04\n",
      "Epside Return: [56.7]\n",
      "\n",
      "1583591939.5465372\n",
      "33.5636625289917\n",
      "\n",
      "[3] Thread\n",
      "4000/20000 episodes. (20.00%)\n",
      "Total loss:\t 108015.484\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "329.35\t\t-977.58\t\t107041.20\n",
      "Epside Return: [124.9]\n",
      "\n",
      "1583591973.1101997\n",
      "50.31988191604614\n",
      "\n",
      "[7] Thread\n",
      "5000/20000 episodes. (25.00%)\n",
      "Total loss:\t 54194.82\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "342.72\t\t-1182.71\t\t53015.54\n",
      "Epside Return: [138.2]\n",
      "\n",
      "1583592023.4300816\n",
      "56.36374855041504\n",
      "\n",
      "[4] Thread\n",
      "6000/20000 episodes. (30.00%)\n",
      "Total loss:\t 49855.07\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "340.81\t\t41.97\t\t49900.45\n",
      "Epside Return: [178.1]\n",
      "\n",
      "1583592079.7938302\n",
      "57.225518226623535\n",
      "\n",
      "[1] Thread\n",
      "7000/20000 episodes. (35.00%)\n",
      "Total loss:\t 91692.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "356.90\t\t-776.30\t\t90919.61\n",
      "Epside Return: [190.2]\n",
      "\n",
      "1583592137.0193484\n",
      "56.70717930793762\n",
      "\n",
      "[6] Thread\n",
      "8000/20000 episodes. (40.00%)\n",
      "Total loss:\t 106490.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "349.25\t\t585.07\t\t107079.54\n",
      "Epside Return: [177.2]\n",
      "\n",
      "1583592193.7265277\n",
      "59.59857702255249\n",
      "\n",
      "[7] Thread\n",
      "9000/20000 episodes. (45.00%)\n",
      "Total loss:\t 5220.0176\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "307.28\t\t-297.98\t\t4925.11\n",
      "Epside Return: [187.5]\n",
      "\n",
      "1583592253.3251047\n",
      "59.29810047149658\n",
      "\n",
      "[3] Thread\n",
      "10000/20000 episodes. (50.00%)\n",
      "Total loss:\t 114282.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "358.83\t\t388.96\t\t114674.93\n",
      "Epside Return: [189.6]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-6468ece587ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mthreads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/py3_cpu/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py3_cpu/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "globalNet = A3C(input_dim, len(action_list), MAX_EP, is_global=True)\n",
    "#globalNet.share_memory()\n",
    "optimizer = optim.Adam(globalNet.parameters(), lr=learning_rate)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "lock = threading.Lock()\n",
    "\n",
    "threads = []\n",
    "for t_idx in range(NUM_THREADS):\n",
    "    t = threading.Thread(target=train, args=(lock, globalNet, optimizer, t_max, t_idx))\n",
    "    t.start()\n",
    "    threads.append(t)\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Learning Rate Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(globalNet.ep_returns[:], color='orange')\n",
    "plt.plot(globalNet.average_returns[:], color='red')\n",
    "fignum = len([f for f in os.listdir() if 'CartPole' in f and 'png' in f])\n",
    "plt.savefig('A3C_CartPole_threads_%d.png'%fignum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
