{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "GITPATH = subprocess.run('git rev-parse --show-toplevel'.split(' '), \\\n",
    "        stdout=subprocess.PIPE).stdout.decode('utf-8').replace('\\n','')\n",
    "sys.path.append(GITPATH)\n",
    "import dobroEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.logger.set_level(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'DobroHalfCheetah-v0'\n",
    "input_dim = 20\n",
    "action_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 8\n",
    "\n",
    "#T_max = 10000\n",
    "MAX_EP = 200000\n",
    "t_max = 100\n",
    "print_freq = 500\n",
    "\n",
    "beta = 0.001   # entropy regularization\n",
    "gamma = 0.99\n",
    "#alpha = 0.99   # RMSProb decay factor\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class A3C(nn.Module):\n",
    "    def __init__(self, input_dim, action_dim, max_ep=0, is_global=False):\n",
    "        super(A3C, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.max_ep = max_ep\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc_mu = nn.Linear(64, action_dim)\n",
    "        self.fc_sigma = nn.Linear(64, action_dim)\n",
    "        self.fc_value = nn.Linear(64, 1)\n",
    "        \n",
    "        self.ep_counter = None\n",
    "        self.ep_returns = None\n",
    "        self.average_returns = None\n",
    "        \n",
    "        if is_global:\n",
    "            self.set_global()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        action_mu = self.fc_mu(x)\n",
    "        action_sigma = self.fc_sigma(x)\n",
    "        V = self.fc_value(x)\n",
    "        return action_mu, action_sigma, V\n",
    "    \n",
    "    def set_global(self):\n",
    "        self.ep_counter = mp.Value('i')\n",
    "        self.ep_counter.value = 0\n",
    "        self.ep_returns = mp.Array('d', self.max_ep)\n",
    "        self.average_returns = mp.Array('d',self.max_ep)\n",
    "        \n",
    "    def log_episode(self, ep_return):\n",
    "        c = self.ep_counter.value\n",
    "        self.ep_returns[c] = ep_return\n",
    "        self.average_returns[c] = np.mean(self.ep_returns[max(0, c-99):c+1])\n",
    "        self.ep_counter.value += 1\n",
    "        return self.ep_counter.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A3C_v3(nn.Module):\n",
    "    def __init__(self, input_dim, action_dim, max_ep=0, is_global=False):\n",
    "        super(A3C_v3, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.max_ep = max_ep\n",
    "        \n",
    "        self.fc_pi1 = nn.Linear(input_dim, 64)\n",
    "        self.fc_pi2 = nn.Linear(64, 64)\n",
    "        self.fc_mu = nn.Linear(64, action_dim)\n",
    "        self.fc_sigma = nn.Linear(64, action_dim)\n",
    "        self.fc_v1 = nn.Linear(input_dim, 64)\n",
    "        self.fc_v2 = nn.Linear(64, 64)\n",
    "        self.fc_v3 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.ep_counter = None\n",
    "        self.ep_returns = None\n",
    "        self.average_returns = None\n",
    "        \n",
    "        if is_global:\n",
    "            self.set_global()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_pi = F.relu(self.fc_pi1(x))\n",
    "        x_pi = F.relu(self.fc_pi2(x_pi))\n",
    "        action_mu = self.fc_mu(x_pi)\n",
    "        action_sigma = self.fc_sigma(x_pi)\n",
    "        \n",
    "        x_v = F.relu(self.fc_v1(x))\n",
    "        x_v = F.relu(self.fc_v2(x_v))\n",
    "        V = self.fc_v3(x_v)\n",
    "        return action_mu, action_sigma, V\n",
    "    \n",
    "    def set_global(self):\n",
    "        self.ep_counter = mp.Value('i')\n",
    "        self.ep_counter.value = 0\n",
    "        self.ep_returns = mp.Array('d', self.max_ep)\n",
    "        self.average_returns = mp.Array('d',self.max_ep)\n",
    "        \n",
    "    def log_episode(self, ep_return):\n",
    "        c = self.ep_counter.value\n",
    "        self.ep_returns[c] = ep_return\n",
    "        self.average_returns[c] = np.mean(self.ep_returns[max(0, c-99):c+1])\n",
    "        self.ep_counter.value += 1\n",
    "        return self.ep_counter.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lock, globalNet, optimizer, scheduler, tmax, pid):\n",
    "    t = 0\n",
    "    done = False\n",
    "    ep_return = 0\n",
    "    log_episode_return = []\n",
    "    cur_ep = 0\n",
    "    step_count = 0\n",
    "    \n",
    "    localNet = A3C_v3(input_dim, action_dim)\n",
    "    localNet.load_state_dict(globalNet.state_dict())\n",
    "    env = gym.make(ENV_NAME)\n",
    "    env.unwrapped.initialize()\n",
    "    obs = env.reset()\n",
    "    \n",
    "    while globalNet.ep_counter.value < MAX_EP:\n",
    "        t_start = t\n",
    "        buff_value = []\n",
    "        buff_reward = []\n",
    "        buff_logp = []\n",
    "        buff_entropy = []\n",
    "\n",
    "        while t_start-t < t_max:\n",
    "            mu, sigma, V = localNet(torch.tensor(obs.astype(np.float32)))\n",
    "            Softplus=nn.Softplus()     \n",
    "            sigma = Softplus(sigma + 1e-5) # constrain to sensible values\n",
    "            normal_dist = torch.normal(mu, sigma)\n",
    "            \n",
    "            sigma = Softplus(sigma + 1e-5) # constrain to sensible values\n",
    "            action_dist = torch.normal(mu, sigma)\n",
    "            action = action_dist.detach().numpy()\n",
    "            action = action.clip(env.action_space.low, env.action_space.high)\n",
    "            \n",
    "            entropy = -0.5 * (torch.log(2. * np.pi * sigma) + 1.)\n",
    "            \n",
    "            # log prob: gaussian negative log-likelihood\n",
    "            log_prob = torch.log(1/torch.sqrt(2*np.pi*sigma**2)) - (action_dist-mu)**2/(2*sigma**2)\n",
    "\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            step_count += 1\n",
    "            ep_return += reward\n",
    "\n",
    "            buff_value.append(V)\n",
    "            buff_reward.append(reward)\n",
    "            buff_logp.append(log_prob.sum())\n",
    "            buff_entropy.append(entropy)\n",
    "            t += 1\n",
    "            \n",
    "            if done:\n",
    "                cur_ep = globalNet.log_episode(ep_return)\n",
    "                obs = env.reset()\n",
    "                if step_count==env._max_episode_steps:\n",
    "                    done = False\n",
    "                step_count = 0\n",
    "                ep_return = 0\n",
    "                break\n",
    "\n",
    "        R = V if not done else 0\n",
    "        policy_loss = 0\n",
    "        value_loss = 0\n",
    "        entropy_loss = 0\n",
    "        for i in range(-1, -(t-t_start)-1, -1):\n",
    "            R = buff_reward[i] + gamma*R\n",
    "            TD = R - buff_value[i]\n",
    "            policy_loss += buff_logp[i] * TD.detach()\n",
    "            value_loss += torch.pow(TD, 2)\n",
    "            entropy_loss += buff_entropy[i].sum()\n",
    "        loss = - policy_loss + value_loss - beta*entropy_loss\n",
    "        \n",
    "        lock.acquire()\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            for local_param, global_param in zip(localNet.parameters(), globalNet.parameters()):\n",
    "                global_param.grad = local_param.grad\n",
    "            optimizer.step()\n",
    "        finally:\n",
    "            lock.release()\n",
    "        localNet.load_state_dict(globalNet.state_dict())\n",
    "        \n",
    "        if cur_ep%print_freq==0:\n",
    "            print('[%d] Process'%pid)\n",
    "            print('%d/%d episodes. (%.2f%%)'%(cur_ep, MAX_EP, cur_ep/MAX_EP*100))\n",
    "            #print('Current learning rate:', optimizer.param_groups[0]['lr'])\n",
    "            print('Total loss:\\t', loss.data.numpy()[0])\n",
    "            print('Entropy\\t\\tPolicy\\t\\tValue')\n",
    "            print('%.2f\\t\\t%.2f\\t\\t%.2f'%(entropy_loss.data.numpy(), policy_loss.data.numpy()[0], \\\n",
    "                  value_loss.data.numpy()[0]))\n",
    "            print('Epside Return: [%.1f]'%globalNet.average_returns[globalNet.ep_counter.value-1])\n",
    "            print()\n",
    "            \n",
    "            global log_df, fig_num\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            average_returns = np.array(globalNet.average_returns[:])\n",
    "            ep_returns = np.array(globalNet.ep_returns[:])\n",
    "            nonzero_indices = average_returns!=0.0\n",
    "            plt.plot(ep_returns[nonzero_indices], color='lightgreen')\n",
    "            plt.plot(average_returns[nonzero_indices], color='green')\n",
    "            plt.savefig('A3C_v3_HalfCheetah_%d.png'%fignum)\n",
    "            plt.close()\n",
    "            \n",
    "            raw_data = [cur_ep/MAX_EP*100, cur_ep, loss.data.numpy()[0], globalNet.average_returns[globalNet.ep_counter.value-1], optimizer.param_groups[0]['lr']]\n",
    "            log_df = log_df.append(pd.Series(raw_data, index = log_df.columns), ignore_index=True)\n",
    "        \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] Process\n",
      "500/200000 episodes. (0.25%)\n",
      "Total loss:\t 92473.336\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8775.47\t\t-37027.23\t\t55437.33\n",
      "Epside Return: [64.0]\n",
      "\n",
      "[4] Process\n",
      "1000/200000 episodes. (0.50%)\n",
      "Total loss:\t 68970.016\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8786.23\t\t5510.85\t\t74472.08\n",
      "Epside Return: [137.4]\n",
      "\n",
      "[3] Process\n",
      "1500/200000 episodes. (0.75%)\n",
      "Total loss:\t 19642.85\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8790.06\t\t48368.00\t\t68002.05\n",
      "Epside Return: [158.8]\n",
      "\n",
      "[0] Process\n",
      "2000/200000 episodes. (1.00%)\n",
      "Total loss:\t 412270.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8781.94\t\t-117430.62\t\t294830.72\n",
      "Epside Return: [220.6]\n",
      "\n",
      "[4] Process\n",
      "2500/200000 episodes. (1.25%)\n",
      "Total loss:\t 189030.86\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8548.05\t\t-17637.66\t\t171384.66\n",
      "Epside Return: [594.0]\n",
      "\n",
      "[1] Process\n",
      "3000/200000 episodes. (1.50%)\n",
      "Total loss:\t 412215.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8511.87\t\t-77410.51\t\t334796.22\n",
      "Epside Return: [769.7]\n",
      "\n",
      "[6] Process\n",
      "3500/200000 episodes. (1.75%)\n",
      "Total loss:\t 799505.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-7746.80\t\t61239.45\t\t860737.19\n",
      "Epside Return: [791.3]\n",
      "\n",
      "[0] Process\n",
      "4000/200000 episodes. (2.00%)\n",
      "Total loss:\t 511802.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8412.36\t\t1313.31\t\t513107.47\n",
      "Epside Return: [859.0]\n",
      "\n",
      "[2] Process\n",
      "4500/200000 episodes. (2.25%)\n",
      "Total loss:\t 233563.98\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8313.07\t\t-31100.06\t\t202455.61\n",
      "Epside Return: [971.4]\n",
      "\n",
      "[4] Process\n",
      "5000/200000 episodes. (2.50%)\n",
      "Total loss:\t 224865.17\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8272.70\t\t-56996.66\t\t167860.25\n",
      "Epside Return: [995.4]\n",
      "\n",
      "[0] Process\n",
      "5500/200000 episodes. (2.75%)\n",
      "Total loss:\t 453349.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8268.31\t\t-104648.76\t\t348692.00\n",
      "Epside Return: [971.1]\n",
      "\n",
      "[3] Process\n",
      "6000/200000 episodes. (3.00%)\n",
      "Total loss:\t 92891.57\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8240.53\t\t4360.65\t\t97243.98\n",
      "Epside Return: [1025.9]\n",
      "\n",
      "[3] Process\n",
      "6500/200000 episodes. (3.25%)\n",
      "Total loss:\t 449762.3\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-939.34\t\t53989.39\t\t503750.78\n",
      "Epside Return: [1015.6]\n",
      "\n",
      "[4] Process\n",
      "7000/200000 episodes. (3.50%)\n",
      "Total loss:\t 236080.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8200.45\t\t5639.13\t\t241711.56\n",
      "Epside Return: [1051.4]\n",
      "\n",
      "[4] Process\n",
      "7500/200000 episodes. (3.75%)\n",
      "Total loss:\t 689649.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8226.81\t\t95869.04\t\t785509.81\n",
      "Epside Return: [1044.6]\n",
      "\n",
      "[6] Process\n",
      "8000/200000 episodes. (4.00%)\n",
      "Total loss:\t 129885.01\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8239.42\t\t10212.94\t\t140089.70\n",
      "Epside Return: [1086.9]\n",
      "\n",
      "[0] Process\n",
      "8500/200000 episodes. (4.25%)\n",
      "Total loss:\t 430432.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8250.17\t\t61949.16\t\t492373.78\n",
      "Epside Return: [1049.8]\n",
      "\n",
      "[5] Process\n",
      "9000/200000 episodes. (4.50%)\n",
      "Total loss:\t 153978.83\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8222.66\t\t-21009.61\t\t132961.00\n",
      "Epside Return: [1106.2]\n",
      "\n",
      "[1] Process\n",
      "9500/200000 episodes. (4.75%)\n",
      "Total loss:\t 251123.95\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8221.92\t\t-35117.48\t\t215998.25\n",
      "Epside Return: [1062.3]\n",
      "\n",
      "[0] Process\n",
      "10000/200000 episodes. (5.00%)\n",
      "Total loss:\t 332764.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8207.24\t\t-42962.87\t\t289793.59\n",
      "Epside Return: [1057.3]\n",
      "\n",
      "[5] Process\n",
      "10500/200000 episodes. (5.25%)\n",
      "Total loss:\t 302206.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8197.84\t\t-62207.38\t\t239991.02\n",
      "Epside Return: [1100.6]\n",
      "\n",
      "[1] Process\n",
      "11000/200000 episodes. (5.50%)\n",
      "Total loss:\t 325747.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8204.63\t\t-57930.23\t\t267809.38\n",
      "Epside Return: [1136.5]\n",
      "\n",
      "[2] Process\n",
      "11500/200000 episodes. (5.75%)\n",
      "Total loss:\t 154384.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8202.46\t\t10563.67\t\t164939.50\n",
      "Epside Return: [1178.3]\n",
      "\n",
      "[5] Process\n",
      "12000/200000 episodes. (6.00%)\n",
      "Total loss:\t 628900.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8198.85\t\t17590.41\t\t646482.69\n",
      "Epside Return: [1160.0]\n",
      "\n",
      "[3] Process\n",
      "12500/200000 episodes. (6.25%)\n",
      "Total loss:\t 223479.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8184.08\t\t19083.43\t\t242555.02\n",
      "Epside Return: [1159.4]\n",
      "\n",
      "[1] Process\n",
      "13000/200000 episodes. (6.50%)\n",
      "Total loss:\t 282097.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8154.94\t\t-31322.95\t\t250766.28\n",
      "Epside Return: [1172.7]\n",
      "\n",
      "[0] Process\n",
      "13500/200000 episodes. (6.75%)\n",
      "Total loss:\t 202716.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8153.29\t\t-39256.30\t\t163452.41\n",
      "Epside Return: [1200.6]\n",
      "\n",
      "[3] Process\n",
      "14000/200000 episodes. (7.00%)\n",
      "Total loss:\t 535225.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8154.96\t\t-3942.98\t\t531274.31\n",
      "Epside Return: [1243.9]\n",
      "\n",
      "[2] Process\n",
      "14500/200000 episodes. (7.25%)\n",
      "Total loss:\t 166088.55\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8131.35\t\t52229.15\t\t218309.58\n",
      "Epside Return: [1221.4]\n",
      "\n",
      "[1] Process\n",
      "15000/200000 episodes. (7.50%)\n",
      "Total loss:\t 226722.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8123.77\t\t-2408.08\t\t224306.45\n",
      "Epside Return: [1270.0]\n",
      "\n",
      "[5] Process\n",
      "15500/200000 episodes. (7.75%)\n",
      "Total loss:\t 117479.92\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-172.66\t\t13008.00\t\t130487.75\n",
      "Epside Return: [1196.0]\n",
      "\n",
      "[1] Process\n",
      "16000/200000 episodes. (8.00%)\n",
      "Total loss:\t 320190.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8113.17\t\t-11286.55\t\t308895.84\n",
      "Epside Return: [1269.0]\n",
      "\n",
      "[2] Process\n",
      "16500/200000 episodes. (8.25%)\n",
      "Total loss:\t 181410.55\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8123.88\t\t-20228.65\t\t161173.78\n",
      "Epside Return: [1279.6]\n",
      "\n",
      "[4] Process\n",
      "17000/200000 episodes. (8.50%)\n",
      "Total loss:\t 334046.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8107.95\t\t-67065.41\t\t266973.09\n",
      "Epside Return: [1281.2]\n",
      "\n",
      "[2] Process\n",
      "17500/200000 episodes. (8.75%)\n",
      "Total loss:\t 120442.805\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8109.57\t\t23041.68\t\t143476.38\n",
      "Epside Return: [1262.1]\n",
      "\n",
      "[5] Process\n",
      "18000/200000 episodes. (9.00%)\n",
      "Total loss:\t 570488.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8128.78\t\t-28065.83\t\t542414.12\n",
      "Epside Return: [1262.9]\n",
      "\n",
      "[4] Process\n",
      "18500/200000 episodes. (9.25%)\n",
      "Total loss:\t 267470.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8092.25\t\t-58172.64\t\t209289.62\n",
      "Epside Return: [1258.8]\n",
      "\n",
      "[5] Process\n",
      "19000/200000 episodes. (9.50%)\n",
      "Total loss:\t 322720.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8096.18\t\t-70330.55\t\t252381.48\n",
      "Epside Return: [1301.9]\n",
      "\n",
      "[7] Process\n",
      "19500/200000 episodes. (9.75%)\n",
      "Total loss:\t 848343.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8108.66\t\t99720.73\t\t948055.69\n",
      "Epside Return: [1284.0]\n",
      "\n",
      "[5] Process\n",
      "20000/200000 episodes. (10.00%)\n",
      "Total loss:\t 409549.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8091.87\t\t-85000.36\t\t324540.66\n",
      "Epside Return: [1286.4]\n",
      "\n",
      "[6] Process\n",
      "20500/200000 episodes. (10.25%)\n",
      "Total loss:\t 344381.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8106.47\t\t-16948.38\t\t327425.16\n",
      "Epside Return: [1269.6]\n",
      "\n",
      "[0] Process\n",
      "21000/200000 episodes. (10.50%)\n",
      "Total loss:\t 352018.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8128.68\t\t57746.32\t\t409757.00\n",
      "Epside Return: [1270.0]\n",
      "\n",
      "[5] Process\n",
      "21500/200000 episodes. (10.75%)\n",
      "Total loss:\t 197878.81\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8104.18\t\t-13035.85\t\t184834.86\n",
      "Epside Return: [1310.0]\n",
      "\n",
      "[6] Process\n",
      "22000/200000 episodes. (11.00%)\n",
      "Total loss:\t 247634.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8088.09\t\t-41227.50\t\t206399.06\n",
      "Epside Return: [1294.0]\n",
      "\n",
      "[3] Process\n",
      "22500/200000 episodes. (11.25%)\n",
      "Total loss:\t 326148.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8107.54\t\t12243.19\t\t338383.25\n",
      "Epside Return: [1340.2]\n",
      "\n",
      "[7] Process\n",
      "23000/200000 episodes. (11.50%)\n",
      "Total loss:\t 168158.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8096.71\t\t-8034.15\t\t160116.72\n",
      "Epside Return: [1320.8]\n",
      "\n",
      "[4] Process\n",
      "23500/200000 episodes. (11.75%)\n",
      "Total loss:\t 144781.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8088.10\t\t-18697.51\t\t126076.05\n",
      "Epside Return: [1331.4]\n",
      "\n",
      "[3] Process\n",
      "24000/200000 episodes. (12.00%)\n",
      "Total loss:\t 260274.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8084.47\t\t-72408.36\t\t187857.69\n",
      "Epside Return: [1307.5]\n",
      "\n",
      "[0] Process\n",
      "24500/200000 episodes. (12.25%)\n",
      "Total loss:\t 953242.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-3142.59\t\t87427.53\t\t1040667.00\n",
      "Epside Return: [1286.1]\n",
      "\n",
      "[3] Process\n",
      "25000/200000 episodes. (12.50%)\n",
      "Total loss:\t 297850.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8103.93\t\t-11083.44\t\t286758.56\n",
      "Epside Return: [1316.7]\n",
      "\n",
      "[6] Process\n",
      "25500/200000 episodes. (12.75%)\n",
      "Total loss:\t 345650.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8088.24\t\t-72440.55\t\t273201.78\n",
      "Epside Return: [1285.6]\n",
      "\n",
      "[5] Process\n",
      "26000/200000 episodes. (13.00%)\n",
      "Total loss:\t 593473.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.92\t\t-21683.20\t\t571782.38\n",
      "Epside Return: [1319.9]\n",
      "\n",
      "[2] Process\n",
      "26500/200000 episodes. (13.25%)\n",
      "Total loss:\t 213148.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8093.33\t\t-15225.34\t\t197915.06\n",
      "Epside Return: [1303.2]\n",
      "\n",
      "[3] Process\n",
      "27000/200000 episodes. (13.50%)\n",
      "Total loss:\t 601276.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8108.59\t\t62764.98\t\t664033.06\n",
      "Epside Return: [1296.6]\n",
      "\n",
      "[4] Process\n",
      "27500/200000 episodes. (13.75%)\n",
      "Total loss:\t 185964.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8077.80\t\t-35700.13\t\t150256.42\n",
      "Epside Return: [1336.3]\n",
      "\n",
      "[5] Process\n",
      "28000/200000 episodes. (14.00%)\n",
      "Total loss:\t 514513.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8084.99\t\t-26654.21\t\t487851.19\n",
      "Epside Return: [1283.3]\n",
      "\n",
      "[3] Process\n",
      "28500/200000 episodes. (14.25%)\n",
      "Total loss:\t 312326.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.98\t\t-17633.40\t\t294684.78\n",
      "Epside Return: [1311.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[7] Process\n",
      "29000/200000 episodes. (14.50%)\n",
      "Total loss:\t 143510.64\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8077.17\t\t-26663.57\t\t116838.98\n",
      "Epside Return: [1261.0]\n",
      "\n",
      "[0] Process\n",
      "29500/200000 episodes. (14.75%)\n",
      "Total loss:\t 291415.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8086.48\t\t47980.80\t\t339388.28\n",
      "Epside Return: [1345.9]\n",
      "\n",
      "[4] Process\n",
      "30000/200000 episodes. (15.00%)\n",
      "Total loss:\t 1064508.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-2673.98\t\t122992.38\t\t1187498.12\n",
      "Epside Return: [1318.8]\n",
      "\n",
      "[7] Process\n",
      "30500/200000 episodes. (15.25%)\n",
      "Total loss:\t 397839.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8088.38\t\t-74667.23\t\t323163.69\n",
      "Epside Return: [1287.3]\n",
      "\n",
      "[4] Process\n",
      "31000/200000 episodes. (15.50%)\n",
      "Total loss:\t 291513.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8085.68\t\t4986.26\t\t296491.38\n",
      "Epside Return: [1310.9]\n",
      "\n",
      "[5] Process\n",
      "31500/200000 episodes. (15.75%)\n",
      "Total loss:\t 248526.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.35\t\t-69470.65\t\t179047.98\n",
      "Epside Return: [1309.3]\n",
      "\n",
      "[0] Process\n",
      "32000/200000 episodes. (16.00%)\n",
      "Total loss:\t 1020455.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6581.21\t\t45281.62\t\t1065730.88\n",
      "Epside Return: [1328.5]\n",
      "\n",
      "[7] Process\n",
      "32500/200000 episodes. (16.25%)\n",
      "Total loss:\t 1346442.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6562.07\t\t103317.84\t\t1449754.25\n",
      "Epside Return: [1296.6]\n",
      "\n",
      "[0] Process\n",
      "33000/200000 episodes. (16.50%)\n",
      "Total loss:\t 356295.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.57\t\t-52897.08\t\t303390.62\n",
      "Epside Return: [1345.8]\n",
      "\n",
      "[7] Process\n",
      "33500/200000 episodes. (16.75%)\n",
      "Total loss:\t 270238.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.18\t\t-73661.22\t\t196569.41\n",
      "Epside Return: [1348.5]\n",
      "\n",
      "[0] Process\n",
      "34000/200000 episodes. (17.00%)\n",
      "Total loss:\t 218547.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.77\t\t-18190.72\t\t200348.67\n",
      "Epside Return: [1354.4]\n",
      "\n",
      "[7] Process\n",
      "34500/200000 episodes. (17.25%)\n",
      "Total loss:\t 142104.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8080.48\t\t31378.82\t\t173475.20\n",
      "Epside Return: [1329.3]\n",
      "\n",
      "[1] Process\n",
      "35000/200000 episodes. (17.50%)\n",
      "Total loss:\t 276652.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8077.04\t\t10512.12\t\t287157.03\n",
      "Epside Return: [1342.8]\n",
      "\n",
      "[0] Process\n",
      "35500/200000 episodes. (17.75%)\n",
      "Total loss:\t 128669.01\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8084.40\t\t17069.00\t\t145729.92\n",
      "Epside Return: [1340.6]\n",
      "\n",
      "[1] Process\n",
      "36000/200000 episodes. (18.00%)\n",
      "Total loss:\t 174755.17\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8082.33\t\t-16232.05\t\t158515.05\n",
      "Epside Return: [1301.2]\n",
      "\n",
      "[5] Process\n",
      "36500/200000 episodes. (18.25%)\n",
      "Total loss:\t 592711.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.64\t\t60163.65\t\t652866.69\n",
      "Epside Return: [1260.4]\n",
      "\n",
      "[7] Process\n",
      "37000/200000 episodes. (18.50%)\n",
      "Total loss:\t 153776.58\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.05\t\t-23795.54\t\t129972.98\n",
      "Epside Return: [1277.9]\n",
      "\n",
      "[5] Process\n",
      "37500/200000 episodes. (18.75%)\n",
      "Total loss:\t 477371.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.29\t\t21728.09\t\t499091.50\n",
      "Epside Return: [1352.5]\n",
      "\n",
      "[2] Process\n",
      "38000/200000 episodes. (19.00%)\n",
      "Total loss:\t 208206.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.63\t\t-42158.14\t\t166039.83\n",
      "Epside Return: [1324.5]\n",
      "\n",
      "[3] Process\n",
      "38500/200000 episodes. (19.25%)\n",
      "Total loss:\t 307880.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.28\t\t-24337.15\t\t283534.78\n",
      "Epside Return: [1300.5]\n",
      "\n",
      "[7] Process\n",
      "39000/200000 episodes. (19.50%)\n",
      "Total loss:\t 504638.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8088.47\t\t48809.31\t\t553439.50\n",
      "Epside Return: [1339.5]\n",
      "\n",
      "[3] Process\n",
      "39500/200000 episodes. (19.75%)\n",
      "Total loss:\t 293223.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.52\t\t-31637.59\t\t261578.12\n",
      "Epside Return: [1303.9]\n",
      "\n",
      "[5] Process\n",
      "40000/200000 episodes. (20.00%)\n",
      "Total loss:\t 389656.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8082.50\t\t8460.83\t\t398109.28\n",
      "Epside Return: [1302.3]\n",
      "\n",
      "[4] Process\n",
      "40500/200000 episodes. (20.25%)\n",
      "Total loss:\t 311876.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.79\t\t-65275.60\t\t246593.19\n",
      "Epside Return: [1348.1]\n",
      "\n",
      "[2] Process\n",
      "41000/200000 episodes. (20.50%)\n",
      "Total loss:\t 227160.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.91\t\t-41414.59\t\t185737.41\n",
      "Epside Return: [1345.1]\n",
      "\n",
      "[7] Process\n",
      "41500/200000 episodes. (20.75%)\n",
      "Total loss:\t 266261.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8093.56\t\t16591.38\t\t282844.94\n",
      "Epside Return: [1291.4]\n",
      "\n",
      "[5] Process\n",
      "42000/200000 episodes. (21.00%)\n",
      "Total loss:\t 539444.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8080.36\t\t2783.63\t\t542220.12\n",
      "Epside Return: [1292.9]\n",
      "\n",
      "[7] Process\n",
      "42500/200000 episodes. (21.25%)\n",
      "Total loss:\t 541163.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8100.81\t\t49447.38\t\t590603.19\n",
      "Epside Return: [1315.0]\n",
      "\n",
      "[6] Process\n",
      "43000/200000 episodes. (21.50%)\n",
      "Total loss:\t 1270569.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-7081.88\t\t92011.39\t\t1362573.50\n",
      "Epside Return: [1299.8]\n",
      "\n",
      "[4] Process\n",
      "43500/200000 episodes. (21.75%)\n",
      "Total loss:\t 213483.61\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.06\t\t-36973.59\t\t176501.94\n",
      "Epside Return: [1293.6]\n",
      "\n",
      "[3] Process\n",
      "44000/200000 episodes. (22.00%)\n",
      "Total loss:\t 157177.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.82\t\t-35344.96\t\t121824.02\n",
      "Epside Return: [1305.6]\n",
      "\n",
      "[5] Process\n",
      "44500/200000 episodes. (22.25%)\n",
      "Total loss:\t 218314.58\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.89\t\t-46431.23\t\t171875.28\n",
      "Epside Return: [1288.0]\n",
      "\n",
      "[4] Process\n",
      "45000/200000 episodes. (22.50%)\n",
      "Total loss:\t 709916.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.13\t\t64581.59\t\t774490.38\n",
      "Epside Return: [1317.7]\n",
      "\n",
      "[6] Process\n",
      "45500/200000 episodes. (22.75%)\n",
      "Total loss:\t 1301186.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6069.81\t\t84528.23\t\t1385708.88\n",
      "Epside Return: [1228.3]\n",
      "\n",
      "[4] Process\n",
      "46000/200000 episodes. (23.00%)\n",
      "Total loss:\t 243500.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.63\t\t-1348.15\t\t242144.69\n",
      "Epside Return: [1327.6]\n",
      "\n",
      "[7] Process\n",
      "46500/200000 episodes. (23.25%)\n",
      "Total loss:\t 875055.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-3708.25\t\t132927.88\t\t1007979.25\n",
      "Epside Return: [1283.7]\n",
      "\n",
      "[0] Process\n",
      "47000/200000 episodes. (23.50%)\n",
      "Total loss:\t 332252.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.29\t\t5873.04\t\t338117.50\n",
      "Epside Return: [1300.5]\n",
      "\n",
      "[7] Process\n",
      "47500/200000 episodes. (23.75%)\n",
      "Total loss:\t 159896.3\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.96\t\t-19189.99\t\t140698.23\n",
      "Epside Return: [1334.5]\n",
      "\n",
      "[5] Process\n",
      "48000/200000 episodes. (24.00%)\n",
      "Total loss:\t 232747.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.36\t\t-54838.82\t\t177900.53\n",
      "Epside Return: [1363.8]\n",
      "\n",
      "[6] Process\n",
      "48500/200000 episodes. (24.25%)\n",
      "Total loss:\t 269066.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8058.51\t\t-63151.39\t\t205906.80\n",
      "Epside Return: [1346.3]\n",
      "\n",
      "[0] Process\n",
      "49000/200000 episodes. (24.50%)\n",
      "Total loss:\t 1314895.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6867.31\t\t109256.14\t\t1424144.25\n",
      "Epside Return: [1328.1]\n",
      "\n",
      "[4] Process\n",
      "49500/200000 episodes. (24.75%)\n",
      "Total loss:\t 286969.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.80\t\t-77950.72\t\t209010.98\n",
      "Epside Return: [1337.2]\n",
      "\n",
      "[4] Process\n",
      "50000/200000 episodes. (25.00%)\n",
      "Total loss:\t 279999.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.53\t\t-52979.72\t\t227011.55\n",
      "Epside Return: [1287.2]\n",
      "\n",
      "[7] Process\n",
      "50500/200000 episodes. (25.25%)\n",
      "Total loss:\t 258112.77\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.01\t\t-31125.84\t\t226978.86\n",
      "Epside Return: [1322.7]\n",
      "\n",
      "[7] Process\n",
      "51000/200000 episodes. (25.50%)\n",
      "Total loss:\t 465537.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8084.05\t\t4161.76\t\t469691.22\n",
      "Epside Return: [1349.1]\n",
      "\n",
      "[2] Process\n",
      "51500/200000 episodes. (25.75%)\n",
      "Total loss:\t 400598.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.26\t\t-29019.51\t\t371571.16\n",
      "Epside Return: [1358.4]\n",
      "\n",
      "[1] Process\n",
      "52000/200000 episodes. (26.00%)\n",
      "Total loss:\t 284633.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8050.47\t\t-70939.06\t\t213686.52\n",
      "Epside Return: [1315.2]\n",
      "\n",
      "[1] Process\n",
      "52500/200000 episodes. (26.25%)\n",
      "Total loss:\t 136600.77\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.37\t\t-4762.92\t\t131829.78\n",
      "Epside Return: [1289.9]\n",
      "\n",
      "[6] Process\n",
      "53000/200000 episodes. (26.50%)\n",
      "Total loss:\t 269836.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.95\t\t-60833.34\t\t208994.97\n",
      "Epside Return: [1353.1]\n",
      "\n",
      "[3] Process\n",
      "53500/200000 episodes. (26.75%)\n",
      "Total loss:\t 153625.39\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.06\t\t-4199.06\t\t149418.25\n",
      "Epside Return: [1252.9]\n",
      "\n",
      "[6] Process\n",
      "54000/200000 episodes. (27.00%)\n",
      "Total loss:\t 172286.81\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.45\t\t-29025.84\t\t143252.91\n",
      "Epside Return: [1249.8]\n",
      "\n",
      "[5] Process\n",
      "54500/200000 episodes. (27.25%)\n",
      "Total loss:\t 283036.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.49\t\t-8979.52\t\t274049.09\n",
      "Epside Return: [1315.6]\n",
      "\n",
      "[2] Process\n",
      "55000/200000 episodes. (27.50%)\n",
      "Total loss:\t 482731.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.08\t\t3424.91\t\t486148.28\n",
      "Epside Return: [1281.9]\n",
      "\n",
      "[6] Process\n",
      "55500/200000 episodes. (27.75%)\n",
      "Total loss:\t 378358.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.41\t\t26817.68\t\t405168.44\n",
      "Epside Return: [1286.5]\n",
      "\n",
      "[4] Process\n",
      "56000/200000 episodes. (28.00%)\n",
      "Total loss:\t 155274.23\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.37\t\t-13321.36\t\t141944.81\n",
      "Epside Return: [1295.3]\n",
      "\n",
      "[3] Process\n",
      "56500/200000 episodes. (28.25%)\n",
      "Total loss:\t 239101.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.05\t\t18451.71\t\t257545.38\n",
      "Epside Return: [1318.6]\n",
      "\n",
      "[5] Process\n",
      "57000/200000 episodes. (28.50%)\n",
      "Total loss:\t 1610083.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy\t\tPolicy\t\tValue\n",
      "-5795.33\t\t181111.86\t\t1791189.88\n",
      "Epside Return: [1255.2]\n",
      "\n",
      "[7] Process\n",
      "57500/200000 episodes. (28.75%)\n",
      "Total loss:\t 156067.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.02\t\t2218.15\t\t158277.12\n",
      "Epside Return: [1272.8]\n",
      "\n",
      "[1] Process\n",
      "58000/200000 episodes. (29.00%)\n",
      "Total loss:\t 694475.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8083.09\t\t78239.41\t\t772707.31\n",
      "Epside Return: [1218.4]\n",
      "\n",
      "[6] Process\n",
      "58500/200000 episodes. (29.25%)\n",
      "Total loss:\t 559278.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.35\t\t45759.63\t\t605030.06\n",
      "Epside Return: [1323.6]\n",
      "\n",
      "[1] Process\n",
      "59000/200000 episodes. (29.50%)\n",
      "Total loss:\t 227578.83\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8072.42\t\t-34734.12\t\t192836.62\n",
      "Epside Return: [1305.2]\n",
      "\n",
      "[7] Process\n",
      "59500/200000 episodes. (29.75%)\n",
      "Total loss:\t 176547.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.38\t\t18357.09\t\t194896.62\n",
      "Epside Return: [1276.0]\n",
      "\n",
      "[2] Process\n",
      "60000/200000 episodes. (30.00%)\n",
      "Total loss:\t 1062771.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-2283.42\t\t122272.83\t\t1185042.38\n",
      "Epside Return: [1290.0]\n",
      "\n",
      "[6] Process\n",
      "60500/200000 episodes. (30.25%)\n",
      "Total loss:\t 286861.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.74\t\t22149.52\t\t309003.16\n",
      "Epside Return: [1334.6]\n",
      "\n",
      "[1] Process\n",
      "61000/200000 episodes. (30.50%)\n",
      "Total loss:\t 1166597.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-1487.99\t\t113723.09\t\t1280318.88\n",
      "Epside Return: [1320.8]\n",
      "\n",
      "[5] Process\n",
      "61500/200000 episodes. (30.75%)\n",
      "Total loss:\t 385472.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8081.20\t\t-21449.26\t\t364015.06\n",
      "Epside Return: [1312.4]\n",
      "\n",
      "[3] Process\n",
      "62000/200000 episodes. (31.00%)\n",
      "Total loss:\t 437319.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8052.26\t\t-102699.33\t\t334612.06\n",
      "Epside Return: [1338.7]\n",
      "\n",
      "[0] Process\n",
      "62500/200000 episodes. (31.25%)\n",
      "Total loss:\t 412184.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.80\t\t-30038.09\t\t382137.94\n",
      "Epside Return: [1294.8]\n",
      "\n",
      "[2] Process\n",
      "63000/200000 episodes. (31.50%)\n",
      "Total loss:\t 1042637.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-1669.85\t\t102171.03\t\t1144807.25\n",
      "Epside Return: [1221.0]\n",
      "\n",
      "[1] Process\n",
      "63500/200000 episodes. (31.75%)\n",
      "Total loss:\t 406091.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8093.57\t\t67239.91\t\t473323.38\n",
      "Epside Return: [1323.8]\n",
      "\n",
      "[1] Process\n",
      "64000/200000 episodes. (32.00%)\n",
      "Total loss:\t 421039.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.27\t\t5191.30\t\t426222.62\n",
      "Epside Return: [1326.2]\n",
      "\n",
      "[6] Process\n",
      "64500/200000 episodes. (32.25%)\n",
      "Total loss:\t 77376.375\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-116.08\t\t8656.05\t\t86032.31\n",
      "Epside Return: [1253.0]\n",
      "\n",
      "[2] Process\n",
      "65000/200000 episodes. (32.50%)\n",
      "Total loss:\t 1415754.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6167.86\t\t115526.07\t\t1531274.38\n",
      "Epside Return: [1274.9]\n",
      "\n",
      "[5] Process\n",
      "65500/200000 episodes. (32.75%)\n",
      "Total loss:\t 187209.73\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.08\t\t4077.28\t\t191278.95\n",
      "Epside Return: [1304.2]\n",
      "\n",
      "[0] Process\n",
      "66000/200000 episodes. (33.00%)\n",
      "Total loss:\t 170453.31\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.82\t\t-23487.54\t\t146957.70\n",
      "Epside Return: [1248.8]\n",
      "\n",
      "[7] Process\n",
      "66500/200000 episodes. (33.25%)\n",
      "Total loss:\t 258231.55\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8064.71\t\t-1670.82\t\t256552.66\n",
      "Epside Return: [1349.0]\n",
      "\n",
      "[1] Process\n",
      "67000/200000 episodes. (33.50%)\n",
      "Total loss:\t 407283.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8086.05\t\t-27570.11\t\t379704.84\n",
      "Epside Return: [1319.4]\n",
      "\n",
      "[0] Process\n",
      "67500/200000 episodes. (33.75%)\n",
      "Total loss:\t 153546.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.28\t\t-15137.68\t\t138400.75\n",
      "Epside Return: [1323.6]\n",
      "\n",
      "[1] Process\n",
      "68000/200000 episodes. (34.00%)\n",
      "Total loss:\t 367868.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.12\t\t-24181.49\t\t343679.28\n",
      "Epside Return: [1305.6]\n",
      "\n",
      "[0] Process\n",
      "68500/200000 episodes. (34.25%)\n",
      "Total loss:\t 808562.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8058.04\t\t35334.12\t\t843888.62\n",
      "Epside Return: [1327.1]\n",
      "\n",
      "[2] Process\n",
      "69000/200000 episodes. (34.50%)\n",
      "Total loss:\t 296021.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.96\t\t17070.20\t\t313083.59\n",
      "Epside Return: [1251.2]\n",
      "\n",
      "[7] Process\n",
      "69500/200000 episodes. (34.75%)\n",
      "Total loss:\t 356033.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8047.92\t\t-88461.40\t\t267564.00\n",
      "Epside Return: [1291.0]\n",
      "\n",
      "[4] Process\n",
      "70000/200000 episodes. (35.00%)\n",
      "Total loss:\t 333754.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8083.27\t\t67889.23\t\t401635.16\n",
      "Epside Return: [1304.9]\n",
      "\n",
      "[5] Process\n",
      "70500/200000 episodes. (35.25%)\n",
      "Total loss:\t 201348.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.87\t\t-44439.68\t\t156900.69\n",
      "Epside Return: [1363.5]\n",
      "\n",
      "[3] Process\n",
      "71000/200000 episodes. (35.50%)\n",
      "Total loss:\t 310836.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.08\t\t15715.75\t\t326543.97\n",
      "Epside Return: [1304.4]\n",
      "\n",
      "[4] Process\n",
      "71500/200000 episodes. (35.75%)\n",
      "Total loss:\t 181116.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.08\t\t-18163.42\t\t162944.86\n",
      "Epside Return: [1325.9]\n",
      "\n",
      "[0] Process\n",
      "72000/200000 episodes. (36.00%)\n",
      "Total loss:\t 358464.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8079.66\t\t44642.23\t\t403098.31\n",
      "Epside Return: [1286.9]\n",
      "\n",
      "[1] Process\n",
      "72500/200000 episodes. (36.25%)\n",
      "Total loss:\t 195968.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.71\t\t-7842.35\t\t188117.72\n",
      "Epside Return: [1270.5]\n",
      "\n",
      "[6] Process\n",
      "73000/200000 episodes. (36.50%)\n",
      "Total loss:\t 686293.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8098.24\t\t102819.95\t\t789105.44\n",
      "Epside Return: [1240.3]\n",
      "\n",
      "[3] Process\n",
      "73500/200000 episodes. (36.75%)\n",
      "Total loss:\t 2051146.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8104.92\t\t233320.12\t\t2284458.75\n",
      "Epside Return: [1326.6]\n",
      "\n",
      "[0] Process\n",
      "74000/200000 episodes. (37.00%)\n",
      "Total loss:\t 229034.39\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.14\t\t-36518.09\t\t192508.23\n",
      "Epside Return: [1373.9]\n",
      "\n",
      "[7] Process\n",
      "74500/200000 episodes. (37.25%)\n",
      "Total loss:\t 291625.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8053.08\t\t-80271.20\t\t211346.19\n",
      "Epside Return: [1307.4]\n",
      "\n",
      "[0] Process\n",
      "75000/200000 episodes. (37.50%)\n",
      "Total loss:\t 348588.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.83\t\t-42443.98\t\t306136.00\n",
      "Epside Return: [1348.9]\n",
      "\n",
      "[4] Process\n",
      "75500/200000 episodes. (37.75%)\n",
      "Total loss:\t 344608.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8072.40\t\t29645.42\t\t374245.84\n",
      "Epside Return: [1291.7]\n",
      "\n",
      "[5] Process\n",
      "76000/200000 episodes. (38.00%)\n",
      "Total loss:\t 474450.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.33\t\t50054.69\t\t524497.00\n",
      "Epside Return: [1327.4]\n",
      "\n",
      "[4] Process\n",
      "76500/200000 episodes. (38.25%)\n",
      "Total loss:\t 195368.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.94\t\t2471.71\t\t197832.12\n",
      "Epside Return: [1347.9]\n",
      "\n",
      "[1] Process\n",
      "77000/200000 episodes. (38.50%)\n",
      "Total loss:\t 349296.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.67\t\t-69130.46\t\t280158.09\n",
      "Epside Return: [1307.6]\n",
      "\n",
      "[6] Process\n",
      "77500/200000 episodes. (38.75%)\n",
      "Total loss:\t 251296.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.24\t\t63773.05\t\t315061.72\n",
      "Epside Return: [1313.7]\n",
      "\n",
      "[4] Process\n",
      "78000/200000 episodes. (39.00%)\n",
      "Total loss:\t 325056.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.45\t\t-49927.31\t\t275121.56\n",
      "Epside Return: [1222.9]\n",
      "\n",
      "[7] Process\n",
      "78500/200000 episodes. (39.25%)\n",
      "Total loss:\t 371233.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.09\t\t14626.18\t\t385851.69\n",
      "Epside Return: [1279.3]\n",
      "\n",
      "[0] Process\n",
      "79000/200000 episodes. (39.50%)\n",
      "Total loss:\t 503777.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8047.48\t\t-104536.51\t\t399232.44\n",
      "Epside Return: [1286.6]\n",
      "\n",
      "[6] Process\n",
      "79500/200000 episodes. (39.75%)\n",
      "Total loss:\t 217033.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.39\t\t-48202.65\t\t168822.75\n",
      "Epside Return: [1308.1]\n",
      "\n",
      "[1] Process\n",
      "80000/200000 episodes. (40.00%)\n",
      "Total loss:\t 186386.05\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.33\t\t-29212.61\t\t157165.38\n",
      "Epside Return: [1341.2]\n",
      "\n",
      "[0] Process\n",
      "80500/200000 episodes. (40.25%)\n",
      "Total loss:\t 505702.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8083.92\t\t52476.39\t\t558170.88\n",
      "Epside Return: [1313.2]\n",
      "\n",
      "[2] Process\n",
      "81000/200000 episodes. (40.50%)\n",
      "Total loss:\t 336219.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8064.09\t\t-79347.73\t\t256863.69\n",
      "Epside Return: [1308.4]\n",
      "\n",
      "[0] Process\n",
      "81500/200000 episodes. (40.75%)\n",
      "Total loss:\t 297014.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.02\t\t-85244.66\t\t211761.66\n",
      "Epside Return: [1312.6]\n",
      "\n",
      "[4] Process\n",
      "82000/200000 episodes. (41.00%)\n",
      "Total loss:\t 378950.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8070.05\t\t-23890.73\t\t355051.97\n",
      "Epside Return: [1285.9]\n",
      "\n",
      "[7] Process\n",
      "82500/200000 episodes. (41.25%)\n",
      "Total loss:\t 261925.98\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8056.45\t\t-68859.36\t\t193058.56\n",
      "Epside Return: [1272.9]\n",
      "\n",
      "[0] Process\n",
      "83000/200000 episodes. (41.50%)\n",
      "Total loss:\t 191308.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.47\t\t-40434.57\t\t150865.61\n",
      "Epside Return: [1291.0]\n",
      "\n",
      "[5] Process\n",
      "83500/200000 episodes. (41.75%)\n",
      "Total loss:\t 196529.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8056.67\t\t-40565.26\t\t155955.77\n",
      "Epside Return: [1282.0]\n",
      "\n",
      "[0] Process\n",
      "84000/200000 episodes. (42.00%)\n",
      "Total loss:\t 119663.74\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.85\t\t2425.16\t\t122080.83\n",
      "Epside Return: [1345.9]\n",
      "\n",
      "[1] Process\n",
      "84500/200000 episodes. (42.25%)\n",
      "Total loss:\t 667224.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.32\t\t59622.46\t\t726839.31\n",
      "Epside Return: [1310.8]\n",
      "\n",
      "[7] Process\n",
      "85000/200000 episodes. (42.50%)\n",
      "Total loss:\t 267505.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.47\t\t-31050.98\t\t236446.45\n",
      "Epside Return: [1343.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[6] Process\n",
      "85500/200000 episodes. (42.75%)\n",
      "Total loss:\t 337943.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8070.85\t\t-3981.69\t\t333953.31\n",
      "Epside Return: [1296.6]\n",
      "\n",
      "[5] Process\n",
      "86000/200000 episodes. (43.00%)\n",
      "Total loss:\t 219795.33\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.29\t\t-38293.56\t\t181493.70\n",
      "Epside Return: [1264.1]\n",
      "\n",
      "[3] Process\n",
      "86500/200000 episodes. (43.25%)\n",
      "Total loss:\t 340498.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.70\t\t-11047.36\t\t329443.03\n",
      "Epside Return: [1293.9]\n",
      "\n",
      "[5] Process\n",
      "87000/200000 episodes. (43.50%)\n",
      "Total loss:\t 529364.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8094.54\t\t51638.19\t\t580994.56\n",
      "Epside Return: [1348.3]\n",
      "\n",
      "[6] Process\n",
      "87500/200000 episodes. (43.75%)\n",
      "Total loss:\t 238988.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8056.86\t\t-29419.83\t\t209561.08\n",
      "Epside Return: [1315.8]\n",
      "\n",
      "[0] Process\n",
      "88000/200000 episodes. (44.00%)\n",
      "Total loss:\t 341641.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.50\t\t50995.25\t\t392629.09\n",
      "Epside Return: [1319.9]\n",
      "\n",
      "[3] Process\n",
      "88500/200000 episodes. (44.25%)\n",
      "Total loss:\t 256045.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8056.20\t\t-60140.82\t\t195896.53\n",
      "Epside Return: [1363.2]\n",
      "\n",
      "[6] Process\n",
      "89000/200000 episodes. (44.50%)\n",
      "Total loss:\t 332420.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.66\t\t-53002.76\t\t279409.19\n",
      "Epside Return: [1307.0]\n",
      "\n",
      "[7] Process\n",
      "89500/200000 episodes. (44.75%)\n",
      "Total loss:\t 185001.39\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8064.06\t\t-24541.45\t\t160451.88\n",
      "Epside Return: [1327.4]\n",
      "\n",
      "[5] Process\n",
      "90000/200000 episodes. (45.00%)\n",
      "Total loss:\t 256083.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.33\t\t-16967.47\t\t239107.92\n",
      "Epside Return: [1254.4]\n",
      "\n",
      "[5] Process\n",
      "90500/200000 episodes. (45.25%)\n",
      "Total loss:\t 182391.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.81\t\t-4034.20\t\t178349.19\n",
      "Epside Return: [1357.6]\n",
      "\n",
      "[3] Process\n",
      "91000/200000 episodes. (45.50%)\n",
      "Total loss:\t 221347.61\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.00\t\t-41362.61\t\t179976.94\n",
      "Epside Return: [1290.9]\n",
      "\n",
      "[7] Process\n",
      "91500/200000 episodes. (45.75%)\n",
      "Total loss:\t 153883.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.75\t\t-20750.13\t\t133125.67\n",
      "Epside Return: [1275.2]\n",
      "\n",
      "[1] Process\n",
      "92000/200000 episodes. (46.00%)\n",
      "Total loss:\t 289373.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.98\t\t-2799.92\t\t286565.78\n",
      "Epside Return: [1345.6]\n",
      "\n",
      "[3] Process\n",
      "92500/200000 episodes. (46.25%)\n",
      "Total loss:\t 280756.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.11\t\t-39808.88\t\t240939.42\n",
      "Epside Return: [1264.1]\n",
      "\n",
      "[7] Process\n",
      "93000/200000 episodes. (46.50%)\n",
      "Total loss:\t 250013.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.86\t\t-59206.80\t\t190798.86\n",
      "Epside Return: [1238.4]\n",
      "\n",
      "[6] Process\n",
      "93500/200000 episodes. (46.75%)\n",
      "Total loss:\t 388359.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8050.24\t\t-98067.70\t\t290283.41\n",
      "Epside Return: [1339.2]\n",
      "\n",
      "[2] Process\n",
      "94000/200000 episodes. (47.00%)\n",
      "Total loss:\t 253274.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.83\t\t-65885.64\t\t187380.80\n",
      "Epside Return: [1358.0]\n",
      "\n",
      "[0] Process\n",
      "94500/200000 episodes. (47.25%)\n",
      "Total loss:\t 214065.52\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.79\t\t-53046.31\t\t161011.14\n",
      "Epside Return: [1327.2]\n",
      "\n",
      "[0] Process\n",
      "95000/200000 episodes. (47.50%)\n",
      "Total loss:\t 443241.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8084.84\t\t400.79\t\t443634.62\n",
      "Epside Return: [1306.4]\n",
      "\n",
      "[1] Process\n",
      "95500/200000 episodes. (47.75%)\n",
      "Total loss:\t 264144.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.10\t\t-59468.05\t\t204667.88\n",
      "Epside Return: [1241.7]\n",
      "\n",
      "[3] Process\n",
      "96000/200000 episodes. (48.00%)\n",
      "Total loss:\t 205886.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.91\t\t17872.60\t\t223750.86\n",
      "Epside Return: [1256.7]\n",
      "\n",
      "[5] Process\n",
      "96500/200000 episodes. (48.25%)\n",
      "Total loss:\t 1147875.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-4203.32\t\t68416.67\t\t1216287.50\n",
      "Epside Return: [1327.5]\n",
      "\n",
      "[2] Process\n",
      "97000/200000 episodes. (48.50%)\n",
      "Total loss:\t 678151.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.50\t\t5042.35\t\t683185.38\n",
      "Epside Return: [1245.8]\n",
      "\n",
      "[4] Process\n",
      "97500/200000 episodes. (48.75%)\n",
      "Total loss:\t 190795.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8050.76\t\t-46245.08\t\t144542.16\n",
      "Epside Return: [1311.2]\n",
      "\n",
      "[1] Process\n",
      "98000/200000 episodes. (49.00%)\n",
      "Total loss:\t 366247.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.36\t\t23228.72\t\t389468.00\n",
      "Epside Return: [1262.3]\n",
      "\n",
      "[5] Process\n",
      "98500/200000 episodes. (49.25%)\n",
      "Total loss:\t 566410.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.98\t\t68826.96\t\t635229.69\n",
      "Epside Return: [1297.0]\n",
      "\n",
      "[1] Process\n",
      "99000/200000 episodes. (49.50%)\n",
      "Total loss:\t 431573.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8051.03\t\t-90388.85\t\t341176.44\n",
      "Epside Return: [1359.4]\n",
      "\n",
      "[6] Process\n",
      "99500/200000 episodes. (49.75%)\n",
      "Total loss:\t 575437.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8080.94\t\t40342.01\t\t615771.00\n",
      "Epside Return: [1331.8]\n",
      "\n",
      "[3] Process\n",
      "100000/200000 episodes. (50.00%)\n",
      "Total loss:\t 884777.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-5367.28\t\t115182.97\t\t999954.62\n",
      "Epside Return: [1293.0]\n",
      "\n",
      "[4] Process\n",
      "100500/200000 episodes. (50.25%)\n",
      "Total loss:\t 231072.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8058.22\t\t-34339.05\t\t196725.59\n",
      "Epside Return: [1308.0]\n",
      "\n",
      "[5] Process\n",
      "101000/200000 episodes. (50.50%)\n",
      "Total loss:\t 289771.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.14\t\t-56130.24\t\t233632.83\n",
      "Epside Return: [1247.7]\n",
      "\n",
      "[2] Process\n",
      "101500/200000 episodes. (50.75%)\n",
      "Total loss:\t 441818.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.54\t\t65857.23\t\t507667.28\n",
      "Epside Return: [1322.1]\n",
      "\n",
      "[4] Process\n",
      "102000/200000 episodes. (51.00%)\n",
      "Total loss:\t 339082.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.19\t\t-66916.27\t\t272157.72\n",
      "Epside Return: [1354.6]\n",
      "\n",
      "[4] Process\n",
      "102500/200000 episodes. (51.25%)\n",
      "Total loss:\t 380161.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.85\t\t-13851.02\t\t366302.56\n",
      "Epside Return: [1336.0]\n",
      "\n",
      "[1] Process\n",
      "103000/200000 episodes. (51.50%)\n",
      "Total loss:\t 279170.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.64\t\t2249.51\t\t281411.91\n",
      "Epside Return: [1310.3]\n",
      "\n",
      "[4] Process\n",
      "103500/200000 episodes. (51.75%)\n",
      "Total loss:\t 212762.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.30\t\t-5380.44\t\t207373.52\n",
      "Epside Return: [1341.3]\n",
      "\n",
      "[4] Process\n",
      "104000/200000 episodes. (52.00%)\n",
      "Total loss:\t 186850.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.82\t\t-33189.38\t\t153653.09\n",
      "Epside Return: [1323.9]\n",
      "\n",
      "[0] Process\n",
      "104500/200000 episodes. (52.25%)\n",
      "Total loss:\t 520112.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.19\t\t90732.66\t\t610837.31\n",
      "Epside Return: [1317.1]\n",
      "\n",
      "[2] Process\n",
      "105000/200000 episodes. (52.50%)\n",
      "Total loss:\t 208778.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.59\t\t-47791.50\t\t160978.64\n",
      "Epside Return: [1302.7]\n",
      "\n",
      "[4] Process\n",
      "105500/200000 episodes. (52.75%)\n",
      "Total loss:\t 248021.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8085.63\t\t33794.52\t\t281807.53\n",
      "Epside Return: [1314.9]\n",
      "\n",
      "[5] Process\n",
      "106000/200000 episodes. (53.00%)\n",
      "Total loss:\t 270503.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.92\t\t-65806.73\t\t204688.36\n",
      "Epside Return: [1307.3]\n",
      "\n",
      "[4] Process\n",
      "106500/200000 episodes. (53.25%)\n",
      "Total loss:\t 887024.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.86\t\t54362.29\t\t941379.06\n",
      "Epside Return: [1311.7]\n",
      "\n",
      "[2] Process\n",
      "107000/200000 episodes. (53.50%)\n",
      "Total loss:\t 362724.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8055.55\t\t-15777.67\t\t346938.47\n",
      "Epside Return: [1309.4]\n",
      "\n",
      "[1] Process\n",
      "107500/200000 episodes. (53.75%)\n",
      "Total loss:\t 160159.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.83\t\t-21050.73\t\t139100.64\n",
      "Epside Return: [1371.9]\n",
      "\n",
      "[1] Process\n",
      "108000/200000 episodes. (54.00%)\n",
      "Total loss:\t 189387.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.39\t\t-40270.19\t\t149108.97\n",
      "Epside Return: [1333.3]\n",
      "\n",
      "[4] Process\n",
      "108500/200000 episodes. (54.25%)\n",
      "Total loss:\t 445330.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8083.26\t\t2899.67\t\t448221.88\n",
      "Epside Return: [1298.7]\n",
      "\n",
      "[3] Process\n",
      "109000/200000 episodes. (54.50%)\n",
      "Total loss:\t 503894.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8053.00\t\t-64668.48\t\t439218.16\n",
      "Epside Return: [1276.8]\n",
      "\n",
      "[4] Process\n",
      "109500/200000 episodes. (54.75%)\n",
      "Total loss:\t 409420.3\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.62\t\t40648.57\t\t450060.81\n",
      "Epside Return: [1293.9]\n",
      "\n",
      "[7] Process\n",
      "110000/200000 episodes. (55.00%)\n",
      "Total loss:\t 286852.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8053.65\t\t-64405.34\t\t222438.61\n",
      "Epside Return: [1341.6]\n",
      "\n",
      "[6] Process\n",
      "110500/200000 episodes. (55.25%)\n",
      "Total loss:\t 243255.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.05\t\t-23823.14\t\t219424.30\n",
      "Epside Return: [1322.9]\n",
      "\n",
      "[1] Process\n",
      "111000/200000 episodes. (55.50%)\n",
      "Total loss:\t 303407.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.26\t\t-38732.12\t\t264667.41\n",
      "Epside Return: [1297.4]\n",
      "\n",
      "[1] Process\n",
      "111500/200000 episodes. (55.75%)\n",
      "Total loss:\t 249549.02\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8081.18\t\t13172.44\t\t262713.38\n",
      "Epside Return: [1336.4]\n",
      "\n",
      "[1] Process\n",
      "112000/200000 episodes. (56.00%)\n",
      "Total loss:\t 695571.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8095.20\t\t102702.16\t\t798265.12\n",
      "Epside Return: [1336.6]\n",
      "\n",
      "[0] Process\n",
      "112500/200000 episodes. (56.25%)\n",
      "Total loss:\t 475675.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.41\t\t3257.28\t\t478924.94\n",
      "Epside Return: [1354.9]\n",
      "\n",
      "[1] Process\n",
      "113000/200000 episodes. (56.50%)\n",
      "Total loss:\t 368271.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.53\t\t14955.46\t\t383219.12\n",
      "Epside Return: [1305.4]\n",
      "\n",
      "[1] Process\n",
      "113500/200000 episodes. (56.75%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss:\t 247411.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8079.62\t\t-3757.47\t\t243645.67\n",
      "Epside Return: [1353.9]\n",
      "\n",
      "[2] Process\n",
      "114000/200000 episodes. (57.00%)\n",
      "Total loss:\t 852056.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-805.37\t\t71918.89\t\t923974.44\n",
      "Epside Return: [1275.1]\n",
      "\n",
      "[2] Process\n",
      "114500/200000 episodes. (57.25%)\n",
      "Total loss:\t 163987.23\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.66\t\t-30453.51\t\t133525.66\n",
      "Epside Return: [1297.0]\n",
      "\n",
      "[3] Process\n",
      "115000/200000 episodes. (57.50%)\n",
      "Total loss:\t 706294.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-737.82\t\t60840.10\t\t767133.81\n",
      "Epside Return: [1320.1]\n",
      "\n",
      "[6] Process\n",
      "115500/200000 episodes. (57.75%)\n",
      "Total loss:\t 308937.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.72\t\t-70313.13\t\t238616.30\n",
      "Epside Return: [1306.5]\n",
      "\n",
      "[6] Process\n",
      "116000/200000 episodes. (58.00%)\n",
      "Total loss:\t 342335.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8090.91\t\t-4570.34\t\t337757.22\n",
      "Epside Return: [1284.0]\n",
      "\n",
      "[2] Process\n",
      "116500/200000 episodes. (58.25%)\n",
      "Total loss:\t 183508.83\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.28\t\t-25978.71\t\t157522.06\n",
      "Epside Return: [1315.8]\n",
      "\n",
      "[6] Process\n",
      "117000/200000 episodes. (58.50%)\n",
      "Total loss:\t 424836.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.33\t\t-43787.46\t\t381041.44\n",
      "Epside Return: [1245.9]\n",
      "\n",
      "[1] Process\n",
      "117500/200000 episodes. (58.75%)\n",
      "Total loss:\t 291496.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.73\t\t-27089.86\t\t264398.06\n",
      "Epside Return: [1322.7]\n",
      "\n",
      "[7] Process\n",
      "118000/200000 episodes. (59.00%)\n",
      "Total loss:\t 827325.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-5698.16\t\t103834.52\t\t931153.94\n",
      "Epside Return: [1232.1]\n",
      "\n",
      "[3] Process\n",
      "118500/200000 episodes. (59.25%)\n",
      "Total loss:\t 257184.39\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8055.93\t\t-54136.00\t\t203040.33\n",
      "Epside Return: [1359.4]\n",
      "\n",
      "[7] Process\n",
      "119000/200000 episodes. (59.50%)\n",
      "Total loss:\t 280371.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8064.96\t\t31911.16\t\t312274.66\n",
      "Epside Return: [1328.6]\n",
      "\n",
      "[3] Process\n",
      "119500/200000 episodes. (59.75%)\n",
      "Total loss:\t 212830.36\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.18\t\t-54999.52\t\t157822.78\n",
      "Epside Return: [1349.8]\n",
      "\n",
      "[5] Process\n",
      "120000/200000 episodes. (60.00%)\n",
      "Total loss:\t 133564.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.02\t\t-15291.37\t\t118265.20\n",
      "Epside Return: [1218.5]\n",
      "\n",
      "[6] Process\n",
      "120500/200000 episodes. (60.25%)\n",
      "Total loss:\t 256907.86\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.13\t\t-34175.70\t\t222724.08\n",
      "Epside Return: [1326.1]\n",
      "\n",
      "[6] Process\n",
      "121000/200000 episodes. (60.50%)\n",
      "Total loss:\t 1200680.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-1333.61\t\t104063.15\t\t1304742.62\n",
      "Epside Return: [1338.3]\n",
      "\n",
      "[6] Process\n",
      "121500/200000 episodes. (60.75%)\n",
      "Total loss:\t 175905.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.23\t\t-34579.29\t\t141317.73\n",
      "Epside Return: [1291.1]\n",
      "\n",
      "[7] Process\n",
      "122000/200000 episodes. (61.00%)\n",
      "Total loss:\t 766449.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8085.74\t\t60048.56\t\t826490.06\n",
      "Epside Return: [1291.4]\n",
      "\n",
      "[2] Process\n",
      "122500/200000 episodes. (61.25%)\n",
      "Total loss:\t 489454.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8053.85\t\t15565.09\t\t505011.78\n",
      "Epside Return: [1277.6]\n",
      "\n",
      "[7] Process\n",
      "123000/200000 episodes. (61.50%)\n",
      "Total loss:\t 534923.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8081.67\t\t45161.05\t\t580076.06\n",
      "Epside Return: [1274.9]\n",
      "\n",
      "[5] Process\n",
      "123500/200000 episodes. (61.75%)\n",
      "Total loss:\t 251857.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.89\t\t-3336.99\t\t248512.39\n",
      "Epside Return: [1301.4]\n",
      "\n",
      "[1] Process\n",
      "124000/200000 episodes. (62.00%)\n",
      "Total loss:\t 983959.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-5347.81\t\t48273.97\t\t1032228.12\n",
      "Epside Return: [1317.5]\n",
      "\n",
      "[5] Process\n",
      "124500/200000 episodes. (62.25%)\n",
      "Total loss:\t 165242.83\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.43\t\t11034.48\t\t176269.23\n",
      "Epside Return: [1307.9]\n",
      "\n",
      "[5] Process\n",
      "125000/200000 episodes. (62.50%)\n",
      "Total loss:\t 217706.83\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8077.15\t\t19474.29\t\t237173.05\n",
      "Epside Return: [1327.5]\n",
      "\n",
      "[0] Process\n",
      "125500/200000 episodes. (62.75%)\n",
      "Total loss:\t 223409.14\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8082.36\t\t31436.15\t\t254837.22\n",
      "Epside Return: [1243.7]\n",
      "\n",
      "[7] Process\n",
      "126000/200000 episodes. (63.00%)\n",
      "Total loss:\t 311657.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.87\t\t-61178.40\t\t250471.22\n",
      "Epside Return: [1295.6]\n",
      "\n",
      "[5] Process\n",
      "126500/200000 episodes. (63.25%)\n",
      "Total loss:\t 221525.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.52\t\t-32928.62\t\t188589.17\n",
      "Epside Return: [1243.6]\n",
      "\n",
      "[5] Process\n",
      "127000/200000 episodes. (63.50%)\n",
      "Total loss:\t 229660.73\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.57\t\t-16356.55\t\t213296.12\n",
      "Epside Return: [1357.2]\n",
      "\n",
      "[2] Process\n",
      "127500/200000 episodes. (63.75%)\n",
      "Total loss:\t 197433.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.11\t\t-8221.89\t\t189203.69\n",
      "Epside Return: [1304.6]\n",
      "\n",
      "[3] Process\n",
      "128000/200000 episodes. (64.00%)\n",
      "Total loss:\t 285003.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.59\t\t-50713.67\t\t234281.66\n",
      "Epside Return: [1297.6]\n",
      "\n",
      "[4] Process\n",
      "128500/200000 episodes. (64.25%)\n",
      "Total loss:\t 194475.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.00\t\t-14201.78\t\t180265.61\n",
      "Epside Return: [1326.6]\n",
      "\n",
      "[3] Process\n",
      "129000/200000 episodes. (64.50%)\n",
      "Total loss:\t 160176.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.18\t\t-14443.63\t\t145725.16\n",
      "Epside Return: [1311.0]\n",
      "\n",
      "[2] Process\n",
      "129500/200000 episodes. (64.75%)\n",
      "Total loss:\t 329403.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.53\t\t-9749.97\t\t319645.31\n",
      "Epside Return: [1293.1]\n",
      "\n",
      "[0] Process\n",
      "130000/200000 episodes. (65.00%)\n",
      "Total loss:\t 335603.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.84\t\t16417.30\t\t352012.91\n",
      "Epside Return: [1296.6]\n",
      "\n",
      "[6] Process\n",
      "130500/200000 episodes. (65.25%)\n",
      "Total loss:\t 313094.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.95\t\t-1020.70\t\t312066.00\n",
      "Epside Return: [1219.5]\n",
      "\n",
      "[7] Process\n",
      "131000/200000 episodes. (65.50%)\n",
      "Total loss:\t 1460841.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8099.51\t\t207465.38\t\t1668298.50\n",
      "Epside Return: [1303.8]\n",
      "\n",
      "[2] Process\n",
      "131500/200000 episodes. (65.75%)\n",
      "Total loss:\t 298684.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8083.18\t\t69703.27\t\t368379.41\n",
      "Epside Return: [1296.6]\n",
      "\n",
      "[2] Process\n",
      "132000/200000 episodes. (66.00%)\n",
      "Total loss:\t 530644.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8089.32\t\t48293.12\t\t578929.69\n",
      "Epside Return: [1361.7]\n",
      "\n",
      "[3] Process\n",
      "132500/200000 episodes. (66.25%)\n",
      "Total loss:\t 182629.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8064.43\t\t-29621.15\t\t152999.98\n",
      "Epside Return: [1273.2]\n",
      "\n",
      "[5] Process\n",
      "133000/200000 episodes. (66.50%)\n",
      "Total loss:\t 227666.86\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.62\t\t-40807.36\t\t186851.42\n",
      "Epside Return: [1313.6]\n",
      "\n",
      "[4] Process\n",
      "133500/200000 episodes. (66.75%)\n",
      "Total loss:\t 256322.31\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.28\t\t-32535.93\t\t223778.30\n",
      "Epside Return: [1359.4]\n",
      "\n",
      "[5] Process\n",
      "134000/200000 episodes. (67.00%)\n",
      "Total loss:\t 524931.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-497.60\t\t43792.90\t\t568724.06\n",
      "Epside Return: [1318.0]\n",
      "\n",
      "[1] Process\n",
      "134500/200000 episodes. (67.25%)\n",
      "Total loss:\t 211139.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8072.49\t\t-9728.19\t\t201403.53\n",
      "Epside Return: [1300.5]\n",
      "\n",
      "[6] Process\n",
      "135000/200000 episodes. (67.50%)\n",
      "Total loss:\t 491955.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.30\t\t82178.85\t\t574126.62\n",
      "Epside Return: [1343.6]\n",
      "\n",
      "[7] Process\n",
      "135500/200000 episodes. (67.75%)\n",
      "Total loss:\t 270578.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.86\t\t20203.50\t\t290773.53\n",
      "Epside Return: [1363.3]\n",
      "\n",
      "[6] Process\n",
      "136000/200000 episodes. (68.00%)\n",
      "Total loss:\t 211743.19\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.37\t\t-42634.75\t\t169100.38\n",
      "Epside Return: [1332.4]\n",
      "\n",
      "[2] Process\n",
      "136500/200000 episodes. (68.25%)\n",
      "Total loss:\t 343606.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8052.57\t\t-85513.24\t\t258085.58\n",
      "Epside Return: [1324.3]\n",
      "\n",
      "[3] Process\n",
      "137000/200000 episodes. (68.50%)\n",
      "Total loss:\t 680762.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8079.29\t\t33688.10\t\t714442.31\n",
      "Epside Return: [1299.0]\n",
      "\n",
      "[6] Process\n",
      "137500/200000 episodes. (68.75%)\n",
      "Total loss:\t 338849.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.93\t\t62945.16\t\t401786.94\n",
      "Epside Return: [1295.9]\n",
      "\n",
      "[2] Process\n",
      "138000/200000 episodes. (69.00%)\n",
      "Total loss:\t 318714.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.44\t\t-83645.24\t\t235060.95\n",
      "Epside Return: [1268.0]\n",
      "\n",
      "[4] Process\n",
      "138500/200000 episodes. (69.25%)\n",
      "Total loss:\t 276660.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.48\t\t-40698.83\t\t235953.75\n",
      "Epside Return: [1272.7]\n",
      "\n",
      "[3] Process\n",
      "139000/200000 episodes. (69.50%)\n",
      "Total loss:\t 1220898.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8094.20\t\t177829.81\t\t1398720.38\n",
      "Epside Return: [1293.2]\n",
      "\n",
      "[2] Process\n",
      "139500/200000 episodes. (69.75%)\n",
      "Total loss:\t 215742.86\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8056.06\t\t-38159.25\t\t177575.55\n",
      "Epside Return: [1325.2]\n",
      "\n",
      "[3] Process\n",
      "140000/200000 episodes. (70.00%)\n",
      "Total loss:\t 189936.02\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.01\t\t1754.27\t\t191682.22\n",
      "Epside Return: [1334.3]\n",
      "\n",
      "[6] Process\n",
      "140500/200000 episodes. (70.25%)\n",
      "Total loss:\t 235437.42\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.45\t\t-50886.46\t\t184542.91\n",
      "Epside Return: [1318.9]\n",
      "\n",
      "[3] Process\n",
      "141000/200000 episodes. (70.50%)\n",
      "Total loss:\t 340669.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.17\t\t-24901.55\t\t315759.94\n",
      "Epside Return: [1303.3]\n",
      "\n",
      "[7] Process\n",
      "141500/200000 episodes. (70.75%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss:\t 298218.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8056.79\t\t-63498.20\t\t234712.61\n",
      "Epside Return: [1285.1]\n",
      "\n",
      "[6] Process\n",
      "142000/200000 episodes. (71.00%)\n",
      "Total loss:\t 276969.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.38\t\t-21058.73\t\t255902.58\n",
      "Epside Return: [1337.9]\n",
      "\n",
      "[4] Process\n",
      "142500/200000 episodes. (71.25%)\n",
      "Total loss:\t 335321.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8051.55\t\t-46910.88\t\t288402.75\n",
      "Epside Return: [1324.4]\n",
      "\n",
      "[0] Process\n",
      "143000/200000 episodes. (71.50%)\n",
      "Total loss:\t 365733.3\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.37\t\t-19621.00\t\t346104.25\n",
      "Epside Return: [1269.5]\n",
      "\n",
      "[4] Process\n",
      "143500/200000 episodes. (71.75%)\n",
      "Total loss:\t 1174646.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6559.59\t\t84721.16\t\t1259361.25\n",
      "Epside Return: [1301.8]\n",
      "\n",
      "[5] Process\n",
      "144000/200000 episodes. (72.00%)\n",
      "Total loss:\t 263255.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.43\t\t-22657.00\t\t240590.06\n",
      "Epside Return: [1301.0]\n",
      "\n",
      "[4] Process\n",
      "144500/200000 episodes. (72.25%)\n",
      "Total loss:\t 287980.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.54\t\t-48583.32\t\t239389.30\n",
      "Epside Return: [1286.6]\n",
      "\n",
      "[0] Process\n",
      "145000/200000 episodes. (72.50%)\n",
      "Total loss:\t 387190.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.01\t\t7567.23\t\t394750.09\n",
      "Epside Return: [1314.4]\n",
      "\n",
      "[3] Process\n",
      "145500/200000 episodes. (72.75%)\n",
      "Total loss:\t 286612.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8054.92\t\t-14802.06\t\t271802.78\n",
      "Epside Return: [1322.1]\n",
      "\n",
      "[2] Process\n",
      "146000/200000 episodes. (73.00%)\n",
      "Total loss:\t 315117.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8054.79\t\t-59519.80\t\t255589.20\n",
      "Epside Return: [1319.8]\n",
      "\n",
      "[5] Process\n",
      "146500/200000 episodes. (73.25%)\n",
      "Total loss:\t 420506.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.22\t\t41142.57\t\t461640.66\n",
      "Epside Return: [1334.0]\n",
      "\n",
      "[5] Process\n",
      "147000/200000 episodes. (73.50%)\n",
      "Total loss:\t 123869.58\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.51\t\t-11116.51\t\t112745.01\n",
      "Epside Return: [1351.4]\n",
      "\n",
      "[1] Process\n",
      "147500/200000 episodes. (73.75%)\n",
      "Total loss:\t 394549.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.81\t\t-12452.53\t\t382089.16\n",
      "Epside Return: [1335.2]\n",
      "\n",
      "[4] Process\n",
      "148000/200000 episodes. (74.00%)\n",
      "Total loss:\t 245486.14\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8054.39\t\t-39155.05\t\t206323.05\n",
      "Epside Return: [1306.2]\n",
      "\n",
      "[4] Process\n",
      "148500/200000 episodes. (74.25%)\n",
      "Total loss:\t 255024.67\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.50\t\t-39363.13\t\t215653.47\n",
      "Epside Return: [1311.1]\n",
      "\n",
      "[3] Process\n",
      "149000/200000 episodes. (74.50%)\n",
      "Total loss:\t 221503.19\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.40\t\t11985.97\t\t233481.09\n",
      "Epside Return: [1317.1]\n",
      "\n",
      "[1] Process\n",
      "149500/200000 episodes. (74.75%)\n",
      "Total loss:\t 329921.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8052.74\t\t-63407.67\t\t266505.66\n",
      "Epside Return: [1281.9]\n",
      "\n",
      "[2] Process\n",
      "150000/200000 episodes. (75.00%)\n",
      "Total loss:\t 185373.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.87\t\t-6762.79\t\t178602.69\n",
      "Epside Return: [1314.8]\n",
      "\n",
      "[0] Process\n",
      "150500/200000 episodes. (75.25%)\n",
      "Total loss:\t 155838.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.95\t\t-19286.91\t\t136543.94\n",
      "Epside Return: [1321.2]\n",
      "\n",
      "[0] Process\n",
      "151000/200000 episodes. (75.50%)\n",
      "Total loss:\t 217677.14\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8065.04\t\t-61105.76\t\t156563.31\n",
      "Epside Return: [1302.9]\n",
      "\n",
      "[3] Process\n",
      "151500/200000 episodes. (75.75%)\n",
      "Total loss:\t 588893.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.13\t\t26445.04\t\t615330.38\n",
      "Epside Return: [1321.0]\n",
      "\n",
      "[1] Process\n",
      "152000/200000 episodes. (76.00%)\n",
      "Total loss:\t 484230.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.21\t\t90106.68\t\t574329.31\n",
      "Epside Return: [1329.5]\n",
      "\n",
      "[5] Process\n",
      "152500/200000 episodes. (76.25%)\n",
      "Total loss:\t 376049.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8055.57\t\t-59572.36\t\t316469.03\n",
      "Epside Return: [1303.5]\n",
      "\n",
      "[0] Process\n",
      "153000/200000 episodes. (76.50%)\n",
      "Total loss:\t 771723.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8106.21\t\t123652.61\t\t895367.94\n",
      "Epside Return: [1348.5]\n",
      "\n",
      "[2] Process\n",
      "153500/200000 episodes. (76.75%)\n",
      "Total loss:\t 227267.83\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8055.90\t\t-69109.06\t\t158150.70\n",
      "Epside Return: [1313.8]\n",
      "\n",
      "[7] Process\n",
      "154000/200000 episodes. (77.00%)\n",
      "Total loss:\t 337419.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8051.93\t\t-43194.38\t\t294217.50\n",
      "Epside Return: [1313.4]\n",
      "\n",
      "[0] Process\n",
      "154500/200000 episodes. (77.25%)\n",
      "Total loss:\t 278892.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.36\t\t-42748.71\t\t236135.22\n",
      "Epside Return: [1259.4]\n",
      "\n",
      "[1] Process\n",
      "155000/200000 episodes. (77.50%)\n",
      "Total loss:\t 1255653.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8095.41\t\t94219.97\t\t1349865.12\n",
      "Epside Return: [1312.3]\n",
      "\n",
      "[6] Process\n",
      "155500/200000 episodes. (77.75%)\n",
      "Total loss:\t 400329.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.69\t\t52128.02\t\t452449.62\n",
      "Epside Return: [1330.8]\n",
      "\n",
      "[7] Process\n",
      "156000/200000 episodes. (78.00%)\n",
      "Total loss:\t 299604.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.34\t\t-49178.28\t\t250417.89\n",
      "Epside Return: [1325.8]\n",
      "\n",
      "[5] Process\n",
      "156500/200000 episodes. (78.25%)\n",
      "Total loss:\t 320167.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.44\t\t-73465.73\t\t246693.70\n",
      "Epside Return: [1342.9]\n",
      "\n",
      "[3] Process\n",
      "157000/200000 episodes. (78.50%)\n",
      "Total loss:\t 347660.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8051.66\t\t4917.26\t\t352569.34\n",
      "Epside Return: [1351.8]\n",
      "\n",
      "[6] Process\n",
      "157500/200000 episodes. (78.75%)\n",
      "Total loss:\t 255533.77\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.09\t\t-47737.70\t\t207788.00\n",
      "Epside Return: [1286.8]\n",
      "\n",
      "[2] Process\n",
      "158000/200000 episodes. (79.00%)\n",
      "Total loss:\t 332406.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.23\t\t-77772.66\t\t254626.02\n",
      "Epside Return: [1335.3]\n",
      "\n",
      "[4] Process\n",
      "158500/200000 episodes. (79.25%)\n",
      "Total loss:\t 234516.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.67\t\t56205.76\t\t290714.53\n",
      "Epside Return: [1319.5]\n",
      "\n",
      "[5] Process\n",
      "159000/200000 episodes. (79.50%)\n",
      "Total loss:\t 1210989.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6174.41\t\t96668.98\t\t1307652.25\n",
      "Epside Return: [1351.6]\n",
      "\n",
      "[2] Process\n",
      "159500/200000 episodes. (79.75%)\n",
      "Total loss:\t 1024416.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8098.51\t\t136668.44\t\t1161076.50\n",
      "Epside Return: [1297.8]\n",
      "\n",
      "[2] Process\n",
      "160000/200000 episodes. (80.00%)\n",
      "Total loss:\t 315158.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.96\t\t-60888.85\t\t254261.66\n",
      "Epside Return: [1304.9]\n",
      "\n",
      "[4] Process\n",
      "160500/200000 episodes. (80.25%)\n",
      "Total loss:\t 1052318.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-984.90\t\t91067.58\t\t1143385.50\n",
      "Epside Return: [1298.6]\n",
      "\n",
      "[5] Process\n",
      "161000/200000 episodes. (80.50%)\n",
      "Total loss:\t 399074.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8081.60\t\t-13190.41\t\t385876.47\n",
      "Epside Return: [1310.3]\n",
      "\n",
      "[2] Process\n",
      "161500/200000 episodes. (80.75%)\n",
      "Total loss:\t 293207.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.46\t\t-80366.00\t\t212833.52\n",
      "Epside Return: [1347.0]\n",
      "\n",
      "[4] Process\n",
      "162000/200000 episodes. (81.00%)\n",
      "Total loss:\t 336681.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8084.06\t\t75717.07\t\t412390.19\n",
      "Epside Return: [1365.6]\n",
      "\n",
      "[7] Process\n",
      "162500/200000 episodes. (81.25%)\n",
      "Total loss:\t 285976.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8070.40\t\t-57768.76\t\t228199.20\n",
      "Epside Return: [1290.7]\n",
      "\n",
      "[7] Process\n",
      "163000/200000 episodes. (81.50%)\n",
      "Total loss:\t 666530.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-762.82\t\t59006.49\t\t725535.94\n",
      "Epside Return: [1274.8]\n",
      "\n",
      "[4] Process\n",
      "163500/200000 episodes. (81.75%)\n",
      "Total loss:\t 230114.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8055.48\t\t-38726.14\t\t191380.42\n",
      "Epside Return: [1317.3]\n",
      "\n",
      "[0] Process\n",
      "164000/200000 episodes. (82.00%)\n",
      "Total loss:\t 348936.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.82\t\t-67310.59\t\t281617.38\n",
      "Epside Return: [1258.7]\n",
      "\n",
      "[0] Process\n",
      "164500/200000 episodes. (82.25%)\n",
      "Total loss:\t 448365.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.62\t\t103490.37\t\t551847.50\n",
      "Epside Return: [1281.7]\n",
      "\n",
      "[7] Process\n",
      "165000/200000 episodes. (82.50%)\n",
      "Total loss:\t 554216.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8093.16\t\t29274.33\t\t583483.12\n",
      "Epside Return: [1310.7]\n",
      "\n",
      "[1] Process\n",
      "165500/200000 episodes. (82.75%)\n",
      "Total loss:\t 171003.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.33\t\t-9700.75\t\t161295.06\n",
      "Epside Return: [1318.1]\n",
      "\n",
      "[6] Process\n",
      "166000/200000 episodes. (83.00%)\n",
      "Total loss:\t 237027.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.97\t\t9636.38\t\t246655.39\n",
      "Epside Return: [1319.0]\n",
      "\n",
      "[2] Process\n",
      "166500/200000 episodes. (83.25%)\n",
      "Total loss:\t 183861.89\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.17\t\t-9263.28\t\t174590.53\n",
      "Epside Return: [1269.5]\n",
      "\n",
      "[6] Process\n",
      "167000/200000 episodes. (83.50%)\n",
      "Total loss:\t 124926.32\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.22\t\t4184.42\t\t129102.66\n",
      "Epside Return: [1287.5]\n",
      "\n",
      "[6] Process\n",
      "167500/200000 episodes. (83.75%)\n",
      "Total loss:\t 123878.17\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-164.47\t\t12563.96\t\t136441.97\n",
      "Epside Return: [1316.4]\n",
      "\n",
      "[1] Process\n",
      "168000/200000 episodes. (84.00%)\n",
      "Total loss:\t 180157.92\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8070.11\t\t-26439.34\t\t153710.52\n",
      "Epside Return: [1345.6]\n",
      "\n",
      "[3] Process\n",
      "168500/200000 episodes. (84.25%)\n",
      "Total loss:\t 1049727.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-4511.13\t\t54550.25\t\t1104273.12\n",
      "Epside Return: [1352.1]\n",
      "\n",
      "[7] Process\n",
      "169000/200000 episodes. (84.50%)\n",
      "Total loss:\t 394530.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.88\t\t33317.61\t\t427840.50\n",
      "Epside Return: [1308.2]\n",
      "\n",
      "[2] Process\n",
      "169500/200000 episodes. (84.75%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss:\t 783214.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-711.10\t\t67209.48\t\t850423.62\n",
      "Epside Return: [1258.3]\n",
      "\n",
      "[5] Process\n",
      "170000/200000 episodes. (85.00%)\n",
      "Total loss:\t 206239.33\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.89\t\t-29557.56\t\t176673.70\n",
      "Epside Return: [1357.2]\n",
      "\n",
      "[0] Process\n",
      "170500/200000 episodes. (85.25%)\n",
      "Total loss:\t 266714.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8079.75\t\t8238.69\t\t274945.03\n",
      "Epside Return: [1319.9]\n",
      "\n",
      "[5] Process\n",
      "171000/200000 episodes. (85.50%)\n",
      "Total loss:\t 110468.266\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.32\t\t4905.04\t\t115365.23\n",
      "Epside Return: [1317.0]\n",
      "\n",
      "[7] Process\n",
      "171500/200000 episodes. (85.75%)\n",
      "Total loss:\t 194324.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.57\t\t11584.93\t\t205901.30\n",
      "Epside Return: [1288.4]\n",
      "\n",
      "[3] Process\n",
      "172000/200000 episodes. (86.00%)\n",
      "Total loss:\t 209679.69\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8078.80\t\t23091.38\t\t232762.98\n",
      "Epside Return: [1307.6]\n",
      "\n",
      "[4] Process\n",
      "172500/200000 episodes. (86.25%)\n",
      "Total loss:\t 252138.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8072.59\t\t33914.48\t\t286044.62\n",
      "Epside Return: [1255.5]\n",
      "\n",
      "[0] Process\n",
      "173000/200000 episodes. (86.50%)\n",
      "Total loss:\t 447892.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.08\t\t-79287.16\t\t368596.81\n",
      "Epside Return: [1324.5]\n",
      "\n",
      "[0] Process\n",
      "173500/200000 episodes. (86.75%)\n",
      "Total loss:\t 244449.52\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.17\t\t-24899.64\t\t219541.81\n",
      "Epside Return: [1289.9]\n",
      "\n",
      "[7] Process\n",
      "174000/200000 episodes. (87.00%)\n",
      "Total loss:\t 1100358.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-6183.34\t\t74474.77\t\t1174827.50\n",
      "Epside Return: [1312.0]\n",
      "\n",
      "[0] Process\n",
      "174500/200000 episodes. (87.25%)\n",
      "Total loss:\t 235360.14\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8061.64\t\t-43278.52\t\t192073.56\n",
      "Epside Return: [1331.4]\n",
      "\n",
      "[1] Process\n",
      "175000/200000 episodes. (87.50%)\n",
      "Total loss:\t 282389.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.04\t\t-61218.52\t\t221162.44\n",
      "Epside Return: [1311.3]\n",
      "\n",
      "[0] Process\n",
      "175500/200000 episodes. (87.75%)\n",
      "Total loss:\t 851069.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8091.31\t\t82600.95\t\t933662.56\n",
      "Epside Return: [1334.6]\n",
      "\n",
      "[4] Process\n",
      "176000/200000 episodes. (88.00%)\n",
      "Total loss:\t 205105.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.28\t\t-52656.00\t\t152441.84\n",
      "Epside Return: [1311.1]\n",
      "\n",
      "[5] Process\n",
      "176500/200000 episodes. (88.25%)\n",
      "Total loss:\t 281014.3\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.51\t\t-67730.11\t\t213276.16\n",
      "Epside Return: [1334.0]\n",
      "\n",
      "[1] Process\n",
      "177000/200000 episodes. (88.50%)\n",
      "Total loss:\t 679609.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.92\t\t78647.43\t\t758249.06\n",
      "Epside Return: [1359.8]\n",
      "\n",
      "[7] Process\n",
      "177500/200000 episodes. (88.75%)\n",
      "Total loss:\t 465825.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-624.63\t\t47129.55\t\t512954.78\n",
      "Epside Return: [1345.6]\n",
      "\n",
      "[6] Process\n",
      "178000/200000 episodes. (89.00%)\n",
      "Total loss:\t 176425.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8056.87\t\t-45001.60\t\t131415.95\n",
      "Epside Return: [1351.1]\n",
      "\n",
      "[4] Process\n",
      "178500/200000 episodes. (89.25%)\n",
      "Total loss:\t 108442.15\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-163.77\t\t11304.92\t\t119746.90\n",
      "Epside Return: [1288.1]\n",
      "\n",
      "[6] Process\n",
      "179000/200000 episodes. (89.50%)\n",
      "Total loss:\t 1209998.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-2566.46\t\t150380.39\t\t1360376.00\n",
      "Epside Return: [1282.8]\n",
      "\n",
      "[1] Process\n",
      "179500/200000 episodes. (89.75%)\n",
      "Total loss:\t 379625.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.53\t\t-6800.71\t\t372816.59\n",
      "Epside Return: [1290.7]\n",
      "\n",
      "[6] Process\n",
      "180000/200000 episodes. (90.00%)\n",
      "Total loss:\t 454835.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8051.41\t\t-80593.51\t\t374234.03\n",
      "Epside Return: [1338.2]\n",
      "\n",
      "[4] Process\n",
      "180500/200000 episodes. (90.25%)\n",
      "Total loss:\t 745184.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8096.94\t\t104387.48\t\t849564.00\n",
      "Epside Return: [1327.9]\n",
      "\n",
      "[7] Process\n",
      "181000/200000 episodes. (90.50%)\n",
      "Total loss:\t 281775.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.57\t\t-667.88\t\t281099.34\n",
      "Epside Return: [1308.8]\n",
      "\n",
      "[2] Process\n",
      "181500/200000 episodes. (90.75%)\n",
      "Total loss:\t 1161632.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-2348.68\t\t133329.45\t\t1294959.75\n",
      "Epside Return: [1293.3]\n",
      "\n",
      "[1] Process\n",
      "182000/200000 episodes. (91.00%)\n",
      "Total loss:\t 191684.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8057.91\t\t-48716.71\t\t142960.19\n",
      "Epside Return: [1292.7]\n",
      "\n",
      "[1] Process\n",
      "182500/200000 episodes. (91.25%)\n",
      "Total loss:\t 241787.77\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8070.92\t\t-18061.33\t\t223718.36\n",
      "Epside Return: [1279.7]\n",
      "\n",
      "[1] Process\n",
      "183000/200000 episodes. (91.50%)\n",
      "Total loss:\t 285474.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.26\t\t-23602.03\t\t261864.81\n",
      "\n",
      "Epside Return: [1348.5]\n",
      "[0] Process\n",
      "183500/200000 episodes. (91.75%)\n",
      "Total loss:\t 243282.61\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8066.31\t\t-2811.69\t\t240462.86\n",
      "Epside Return: [1337.1]\n",
      "\n",
      "[0] Process\n",
      "184000/200000 episodes. (92.00%)\n",
      "Total loss:\t 156260.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8076.06\t\t-20900.73\t\t135351.69\n",
      "Epside Return: [1309.1]\n",
      "\n",
      "[1] Process\n",
      "184500/200000 episodes. (92.25%)\n",
      "Total loss:\t 521035.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8089.51\t\t71824.94\t\t592852.75\n",
      "Epside Return: [1315.9]\n",
      "\n",
      "[6] Process\n",
      "185000/200000 episodes. (92.50%)\n",
      "Total loss:\t 113349.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-155.59\t\t13030.23\t\t126379.91\n",
      "Epside Return: [1306.1]\n",
      "\n",
      "[3] Process\n",
      "185500/200000 episodes. (92.75%)\n",
      "Total loss:\t 1548038.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-7826.82\t\t75650.27\t\t1623680.88\n",
      "Epside Return: [1347.5]\n",
      "\n",
      "[4] Process\n",
      "186000/200000 episodes. (93.00%)\n",
      "Total loss:\t 730316.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8092.77\t\t110637.77\t\t840945.69\n",
      "Epside Return: [1203.8]\n",
      "\n",
      "[1] Process\n",
      "186500/200000 episodes. (93.25%)\n",
      "Total loss:\t 177903.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.97\t\t-13428.62\t\t164467.08\n",
      "Epside Return: [1338.3]\n",
      "\n",
      "[1] Process\n",
      "187000/200000 episodes. (93.50%)\n",
      "Total loss:\t 308117.94\n",
      "\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.94\t\t35127.03\t\t343236.91\n",
      "Epside Return: [1300.8]\n",
      "[1] Process\n",
      "187500/200000 episodes. (93.75%)\n",
      "Total loss:\t 275784.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.74\t\t4520.48\t\t280297.06\n",
      "Epside Return: [1265.7]\n",
      "\n",
      "[0] Process\n",
      "188000/200000 episodes. (94.00%)\n",
      "Total loss:\t 253132.95\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8080.94\t\t-12416.55\t\t240708.33\n",
      "Epside Return: [1270.5]\n",
      "\n",
      "[7] Process\n",
      "188500/200000 episodes. (94.25%)\n",
      "Total loss:\t 168558.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.87\t\t-26701.19\t\t141849.25\n",
      "Epside Return: [1370.8]\n",
      "\n",
      "[1] Process\n",
      "189000/200000 episodes. (94.50%)\n",
      "Total loss:\t 242874.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8058.25\t\t-22544.94\t\t220321.70\n",
      "Epside Return: [1297.3]\n",
      "\n",
      "[2] Process\n",
      "189500/200000 episodes. (94.75%)\n",
      "Total loss:\t 239522.05\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8062.50\t\t-38422.41\t\t201091.58\n",
      "Epside Return: [1297.9]\n",
      "\n",
      "[1] Process\n",
      "190000/200000 episodes. (95.00%)\n",
      "Total loss:\t 400235.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8072.55\t\t113626.19\t\t513853.75\n",
      "Epside Return: [1298.6]\n",
      "\n",
      "[6] Process\n",
      "190500/200000 episodes. (95.25%)\n",
      "Total loss:\t 314413.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8052.34\t\t-70167.40\t\t244237.70\n",
      "Epside Return: [1244.1]\n",
      "\n",
      "[0] Process\n",
      "191000/200000 episodes. (95.50%)\n",
      "Total loss:\t 226029.27\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8058.33\t\t-46576.27\t\t179444.94\n",
      "Epside Return: [1324.8]\n",
      "\n",
      "[1] Process\n",
      "191500/200000 episodes. (95.75%)\n",
      "Total loss:\t 306784.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.44\t\t-763.58\t\t306012.78\n",
      "Epside Return: [1284.9]\n",
      "\n",
      "[1] Process\n",
      "192000/200000 episodes. (96.00%)\n",
      "Total loss:\t 274064.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.29\t\t11628.41\t\t285685.06\n",
      "Epside Return: [1285.5]\n",
      "\n",
      "[7] Process\n",
      "192500/200000 episodes. (96.25%)\n",
      "Total loss:\t 176708.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8071.48\t\t-30911.42\t\t145788.56\n",
      "Epside Return: [1355.6]\n",
      "\n",
      "[7] Process\n",
      "193000/200000 episodes. (96.50%)\n",
      "Total loss:\t 192579.81\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8063.13\t\t-15491.28\t\t177080.47\n",
      "Epside Return: [1342.7]\n",
      "\n",
      "[5] Process\n",
      "193500/200000 episodes. (96.75%)\n",
      "Total loss:\t 268432.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8059.48\t\t-69025.68\t\t199398.64\n",
      "Epside Return: [1293.0]\n",
      "\n",
      "[3] Process\n",
      "194000/200000 episodes. (97.00%)\n",
      "Total loss:\t 226338.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8067.64\t\t-43339.57\t\t182990.61\n",
      "Epside Return: [1267.5]\n",
      "\n",
      "[0] Process\n",
      "194500/200000 episodes. (97.25%)\n",
      "Total loss:\t 407275.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8074.51\t\t-10149.12\t\t397117.88\n",
      "Epside Return: [1202.6]\n",
      "\n",
      "[1] Process\n",
      "195000/200000 episodes. (97.50%)\n",
      "Total loss:\t 154940.14\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.51\t\t-21110.66\t\t133821.41\n",
      "Epside Return: [1228.6]\n",
      "\n",
      "[0] Process\n",
      "195500/200000 episodes. (97.75%)\n",
      "Total loss:\t 293667.62\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8058.88\t\t-50569.22\t\t243090.34\n",
      "Epside Return: [1280.9]\n",
      "\n",
      "[3] Process\n",
      "196000/200000 episodes. (98.00%)\n",
      "Total loss:\t 325570.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8054.97\t\t-79131.17\t\t246431.47\n",
      "Epside Return: [1261.7]\n",
      "\n",
      "[6] Process\n",
      "196500/200000 episodes. (98.25%)\n",
      "Total loss:\t 196089.23\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8075.90\t\t46562.56\t\t242643.72\n",
      "Epside Return: [1309.8]\n",
      "\n",
      "[7] Process\n",
      "197000/200000 episodes. (98.50%)\n",
      "Total loss:\t 162174.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8060.43\t\t-19443.89\t\t142722.45\n",
      "Epside Return: [1323.0]\n",
      "\n",
      "[4] Process\n",
      "197500/200000 episodes. (98.75%)\n",
      "Total loss:\t 341532.22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy\t\tPolicy\t\tValue\n",
      "-8073.62\t\t38319.01\t\t379843.16\n",
      "Epside Return: [1318.0]\n",
      "\n",
      "[4] Process\n",
      "198000/200000 episodes. (99.00%)\n",
      "Total loss:\t 265838.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8064.72\t\t-18857.41\t\t246972.92\n",
      "Epside Return: [1294.7]\n",
      "\n",
      "[0] Process\n",
      "198500/200000 episodes. (99.25%)\n",
      "Total loss:\t 320274.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8068.52\t\t-11282.57\t\t308983.91\n",
      "Epside Return: [1279.5]\n",
      "\n",
      "[3] Process\n",
      "199000/200000 episodes. (99.50%)\n",
      "Total loss:\t 308991.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8097.86\t\t92049.80\t\t401033.00\n",
      "Epside Return: [1242.6]\n",
      "\n",
      "[7] Process\n",
      "199500/200000 episodes. (99.75%)\n",
      "Total loss:\t 366726.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8070.71\t\t39789.24\t\t406507.84\n",
      "Epside Return: [1292.9]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "IndexError: invalid index\n",
      "  File \"<ipython-input-7-b409b9399f04>\", line 49, in train\n",
      "    cur_ep = globalNet.log_episode(ep_return)\n",
      "  File \"<ipython-input-6-c29db70bbb99>\", line 42, in log_episode\n",
      "    self.ep_returns[c] = ep_return\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/sharedctypes.py\", line 226, in __setitem__\n",
      "    self._obj[i] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] Process\n",
      "200000/200000 episodes. (100.00%)\n",
      "Total loss:\t 228642.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "-8069.16\t\t31237.00\t\t259871.78\n",
      "Epside Return: [1340.7]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "globalNet = A3C_v3(input_dim, action_dim, MAX_EP, is_global=True)\n",
    "globalNet.share_memory()\n",
    "\n",
    "optimizer = optim.Adam(globalNet.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "lock = mp.Lock()\n",
    "\n",
    "Softplus=nn.Softplus()\n",
    "log_df = pd.DataFrame(columns=['running', 'EP', 'Loss', 'Return', 'LR'])\n",
    "fignum = len([f for f in os.listdir() if 'v3_HalfCheetah' in f and 'png' in f])\n",
    "\n",
    "processes = []\n",
    "for p_idx in range(NUM_THREADS):\n",
    "    p = mp.Process(target=train, args=(lock, globalNet, optimizer, scheduler, t_max, p_idx))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "average_returns = np.array(globalNet.average_returns[:])\n",
    "ep_returns = np.array(globalNet.ep_returns[:])\n",
    "nonzero_indices = average_returns!=0.0\n",
    "plt.plot(ep_returns[nonzero_indices], color='lightgreen')\n",
    "plt.plot(average_returns[nonzero_indices], color='green')\n",
    "plt.show()\n",
    "#fignum = len([f for f in os.listdir() if 'v3_HalfCheetah' in f and 'png' in f])\n",
    "#plt.savefig('A3C_v3_HalfCheetah_%d.png'%fignum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>running</th>\n",
       "      <th>EP</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Return</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [running, EP, Loss, Return, LR]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "env.unwrapped.initialize(is_render=True)\n",
    "obs = env.reset()\n",
    "ep_return = 0\n",
    "\n",
    "while False: #True:\n",
    "    mu, sigma, V = globalNet(torch.tensor(obs.astype(np.float32)))\n",
    "    Softplus=nn.Softplus()     \n",
    "    sigma = Softplus(sigma + 1e-5) # constrain to sensible values\n",
    "    normal_dist = torch.normal(mu, sigma)\n",
    "\n",
    "    sigma = Softplus(sigma + 1e-5) # constrain to sensible values\n",
    "    action_dist = torch.normal(mu, sigma)\n",
    "    action = action_dist.detach().numpy()\n",
    "    action = action.clip(env.action_space.low, env.action_space.high)\n",
    "    \n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    ep_return += reward\n",
    "    if done:\n",
    "        env.reset()\n",
    "        print('Score:', ep_return)\n",
    "        ep_return = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
