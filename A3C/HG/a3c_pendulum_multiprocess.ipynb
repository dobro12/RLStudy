{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.logger.set_level(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'Pendulum-v0'\n",
    "input_dim = 3\n",
    "action_list = [4/10*i-2 for i in range(11)]\n",
    "action_dim = len(action_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 8\n",
    "\n",
    "#T_max = 10000\n",
    "MAX_EP = 200000\n",
    "t_max = 100\n",
    "print_freq = 500\n",
    "\n",
    "beta = 0.01   # entropy regularization\n",
    "gamma = 0.9\n",
    "alpha = 0.99   # RMSProb decay factor\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class A3C_v2(nn.Module):\n",
    "    def __init__(self, input_dim, action_dim, max_ep=0, is_global=False):\n",
    "        super(A3C_v2, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.max_ep = max_ep\n",
    "        \n",
    "        self.distribution = torch.distributions.Categorical\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, action_dim)\n",
    "        self.fc5 = nn.Linear(64, 1)\n",
    "        \n",
    "        self.ep_counter = None\n",
    "        self.ep_returns = None\n",
    "        self.average_returns = None\n",
    "        \n",
    "        if is_global:\n",
    "            self.set_global()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        pi = self.fc4(x)\n",
    "        prob = self.distribution(F.softmax(pi, dim=0))\n",
    "        value = self.fc5(x)\n",
    "        return pi, prob, value\n",
    "    \n",
    "    def set_global(self):\n",
    "        self.ep_counter = mp.Value('i')\n",
    "        self.ep_counter.value = 0\n",
    "        self.ep_returns = mp.Array('d', self.max_ep)\n",
    "        self.average_returns = mp.Array('d',self.max_ep)\n",
    "        \n",
    "    def log_episode(self, ep_return):\n",
    "        c = self.ep_counter.value\n",
    "        self.ep_returns[c] = ep_return\n",
    "        self.average_returns[c] = np.mean(self.ep_returns[max(0, c-99):c+1])\n",
    "        self.ep_counter.value += 1\n",
    "        return self.ep_counter.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A3C_v3(nn.Module):\n",
    "    def __init__(self, input_dim, action_dim, max_ep=0, is_global=False):\n",
    "        super(A3C_v3, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.max_ep = max_ep\n",
    "        \n",
    "        self.distribution = torch.distributions.Categorical\n",
    "        \n",
    "        self.fc_pi1 = nn.Linear(input_dim, 128)\n",
    "        self.fc_pi2 = nn.Linear(128, action_dim)\n",
    "        self.fc_v1 = nn.Linear(input_dim, 128)\n",
    "        self.fc_v2 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.ep_counter = None\n",
    "        self.ep_returns = None\n",
    "        self.average_returns = None\n",
    "        \n",
    "        if is_global:\n",
    "            self.set_global()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_pi = F.relu(self.fc_pi1(x))\n",
    "        pi = self.fc_pi2(x_pi)\n",
    "        prob = self.distribution(F.softmax(pi, dim=0))\n",
    "        x_v = F.relu(self.fc_v1(x))\n",
    "        value = self.fc_v2(x_v)\n",
    "        return pi, prob, value\n",
    "    \n",
    "    def set_global(self):\n",
    "        self.ep_counter = mp.Value('i')\n",
    "        self.ep_counter.value = 0\n",
    "        self.ep_returns = mp.Array('d', self.max_ep)\n",
    "        self.average_returns = mp.Array('d',self.max_ep)\n",
    "        \n",
    "    def log_episode(self, ep_return):\n",
    "        c = self.ep_counter.value\n",
    "        self.ep_returns[c] = ep_return\n",
    "        self.average_returns[c] = np.mean(self.ep_returns[max(0, c-99):c+1])\n",
    "        self.ep_counter.value += 1\n",
    "        return self.ep_counter.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lock, globalNet, optimizer, scheduler, tmax, pid):\n",
    "    t = 0\n",
    "    done = False\n",
    "    ep_return = 0\n",
    "    log_episode_return = []\n",
    "    cur_ep = 0\n",
    "    step_count = 0\n",
    "    \n",
    "    localNet = A3C_v3(input_dim, len(action_list))\n",
    "    localNet.load_state_dict(globalNet.state_dict())\n",
    "    env = gym.make(ENV_NAME)\n",
    "    obs = env.reset()\n",
    "    \n",
    "    while globalNet.ep_counter.value < MAX_EP:\n",
    "        t_start = t\n",
    "        buff_value = []\n",
    "        buff_q = []\n",
    "        buff_reward = []\n",
    "        buff_logp = []\n",
    "        buff_entropy = []\n",
    "        \n",
    "        while t_start-t < t_max:\n",
    "            pi, prob, value = localNet(torch.tensor(obs.astype(np.float32)))\n",
    "            a = prob.sample()\n",
    "            log_prob = prob.log_prob(a)\n",
    "\n",
    "            obs, reward, done, _ = env.step([action_list[a.numpy()]])\n",
    "            ep_return += reward\n",
    "            step_count += 1\n",
    "            entropy = prob.entropy()\n",
    "\n",
    "            buff_value.append(value)\n",
    "            buff_reward.append(reward)\n",
    "            buff_logp.append(log_prob)\n",
    "            buff_entropy.append(entropy)\n",
    "            t += 1\n",
    "            \n",
    "            if done:\n",
    "                cur_ep = globalNet.log_episode(ep_return)\n",
    "                obs = env.reset()\n",
    "                if step_count==env._max_episode_steps:\n",
    "                    done = False\n",
    "                step_count = 0\n",
    "                ep_return = 0\n",
    "                break\n",
    "\n",
    "        R = value if not done else 0\n",
    "        policy_loss = 0\n",
    "        value_loss = 0\n",
    "        entropy_loss = 0\n",
    "        for i in range(-1, -(t-t_start)-1, -1): #range(t-1, t_start-1, -1):\n",
    "            R = buff_reward[i] + gamma*R\n",
    "            TD = R - buff_value[i]\n",
    "            policy_loss += buff_logp[i] * TD.detach()\n",
    "            value_loss += torch.pow(TD, 2)\n",
    "            entropy_loss += buff_entropy[i].sum()\n",
    "        loss = - policy_loss + value_loss - beta*entropy_loss\n",
    "        \n",
    "        lock.acquire()\n",
    "        try:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            for local_param, global_param in zip(localNet.parameters(), globalNet.parameters()):\n",
    "                global_param.grad = local_param.grad\n",
    "            optimizer.step()\n",
    "        finally:\n",
    "            lock.release()\n",
    "        localNet.load_state_dict(globalNet.state_dict())\n",
    "        \n",
    "        if cur_ep%print_freq==0: #globalNet.ep_counter.value%100==0:\n",
    "            print('[%d] Process'%pid)\n",
    "            print('%d/%d episodes. (%.2f%%)'%(cur_ep, MAX_EP, cur_ep/MAX_EP*100))\n",
    "            #print('Current learning rate:', optimizer.param_groups[0]['lr'])\n",
    "            #print(globalNet.ep_counter.value-1, 'episodes.')\n",
    "            print('Total loss:\\t', loss.data.numpy()[0])\n",
    "            print('Entropy\\t\\tPolicy\\t\\tValue')\n",
    "            print('%.2f\\t\\t%.2f\\t\\t%.2f'%(entropy_loss.data.numpy(), policy_loss.data.numpy()[0], \\\n",
    "                  value_loss.data.numpy()[0]))\n",
    "            print('Epside Return: [%.1f]'%globalNet.average_returns[globalNet.ep_counter.value-1])\n",
    "            print()\n",
    "            \n",
    "            global log_df, fig_num\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            average_returns = np.array(globalNet.average_returns[:])\n",
    "            ep_returns = np.array(globalNet.ep_returns[:])\n",
    "            nonzero_indices = average_returns!=0.0\n",
    "            plt.plot(ep_returns[nonzero_indices], color='lightgreen')\n",
    "            plt.plot(average_returns[nonzero_indices], color='green')\n",
    "            plt.savefig('A3C_v3_Pendulum_%d.png'%fignum)\n",
    "            plt.close()\n",
    "            \n",
    "            raw_data = [cur_ep/MAX_EP*100, cur_ep, loss.data.numpy()[0], globalNet.average_returns[globalNet.ep_counter.value-1], optimizer.param_groups[0]['lr']]\n",
    "            log_df = log_df.append(pd.Series(raw_data, index = log_df.columns), ignore_index=True)\n",
    "        \n",
    "        scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Process\n",
      "500/200000 episodes. (0.25%)\n",
      "Total loss:\t 406145.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.91\t\t19745.94\t\t425895.56\n",
      "Epside Return: [-1268.9]\n",
      "\n",
      "[7] Process\n",
      "1000/200000 episodes. (0.50%)\n",
      "Total loss:\t 406787.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "456.37\t\t19358.77\t\t426150.41\n",
      "Epside Return: [-1246.8]\n",
      "\n",
      "[7] Process\n",
      "1500/200000 episodes. (0.75%)\n",
      "Total loss:\t 209130.83\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.90\t\t12160.20\t\t221295.45\n",
      "Epside Return: [-1204.9]\n",
      "\n",
      "[5] Process\n",
      "2000/200000 episodes. (1.00%)\n",
      "Total loss:\t 162278.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.52\t\t10924.67\t\t173207.42\n",
      "Epside Return: [-1203.4]\n",
      "\n",
      "[2] Process\n",
      "2500/200000 episodes. (1.25%)\n",
      "Total loss:\t 87609.36\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.02\t\t6171.07\t\t93784.83\n",
      "Epside Return: [-1142.5]\n",
      "\n",
      "[4] Process\n",
      "3000/200000 episodes. (1.50%)\n",
      "Total loss:\t 83812.07\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.51\t\t4590.76\t\t88407.24\n",
      "Epside Return: [-1181.8]\n",
      "\n",
      "[5] Process\n",
      "3500/200000 episodes. (1.75%)\n",
      "Total loss:\t 292705.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.14\t\t16760.38\t\t309470.19\n",
      "Epside Return: [-1193.3]\n",
      "\n",
      "[7] Process\n",
      "4000/200000 episodes. (2.00%)\n",
      "Total loss:\t 117349.484\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "453.87\t\t9020.60\t\t126374.62\n",
      "Epside Return: [-1167.6]\n",
      "\n",
      "[4] Process\n",
      "4500/200000 episodes. (2.25%)\n",
      "Total loss:\t 73105.23\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.29\t\t-721.94\t\t72387.78\n",
      "Epside Return: [-1137.6]\n",
      "\n",
      "[3] Process\n",
      "5000/200000 episodes. (2.50%)\n",
      "Total loss:\t 77388.65\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.92\t\t327.16\t\t77720.25\n",
      "Epside Return: [-1155.4]\n",
      "\n",
      "[2] Process\n",
      "5500/200000 episodes. (2.75%)\n",
      "Total loss:\t 89001.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.15\t\t-600.94\t\t88405.08\n",
      "Epside Return: [-1165.8]\n",
      "\n",
      "[7] Process\n",
      "6000/200000 episodes. (3.00%)\n",
      "Total loss:\t 86485.92\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "448.83\t\t-1178.84\t\t85311.58\n",
      "Epside Return: [-1194.3]\n",
      "\n",
      "[7] Process\n",
      "6500/200000 episodes. (3.25%)\n",
      "Total loss:\t 368220.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "467.87\t\t19320.65\t\t387545.50\n",
      "Epside Return: [-1116.2]\n",
      "\n",
      "[1] Process\n",
      "7000/200000 episodes. (3.50%)\n",
      "Total loss:\t 633111.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "472.60\t\t26890.70\t\t660006.81\n",
      "Epside Return: [-1156.1]\n",
      "\n",
      "[3] Process\n",
      "7500/200000 episodes. (3.75%)\n",
      "Total loss:\t 89286.57\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.94\t\t-793.81\t\t88497.20\n",
      "Epside Return: [-1135.2]\n",
      "\n",
      "[3] Process\n",
      "8000/200000 episodes. (4.00%)\n",
      "Total loss:\t 84938.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.50\t\t-2311.53\t\t82631.45\n",
      "Epside Return: [-1117.5]\n",
      "\n",
      "[2] Process\n",
      "8500/200000 episodes. (4.25%)\n",
      "Total loss:\t 81645.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.10\t\t8377.15\t\t90027.19\n",
      "Epside Return: [-1134.6]\n",
      "\n",
      "[5] Process\n",
      "9000/200000 episodes. (4.50%)\n",
      "Total loss:\t 100978.69\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.03\t\t8307.18\t\t109290.45\n",
      "Epside Return: [-1158.9]\n",
      "\n",
      "[6] Process\n",
      "9500/200000 episodes. (4.75%)\n",
      "Total loss:\t 485952.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "472.29\t\t23400.86\t\t509358.16\n",
      "Epside Return: [-1129.1]\n",
      "\n",
      "[3] Process\n",
      "10000/200000 episodes. (5.00%)\n",
      "Total loss:\t 48387.73\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.65\t\t1710.11\t\t50102.32\n",
      "Epside Return: [-1093.3]\n",
      "\n",
      "[7] Process\n",
      "10500/200000 episodes. (5.25%)\n",
      "Total loss:\t 85464.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.13\t\t-3231.96\t\t82237.17\n",
      "Epside Return: [-1087.6]\n",
      "\n",
      "[5] Process\n",
      "11000/200000 episodes. (5.50%)\n",
      "Total loss:\t 278585.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "469.52\t\t17284.54\t\t295874.25\n",
      "Epside Return: [-1126.4]\n",
      "\n",
      "[1] Process\n",
      "11500/200000 episodes. (5.75%)\n",
      "Total loss:\t 80664.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.31\t\t7316.77\t\t87985.96\n",
      "Epside Return: [-1076.9]\n",
      "\n",
      "[7] Process\n",
      "12000/200000 episodes. (6.00%)\n",
      "Total loss:\t 94848.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.17\t\t7592.70\t\t102446.16\n",
      "Epside Return: [-1125.4]\n",
      "\n",
      "[0] Process\n",
      "12500/200000 episodes. (6.25%)\n",
      "Total loss:\t 87558.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "459.10\t\t8309.96\t\t95873.09\n",
      "Epside Return: [-1177.4]\n",
      "\n",
      "[4] Process\n",
      "13000/200000 episodes. (6.50%)\n",
      "Total loss:\t 62151.52\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.97\t\t-455.50\t\t61700.52\n",
      "Epside Return: [-1110.5]\n",
      "\n",
      "[5] Process\n",
      "13500/200000 episodes. (6.75%)\n",
      "Total loss:\t 301890.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "471.05\t\t18596.18\t\t320491.47\n",
      "Epside Return: [-1158.7]\n",
      "\n",
      "[2] Process\n",
      "14000/200000 episodes. (7.00%)\n",
      "Total loss:\t 68519.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.11\t\t-2440.81\t\t66083.04\n",
      "Epside Return: [-1112.1]\n",
      "\n",
      "[7] Process\n",
      "14500/200000 episodes. (7.25%)\n",
      "Total loss:\t 65109.203\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.29\t\t-426.02\t\t64687.59\n",
      "Epside Return: [-1127.1]\n",
      "\n",
      "[3] Process\n",
      "15000/200000 episodes. (7.50%)\n",
      "Total loss:\t 126056.445\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "465.11\t\t11895.70\t\t137956.80\n",
      "Epside Return: [-1058.6]\n",
      "\n",
      "[0] Process\n",
      "15500/200000 episodes. (7.75%)\n",
      "Total loss:\t 151201.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "467.40\t\t13261.64\t\t164467.88\n",
      "Epside Return: [-1134.0]\n",
      "\n",
      "[1] Process\n",
      "16000/200000 episodes. (8.00%)\n",
      "Total loss:\t 39571.188\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.57\t\t2089.80\t\t41665.49\n",
      "Epside Return: [-1143.1]\n",
      "\n",
      "[4] Process\n",
      "16500/200000 episodes. (8.25%)\n",
      "Total loss:\t 43956.133\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.93\t\t550.58\t\t44511.17\n",
      "Epside Return: [-1133.2]\n",
      "\n",
      "[0] Process\n",
      "17000/200000 episodes. (8.50%)\n",
      "Total loss:\t 49406.445\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "457.17\t\t6477.91\t\t55888.93\n",
      "Epside Return: [-1058.8]\n",
      "\n",
      "[7] Process\n",
      "17500/200000 episodes. (8.75%)\n",
      "Total loss:\t 54153.4\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.35\t\t-229.70\t\t53928.16\n",
      "Epside Return: [-1121.4]\n",
      "\n",
      "[1] Process\n",
      "18000/200000 episodes. (9.00%)\n",
      "Total loss:\t 60643.773\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "450.09\t\t-2566.18\t\t58082.09\n",
      "Epside Return: [-1095.6]\n",
      "\n",
      "[0] Process\n",
      "18500/200000 episodes. (9.25%)\n",
      "Total loss:\t 47220.793\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.23\t\t3168.80\t\t50394.11\n",
      "Epside Return: [-1069.0]\n",
      "\n",
      "[5] Process\n",
      "19000/200000 episodes. (9.50%)\n",
      "Total loss:\t 34772.96\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.06\t\t4178.16\t\t38955.63\n",
      "Epside Return: [-1101.6]\n",
      "\n",
      "[3] Process\n",
      "19500/200000 episodes. (9.75%)\n",
      "Total loss:\t 55825.875\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.71\t\t-587.34\t\t55243.01\n",
      "Epside Return: [-1098.0]\n",
      "\n",
      "[6] Process\n",
      "20000/200000 episodes. (10.00%)\n",
      "Total loss:\t 52181.875\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "453.41\t\t5202.00\t\t57388.41\n",
      "Epside Return: [-1122.1]\n",
      "\n",
      "[6] Process\n",
      "20500/200000 episodes. (10.25%)\n",
      "Total loss:\t 57319.67\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.53\t\t-2354.00\t\t54970.15\n",
      "Epside Return: [-1124.8]\n",
      "\n",
      "[2] Process\n",
      "21000/200000 episodes. (10.50%)\n",
      "Total loss:\t 172857.36\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.06\t\t11183.61\t\t184045.59\n",
      "Epside Return: [-1102.0]\n",
      "\n",
      "[1] Process\n",
      "21500/200000 episodes. (10.75%)\n",
      "Total loss:\t 47247.46\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.40\t\t-806.66\t\t46445.25\n",
      "Epside Return: [-1082.8]\n",
      "\n",
      "[6] Process\n",
      "22000/200000 episodes. (11.00%)\n",
      "Total loss:\t 73931.48\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.91\t\t6938.36\t\t80874.40\n",
      "Epside Return: [-1069.2]\n",
      "\n",
      "[6] Process\n",
      "22500/200000 episodes. (11.25%)\n",
      "Total loss:\t 32850.21\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "448.36\t\t2917.45\t\t35772.14\n",
      "Epside Return: [-1098.4]\n",
      "\n",
      "[1] Process\n",
      "23000/200000 episodes. (11.50%)\n",
      "Total loss:\t 77913.766\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.48\t\t6538.33\t\t84456.64\n",
      "Epside Return: [-1107.6]\n",
      "\n",
      "[4] Process\n",
      "23500/200000 episodes. (11.75%)\n",
      "Total loss:\t 59330.85\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.56\t\t-2218.59\t\t57116.63\n",
      "Epside Return: [-1090.5]\n",
      "\n",
      "[2] Process\n",
      "24000/200000 episodes. (12.00%)\n",
      "Total loss:\t 37387.04\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.89\t\t893.97\t\t38285.49\n",
      "Epside Return: [-1091.7]\n",
      "\n",
      "[2] Process\n",
      "24500/200000 episodes. (12.25%)\n",
      "Total loss:\t 36157.023\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.96\t\t3428.53\t\t39590.05\n",
      "Epside Return: [-1089.8]\n",
      "\n",
      "[4] Process\n",
      "25000/200000 episodes. (12.50%)\n",
      "Total loss:\t 55448.484\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.33\t\t-3186.57\t\t52266.45\n",
      "Epside Return: [-1135.7]\n",
      "\n",
      "[4] Process\n",
      "25500/200000 episodes. (12.75%)\n",
      "Total loss:\t 35684.426\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.49\t\t875.74\t\t36564.53\n",
      "Epside Return: [-1101.0]\n",
      "\n",
      "[1] Process\n",
      "26000/200000 episodes. (13.00%)\n",
      "Total loss:\t 61740.875\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.47\t\t-2594.65\t\t59150.61\n",
      "Epside Return: [-1074.8]\n",
      "\n",
      "[0] Process\n",
      "26500/200000 episodes. (13.25%)\n",
      "Total loss:\t 47866.723\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.53\t\t-494.45\t\t47376.72\n",
      "Epside Return: [-1068.0]\n",
      "\n",
      "[1] Process\n",
      "27000/200000 episodes. (13.50%)\n",
      "Total loss:\t 31440.695\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.96\t\t2998.34\t\t34443.50\n",
      "Epside Return: [-1071.5]\n",
      "\n",
      "[5] Process\n",
      "27500/200000 episodes. (13.75%)\n",
      "Total loss:\t 36212.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.00\t\t1068.63\t\t37285.80\n",
      "Epside Return: [-1095.3]\n",
      "\n",
      "[6] Process\n",
      "28000/200000 episodes. (14.00%)\n",
      "Total loss:\t 63498.965\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.29\t\t5900.29\t\t69403.80\n",
      "Epside Return: [-1102.8]\n",
      "\n",
      "[0] Process\n",
      "28500/200000 episodes. (14.25%)\n",
      "Total loss:\t 150955.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.87\t\t10985.02\t\t161945.02\n",
      "Epside Return: [-1086.7]\n",
      "\n",
      "[0] Process\n",
      "29000/200000 episodes. (14.50%)\n",
      "Total loss:\t 50353.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "409.56\t\t-1432.33\t\t48925.66\n",
      "Epside Return: [-1055.1]\n",
      "\n",
      "[7] Process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29500/200000 episodes. (14.75%)\n",
      "Total loss:\t 306328.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "470.92\t\t18351.22\t\t324684.91\n",
      "Epside Return: [-1104.6]\n",
      "\n",
      "[2] Process\n",
      "30000/200000 episodes. (15.00%)\n",
      "Total loss:\t 45037.957\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.21\t\t4560.99\t\t49603.47\n",
      "Epside Return: [-1110.8]\n",
      "\n",
      "[2] Process\n",
      "30500/200000 episodes. (15.25%)\n",
      "Total loss:\t 30046.309\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.96\t\t3183.97\t\t33234.75\n",
      "Epside Return: [-1097.3]\n",
      "\n",
      "[6] Process\n",
      "31000/200000 episodes. (15.50%)\n",
      "Total loss:\t 173843.5\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "462.62\t\t11656.92\t\t185505.05\n",
      "Epside Return: [-1077.5]\n",
      "\n",
      "[1] Process\n",
      "31500/200000 episodes. (15.75%)\n",
      "Total loss:\t 42674.445\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.33\t\t-1202.89\t\t41475.98\n",
      "Epside Return: [-1097.6]\n",
      "\n",
      "[4] Process\n",
      "32000/200000 episodes. (16.00%)\n",
      "Total loss:\t 56845.492\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "453.41\t\t5482.62\t\t62332.65\n",
      "Epside Return: [-1093.5]\n",
      "\n",
      "[3] Process\n",
      "32500/200000 episodes. (16.25%)\n",
      "Total loss:\t 52838.27\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "419.87\t\t-1935.98\t\t50906.48\n",
      "Epside Return: [-1090.6]\n",
      "\n",
      "[1] Process\n",
      "33000/200000 episodes. (16.50%)\n",
      "Total loss:\t 33835.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.41\t\t945.20\t\t34785.00\n",
      "Epside Return: [-1073.8]\n",
      "\n",
      "[1] Process\n",
      "33500/200000 episodes. (16.75%)\n",
      "Total loss:\t 128209.18\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.12\t\t9533.01\t\t137746.80\n",
      "Epside Return: [-1107.9]\n",
      "\n",
      "[6] Process\n",
      "34000/200000 episodes. (17.00%)\n",
      "Total loss:\t 59686.293\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "456.19\t\t7151.79\t\t66842.65\n",
      "Epside Return: [-1060.5]\n",
      "\n",
      "[6] Process\n",
      "34500/200000 episodes. (17.25%)\n",
      "Total loss:\t 147642.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "460.52\t\t10051.28\t\t157698.23\n",
      "Epside Return: [-1068.6]\n",
      "\n",
      "[3] Process\n",
      "35000/200000 episodes. (17.50%)\n",
      "Total loss:\t 60579.92\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.14\t\t7964.54\t\t68549.05\n",
      "Epside Return: [-1106.8]\n",
      "\n",
      "[4] Process\n",
      "35500/200000 episodes. (17.75%)\n",
      "Total loss:\t 57883.535\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "453.04\t\t4190.76\t\t62078.83\n",
      "Epside Return: [-1060.9]\n",
      "\n",
      "[1] Process\n",
      "36000/200000 episodes. (18.00%)\n",
      "Total loss:\t 66036.91\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "453.50\t\t6530.29\t\t72571.73\n",
      "Epside Return: [-1083.8]\n",
      "\n",
      "[7] Process\n",
      "36500/200000 episodes. (18.25%)\n",
      "Total loss:\t 35516.152\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.45\t\t857.33\t\t36377.88\n",
      "Epside Return: [-1081.3]\n",
      "\n",
      "[7] Process\n",
      "37000/200000 episodes. (18.50%)\n",
      "Total loss:\t 273597.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "470.63\t\t17651.34\t\t291253.34\n",
      "Epside Return: [-1101.7]\n",
      "\n",
      "[5] Process\n",
      "37500/200000 episodes. (18.75%)\n",
      "Total loss:\t 154018.39\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "465.85\t\t12694.94\t\t166717.98\n",
      "Epside Return: [-1148.9]\n",
      "\n",
      "[2] Process\n",
      "38000/200000 episodes. (19.00%)\n",
      "Total loss:\t 33034.527\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.26\t\t3331.45\t\t36370.45\n",
      "Epside Return: [-1077.5]\n",
      "\n",
      "[4] Process\n",
      "38500/200000 episodes. (19.25%)\n",
      "Total loss:\t 45013.965\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.59\t\t2079.28\t\t47097.71\n",
      "Epside Return: [-1089.6]\n",
      "\n",
      "[4] Process\n",
      "39000/200000 episodes. (19.50%)\n",
      "Total loss:\t 41677.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.20\t\t1.83\t\t41683.99\n",
      "Epside Return: [-1114.4]\n",
      "\n",
      "[3] Process\n",
      "39500/200000 episodes. (19.75%)\n",
      "Total loss:\t 52013.91\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "427.54\t\t-1651.99\t\t50366.19\n",
      "Epside Return: [-1065.8]\n",
      "\n",
      "[4] Process\n",
      "40000/200000 episodes. (20.00%)\n",
      "Total loss:\t 71312.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "456.89\t\t7791.12\t\t79108.35\n",
      "Epside Return: [-1137.0]\n",
      "\n",
      "[7] Process\n",
      "40500/200000 episodes. (20.25%)\n",
      "Total loss:\t 42390.43\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "432.32\t\t627.36\t\t43022.11\n",
      "Epside Return: [-1103.8]\n",
      "\n",
      "[2] Process\n",
      "41000/200000 episodes. (20.50%)\n",
      "Total loss:\t 24736.574\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.16\t\t2069.61\t\t26810.64\n",
      "Epside Return: [-1071.8]\n",
      "\n",
      "[5] Process\n",
      "41500/200000 episodes. (20.75%)\n",
      "Total loss:\t 53899.94\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.46\t\t-2604.62\t\t51299.79\n",
      "Epside Return: [-1063.6]\n",
      "\n",
      "[6] Process\n",
      "42000/200000 episodes. (21.00%)\n",
      "Total loss:\t 73414.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.89\t\t7525.74\t\t80944.65\n",
      "Epside Return: [-1075.1]\n",
      "\n",
      "[3] Process\n",
      "42500/200000 episodes. (21.25%)\n",
      "Total loss:\t 43565.188\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.16\t\t-575.69\t\t42993.90\n",
      "Epside Return: [-1068.5]\n",
      "\n",
      "[4] Process\n",
      "43000/200000 episodes. (21.50%)\n",
      "Total loss:\t 55809.95\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.99\t\t5686.24\t\t61500.72\n",
      "Epside Return: [-1089.6]\n",
      "\n",
      "[7] Process\n",
      "43500/200000 episodes. (21.75%)\n",
      "Total loss:\t 49773.68\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "425.18\t\t-2323.37\t\t47454.56\n",
      "Epside Return: [-1073.6]\n",
      "\n",
      "[0] Process\n",
      "44000/200000 episodes. (22.00%)\n",
      "Total loss:\t 44062.496\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.31\t\t4470.96\t\t48537.95\n",
      "Epside Return: [-1074.3]\n",
      "\n",
      "[4] Process\n",
      "44500/200000 episodes. (22.25%)\n",
      "Total loss:\t 49185.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "430.99\t\t-1563.61\t\t47626.36\n",
      "Epside Return: [-1103.8]\n",
      "\n",
      "[6] Process\n",
      "45000/200000 episodes. (22.50%)\n",
      "Total loss:\t 36372.93\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.27\t\t425.37\t\t36802.68\n",
      "Epside Return: [-1103.9]\n",
      "\n",
      "[1] Process\n",
      "45500/200000 episodes. (22.75%)\n",
      "Total loss:\t 35249.63\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.18\t\t3037.23\t\t38291.31\n",
      "Epside Return: [-1089.3]\n",
      "\n",
      "[7] Process\n",
      "46000/200000 episodes. (23.00%)\n",
      "Total loss:\t 30565.293\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.49\t\t1373.55\t\t31943.26\n",
      "Epside Return: [-1070.5]\n",
      "\n",
      "[7] Process\n",
      "46500/200000 episodes. (23.25%)\n",
      "Total loss:\t 31979.262\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.66\t\t1488.12\t\t33471.79\n",
      "Epside Return: [-1072.0]\n",
      "\n",
      "[0] Process\n",
      "47000/200000 episodes. (23.50%)\n",
      "Total loss:\t 317873.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "472.83\t\t19009.83\t\t336887.69\n",
      "Epside Return: [-1082.3]\n",
      "\n",
      "[7] Process\n",
      "47500/200000 episodes. (23.75%)\n",
      "Total loss:\t 35728.695\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.01\t\t-757.00\t\t34976.11\n",
      "Epside Return: [-1110.0]\n",
      "\n",
      "[7] Process\n",
      "48000/200000 episodes. (24.00%)\n",
      "Total loss:\t 62165.74\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.67\t\t7940.57\t\t70110.89\n",
      "Epside Return: [-1121.2]\n",
      "\n",
      "[0] Process\n",
      "48500/200000 episodes. (24.25%)\n",
      "Total loss:\t 45437.504\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "435.54\t\t131.86\t\t45573.72\n",
      "Epside Return: [-1123.9]\n",
      "\n",
      "[3] Process\n",
      "49000/200000 episodes. (24.50%)\n",
      "Total loss:\t 119612.414\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.67\t\t10057.68\t\t129674.68\n",
      "Epside Return: [-1084.1]\n",
      "\n",
      "[1] Process\n",
      "49500/200000 episodes. (24.75%)\n",
      "Total loss:\t 37813.164\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.84\t\t-550.72\t\t37266.85\n",
      "Epside Return: [-1069.3]\n",
      "\n",
      "[6] Process\n",
      "50000/200000 episodes. (25.00%)\n",
      "Total loss:\t 55405.977\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.45\t\t-1817.79\t\t53592.62\n",
      "Epside Return: [-1082.1]\n",
      "\n",
      "[3] Process\n",
      "50500/200000 episodes. (25.25%)\n",
      "Total loss:\t 41450.91\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "439.78\t\t-1482.03\t\t39973.28\n",
      "Epside Return: [-1075.1]\n",
      "\n",
      "[0] Process\n",
      "51000/200000 episodes. (25.50%)\n",
      "Total loss:\t 54769.79\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "433.90\t\t-2269.12\t\t52505.01\n",
      "Epside Return: [-1118.4]\n",
      "\n",
      "[4] Process\n",
      "51500/200000 episodes. (25.75%)\n",
      "Total loss:\t 28043.238\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.78\t\t854.09\t\t28901.78\n",
      "Epside Return: [-1090.0]\n",
      "\n",
      "[7] Process\n",
      "52000/200000 episodes. (26.00%)\n",
      "Total loss:\t 30522.861\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "432.43\t\t951.94\t\t31479.13\n",
      "Epside Return: [-1163.6]\n",
      "\n",
      "[0] Process\n",
      "52500/200000 episodes. (26.25%)\n",
      "Total loss:\t 47626.48\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.91\t\t6470.73\t\t54101.77\n",
      "Epside Return: [-1072.4]\n",
      "\n",
      "[0] Process\n",
      "53000/200000 episodes. (26.50%)\n",
      "Total loss:\t 44584.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.64\t\t5586.46\t\t50175.03\n",
      "Epside Return: [-1104.5]\n",
      "\n",
      "[0] Process\n",
      "53500/200000 episodes. (26.75%)\n",
      "Total loss:\t 61289.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.79\t\t6474.92\t\t67768.69\n",
      "Epside Return: [-1134.1]\n",
      "\n",
      "[0] Process\n",
      "54000/200000 episodes. (27.00%)\n",
      "Total loss:\t 47156.914\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "414.94\t\t-1557.88\t\t45603.19\n",
      "Epside Return: [-1095.9]\n",
      "\n",
      "[7] Process\n",
      "54500/200000 episodes. (27.25%)\n",
      "Total loss:\t 79812.555\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.61\t\t6535.12\t\t86352.23\n",
      "Epside Return: [-1065.6]\n",
      "\n",
      "[2] Process\n",
      "55000/200000 episodes. (27.50%)\n",
      "Total loss:\t 39940.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "450.90\t\t4703.45\t\t44648.12\n",
      "Epside Return: [-1103.0]\n",
      "\n",
      "[5] Process\n",
      "55500/200000 episodes. (27.75%)\n",
      "Total loss:\t 32958.395\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.13\t\t266.20\t\t33229.02\n",
      "Epside Return: [-1076.5]\n",
      "\n",
      "[1] Process\n",
      "56000/200000 episodes. (28.00%)\n",
      "Total loss:\t 40998.23\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "439.90\t\t-935.87\t\t40066.76\n",
      "Epside Return: [-1082.6]\n",
      "\n",
      "[5] Process\n",
      "56500/200000 episodes. (28.25%)\n",
      "Total loss:\t 57928.773\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "430.10\t\t-2565.52\t\t55367.55\n",
      "Epside Return: [-1104.6]\n",
      "\n",
      "[5] Process\n",
      "57000/200000 episodes. (28.50%)\n",
      "Total loss:\t 37701.348\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.52\t\t-281.49\t\t37424.25\n",
      "Epside Return: [-1087.0]\n",
      "\n",
      "[5] Process\n",
      "57500/200000 episodes. (28.75%)\n",
      "Total loss:\t 34151.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.57\t\t3423.92\t\t37579.73\n",
      "Epside Return: [-1090.8]\n",
      "\n",
      "[1] Process\n",
      "58000/200000 episodes. (29.00%)\n",
      "Total loss:\t 41514.293\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.77\t\t-536.32\t\t40982.39\n",
      "Epside Return: [-1076.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1] Process\n",
      "58500/200000 episodes. (29.25%)\n",
      "Total loss:\t 41478.105\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.12\t\t1781.13\t\t43263.68\n",
      "Epside Return: [-1045.2]\n",
      "\n",
      "[0] Process\n",
      "59000/200000 episodes. (29.50%)\n",
      "Total loss:\t 34153.95\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.85\t\t1146.71\t\t35305.05\n",
      "Epside Return: [-1057.1]\n",
      "\n",
      "[6] Process\n",
      "59500/200000 episodes. (29.75%)\n",
      "Total loss:\t 70262.945\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "457.51\t\t7601.68\t\t77869.20\n",
      "Epside Return: [-1085.0]\n",
      "\n",
      "[4] Process\n",
      "60000/200000 episodes. (30.00%)\n",
      "Total loss:\t 50519.016\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "437.21\t\t-2283.58\t\t48239.81\n",
      "Epside Return: [-1052.5]\n",
      "\n",
      "[2] Process\n",
      "60500/200000 episodes. (30.25%)\n",
      "Total loss:\t 41185.848\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.25\t\t-984.48\t\t40205.73\n",
      "Epside Return: [-1088.3]\n",
      "\n",
      "[0] Process\n",
      "61000/200000 episodes. (30.50%)\n",
      "Total loss:\t 55105.633\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.49\t\t-2742.88\t\t52367.23\n",
      "Epside Return: [-1064.6]\n",
      "\n",
      "[4] Process\n",
      "61500/200000 episodes. (30.75%)\n",
      "Total loss:\t 45888.27\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "423.20\t\t-1148.23\t\t44744.27\n",
      "Epside Return: [-1054.4]\n",
      "\n",
      "[4] Process\n",
      "62000/200000 episodes. (31.00%)\n",
      "Total loss:\t 40520.97\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "429.61\t\t-743.92\t\t39781.35\n",
      "Epside Return: [-1084.5]\n",
      "\n",
      "[0] Process\n",
      "62500/200000 episodes. (31.25%)\n",
      "Total loss:\t 50976.652\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "437.38\t\t-1804.11\t\t49176.92\n",
      "Epside Return: [-1070.6]\n",
      "\n",
      "[7] Process\n",
      "63000/200000 episodes. (31.50%)\n",
      "Total loss:\t 33719.254\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "431.74\t\t-3.52\t\t33720.05\n",
      "Epside Return: [-1072.3]\n",
      "\n",
      "[7] Process\n",
      "63500/200000 episodes. (31.75%)\n",
      "Total loss:\t 49145.426\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "419.40\t\t-1507.69\t\t47641.93\n",
      "Epside Return: [-1102.1]\n",
      "\n",
      "[4] Process\n",
      "64000/200000 episodes. (32.00%)\n",
      "Total loss:\t 34489.035\n",
      "441.31\t\t192.29\t\t34685.74\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "Epside Return: [-1087.6]\n",
      "\n",
      "[3] Process\n",
      "64500/200000 episodes. (32.25%)\n",
      "Total loss:\t 98368.89\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "456.34\t\t7408.01\t\t105781.47\n",
      "Epside Return: [-1094.7]\n",
      "\n",
      "[1] Process\n",
      "65000/200000 episodes. (32.50%)\n",
      "Total loss:\t 32301.87\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.43\t\t4247.54\t\t36553.90\n",
      "Epside Return: [-1086.5]\n",
      "\n",
      "[6] Process\n",
      "65500/200000 episodes. (32.75%)\n",
      "Total loss:\t 49695.51\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "417.86\t\t-2166.78\t\t47532.91\n",
      "Epside Return: [-1097.2]\n",
      "\n",
      "[7] Process\n",
      "66000/200000 episodes. (33.00%)\n",
      "Total loss:\t 51876.38\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "432.89\t\t-1665.85\t\t50214.86\n",
      "Epside Return: [-1050.6]\n",
      "\n",
      "[6] Process\n",
      "66500/200000 episodes. (33.25%)\n",
      "Total loss:\t 37326.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.63\t\t1389.58\t\t38720.59\n",
      "Epside Return: [-1083.1]\n",
      "\n",
      "[6] Process\n",
      "67000/200000 episodes. (33.50%)\n",
      "Total loss:\t 50448.2\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "412.39\t\t-1277.33\t\t49174.99\n",
      "Epside Return: [-1087.0]\n",
      "\n",
      "[2] Process\n",
      "67500/200000 episodes. (33.75%)\n",
      "Total loss:\t 35248.93\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.97\t\t-789.52\t\t34463.80\n",
      "Epside Return: [-1100.7]\n",
      "\n",
      "[0] Process\n",
      "68000/200000 episodes. (34.00%)\n",
      "Total loss:\t 33579.418\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "435.57\t\t1092.32\t\t34676.09\n",
      "Epside Return: [-1099.9]\n",
      "\n",
      "[7] Process\n",
      "68500/200000 episodes. (34.25%)\n",
      "Total loss:\t 38059.883\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.02\t\t-604.31\t\t37460.02\n",
      "Epside Return: [-1118.1]\n",
      "\n",
      "[2] Process\n",
      "69000/200000 episodes. (34.50%)\n",
      "Total loss:\t 30957.746\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "439.72\t\t669.50\t\t31631.64\n",
      "Epside Return: [-1090.9]\n",
      "\n",
      "[0] Process\n",
      "69500/200000 episodes. (34.75%)\n",
      "Total loss:\t 48931.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.14\t\t-2321.83\t\t46613.82\n",
      "Epside Return: [-1105.1]\n",
      "\n",
      "[5] Process\n",
      "70000/200000 episodes. (35.00%)\n",
      "Total loss:\t 29202.096\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.01\t\t1314.65\t\t30521.20\n",
      "Epside Return: [-1076.1]\n",
      "\n",
      "[6] Process\n",
      "70500/200000 episodes. (35.25%)\n",
      "Total loss:\t 22714.445\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.09\t\t2838.92\t\t25557.83\n",
      "Epside Return: [-1114.1]\n",
      "\n",
      "[2] Process\n",
      "71000/200000 episodes. (35.50%)\n",
      "Total loss:\t 45801.66\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.57\t\t-1390.06\t\t44416.00\n",
      "Epside Return: [-1086.7]\n",
      "\n",
      "[4] Process\n",
      "71500/200000 episodes. (35.75%)\n",
      "Total loss:\t 104333.42\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "462.70\t\t10575.26\t\t114913.30\n",
      "Epside Return: [-1115.3]\n",
      "\n",
      "[4] Process\n",
      "72000/200000 episodes. (36.00%)\n",
      "Total loss:\t 81758.195\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "460.42\t\t8756.85\t\t90519.64\n",
      "Epside Return: [-1103.6]\n",
      "\n",
      "[7] Process\n",
      "72500/200000 episodes. (36.25%)\n",
      "Total loss:\t 30950.668\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.18\t\t2770.23\t\t33725.35\n",
      "Epside Return: [-1082.4]\n",
      "\n",
      "[3] Process\n",
      "73000/200000 episodes. (36.50%)\n",
      "Total loss:\t 44340.426\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "414.86\t\t-110.58\t\t44234.00\n",
      "Epside Return: [-1117.6]\n",
      "\n",
      "[6] Process\n",
      "73500/200000 episodes. (36.75%)\n",
      "Total loss:\t 57573.277\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.85\t\t7034.20\t\t64612.04\n",
      "Epside Return: [-1086.9]\n",
      "\n",
      "[2] Process\n",
      "74000/200000 episodes. (37.00%)\n",
      "Total loss:\t 33755.34\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.31\t\t5043.33\t\t38803.18\n",
      "Epside Return: [-1098.8]\n",
      "\n",
      "[7] Process\n",
      "74500/200000 episodes. (37.25%)\n",
      "Total loss:\t 48088.17\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.45\t\t-1500.76\t\t46591.88\n",
      "Epside Return: [-1112.7]\n",
      "\n",
      "[3] Process\n",
      "75000/200000 episodes. (37.50%)\n",
      "Total loss:\t 28269.96\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.82\t\t1252.87\t\t29527.21\n",
      "Epside Return: [-1103.3]\n",
      "\n",
      "[3] Process\n",
      "75500/200000 episodes. (37.75%)\n",
      "Total loss:\t 49164.395\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.90\t\t-2462.79\t\t46706.13\n",
      "Epside Return: [-1100.7]\n",
      "\n",
      "[3] Process\n",
      "76000/200000 episodes. (38.00%)\n",
      "Total loss:\t 31107.984\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.99\t\t581.75\t\t31694.16\n",
      "Epside Return: [-1065.8]\n",
      "\n",
      "[1] Process\n",
      "76500/200000 episodes. (38.25%)\n",
      "Total loss:\t 62649.676\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.74\t\t4583.52\t\t67237.71\n",
      "Epside Return: [-1100.9]\n",
      "\n",
      "[3] Process\n",
      "77000/200000 episodes. (38.50%)\n",
      "Total loss:\t 34692.39\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.07\t\t4875.89\t\t39572.80\n",
      "Epside Return: [-1055.6]\n",
      "\n",
      "[3] Process\n",
      "77500/200000 episodes. (38.75%)\n",
      "Total loss:\t 57677.668\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.24\t\t-2964.19\t\t54717.88\n",
      "Epside Return: [-1063.6]\n",
      "\n",
      "[3] Process\n",
      "78000/200000 episodes. (39.00%)\n",
      "Total loss:\t 37606.17\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "437.84\t\t-411.77\t\t37198.78\n",
      "Epside Return: [-1031.1]\n",
      "\n",
      "[6] Process\n",
      "78500/200000 episodes. (39.25%)\n",
      "Total loss:\t 50484.016\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.57\t\t-2493.23\t\t47995.23\n",
      "Epside Return: [-1074.1]\n",
      "\n",
      "[4] Process\n",
      "79000/200000 episodes. (39.50%)\n",
      "Total loss:\t 55217.242\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.53\t\t5104.60\t\t60326.36\n",
      "Epside Return: [-1060.6]\n",
      "\n",
      "[4] Process\n",
      "79500/200000 episodes. (39.75%)\n",
      "Total loss:\t 40940.902\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.34\t\t-1165.25\t\t39780.01\n",
      "Epside Return: [-1071.8]\n",
      "\n",
      "[0] Process\n",
      "80000/200000 episodes. (40.00%)\n",
      "Total loss:\t 46712.367\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "421.86\t\t-1405.60\t\t45310.98\n",
      "Epside Return: [-1042.2]\n",
      "\n",
      "[7] Process\n",
      "80500/200000 episodes. (40.25%)\n",
      "Total loss:\t 134014.88\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "464.71\t\t12236.53\t\t146256.05\n",
      "Epside Return: [-1087.2]\n",
      "\n",
      "[7] Process\n",
      "81000/200000 episodes. (40.50%)\n",
      "Total loss:\t 34284.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.52\t\t3407.14\t\t37696.30\n",
      "Epside Return: [-1100.0]\n",
      "\n",
      "[4] Process\n",
      "81500/200000 episodes. (40.75%)\n",
      "Total loss:\t 42074.746\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.02\t\t-1494.25\t\t40584.86\n",
      "Epside Return: [-1139.4]\n",
      "\n",
      "[3] Process\n",
      "82000/200000 episodes. (41.00%)\n",
      "Total loss:\t 53369.516\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "435.34\t\t-1883.04\t\t51490.83\n",
      "Epside Return: [-1089.5]\n",
      "\n",
      "[5] Process\n",
      "82500/200000 episodes. (41.25%)\n",
      "Total loss:\t 52257.023\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.74\t\t3390.76\t\t55652.30\n",
      "Epside Return: [-1078.0]\n",
      "\n",
      "[4] Process\n",
      "83000/200000 episodes. (41.50%)\n",
      "Total loss:\t 41916.93\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.08\t\t-640.26\t\t41281.03\n",
      "Epside Return: [-1064.2]\n",
      "\n",
      "[3] Process\n",
      "83500/200000 episodes. (41.75%)\n",
      "Total loss:\t 36987.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.12\t\t1571.75\t\t38563.62\n",
      "Epside Return: [-1091.0]\n",
      "\n",
      "[4] Process\n",
      "84000/200000 episodes. (42.00%)\n",
      "Total loss:\t 34590.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.65\t\t687.60\t\t35282.52\n",
      "Epside Return: [-1080.5]\n",
      "\n",
      "[2] Process\n",
      "84500/200000 episodes. (42.25%)\n",
      "Total loss:\t 29176.695\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.85\t\t1319.38\t\t30500.50\n",
      "Epside Return: [-1137.6]\n",
      "\n",
      "[0] Process\n",
      "85000/200000 episodes. (42.50%)\n",
      "Total loss:\t 39256.145\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.78\t\t-520.88\t\t38739.63\n",
      "Epside Return: [-1074.9]\n",
      "\n",
      "[6] Process\n",
      "85500/200000 episodes. (42.75%)\n",
      "Total loss:\t 299305.53\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "471.75\t\t18366.17\t\t317676.44\n",
      "Epside Return: [-1069.9]\n",
      "\n",
      "[3] Process\n",
      "86000/200000 episodes. (43.00%)\n",
      "Total loss:\t 47805.09\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.55\t\t2332.30\t\t50141.92\n",
      "Epside Return: [-1095.5]\n",
      "\n",
      "[4] Process\n",
      "86500/200000 episodes. (43.25%)\n",
      "Total loss:\t 44844.773\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "453.30\t\t5526.12\t\t50375.42\n",
      "Epside Return: [-1057.2]\n",
      "\n",
      "[5] Process\n",
      "87000/200000 episodes. (43.50%)\n",
      "Total loss:\t 52424.61\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "416.10\t\t-2083.50\t\t50345.27\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epside Return: [-1101.7]\n",
      "\n",
      "[2] Process\n",
      "87500/200000 episodes. (43.75%)\n",
      "Total loss:\t 196747.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "466.89\t\t14172.87\t\t210925.11\n",
      "Epside Return: [-1063.0]\n",
      "\n",
      "[1] Process\n",
      "88000/200000 episodes. (44.00%)\n",
      "Total loss:\t 46025.75\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.98\t\t-1184.91\t\t44845.21\n",
      "Epside Return: [-1129.8]\n",
      "\n",
      "[0] Process\n",
      "88500/200000 episodes. (44.25%)\n",
      "Total loss:\t 26529.982\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "448.12\t\t3484.26\t\t30018.72\n",
      "Epside Return: [-1100.9]\n",
      "\n",
      "[6] Process\n",
      "89000/200000 episodes. (44.50%)\n",
      "Total loss:\t 39656.586\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "430.16\t\t-194.67\t\t39466.22\n",
      "Epside Return: [-1066.6]\n",
      "\n",
      "[1] Process\n",
      "89500/200000 episodes. (44.75%)\n",
      "Total loss:\t 34715.457\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.00\t\t511.75\t\t35231.59\n",
      "Epside Return: [-1069.1]\n",
      "\n",
      "[6] Process\n",
      "90000/200000 episodes. (45.00%)\n",
      "Total loss:\t 322036.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "472.87\t\t19297.00\t\t341338.19\n",
      "Epside Return: [-1071.7]\n",
      "\n",
      "[0] Process\n",
      "90500/200000 episodes. (45.25%)\n",
      "Total loss:\t 44248.535\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.67\t\t-1727.88\t\t42525.08\n",
      "Epside Return: [-1043.8]\n",
      "\n",
      "[0] Process\n",
      "91000/200000 episodes. (45.50%)\n",
      "Total loss:\t 95296.086\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.26\t\t5383.61\t\t100684.29\n",
      "Epside Return: [-1104.3]\n",
      "\n",
      "[2] Process\n",
      "91500/200000 episodes. (45.75%)\n",
      "Total loss:\t 40071.72\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "415.82\t\t-579.17\t\t39496.70\n",
      "Epside Return: [-1117.7]\n",
      "\n",
      "[3] Process\n",
      "92000/200000 episodes. (46.00%)\n",
      "Total loss:\t 35569.543\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "431.55\t\t-419.61\t\t35154.25\n",
      "Epside Return: [-1054.3]\n",
      "\n",
      "[1] Process\n",
      "92500/200000 episodes. (46.25%)\n",
      "Total loss:\t 57977.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.38\t\t-3051.15\t\t54930.50\n",
      "Epside Return: [-1074.9]\n",
      "\n",
      "[1] Process\n",
      "93000/200000 episodes. (46.50%)\n",
      "Total loss:\t 52075.254\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.76\t\t5576.02\t\t57655.82\n",
      "Epside Return: [-1080.3]\n",
      "\n",
      "[7] Process\n",
      "93500/200000 episodes. (46.75%)\n",
      "Total loss:\t 46933.914\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "435.18\t\t-1626.53\t\t45311.73\n",
      "Epside Return: [-1037.1]\n",
      "\n",
      "[6] Process\n",
      "94000/200000 episodes. (47.00%)\n",
      "Total loss:\t 50984.41\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "417.99\t\t-2079.03\t\t48909.55\n",
      "Epside Return: [-1068.6]\n",
      "\n",
      "[5] Process\n",
      "94500/200000 episodes. (47.25%)\n",
      "Total loss:\t 27815.502\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "448.88\t\t3692.40\t\t31512.39\n",
      "Epside Return: [-1081.0]\n",
      "\n",
      "[4] Process\n",
      "95000/200000 episodes. (47.50%)\n",
      "Total loss:\t 46382.223\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.64\t\t-1233.45\t\t45153.16\n",
      "Epside Return: [-1073.3]\n",
      "\n",
      "[0] Process\n",
      "95500/200000 episodes. (47.75%)\n",
      "Total loss:\t 45084.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "416.48\t\t-428.17\t\t44660.78\n",
      "Epside Return: [-1097.7]\n",
      "\n",
      "[0] Process\n",
      "96000/200000 episodes. (48.00%)\n",
      "Total loss:\t 45523.477\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.07\t\t-1557.68\t\t43970.33\n",
      "Epside Return: [-1098.1]\n",
      "\n",
      "[4] Process\n",
      "96500/200000 episodes. (48.25%)\n",
      "Total loss:\t 39843.19\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.07\t\t-978.32\t\t38869.30\n",
      "Epside Return: [-1101.1]\n",
      "\n",
      "[4] Process\n",
      "97000/200000 episodes. (48.50%)\n",
      "Total loss:\t 48555.574\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.67\t\t-1982.08\t\t46577.88\n",
      "\n",
      "Epside Return: [-1124.2]\n",
      "[7] Process\n",
      "97500/200000 episodes. (48.75%)\n",
      "Total loss:\t 62634.91\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.56\t\t-3433.44\t\t59205.99\n",
      "Epside Return: [-1089.2]\n",
      "\n",
      "[3] Process\n",
      "98000/200000 episodes. (49.00%)\n",
      "Total loss:\t 33542.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.40\t\t1002.25\t\t34549.15\n",
      "Epside Return: [-1056.8]\n",
      "\n",
      "[0] Process\n",
      "98500/200000 episodes. (49.25%)\n",
      "Total loss:\t 50446.152\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.64\t\t-1436.08\t\t49014.54\n",
      "Epside Return: [-1092.6]\n",
      "\n",
      "[3] Process\n",
      "99000/200000 episodes. (49.50%)\n",
      "Total loss:\t 121260.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.27\t\t10771.48\t\t132037.02\n",
      "Epside Return: [-1068.8]\n",
      "\n",
      "[7] Process\n",
      "99500/200000 episodes. (49.75%)\n",
      "Total loss:\t 98188.59\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "459.08\t\t9587.81\t\t107780.99\n",
      "Epside Return: [-1051.2]\n",
      "\n",
      "[6] Process\n",
      "100000/200000 episodes. (50.00%)\n",
      "Total loss:\t 42681.234\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "407.74\t\t-1198.40\t\t41486.91\n",
      "Epside Return: [-1097.6]\n",
      "\n",
      "[1] Process\n",
      "100500/200000 episodes. (50.25%)\n",
      "Total loss:\t 35204.402\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.41\t\t5257.16\t\t40466.09\n",
      "Epside Return: [-1100.6]\n",
      "\n",
      "[4] Process\n",
      "101000/200000 episodes. (50.50%)\n",
      "Total loss:\t 47485.895\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "387.55\t\t-804.45\t\t46685.32\n",
      "Epside Return: [-1077.4]\n",
      "\n",
      "[4] Process\n",
      "101500/200000 episodes. (50.75%)\n",
      "Total loss:\t 44233.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "439.98\t\t-598.83\t\t43639.23\n",
      "Epside Return: [-1084.0]\n",
      "\n",
      "[4] Process\n",
      "102000/200000 episodes. (51.00%)\n",
      "Total loss:\t 37493.918\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.24\t\t413.43\t\t37911.71\n",
      "Epside Return: [-1092.4]\n",
      "\n",
      "[4] Process\n",
      "102500/200000 episodes. (51.25%)\n",
      "Total loss:\t 37693.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.81\t\t2014.97\t\t39713.10\n",
      "Epside Return: [-1080.2]\n",
      "\n",
      "[5] Process\n",
      "103000/200000 episodes. (51.50%)\n",
      "Total loss:\t 35137.582\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.60\t\t-754.08\t\t34387.93\n",
      "Epside Return: [-1080.2]\n",
      "\n",
      "[3] Process\n",
      "103500/200000 episodes. (51.75%)\n",
      "Total loss:\t 31589.725\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.69\t\t1264.11\t\t32858.25\n",
      "Epside Return: [-1073.9]\n",
      "\n",
      "[1] Process\n",
      "104000/200000 episodes. (52.00%)\n",
      "Total loss:\t 49561.703\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "408.62\t\t-1502.47\t\t48063.32\n",
      "Epside Return: [-1023.3]\n",
      "\n",
      "[0] Process\n",
      "104500/200000 episodes. (52.25%)\n",
      "Total loss:\t 47105.676\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "431.66\t\t-1388.45\t\t45721.54\n",
      "Epside Return: [-1045.3]\n",
      "\n",
      "[4] Process\n",
      "105000/200000 episodes. (52.50%)\n",
      "Total loss:\t 43711.766\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "411.81\t\t-1035.10\t\t42680.79\n",
      "Epside Return: [-1108.8]\n",
      "\n",
      "[7] Process\n",
      "105500/200000 episodes. (52.75%)\n",
      "Total loss:\t 48898.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.27\t\t-1263.52\t\t47639.62\n",
      "Epside Return: [-1078.1]\n",
      "\n",
      "[7] Process\n",
      "106000/200000 episodes. (53.00%)\n",
      "Total loss:\t 30031.352\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.22\t\t2389.04\t\t32424.86\n",
      "Epside Return: [-1087.2]\n",
      "\n",
      "[4] Process\n",
      "106500/200000 episodes. (53.25%)\n",
      "Total loss:\t 37962.49\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.56\t\t889.58\t\t38856.52\n",
      "Epside Return: [-1094.4]\n",
      "\n",
      "[2] Process\n",
      "107000/200000 episodes. (53.50%)\n",
      "Total loss:\t 36506.35\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.89\t\t-497.06\t\t36013.68\n",
      "Epside Return: [-1091.2]\n",
      "\n",
      "[1] Process\n",
      "107500/200000 episodes. (53.75%)\n",
      "Total loss:\t 257838.89\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "470.60\t\t17462.26\t\t275305.84\n",
      "Epside Return: [-1101.0]\n",
      "\n",
      "[2] Process\n",
      "108000/200000 episodes. (54.00%)\n",
      "Total loss:\t 39671.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.33\t\t-757.67\t\t38917.98\n",
      "Epside Return: [-1100.3]\n",
      "\n",
      "[5] Process\n",
      "108500/200000 episodes. (54.25%)\n",
      "Total loss:\t 37462.24\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "435.27\t\t-367.36\t\t37099.23\n",
      "Epside Return: [-1069.3]\n",
      "\n",
      "[0] Process\n",
      "109000/200000 episodes. (54.50%)\n",
      "Total loss:\t 50338.23\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.46\t\t4416.93\t\t54759.66\n",
      "Epside Return: [-1125.9]\n",
      "\n",
      "[1] Process\n",
      "109500/200000 episodes. (54.75%)\n",
      "Total loss:\t 111856.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "459.87\t\t9803.73\t\t121665.03\n",
      "Epside Return: [-1096.6]\n",
      "\n",
      "[7] Process\n",
      "110000/200000 episodes. (55.00%)\n",
      "Total loss:\t 43707.004\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "\n",
      "450.36\t\t4762.80\t\t48474.31\n",
      "Epside Return: [-1105.3]\n",
      "[4] Process\n",
      "110500/200000 episodes. (55.25%)\n",
      "Total loss:\t 70973.15\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "457.22\t\t7840.99\t\t78818.71\n",
      "Epside Return: [-1085.8]\n",
      "\n",
      "[3] Process\n",
      "111000/200000 episodes. (55.50%)\n",
      "Total loss:\t 25954.078\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.35\t\t3021.68\t\t28980.21\n",
      "Epside Return: [-1098.9]\n",
      "\n",
      "[1] Process\n",
      "111500/200000 episodes. (55.75%)\n",
      "Total loss:\t 30678.371\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.16\t\t4337.52\t\t35020.40\n",
      "Epside Return: [-1151.2]\n",
      "\n",
      "[2] Process\n",
      "112000/200000 episodes. (56.00%)\n",
      "Total loss:\t 60918.207\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "457.57\t\t7968.05\t\t68890.83\n",
      "Epside Return: [-1089.1]\n",
      "\n",
      "[7] Process\n",
      "112500/200000 episodes. (56.25%)\n",
      "Total loss:\t 85423.125\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "457.30\t\t8507.43\t\t93935.12\n",
      "Epside Return: [-1059.7]\n",
      "\n",
      "[6] Process\n",
      "113000/200000 episodes. (56.50%)\n",
      "Total loss:\t 48197.938\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.57\t\t-1432.90\t\t46769.39\n",
      "Epside Return: [-1096.4]\n",
      "\n",
      "[6] Process\n",
      "113500/200000 episodes. (56.75%)\n",
      "Total loss:\t 140023.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.73\t\t11787.75\t\t151816.23\n",
      "Epside Return: [-1092.3]\n",
      "\n",
      "[7] Process\n",
      "114000/200000 episodes. (57.00%)\n",
      "Total loss:\t 41338.332\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.33\t\t-1236.98\t\t40105.78\n",
      "Epside Return: [-1065.6]\n",
      "\n",
      "[0] Process\n",
      "114500/200000 episodes. (57.25%)\n",
      "Total loss:\t 44224.586\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.22\t\t-1214.45\t\t43014.59\n",
      "Epside Return: [-1082.8]\n",
      "\n",
      "[3] Process\n",
      "115000/200000 episodes. (57.50%)\n",
      "Total loss:\t 39878.008\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.31\t\t178.16\t\t40060.51\n",
      "Epside Return: [-1081.1]\n",
      "\n",
      "[4] Process\n",
      "115500/200000 episodes. (57.75%)\n",
      "Total loss:\t 48692.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "435.12\t\t-1469.98\t\t47226.43\n",
      "Epside Return: [-1055.1]\n",
      "\n",
      "[5] Process\n",
      "116000/200000 episodes. (58.00%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss:\t 30423.977\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.17\t\t1582.71\t\t32011.16\n",
      "Epside Return: [-1106.3]\n",
      "\n",
      "[1] Process\n",
      "116500/200000 episodes. (58.25%)\n",
      "Total loss:\t 37062.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.16\t\t264.09\t\t37331.32\n",
      "Epside Return: [-1055.6]\n",
      "\n",
      "[0] Process\n",
      "117000/200000 episodes. (58.50%)\n",
      "Total loss:\t 33274.535\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.68\t\t886.21\t\t34165.13\n",
      "Epside Return: [-1085.3]\n",
      "\n",
      "[6] Process\n",
      "117500/200000 episodes. (58.75%)\n",
      "Total loss:\t 68870.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.82\t\t5785.35\t\t74659.97\n",
      "Epside Return: [-1056.3]\n",
      "\n",
      "[1] Process\n",
      "118000/200000 episodes. (59.00%)\n",
      "Total loss:\t 43501.055\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.54\t\t1489.75\t\t44995.20\n",
      "Epside Return: [-1066.3]\n",
      "\n",
      "[5] Process\n",
      "118500/200000 episodes. (59.25%)\n",
      "Total loss:\t 32588.268\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "450.26\t\t4014.24\t\t36607.01\n",
      "Epside Return: [-1097.0]\n",
      "\n",
      "[3] Process\n",
      "119000/200000 episodes. (59.50%)\n",
      "Total loss:\t 25942.07\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.18\t\t2486.63\t\t28433.15\n",
      "Epside Return: [-1057.7]\n",
      "\n",
      "[4] Process\n",
      "119500/200000 episodes. (59.75%)\n",
      "Total loss:\t 37113.875\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.07\t\t4423.70\t\t41542.09\n",
      "Epside Return: [-1081.1]\n",
      "\n",
      "[1] Process\n",
      "120000/200000 episodes. (60.00%)\n",
      "Total loss:\t 38521.07\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "429.56\t\t-65.65\t\t38459.71\n",
      "Epside Return: [-1136.7]\n",
      "\n",
      "[4] Process\n",
      "120500/200000 episodes. (60.25%)\n",
      "Total loss:\t 24447.463\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.00\t\t1700.99\t\t26152.86\n",
      "Epside Return: [-1074.4]\n",
      "\n",
      "[3] Process\n",
      "121000/200000 episodes. (60.50%)\n",
      "Total loss:\t 56820.137\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.69\t\t-3298.61\t\t53525.99\n",
      "Epside Return: [-1122.4]\n",
      "\n",
      "[0] Process\n",
      "121500/200000 episodes. (60.75%)\n",
      "Total loss:\t 46462.125\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.98\t\t-1259.53\t\t45207.07\n",
      "Epside Return: [-1082.1]\n",
      "\n",
      "[4] Process\n",
      "122000/200000 episodes. (61.00%)\n",
      "Total loss:\t 39080.19\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.43\t\t-751.71\t\t38332.90\n",
      "Epside Return: [-1073.3]\n",
      "\n",
      "[7] Process\n",
      "122500/200000 episodes. (61.25%)\n",
      "Total loss:\t 74025.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.05\t\t5672.40\t\t79702.09\n",
      "Epside Return: [-1106.8]\n",
      "\n",
      "[6] Process\n",
      "123000/200000 episodes. (61.50%)\n",
      "Total loss:\t 49890.42\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.16\t\t-2250.73\t\t47644.11\n",
      "Epside Return: [-1094.2]\n",
      "\n",
      "[2] Process\n",
      "123500/200000 episodes. (61.75%)\n",
      "Total loss:\t 77112.555\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "456.01\t\t7632.42\t\t84749.54\n",
      "Epside Return: [-1079.3]\n",
      "\n",
      "[1] Process\n",
      "124000/200000 episodes. (62.00%)\n",
      "Total loss:\t 78647.58\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.80\t\t7934.96\t\t86587.09\n",
      "Epside Return: [-1087.0]\n",
      "\n",
      "[2] Process\n",
      "124500/200000 episodes. (62.25%)\n",
      "Total loss:\t 99441.41\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "458.91\t\t9377.61\t\t108823.60\n",
      "Epside Return: [-1066.6]\n",
      "\n",
      "[3] Process\n",
      "125000/200000 episodes. (62.50%)\n",
      "Total loss:\t 41009.64\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "399.09\t\t-238.80\t\t40774.83\n",
      "Epside Return: [-1105.9]\n",
      "\n",
      "[1] Process\n",
      "125500/200000 episodes. (62.75%)\n",
      "Total loss:\t 27945.414\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.43\t\t2191.48\t\t30141.33\n",
      "Epside Return: [-1060.2]\n",
      "\n",
      "[4] Process\n",
      "126000/200000 episodes. (63.00%)\n",
      "Total loss:\t 46139.49\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.61\t\t-1376.40\t\t44767.44\n",
      "Epside Return: [-1052.3]\n",
      "\n",
      "[7] Process\n",
      "126500/200000 episodes. (63.25%)\n",
      "Total loss:\t 49195.527\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "421.95\t\t-1695.03\t\t47504.72\n",
      "Epside Return: [-1086.4]\n",
      "\n",
      "[1] Process\n",
      "127000/200000 episodes. (63.50%)\n",
      "Total loss:\t 49730.28\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.90\t\t-2305.97\t\t47428.79\n",
      "Epside Return: [-1103.5]\n",
      "\n",
      "[7] Process\n",
      "127500/200000 episodes. (63.75%)\n",
      "Total loss:\t 170402.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "467.21\t\t13389.92\t\t183797.19\n",
      "Epside Return: [-1080.7]\n",
      "\n",
      "[4] Process\n",
      "128000/200000 episodes. (64.00%)\n",
      "Total loss:\t 28685.545\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.83\t\t929.97\t\t29619.92\n",
      "Epside Return: [-1089.9]\n",
      "\n",
      "[5] Process\n",
      "128500/200000 episodes. (64.25%)\n",
      "Total loss:\t 46691.164\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.38\t\t1241.66\t\t47937.34\n",
      "Epside Return: [-1092.0]\n",
      "\n",
      "[3] Process\n",
      "129000/200000 episodes. (64.50%)\n",
      "Total loss:\t 31802.934\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.60\t\t3520.46\t\t35327.86\n",
      "Epside Return: [-1105.3]\n",
      "\n",
      "[1] Process\n",
      "129500/200000 episodes. (64.75%)\n",
      "Total loss:\t 45512.293\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "428.50\t\t-1209.15\t\t44307.43\n",
      "Epside Return: [-1101.8]\n",
      "\n",
      "[5] Process\n",
      "130000/200000 episodes. (65.00%)\n",
      "Total loss:\t 82025.984\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "459.56\t\t8930.70\t\t90961.28\n",
      "Epside Return: [-1083.0]\n",
      "\n",
      "[4] Process\n",
      "130500/200000 episodes. (65.25%)\n",
      "Total loss:\t 119332.15\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.13\t\t9727.53\t\t129064.29\n",
      "Epside Return: [-1049.1]\n",
      "\n",
      "[6] Process\n",
      "131000/200000 episodes. (65.50%)\n",
      "Total loss:\t 49601.45\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "433.83\t\t-1293.59\t\t48312.20\n",
      "Epside Return: [-1132.1]\n",
      "\n",
      "[2] Process\n",
      "131500/200000 episodes. (65.75%)\n",
      "Total loss:\t 40965.01\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "428.15\t\t-618.26\t\t40351.03\n",
      "Epside Return: [-1099.0]\n",
      "\n",
      "[4] Process\n",
      "132000/200000 episodes. (66.00%)\n",
      "Total loss:\t 46410.742\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.51\t\t-1178.39\t\t45236.87\n",
      "Epside Return: [-1099.4]\n",
      "\n",
      "[7] Process\n",
      "132500/200000 episodes. (66.25%)\n",
      "Total loss:\t 53193.19\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "437.99\t\t-1085.01\t\t52112.57\n",
      "Epside Return: [-1073.6]\n",
      "\n",
      "[2] Process\n",
      "133000/200000 episodes. (66.50%)\n",
      "Total loss:\t 41935.523\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.43\t\t-1090.46\t\t40849.52\n",
      "Epside Return: [-1148.3]\n",
      "\n",
      "[4] Process\n",
      "133500/200000 episodes. (66.75%)\n",
      "Total loss:\t 32948.336\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.36\t\t2131.78\t\t35084.56\n",
      "Epside Return: [-1145.5]\n",
      "\n",
      "[3] Process\n",
      "134000/200000 episodes. (67.00%)\n",
      "Total loss:\t 43953.383\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "430.74\t\t-827.55\t\t43130.14\n",
      "Epside Return: [-1059.2]\n",
      "\n",
      "[0] Process\n",
      "134500/200000 episodes. (67.25%)\n",
      "Total loss:\t 42334.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "450.28\t\t4534.56\t\t46873.06\n",
      "Epside Return: [-1084.5]\n",
      "\n",
      "[4] Process\n",
      "135000/200000 episodes. (67.50%)\n",
      "Total loss:\t 41242.492\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.52\t\t-617.24\t\t40629.63\n",
      "Epside Return: [-1062.0]\n",
      "\n",
      "[0] Process\n",
      "135500/200000 episodes. (67.75%)\n",
      "Total loss:\t 53664.65\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "419.72\t\t-2217.21\t\t51451.64\n",
      "Epside Return: [-1123.8]\n",
      "\n",
      "[2] Process\n",
      "136000/200000 episodes. (68.00%)\n",
      "Total loss:\t 96591.17\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "459.09\t\t8952.47\t\t105548.23\n",
      "Epside Return: [-1096.5]\n",
      "\n",
      "[3] Process\n",
      "136500/200000 episodes. (68.25%)\n",
      "Total loss:\t 44226.484\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.50\t\t-852.67\t\t43378.18\n",
      "Epside Return: [-1093.0]\n",
      "\n",
      "[7] Process\n",
      "137000/200000 episodes. (68.50%)\n",
      "Total loss:\t 55511.875\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "437.49\t\t-2486.07\t\t53030.18\n",
      "Epside Return: [-1074.3]\n",
      "\n",
      "[6] Process\n",
      "137500/200000 episodes. (68.75%)\n",
      "Total loss:\t 26994.383\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.99\t\t3911.92\t\t30910.81\n",
      "Epside Return: [-1114.5]\n",
      "\n",
      "[3] Process\n",
      "138000/200000 episodes. (69.00%)\n",
      "Total loss:\t 43494.51\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.74\t\t-698.72\t\t42800.21\n",
      "Epside Return: [-1093.2]\n",
      "\n",
      "[1] Process\n",
      "138500/200000 episodes. (69.25%)\n",
      "Total loss:\t 32492.143\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.68\t\t184.89\t\t32681.47\n",
      "Epside Return: [-1128.5]\n",
      "\n",
      "[6] Process\n",
      "139000/200000 episodes. (69.50%)\n",
      "Total loss:\t 129449.8\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "462.70\t\t11365.67\t\t140820.09\n",
      "Epside Return: [-1066.3]\n",
      "\n",
      "[7] Process\n",
      "139500/200000 episodes. (69.75%)\n",
      "Total loss:\t 37254.945\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "450.73\t\t4201.61\t\t41461.07\n",
      "Epside Return: [-1112.7]\n",
      "\n",
      "[4] Process\n",
      "140000/200000 episodes. (70.00%)\n",
      "Total loss:\t 41106.414\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "423.97\t\t-350.89\t\t40759.76\n",
      "Epside Return: [-1111.3]\n",
      "\n",
      "[3] Process\n",
      "140500/200000 episodes. (70.25%)\n",
      "Total loss:\t 83366.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.61\t\t7783.62\t\t91154.20\n",
      "Epside Return: [-1073.4]\n",
      "\n",
      "[0] Process\n",
      "141000/200000 episodes. (70.50%)\n",
      "Total loss:\t 51157.688\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "415.65\t\t-1460.16\t\t49701.69\n",
      "Epside Return: [-1080.7]\n",
      "\n",
      "[2] Process\n",
      "141500/200000 episodes. (70.75%)\n",
      "Total loss:\t 43258.56\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.55\t\t-1095.34\t\t42167.56\n",
      "Epside Return: [-1086.3]\n",
      "\n",
      "[6] Process\n",
      "142000/200000 episodes. (71.00%)\n",
      "Total loss:\t 49468.09\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.44\t\t-2104.66\t\t47367.87\n",
      "Epside Return: [-1064.0]\n",
      "\n",
      "[1] Process\n",
      "142500/200000 episodes. (71.25%)\n",
      "Total loss:\t 53949.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.20\t\t-2208.26\t\t51745.88\n",
      "Epside Return: [-1090.3]\n",
      "\n",
      "[2] Process\n",
      "143000/200000 episodes. (71.50%)\n",
      "Total loss:\t 39304.13\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.98\t\t-477.11\t\t38831.45\n",
      "Epside Return: [-1052.0]\n",
      "\n",
      "[5] Process\n",
      "143500/200000 episodes. (71.75%)\n",
      "Total loss:\t 48069.793\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.32\t\t-1826.02\t\t46248.17\n",
      "Epside Return: [-1083.7]\n",
      "\n",
      "[4] Process\n",
      "144000/200000 episodes. (72.00%)\n",
      "Total loss:\t 233568.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "470.43\t\t16076.71\t\t249650.11\n",
      "Epside Return: [-1075.2]\n",
      "\n",
      "[6] Process\n",
      "144500/200000 episodes. (72.25%)\n",
      "Total loss:\t 27521.697\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.60\t\t1279.39\t\t28805.47\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epside Return: [-1091.1]\n",
      "\n",
      "[5] Process\n",
      "145000/200000 episodes. (72.50%)\n",
      "Total loss:\t 105139.445\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "460.03\t\t9401.41\t\t114545.45\n",
      "Epside Return: [-1078.6]\n",
      "\n",
      "[2] Process\n",
      "145500/200000 episodes. (72.75%)\n",
      "Total loss:\t 42537.91\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.88\t\t-563.52\t\t41978.73\n",
      "Epside Return: [-1095.6]\n",
      "\n",
      "[3] Process\n",
      "146000/200000 episodes. (73.00%)\n",
      "Total loss:\t 67669.54\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.19\t\t6713.46\t\t74387.52\n",
      "Epside Return: [-1061.0]\n",
      "\n",
      "[2] Process\n",
      "146500/200000 episodes. (73.25%)\n",
      "Total loss:\t 44407.445\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.97\t\t4459.89\t\t48871.87\n",
      "Epside Return: [-1104.8]\n",
      "\n",
      "[1] Process\n",
      "147000/200000 episodes. (73.50%)\n",
      "Total loss:\t 45398.867\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.56\t\t6645.99\t\t52049.41\n",
      "Epside Return: [-1092.9]\n",
      "\n",
      "[7] Process\n",
      "147500/200000 episodes. (73.75%)\n",
      "Total loss:\t 54050.0\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "418.49\t\t-1855.23\t\t52198.95\n",
      "Epside Return: [-1096.4]\n",
      "\n",
      "[7] Process\n",
      "148000/200000 episodes. (74.00%)\n",
      "Total loss:\t 47673.99\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.84\t\t-2058.23\t\t45620.21\n",
      "Epside Return: [-1049.8]\n",
      "\n",
      "[1] Process\n",
      "148500/200000 episodes. (74.25%)\n",
      "Total loss:\t 113224.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.80\t\t10480.75\t\t123710.03\n",
      "Epside Return: [-1084.8]\n",
      "\n",
      "[5] Process\n",
      "149000/200000 episodes. (74.50%)\n",
      "Total loss:\t 50295.668\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.97\t\t-2484.28\t\t47815.88\n",
      "Epside Return: [-1063.2]\n",
      "\n",
      "[0] Process\n",
      "149500/200000 episodes. (74.75%)\n",
      "Total loss:\t 49196.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.56\t\t-1314.56\t\t47886.45\n",
      "Epside Return: [-1053.7]\n",
      "\n",
      "[1] Process\n",
      "150000/200000 episodes. (75.00%)\n",
      "Total loss:\t 110904.11\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.80\t\t10796.45\t\t121705.20\n",
      "Epside Return: [-1066.9]\n",
      "\n",
      "[2] Process\n",
      "150500/200000 episodes. (75.25%)\n",
      "Total loss:\t 30873.834\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.13\t\t783.65\t\t31661.87\n",
      "Epside Return: [-1083.2]\n",
      "\n",
      "[0] Process\n",
      "151000/200000 episodes. (75.50%)\n",
      "Total loss:\t 65689.84\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "456.70\t\t7664.22\t\t73358.64\n",
      "Epside Return: [-1095.4]\n",
      "\n",
      "[4] Process\n",
      "151500/200000 episodes. (75.75%)\n",
      "Total loss:\t 131603.58\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.02\t\t10371.57\t\t141979.75\n",
      "Epside Return: [-1038.7]\n",
      "\n",
      "[7] Process\n",
      "152000/200000 episodes. (76.00%)\n",
      "Total loss:\t 49499.64\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.41\t\t-1217.72\t\t48286.33\n",
      "Epside Return: [-1053.3]\n",
      "\n",
      "[3] Process\n",
      "152500/200000 episodes. (76.25%)\n",
      "Total loss:\t 36152.977\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "446.49\t\t-560.88\t\t35596.56\n",
      "Epside Return: [-1101.9]\n",
      "\n",
      "[5] Process\n",
      "153000/200000 episodes. (76.50%)\n",
      "Total loss:\t 50415.723\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "423.82\t\t-1186.40\t\t49233.55\n",
      "Epside Return: [-1128.1]\n",
      "\n",
      "[2] Process\n",
      "153500/200000 episodes. (76.75%)\n",
      "Total loss:\t 48353.22\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.04\t\t-1578.98\t\t46778.64\n",
      "Epside Return: [-1097.5]\n",
      "\n",
      "[4] Process\n",
      "154000/200000 episodes. (77.00%)\n",
      "Total loss:\t 50303.48\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.85\t\t-1956.77\t\t48351.14\n",
      "Epside Return: [-1078.9]\n",
      "\n",
      "[7] Process\n",
      "154500/200000 episodes. (77.25%)\n",
      "Total loss:\t 48120.562\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "420.64\t\t-1278.26\t\t46846.51\n",
      "Epside Return: [-1040.3]\n",
      "\n",
      "[4] Process\n",
      "155000/200000 episodes. (77.50%)\n",
      "Total loss:\t 60057.33\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "456.09\t\t6945.33\t\t67007.22\n",
      "Epside Return: [-1051.5]\n",
      "\n",
      "[1] Process\n",
      "155500/200000 episodes. (77.75%)\n",
      "Total loss:\t 27289.076\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "440.63\t\t2210.86\t\t29504.34\n",
      "Epside Return: [-1109.0]\n",
      "\n",
      "[7] Process\n",
      "156000/200000 episodes. (78.00%)\n",
      "Total loss:\t 35791.504\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.32\t\t635.70\t\t36431.55\n",
      "Epside Return: [-1063.5]\n",
      "\n",
      "[4] Process\n",
      "156500/200000 episodes. (78.25%)\n",
      "Total loss:\t 160616.08\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "465.58\t\t13130.82\t\t173751.56\n",
      "Epside Return: [-1107.6]\n",
      "\n",
      "[5] Process\n",
      "157000/200000 episodes. (78.50%)\n",
      "Total loss:\t 47396.176\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.70\t\t-2037.38\t\t45363.22\n",
      "Epside Return: [-1143.7]\n",
      "\n",
      "[4] Process\n",
      "157500/200000 episodes. (78.75%)\n",
      "Total loss:\t 49122.742\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.21\t\t-1121.54\t\t48005.73\n",
      "Epside Return: [-1059.3]\n",
      "\n",
      "[3] Process\n",
      "158000/200000 episodes. (79.00%)\n",
      "Total loss:\t 45120.254\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "392.19\t\t-1322.30\t\t43801.88\n",
      "Epside Return: [-1096.7]\n",
      "\n",
      "[5] Process\n",
      "158500/200000 episodes. (79.25%)\n",
      "Total loss:\t 28479.436\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.41\t\t3100.90\t\t31584.79\n",
      "Epside Return: [-1097.6]\n",
      "\n",
      "[0] Process\n",
      "159000/200000 episodes. (79.50%)\n",
      "Total loss:\t 47211.207\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "432.82\t\t-1275.80\t\t45939.73\n",
      "Epside Return: [-1092.3]\n",
      "\n",
      "[7] Process\n",
      "159500/200000 episodes. (79.75%)\n",
      "Total loss:\t 321419.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "472.55\t\t19103.30\t\t340527.06\n",
      "Epside Return: [-1114.5]\n",
      "\n",
      "[6] Process\n",
      "160000/200000 episodes. (80.00%)\n",
      "Total loss:\t 183380.6\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "464.99\t\t12760.58\t\t196145.83\n",
      "Epside Return: [-1082.7]\n",
      "\n",
      "[4] Process\n",
      "160500/200000 episodes. (80.25%)\n",
      "Total loss:\t 37560.867\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.45\t\t4183.08\t\t41748.42\n",
      "Epside Return: [-1116.2]\n",
      "\n",
      "[3] Process\n",
      "\n",
      "161000/200000 episodes. (80.50%)\n",
      "Total loss:\t 30584.06\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.72\t\t3399.55\t\t33988.11\n",
      "Epside Return: [-1070.2]\n",
      "[6] Process\n",
      "161500/200000 episodes. (80.75%)\n",
      "Total loss:\t 40701.9\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "450.34\t\t4220.43\t\t44926.84\n",
      "Epside Return: [-1115.9]\n",
      "\n",
      "[5] Process\n",
      "162000/200000 episodes. (81.00%)\n",
      "Total loss:\t 36854.004\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.04\t\t5592.93\t\t42451.45\n",
      "Epside Return: [-1130.3]\n",
      "\n",
      "[3] Process\n",
      "162500/200000 episodes. (81.25%)\n",
      "Total loss:\t 28778.639\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.00\t\t1493.72\t\t30276.80\n",
      "Epside Return: [-1082.4]\n",
      "\n",
      "[4] Process\n",
      "163000/200000 episodes. (81.50%)\n",
      "Total loss:\t 29806.002\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.46\t\t1980.81\t\t31791.22\n",
      "Epside Return: [-1098.7]\n",
      "\n",
      "[0] Process\n",
      "163500/200000 episodes. (81.75%)\n",
      "Total loss:\t 47313.246\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.22\t\t4160.45\t\t51478.19\n",
      "Epside Return: [-1116.9]\n",
      "\n",
      "[3] Process\n",
      "164000/200000 episodes. (82.00%)\n",
      "Total loss:\t 224544.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "467.30\t\t14450.59\t\t238999.70\n",
      "Epside Return: [-1108.7]\n",
      "\n",
      "[1] Process\n",
      "164500/200000 episodes. (82.25%)\n",
      "Total loss:\t 42165.89\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.69\t\t3868.04\t\t46038.41\n",
      "Epside Return: [-1074.8]\n",
      "\n",
      "[3] Process\n",
      "165000/200000 episodes. (82.50%)\n",
      "Total loss:\t 49305.49\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.34\t\t-1932.91\t\t47377.00\n",
      "Epside Return: [-1075.3]\n",
      "\n",
      "[6] Process\n",
      "165500/200000 episodes. (82.75%)\n",
      "Total loss:\t 45527.03\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "387.42\t\t-967.07\t\t44563.84\n",
      "Epside Return: [-1069.1]\n",
      "\n",
      "[0] Process\n",
      "166000/200000 episodes. (83.00%)\n",
      "Total loss:\t 34182.87\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.89\t\t867.55\t\t35054.84\n",
      "Epside Return: [-1083.0]\n",
      "\n",
      "[2] Process\n",
      "166500/200000 episodes. (83.25%)\n",
      "Total loss:\t 119836.02\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "462.63\t\t10814.91\t\t130655.55\n",
      "Epside Return: [-1103.7]\n",
      "\n",
      "[4] Process\n",
      "167000/200000 episodes. (83.50%)\n",
      "Total loss:\t 45162.543\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "396.51\t\t-873.56\t\t44292.95\n",
      "Epside Return: [-1079.8]\n",
      "\n",
      "[4] Process\n",
      "167500/200000 episodes. (83.75%)\n",
      "Total loss:\t 33320.21\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.53\t\t3259.01\t\t36583.68\n",
      "Epside Return: [-1069.3]\n",
      "\n",
      "[0] Process\n",
      "168000/200000 episodes. (84.00%)\n",
      "Total loss:\t 41513.695\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "438.05\t\t-736.40\t\t40781.68\n",
      "Epside Return: [-1097.5]\n",
      "\n",
      "[1] Process\n",
      "168500/200000 episodes. (84.25%)\n",
      "Total loss:\t 34988.938\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.93\t\t1404.80\t\t36398.17\n",
      "Epside Return: [-1082.8]\n",
      "\n",
      "[5] Process\n",
      "169000/200000 episodes. (84.50%)\n",
      "Total loss:\t 51237.484\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "409.40\t\t-1991.58\t\t49250.00\n",
      "Epside Return: [-1077.6]\n",
      "\n",
      "[0] Process\n",
      "169500/200000 episodes. (84.75%)\n",
      "Total loss:\t 39062.508\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "442.08\t\t-1120.66\t\t37946.27\n",
      "Epside Return: [-1043.4]\n",
      "\n",
      "[4] Process\n",
      "170000/200000 episodes. (85.00%)\n",
      "Total loss:\t 44988.57\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.18\t\t-1338.65\t\t43654.36\n",
      "Epside Return: [-1078.2]\n",
      "\n",
      "[3] Process\n",
      "170500/200000 episodes. (85.25%)\n",
      "Total loss:\t 110816.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "461.79\t\t10475.43\t\t121296.15\n",
      "Epside Return: [-1060.0]\n",
      "\n",
      "[0] Process\n",
      "171000/200000 episodes. (85.50%)\n",
      "Total loss:\t 45393.64\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "450.59\t\t5243.58\t\t50641.73\n",
      "Epside Return: [-1058.2]\n",
      "\n",
      "[4] Process\n",
      "171500/200000 episodes. (85.75%)\n",
      "Total loss:\t 151859.27\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "462.74\t\t11853.91\t\t163717.80\n",
      "Epside Return: [-1102.4]\n",
      "\n",
      "[2] Process\n",
      "172000/200000 episodes. (86.00%)\n",
      "Total loss:\t 34010.348\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.10\t\t2090.01\t\t36104.80\n",
      "Epside Return: [-1094.7]\n",
      "\n",
      "[5] Process\n",
      "172500/200000 episodes. (86.25%)\n",
      "Total loss:\t 155286.16\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.15\t\t12180.73\t\t167471.50\n",
      "Epside Return: [-1090.2]\n",
      "\n",
      "[4] Process\n",
      "173000/200000 episodes. (86.50%)\n",
      "Total loss:\t 37530.043\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "453.29\t\t5757.03\t\t43291.60\n",
      "Epside Return: [-1094.9]\n",
      "\n",
      "[6] Process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173500/200000 episodes. (86.75%)\n",
      "Total loss:\t 55141.93\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.33\t\t4641.57\t\t59787.99\n",
      "Epside Return: [-1064.3]\n",
      "\n",
      "[5] Process\n",
      "174000/200000 episodes. (87.00%)\n",
      "Total loss:\t 38998.324\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.83\t\t-342.91\t\t38659.76\n",
      "Epside Return: [-1075.3]\n",
      "\n",
      "[6] Process\n",
      "174500/200000 episodes. (87.25%)\n",
      "Total loss:\t 210548.89\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "469.04\t\t15314.57\t\t225868.16\n",
      "Epside Return: [-1090.8]\n",
      "\n",
      "[0] Process\n",
      "175000/200000 episodes. (87.50%)\n",
      "Total loss:\t 50053.223\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.15\t\t-1183.90\t\t48873.73\n",
      "Epside Return: [-1090.2]\n",
      "\n",
      "[3] Process\n",
      "175500/200000 episodes. (87.75%)\n",
      "Total loss:\t 46233.285\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "428.70\t\t-1526.84\t\t44710.73\n",
      "Epside Return: [-1052.3]\n",
      "\n",
      "[2] Process\n",
      "176000/200000 episodes. (88.00%)\n",
      "Total loss:\t 151342.58\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.60\t\t11310.10\t\t162657.31\n",
      "Epside Return: [-1075.2]\n",
      "\n",
      "[5] Process\n",
      "176500/200000 episodes. (88.25%)\n",
      "Total loss:\t 28395.055\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "444.83\t\t2713.80\t\t31113.31\n",
      "Epside Return: [-1102.2]\n",
      "\n",
      "[2] Process\n",
      "177000/200000 episodes. (88.50%)\n",
      "Total loss:\t 89190.73\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "459.64\t\t8839.02\t\t98034.34\n",
      "Epside Return: [-1121.0]\n",
      "\n",
      "[0] Process\n",
      "177500/200000 episodes. (88.75%)\n",
      "Total loss:\t 57471.418\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "431.46\t\t-2269.04\t\t55206.70\n",
      "Epside Return: [-1145.0]\n",
      "\n",
      "[5] Process\n",
      "178000/200000 episodes. (89.00%)\n",
      "Total loss:\t 42367.25\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.59\t\t-1184.09\t\t41187.57\n",
      "Epside Return: [-1120.5]\n",
      "\n",
      "[5] Process\n",
      "178500/200000 episodes. (89.25%)\n",
      "Total loss:\t 33692.613\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.79\t\t1000.59\t\t34697.62\n",
      "Epside Return: [-1091.0]\n",
      "\n",
      "[4] Process\n",
      "179000/200000 episodes. (89.50%)\n",
      "Total loss:\t 38907.445\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "432.18\t\t-901.84\t\t38009.93\n",
      "Epside Return: [-1066.6]\n",
      "\n",
      "[1] Process\n",
      "179500/200000 episodes. (89.75%)\n",
      "Total loss:\t 29279.258\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.58\t\t1265.13\t\t30548.83\n",
      "Epside Return: [-1112.1]\n",
      "\n",
      "[3] Process\n",
      "180000/200000 episodes. (90.00%)\n",
      "Total loss:\t 51270.066\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.80\t\t-2776.75\t\t48497.88\n",
      "Epside Return: [-1080.7]\n",
      "\n",
      "[7] Process\n",
      "180500/200000 episodes. (90.25%)\n",
      "Total loss:\t 38857.535\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.85\t\t1215.07\t\t40077.07\n",
      "Epside Return: [-1091.9]\n",
      "\n",
      "[6] Process\n",
      "181000/200000 episodes. (90.50%)\n",
      "Total loss:\t 60463.023\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.02\t\t3833.39\t\t64300.75\n",
      "Epside Return: [-1035.0]\n",
      "\n",
      "[7] Process\n",
      "181500/200000 episodes. (90.75%)\n",
      "Total loss:\t 153602.12\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "464.96\t\t12297.59\t\t165904.38\n",
      "Epside Return: [-1109.6]\n",
      "\n",
      "[6] Process\n",
      "182000/200000 episodes. (91.00%)\n",
      "Total loss:\t 34748.414\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.58\t\t1575.38\t\t36328.23\n",
      "Epside Return: [-1094.6]\n",
      "\n",
      "[1] Process\n",
      "182500/200000 episodes. (91.25%)\n",
      "Total loss:\t 26921.102\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "448.10\t\t3436.85\t\t30362.43\n",
      "Epside Return: [-1044.0]\n",
      "\n",
      "[5] Process\n",
      "183000/200000 episodes. (91.50%)\n",
      "Total loss:\t 28046.596\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.51\t\t807.93\t\t28858.94\n",
      "Epside Return: [-1082.5]\n",
      "\n",
      "[2] Process\n",
      "183500/200000 episodes. (91.75%)\n",
      "Total loss:\t 42958.598\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "433.65\t\t-567.22\t\t42395.71\n",
      "Epside Return: [-1098.9]\n",
      "\n",
      "[7] Process\n",
      "184000/200000 episodes. (92.00%)\n",
      "Total loss:\t 54896.95\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "420.64\t\t-2208.86\t\t52692.30\n",
      "Epside Return: [-1093.2]\n",
      "\n",
      "[2] Process\n",
      "184500/200000 episodes. (92.25%)\n",
      "Total loss:\t 26008.63\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "449.05\t\t3401.26\t\t29414.38\n",
      "Epside Return: [-1096.0]\n",
      "\n",
      "[1] Process\n",
      "185000/200000 episodes. (92.50%)\n",
      "Total loss:\t 50719.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "428.56\t\t-1269.11\t\t49454.28\n",
      "Epside Return: [-1104.3]\n",
      "\n",
      "[2] Process\n",
      "185500/200000 episodes. (92.75%)\n",
      "Total loss:\t 47465.215\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "436.76\t\t-1813.02\t\t45656.56\n",
      "Epside Return: [-1088.0]\n",
      "\n",
      "[0] Process\n",
      "186000/200000 episodes. (93.00%)\n",
      "Total loss:\t 46652.69\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "422.47\t\t-644.27\t\t46012.65\n",
      "Epside Return: [-1063.6]\n",
      "\n",
      "[7] Process\n",
      "186500/200000 episodes. (93.25%)\n",
      "Total loss:\t 55464.918\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "431.20\t\t-2079.32\t\t53389.91\n",
      "Epside Return: [-1070.1]\n",
      "\n",
      "[2] Process\n",
      "187000/200000 episodes. (93.50%)\n",
      "Total loss:\t 48746.55\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "420.66\t\t-1550.86\t\t47199.89\n",
      "Epside Return: [-1073.2]\n",
      "\n",
      "[0] Process\n",
      "187500/200000 episodes. (93.75%)\n",
      "Total loss:\t 37122.008\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "434.84\t\t-456.42\t\t36669.94\n",
      "Epside Return: [-1052.2]\n",
      "\n",
      "[7] Process\n",
      "188000/200000 episodes. (94.00%)\n",
      "Total loss:\t 32045.78\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "443.42\t\t613.67\t\t32663.88\n",
      "Epside Return: [-1088.1]\n",
      "\n",
      "[2] Process\n",
      "188500/200000 episodes. (94.25%)\n",
      "Total loss:\t 38433.598\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "448.22\t\t3253.19\t\t41691.27\n",
      "Epside Return: [-1117.4]\n",
      "\n",
      "[3] Process\n",
      "189000/200000 episodes. (94.50%)\n",
      "Total loss:\t 36553.76\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "421.34\t\t13.06\t\t36571.04\n",
      "Epside Return: [-1085.6]\n",
      "\n",
      "[2] Process\n",
      "189500/200000 episodes. (94.75%)\n",
      "Total loss:\t 49955.613\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "421.64\t\t-1421.61\t\t48538.22\n",
      "Epside Return: [-1157.8]\n",
      "\n",
      "[0] Process\n",
      "190000/200000 episodes. (95.00%)\n",
      "Total loss:\t 43103.46\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "445.16\t\t320.28\t\t43428.19\n",
      "Epside Return: [-1099.2]\n",
      "\n",
      "[6] Process\n",
      "190500/200000 episodes. (95.25%)\n",
      "Total loss:\t 77051.664\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "455.25\t\t7259.44\t\t84315.66\n",
      "Epside Return: [-1111.1]\n",
      "\n",
      "[0] Process\n",
      "191000/200000 episodes. (95.50%)\n",
      "Total loss:\t 34679.523\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.35\t\t-33.70\t\t34650.24\n",
      "Epside Return: [-1070.0]\n",
      "\n",
      "[1] Process\n",
      "191500/200000 episodes. (95.75%)\n",
      "Total loss:\t 42011.957\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "417.85\t\t138.20\t\t42154.34\n",
      "Epside Return: [-1074.5]\n",
      "\n",
      "[2] Process\n",
      "192000/200000 episodes. (96.00%)\n",
      "Total loss:\t 140750.17\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.63\t\t11921.20\t\t152676.02\n",
      "Epside Return: [-1065.5]\n",
      "\n",
      "[1] Process\n",
      "192500/200000 episodes. (96.25%)\n",
      "Total loss:\t 47080.79\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.01\t\t3969.89\t\t51055.09\n",
      "Epside Return: [-1046.7]\n",
      "\n",
      "[1] Process\n",
      "193000/200000 episodes. (96.50%)\n",
      "Total loss:\t 35301.3\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "439.49\t\t-101.31\t\t35204.39\n",
      "Epside Return: [-1098.3]\n",
      "\n",
      "[3] Process\n",
      "193500/200000 episodes. (96.75%)\n",
      "Total loss:\t 66054.27\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "454.48\t\t6524.67\t\t72583.48\n",
      "Epside Return: [-1096.6]\n",
      "\n",
      "[5] Process\n",
      "194000/200000 episodes. (97.00%)\n",
      "Total loss:\t 244298.44\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "468.63\t\t15663.86\t\t259966.98\n",
      "Epside Return: [-1056.3]\n",
      "\n",
      "[3] Process\n",
      "194500/200000 episodes. (97.25%)\n",
      "Total loss:\t 299958.7\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "470.14\t\t17671.19\t\t317634.56\n",
      "Epside Return: [-1061.9]\n",
      "\n",
      "[5] Process\n",
      "195000/200000 episodes. (97.50%)\n",
      "Total loss:\t 134624.55\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "463.21\t\t11060.00\t\t145689.17\n",
      "Epside Return: [-1089.5]\n",
      "\n",
      "[6] Process\n",
      "195500/200000 episodes. (97.75%)\n",
      "Total loss:\t 41353.08\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "441.97\t\t-771.30\t\t40586.20\n",
      "Epside Return: [-1094.8]\n",
      "\n",
      "[6] Process\n",
      "196000/200000 episodes. (98.00%)\n",
      "Total loss:\t 45715.695\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "452.74\t\t4881.58\t\t50601.80\n",
      "Epside Return: [-1095.8]\n",
      "\n",
      "[3] Process\n",
      "196500/200000 episodes. (98.25%)\n",
      "Total loss:\t 187056.73\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "467.11\t\t13692.57\t\t200753.97\n",
      "Epside Return: [-1076.6]\n",
      "\n",
      "[0] Process\n",
      "197000/200000 episodes. (98.50%)\n",
      "Total loss:\t 41225.312\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "439.58\t\t-1514.33\t\t39715.38\n",
      "Epside Return: [-1079.3]\n",
      "\n",
      "[6] Process\n",
      "197500/200000 episodes. (98.75%)\n",
      "Total loss:\t 43657.27\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "428.77\t\t-598.76\t\t43062.80\n",
      "Epside Return: [-1083.7]\n",
      "\n",
      "[1] Process\n",
      "198000/200000 episodes. (99.00%)\n",
      "Total loss:\t 31831.998\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "447.44\t\t2088.76\t\t33925.23\n",
      "Epside Return: [-1076.4]\n",
      "\n",
      "[6] Process\n",
      "198500/200000 episodes. (99.25%)\n",
      "Total loss:\t 32992.1\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "451.46\t\t4779.76\t\t37776.38\n",
      "Epside Return: [-1077.3]\n",
      "\n",
      "[4] Process\n",
      "199000/200000 episodes. (99.50%)\n",
      "Total loss:\t 206153.77\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "468.99\t\t14955.35\t\t221113.81\n",
      "Epside Return: [-1126.6]\n",
      "\n",
      "[1] Process\n",
      "199500/200000 episodes. (99.75%)\n",
      "Total loss:\t 290507.47\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "471.16\t\t18128.43\t\t308640.62\n",
      "Epside Return: [-1085.8]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-163c6fb02ec4>\", line 39, in train\n",
      "    cur_ep = globalNet.log_episode(ep_return)\n",
      "  File \"<ipython-input-5-970a5bb332c4>\", line 38, in log_episode\n",
      "    self.ep_returns[c] = ep_return\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/sharedctypes.py\", line 226, in __setitem__\n",
      "    self._obj[i] = value\n",
      "IndexError: invalid index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7] Process\n",
      "200000/200000 episodes. (100.00%)\n",
      "Total loss:\t 45544.15\n",
      "Entropy\t\tPolicy\t\tValue\n",
      "435.32\t\t528.71\t\t46077.21\n",
      "Epside Return: [-1129.8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "globalNet = A3C_v3(input_dim, action_dim, MAX_EP, is_global=True)\n",
    "globalNet.share_memory()\n",
    "\n",
    "optimizer = optim.Adam(globalNet.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "lock = mp.Lock()\n",
    "\n",
    "log_df = pd.DataFrame(columns=['running', 'EP', 'Loss', 'Return', 'LR'])\n",
    "fignum = len([f for f in os.listdir() if 'v3_Pendulum' in f and 'png' in f])\n",
    "\n",
    "processes = []\n",
    "for p_idx in range(NUM_THREADS):\n",
    "    p = mp.Process(target=train, args=(lock, globalNet, optimizer, scheduler, t_max, p_idx))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Learning Rate Decay & Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmUAAAEvCAYAAAAEpLawAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdd5gT1foH8O/JZnuFXXoHQUSkLtiuIkWxY2/XXrDX+7sqitdyVez12rBixa4oKCoqqKBIk97rSs3W9Hp+f0zKJJm03WSTXb6f5+FhdzKbnCQzZ97znjJCSgkiIiIiSi9dugtARERERAzKiIiIiDICgzIiIiKiDMCgjIiIiCgDMCgjIiIiygAMyoiIiIgygD7dBWiqiooK2bNnz3QXg4iIiCimxYsXG6SU7bQea/FBWc+ePbFo0aJ0F4OIiIgoJiHEtkiPsfuSiIiIKAMwKCMiIiLKAAzKiIiIiDIAgzIiIiKiDMCgjIiIiCgDMCgjIiIiygAMyoiIiIgyAIMyIiIiogzAoIyIiIgoAzAoIyKKocrkhMMt010MImrlGJQRNSOby4OdZme6i0EabC4PdltcYdvNTg/e3VCPr7YZ01CqzLLb4sLyalu6i0HUajEo28+9tqYWn2xuSHcxEmZ1ebCm1p7uYiTsg431eHt9fbqLQRre21CPt9bVhW13epQM2V5reMDWEs3cZsQjSw1h26WUeHd9HdbVRT6v3lpXh1nbTaksXlQ2twcvrqzB396GzR97LPh4E88naj0YlO3nDDY3NtY70l2MhH251YgvtxpRZ3enuygJ2WONXl4pJT7d3IAdptaXTdtqdOCRpQaYnZ50F0XTPlvLOpYaa0VN5KCryuzC51syNyO40+xCg9ODX3dZAAA/7bRgU0PrO1do/8WgjFoEu9uDaevqUG1TshUNDuXC7pata5yPxSWxod6Bz7e0vOxlLIv2Kt1eOy28iFLLttfqgsHqippVJGoMBmXUImxucGKXxYVfvC1kSo3PNjektTtoh8mJBsf+kbGiluuNtXV4bW0dPt9ihGxlDUNKLwZlRCkipcT7G+qxqQV1D6+vd6S1O+i9DfV4dU1t2l5/f8bQgij9GJQRpYjTA2w3OfHF1tbXFZlKGTrkbL8h0l0Aov0YgzIiIkqI1tIhRNR0DMooKaSUqG1hMyGJqHFWt8DlaIhaAgZllBQL9ljxyupaGGxsQVN0HBdNRKSNQRklxXbvulpGBwcEUQQcrJTRfLEyvyZqKodbwu7mtaAxGJQRZRAmkagl4DIQFM3zK6vx9PKadBejRdKnuwCUGgt2W+ABcGTHgnQXhRqB2QqiYPN2mrGtFd7pojXiDOrGY6aslZq7y5LyhVYtTg/eXV8Ho5MD/NPhw431ePqv6pQ8d0u7fRW1fvP3WPG3OfKY1b1WF95cW8tuM2rRGJRRo/1VbUOV2YXF+2zpLsp+aYvRCbsnNd1IrfHem03V6jvsWvgbnLvTjD1WN3aYONmIWq6UBmVCiBuFEOuEEKuEEI+ptk8SQmz0PjZetf1477aNQog7U1k2otZoQ73dP+mCKJqVNTas17p3YwvoO2/h8SNRRCkbUyaEGA1gAoBBUkq7EKK9d/sAAOcBOBhAZwA/CCH6ef/sBQDHAqgC8KcQYoaUcnWqykjU2ny62QgAuHNoRZpLQpnu620mAMCdQ3PTXBIi8kllpuxaAI9IKe0AIKXc690+AcB0KaVdSrkFwEYAI73/NkopN0spHQCme/elFoCTsVqXSF/n+jp7o8fsZFICZmO9AxYXxx6p8RQmSr9UBmX9ABwlhPhDCDFXCDHCu70LgB2q/aq82yJtDyOEmCiEWCSEWLRv374UFJ0aKx0X3gW7LXhkqQEONy8ram+trcPMbcakPV+NzY3Pthgx05thaalsbg8+2dyATzbxnqRa4jmHo51p24wOmDn9jqhRmhSUCSF+EEKs1Pg3AUrXaBsAhwH4N4CPhBAC2ue8jLI9fKOUU6WUlVLKynbt2jXlLVCCvtthwsZ6R7qLEWSpQZloYM3QWVdNySLa3J5GB5u7rS6sqGn67XDW19lhdXng8E4qqHO07JmZvrkRLfm2YDO2GjGnKjOD4w82NuC9DfXN+prGFn5MxssjJb7bYeLs6DhtaXBga0NmXa9iaVJQJqUcJ6UcqPHvSyiZrs+kYiEAD4AK7/ZuqqfpCmBnlO37JSllRi7QuMRgwyebo2QYMqmPSmWZwdbswaRIwmfxzPIaPLsiNctexMPk9OCzLUZ8viV5GbfmtqHeDleKZqmmy+paO/7M4FnPNc0QNKjrx8xsjsVvt8UVV32/y+LCEoMNM7Y2//lYY3PDlOQMaI3NndKZ3h9uasD0FpYRT2X35RcAxgCAdyB/DgADgBkAzhNC5AohegHoC2AhgD8B9BVC9BJC5ECZDDAjheVLmvV1dlQn+Z6Pz6+swfMrE1sReck+K/6qbnpFLaXEjK1GbDW2rBbGujpHxIrt2x2m6MGkitnpQYPDDaPDHTOb4vRI7DRrVyorEvwuthkd+GNP+NpyyeiVlVKivhHZBFeKsmNuKZslUNphcuLTzUb8vNMMo9ONBbstMQdPPbeiGt/tyMwslJQyrGvQ6vJgwW5Lyhtxa2LchPxvsxM21Ti9KpMTyyOcAwZrcBBidXkSPh7m77EmtH+yfLM9uQFRlcmJt9bV4fsqc9B2m8sDd4zv1BPHd250uiGljGtfLb7vZeqaWvwvwWtSLFPX1OK9DfVwel/D5vZEHLO6ucGBLQ0OuDwSDrfEzG1GWFvhuNBUruj/BoA3hBArATgAXCKVs3CVEOIjAKsBuABcL6V0A4AQ4gYAswFkAXhDSrkqheVLWJ3djZnbjTizVwny9IF49rMtkWe81TvcyM/SIScrOG1ic3nw7IoanHtACcpyspCvF8jNCjynxRX/CVRjc6NAL/Cd96Q+pG34bKo6uxvLq204omMB9lhdcLolOhZG/vpX19qxutaOO4aU47sqMwaX56FjQWD/NbV27LNpX6gNNhdq7W5U5OnRJjfLv93pUVLvozsXoiBbuz3Q4HBjZY0dh3fIh1Clmhz+kzby5/Lj32a0ydWhb2n02WTT1tXhkLa5WFVrR++SnKC7Hkgpw4LhIeV5GNOlEDV2N8xOD3qVZEPnLdusbUasqXOga6EeLglcemCZ/+++C6lkY/lgY+Sg0XcBE1HSb+qLnDogtLk8+GmnGX9V23HVQWVok5uFFdV2ODwSI9rnx12+eFrJUkrM3WnBwPJcVORpH18SwHvr67HT4sL4boUYWhF/GQBgn9WFLUYnRnrLXm1zweyS6F6U7d/H6HCj3uHxV9p7rC58tLEB+2xudPIe91a3xPSN9Ti+WxHKVMepxSWxxGDDcd2KNN8fEPw9bGlwoF2+HkUhx3St3Y28LIF8ffD2nWYn9lhdaJenR43djYPa5CJbFz2tanV5sHCvFVlC4NfdwYH7N9tNWF/vQEmODge3zfNvX1Vjg9Gp/N1xXYvQv432efFXtQ29i7OD6rRQa2vt+DJKdkZKiXfWB3dZvuvtwhxUHijT32Yn/thjxfp6B47pXACnR8LslFhWbUPP4mycd0ApdlmcEBBB9U2orUYnthoDjSGtgG6HyYkuhXr/uRqLwy1RbXehU0E2LE4PLG4PLE6JLkV6ZKme46/q4ODUI4E9FieKsnXwSKAsNwtvra1Dj+JsjO5SGPH1pJRwSaDBe7/gJQYbRnUu8F8HnllRg76lOTizd4nm32+ot+PTzUZcdmAZhAD2WFw4RPVZA0pD74ONDehRlI1tJifGdyuEzSVhdnkwpkthzM9mY70Dn2xuwLCK4Oe1uDx4bkUN+pfl4LRe2uVLhMvbuPXVgcMq8nBExwLoBaDXCeh1Ah+pMl5juhRiRY0dq2rs+PeQcuyxurG21o4BbXNRkq1Dnl7nD/QA4LfdFvQszoZeCLTLz4JOCHikhEDgXP5uhwlluVn+eiVdUhaUeWdQXhjhsYcAPKSxfRaAWakqU1PN323BDpML6+odGBxy8Efy0qpaAMB5B5TA5lYi/PK8LOwwOSEBTPcehB3ys3BZ/zZhfx/pYryp3oFquxsj2uVh6pra4MdUfegmpwceKfHyamUfdeuyh+oiZnF6YHR60CGkIrS6JZYabFhqsAUFnaEV9F5vprDO7vG/JwD41+ByZAlAJwRW19qxosaOXRYXrjwo/L0CwGtr6uDwSMzbZcGNA9uiMFsHj5T4ZruSudhqdAZlr7YZnWhQBQtWbzD7t9kJjwQW7rUGVdgvrqxBg9ODXRaXdz8XjuxYgC0NDny4qQE9iwOfic+yahuWqYKcozoV4JC2uVi8z4Y1dcpnXeVdafyRpQb0KcnG2X1K/fu7pBIUqy/8H2yoR/fi7Ii3wQoNPpcabPiuyowbBrZFUbYu7C4K6+rs/vcOADO3BzI9z6wIBJmvrqkL+ruuRXp0KlDes/pzmrXdhH6lOZjlfZ4Gh8efadxrdWP2DhOO61qIv80ufF9lwkX9yqDXCZicHvy+14pVtXZcP7Ct/3mdHunv2W5weLDT+/nP3mH2B2XqrIqUEjvMLnQr1PuPfYdbQgjg9bXKe/hzrxXXD2zrf093Dq2A3e3Bl1uN2NygXLDHeC+K6gVFfWMQAeV4mrfLglN7FkPLLosTvo9aAHjyr2q4JHD7kHLohMBvuwN3zsjWARf1K0P7fOUcemV1LYr0OtxwSNug53w7JHhZXm3DGb1LsMfiwgbvrNA+JTk4sCwXz6+sxmk9S7C0Wrv7fXODA+u927/dYUL34mzkZ+mwYI8Fv+0OnOtfbDXifL12oOM7t64Z0Mb/Pn12W1zYZnTgp53BgeBWoxNzd5rxV7UNNx1SrvnZ+SzZZ8XQijwIIYICt431Dv9543tOm8uDaeuUfe4cWoGvthqx0+JEXlb0Tp1X19ShT0ng3N1ucuL9DfU4qlOB/xwzOtz4cFMDxnYpRLeibLg8ErlZwn98fb3N6P8sQ53aoxhluTpotZXfWFuHalWddNmBZdhtdWG31YXRXQqxw+TEvF1mCAhM6FmMr7YZUZKtg9UtsaHeAXV73eUBcrPgzzhuUJXH5QkEvjstLv/yN+9tqPc3WkODsj1WpVy+21PN3hFoKOqEwJguhXC4JbYYHehbmgMBpQ7NzhJYWWPz77/EEJzx9AWSa+sc2FBvx7fbTbj4wDJYXTLo+PHVe1JKuKUSYKnPGTV1o3SJweZ/zfK8LBxUFtyg+PFvpVweAPN2WbDAe137fa/y/5m9i1GjShr8ssuCX3YpPw8uz8WmBidMTg+O7VqI4e3yg95jqw3K9ldzqkzY2ODAJf3Kglqe00OyIMd0Dr4Y77G68c12I9rn6/0HCQA8u6IGNrfEvwaXw+mRmLXdBJdH+luJle3Cg8PfVYHX/1bWoDhCVkp9H7k31tXB5PQ0bn0rGQiGVtYEn7xPem8D9M++pf70ucGmpNOFEFhTa8ePf5sxvF0epAxkxADg190WjO9WhNAMtfpki5SNCm21+zREyPZ86G2FqVvfkfyyy4L5uy0RuxU3NYQ/x9fbjLiwXyCLts3kxDaTE7/ssuDfQ8qDWuKA0mU5X5URWekdsL/V6EDP4hy8sDIQiNc73I0e82VyemBze+D2ICxDqA7mQi012DCqU4E/G7K61o5Z2004oDQHQHAP4RMht4Ka87f2dzZLFUg+ukz5G70AbhlUDr1O4Knl1eisCiqMGt/l2jqHPyADApW32raQ73h1rR2n9AjPigHwBwiA8p58F+XHloWP83N6lAu0+hwyuTxYvM+KzoVK8KvVHV5lduG5kM96bZ2SfXN6gI+jdLurswceCbywsha9i7OxWeM4/mBjQ1DgEsrXcFN7a12dxp7KOWywxdd9+F2VGR0K9OhSGPzaVRq3TJq2Pvj1Vvm7TOPvplJndgxWF37bbUFxtg71DjcMNiUw616Uje0mJ4ZV5GFYuzy0yc2KGJABwIwos5irQ77T9fWBTFpoAKI1JEVdjzg8Es8vNYTtY/X2rGhxaGQJnR7pr3sjWVVjw6Ht8/FDlcnfuDyiQz7m77GiTa4OtXbtz/zb7SZI1RnuCw59CQi1l1fXYkCbXKz2fo+3DGqrGZAZIvS6AEC1zR2WHVZboNGN/elmY1h2z0ed6fy+yowhFXlh9W86MShLMt/g22dW1EQNcLQGwioHiz0oKPNlTD7YUO/PLqhVaxzMoal8rYtXqHi6piKNSVgVY6wJoLTmclVNwt92W1Gco/O30n/eGX7SLTXYML5bUVAFEEtj1p7a0ojZOclcfWOn2QW7xhPO06i8vtZYjkKrMoyXr0Jtqs3ez9CXzTE5PXhkqQFn9tbOQKnN2mbE8gizRF1SCeqKvA0crXPAx+0JZFSj0eoC17og77IEBza+7EA81Fmt0LFCqaYVkPnsjvL5+bgk8NVWIwaVx7eo7JdbGmLe2sjlkdhnjf3a6kDgEY3gJF6+rEeN3e0POHqHZNJ8+y0x2HBQWU6jXyvstVUTMBYmOO7ttTXa53KkgCyUwepCRb4ehjjGOJtd4UM1/tynlDdSQAYgqNcgHqtV14cNddp17edbkj8YPzS7F8lOsyuosZdumVOSDOZwS83WiNsjI2ZeYllendhSBZEuRr6unFRRB3j1ES5K8QR9AIICj2gtn6b4eacFI9olln7+MAWzc/bGcQFSi3cSQqZaG6GyjSfoixSQqZkiBNs21aDgSGMc46EVFKuzZIlwuGXGfp/mOMeqrqq1x9XYAuAPeqL5vsocNRuSKr7uOwBBGdRQ8byHeFlVx1Ki96bVauz9HWEikZbXQjK1iUr18nIzIzSaEhlDnQqNvY6nAoOyOExbX4dqmxuDQgbQf7vDFLQOVEte98jH7FQGhfu8meKgLxUej5G2bw5vtMDPrSV6ZnlyZ4MlQ6YGZOnUHAFZui/sqbIqCWsNUnSN6S1JFQZlcdDqIgTCxx+9ojEmo6WZtd0YNCZK3eqLp+sj0mfVFK2zqqVMEs+xHS/eED49diXxO6T9S6Iz5VMpleuUUZqoU/aJ0hqk7rNwb+zxEVbe6mi/odWl31LFO/6EqLk5W9F5lokyrYeLQRlltAaHm6myDPViEyYYUPLxNGmdknGrNIpsVhyTg5oTgzLKaJ9GGJ/THLdxySTRZh0SAWBURtQKMChLQDyzxFqzdNT5raWLrMrsyrg0ORG1PgabCyJTb0JMMTEoS6HQe9S1dMkcDJ2I0LCsMWuRZYJNEWb4ZOB95ykDJPvmz7R/SHS5JcosDMpSqCqB9WXUUn1j4ZYu0lo3ma4qwqy8jzc3bj0sat24tAY1Rp3dHfFODJT5GJRloL81bj+yP2stIWqkBVaZEKFkaC3nCTXNxgxac6slcqR5BQEGZU2Qql770Nsk7e8WpGj1fyKi1oaXj6aJ5xZVqcSgjDJard3jv58oERFRa8agjIiIiCgDMChLIWaRiZrPX9X7d0aV9Q1Ry8egjIhahaW8VRIRtXAMyjIQW7xERET7HwZlTdAQay2DRkZXH27i+kRERET7GwZljbS2LvaqyV9sNTZDSYiIiKg10Ke7AJnu113ha2R900JXlCciIqLMxUxZDL9y4VIiIiJqBgzKiIiIiDIAgzIiIiKiDMCgjIiIiCgDMCgjIiIiygAMyoiIiIgyQMqCMiHEECHE70KIZUKIRUKIkd7tQgjxnBBioxBiuRBimOpvLhFCbPD+uyRVZSMiIiLKNKlcp+wxAPdLKb8RQpzo/f0YACcA6Ov9dyiAlwAcKoRoC+BeAJVQ1sJfLISYIaWsTWEZiYiIiDJCKrsvJYAS78+lAHZ6f54A4G2p+B1AmRCiE4DxAL6XUtZ4A7HvARyfwvIRERERZYxUZspuATBbCPEElODvCO/2LgB2qPar8m6LtJ2IiIio1WtSUCaE+AFAR42H7gYwFsCtUspPhRDnAHgdwDgAQmN/GWW71utOBDARALp3796IkhMRERFlliYFZVLKcZEeE0K8DeBm768fA3jN+3MVgG6qXbtC6dqsgjLmTL395wivOxXAVACorKzUDNyIiIiIEuFJc0SRyjFlOwGM8v48BsAG788zAFzsnYV5GIB6KeUuALMBHCeEaCOEaAPgOO82IiIiopQzuzxpff1Ujim7CsCzQgg9ABu83Y0AZgE4EcBGABYAlwGAlLJGCPFfAH9693tASlmTwvIRERER+aW76y1lQZmU8lcAwzW2SwDXR/ibNwC8kaoyEREREUXUirsviYiIiChODMqIiIiIkPZEGYMyIiIiokzAoIyIiIgIgOSYMiIiIqL0k2nuwGRQRkRERJQBGJQRERERgQP9iYiIiAgMyoiIiIgAcKA/ERERUUbQiTS/fnpfnoiIiCgztM9P5S3BY2NQRkRERAQgzYkyBmVEREREmYBBGREREVEGYFBGRERElAEYlBERERGBi8cSERERERiUEREREWUEBmVEREREGYBBGREREVEGYFBGRERElAEYlBERERFlAAZlRERERBmAQRkRERFRBmBQRkRERJQBGJQRERERZQAGZUREREQZoElBmRDibCHEKiGERwhRGfLYJCHERiHEOiHEeNX2473bNgoh7lRt7yWE+EMIsUEI8aEQIqcpZSMiIiJqSZqaKVsJ4AwA89QbhRADAJwH4GAAxwN4UQiRJYTIAvACgBMADABwvndfAHgUwNNSyr4AagFc0cSyEREREbUYTQrKpJRrpJTrNB6aAGC6lNIupdwCYCOAkd5/G6WUm6WUDgDTAUwQQggAYwB84v37aQBOa0rZiFqzScMqMGlYRbqLsd+r3anD7g1Z6S4GESWJTPPrp2pMWRcAO1S/V3m3RdpeDqBOSukK2U5ESSAlMOvpAuxcxwAimR47uS2ePbdNuovRZP8d0xY/vpaf7mIQJcxuFukuQlLFDMqEED8IIVZq/JsQ7c80tslGbI9UpolCiEVCiEX79u2L/gaIMkjDPgG7BaharYfbmdjfznisEI+dnHgAsHdzFu4aXoFf3inA8+e3/ACCks9Sp8P3LxamuxhECVn7azbuO6ocW5bo012UpIkZlEkpx0kpB2r8+zLKn1UB6Kb6vSuAnVG2GwCUCSH0IdsjlWmqlLJSSlnZrl27WG+BksDtir0PxTZlfDnu+0cFXriwDLP/V5DQ3y6Yno/anYlnutb+mrw5MzajgMcde7/6vTqY61pXC7Z6hw7v/bsYTnu6S5I6NqNo1e+vJbOZBGY8VginLd0lic5uFjAaBCYNq8BXj6c20N+yOBsAsH15dtKe0+ryJO25GiNV3ZczAJwnhMgVQvQC0BfAQgB/AujrnWmZA2UywAwppQTwE4CzvH9/CYBoQR81o2Xf5mDyyApsXpS8A78xPGk8V9b+mo1d6yMHRC4HsH5BNiYNq8BbN5XE9Zy7NzZP665Tv+CIesFHeZg0rAIOa2Db/Ol5ePi46Fk0jwe4f1Q57h4ReyzbI8e3xYNjyhtV3nTauTYLK77XDmK/nFKElXNy034eNEbDvsgBslT1Sdw/qhyPn9I25vP98Uke1i9oeZ9DMm1dqoeUwL5tOkwaVgGbqemNkDVzc/DNs9qNtZ9ey8eC6flY+Hlek19Hi8cTfCwkSkql8X7fUeV4+Djl3J//QXK7xJ12YMnXuf5yCm8EI1XXBrcr9vvYtT4r4j51jhYclAkhThdCVAE4HMBMIcRsAJBSrgLwEYDVAL4FcL2U0u0dM3YDgNkA1gD4yLsvANwB4DYhxEYoY8xeb0rZKFhTBoZvWqhcpHasTF+KeP70PNxdWYE/PklehSSlEqCogxNAu3KadlMpnjuvDUw12pmiJya0wZvXlwIA1kXITIU+Z+1OHb6cUhgUbHo8gazk69eV4Jd3wiu1pmYt57yiVPrqi8hXjxXBaIiehUu0uzXdrA3xZfXUnr+gDd6/Qwmq1/6SDWO16kIb5ZprqRewGjMzM7j8uxxMGV+OLYu1z19PyPFkNMS+LHzxcJH/eG8uezdnYd9W5RiVEpj7Vj5MNen5zH97Pw+vXFGGedPy8dTpShD7+YNFQfus/jkH2/5KrM58+9YSzJumHZS5Xcp7TfSYjtdjJ7XBXcMrICXw0qWl2LkuC7OfL4j7uvHxf4oweWR8+3rc4fWhzSRiNry/f7EAH/+nGGt/URoEwvv1+4Iypw2YPLIC378UuRdi9dwcPHdeGyydmRtXWZtbU2dffi6l7CqlzJVSdpBSjlc99pCUso+U8kAp5Teq7bOklP28jz2k2r5ZSjlSSnmAlPJsKSWT6HFyWJWga+FnqTnIcvKVs0efm7p5KR43sO637KAT9aFj2+LzB5X098JPlWDMVymrSRl8gtuMAi5H7NdcMzcHMx4pwps3BC4uThtwd2UF7hoeqFwM2wOnyUPjyjHzqUBKfue6LEwaVoH6PcHlspsF6nYHn14ypMIxbNPj94/zsUs1+P7ly0oxeaRSMW78PQezng5P/y/7JrHvOTSYMtcq5areof1ZRmKuCbyfZ88tw73/iJ1RiZfHnVjQ986/ijFpWAX+mh0eAEupfC8PHFOOB8c2row712Zh2s2lePjYQLbPfwGQwJs3lODps8r8j/13dDkeGNW0zKBhuw6f3l+E7SvCL+SG7TrMmZof9P34ApPVc6N3T/u6eDYu1N7P5Ygc2NiMIu6B1FuW6PHyZaX+C2vN3zp8+1xB2DE16+kCrJ8fnmVb9WMOHhjdNmL36dNntcFTZyjZ3KpVenz7XCE+/k+x//FvninAjlXN03D8+gklAPv2ucD5uXdL8Pn0zm0lePmyMmhZ8UMO9m5ObCjCZu/3+MfHqZmQ4avDti7RY/vybDx/fhv8/Gb8QyyWzoyvwex2AnePqMC3zxXgr9k5mDSsAuZagfuPLsc3zwTXd1uW6PHbB8rzSgnU71XKaDMpdZEvU/bdi4WYNKzCf33wXS/cLmDrMuWYePOGEjx1Rhn+8taf6+dnw2EN1O8LP8tN+DtJBa7o3wrU7VYOpM8fLE5aNqNhnw5Gg1IZ+4IJmzF14wR+eKUAb91YilU/Bi4cpmodFn6mVEB7Niknlt0SfoGYPqkYdw2vgLlOoG6XDvePKsc9hwW32Dzu8AzT7o3eSuBGCIAAACAASURBVGhp4AJht4Y//zNnB3frrfopUMaVP2gHSPcdVY5HT2wbNK4qUivwf/9sg41/KF2fO1YoZQltddtUWRiXPfDz6rk5aNinw71HlmPTQu3upPnTtSvxrUvC9/dlTd6/oxgvXVqKScMq/IHN4xMCn8PuDXo4LDqs+CEHriQcc9NuKcHkQ6O3sn95J9/fZbb6J+Vz//T+4rD9FnyY55/QYG3Q+TOhWxbrNcvqcSsVszoj8PwF4V25vgvAp/cVY/38HOzdHB4APHRs5CBQ3a0iJTDzqUL/MQgAr15VikVf5uGlS8rwyX3K9795sR7fPFOAFy4sww8vF8KiOp7e+79ifPtcId65tSQs26v2u/ci/uOrBTDXCSydlYtFXyifn80oYIsQdLldSnfmfUdFDzbnT8/DvUeWY+qVZdj2Vzaqtyvv6e1bSzD3rQJs+0uPVyeWYNKwClTv0OGXdwrw5g2lYZnFmU8Vwlqvg3Ff7MuS77xaP185F6UE5r1dgBcv0g6CYvn6iULNjJDTrpTrruHl+Hu18r4iZY52b4g/IHz/9hI8fVabhOprXyNPqzGlJiXw67t5Qc+9a30Wandqf64Oq5JV9rHUh++nlZ178vQyvDoxvqEaar5GwO8f5WP6JOXv501TjtFf380POpanXlmGrx9XzoV3/68Yy2crx62vgSRCDl3feWuu1WH+9DxMHlmBVy4vw/YVeqyfn4N9W/VY/p3yHH99m4f3bi/Bk6e1hcejXD+fPiv9E6EYlLUCQhdoisa6sEXjdirjIwBgyvi2/nEBvgvJut+UCnD+B/lwORGxReuwKuMtopEyuCL46TWlRfbT6wXwuCMHMFKjcvCdZF9OKcKjJ2lfFO8eUYHJIyuCLspuZ/jFKPQk19pPvU+ssQvqcVVaZfd5/drgrqA/Q8aNfKYK0rKyAy/6zq0leOHCUjisAu/doQQoy7/LwZxXA4GYJcKA+x9eKYDNJLBnU6CSn3yo0s294vtc/+BZc60OHg/gcYU/z/u3l+CHlwvgsAIPjmkbNnlh4x+BwM9mEv7Py1gtULXaG2ibBdZ7j61IXbNuJzDr6UK8eX1pUKWdlS1hqVcaC76A/qvHggNa6RHY+Ec2pl5VhumTgoM4m0ng7hEVeHVi5K64Fy5WglNft7SpJnK1aarWfmzfNh0mj6zAnKn52LdNhyVf5+LXd/Px5g2Bi5rVGPjbxTOU7//Vq8ow7+0Cf2bg9etK/UMRVv0UaBB4XAIr5+Rg0ZfRs6jblmXjo8nF+PSBYmxZosf9o8qDyuDTsE9odkXNfSs/KCj5+slCfPVYERzW8MaHb9srl5dh8yLls9uiagg8MKoca38N/O4Lel0OEbR0S2jWe/l3OZh2U/D3Fa1Lv6ZKp9mNaDcLmOuUY/K395XzZdKwCsx9K3DuzH2zAL++mw8pBf53YfQLtq9HIRHT7w5vVACB8Vnq+iW3IPCL26k8tmlhcO+CywncNbwCM58qCroWPHdeGzx2snbd+PipbfHAMYF66sPJ4WVa+FkeNi3MDqqzDdv0/u81Eb7yqo+ZHasCx8E7tynHo/o73b0hy98QA4APvZ+b1vAOn5/fCDy25mftcvrqnWh1c3NrPfNIW6ld67Mw9apS3PZpLYorAmeff6CjAHQh1wG3C8hSfbPxDN50O4HXrinF1qXZmDynOvhB79+ruzHu8Z7wU5YY/OXMLZBo08WDe49UHrvx/VpsW56NEafZoPeeE0+fWYY2XTzoPsiJ718sxAWPNuCQY4Nr3btHVKB3ZWBbvLP4Vnwfu1vvnkMrcNP0WnTq59bs4gz9rLRaiLos5UJhM4u4B/fW79Fh05+NGxjttCljlnxCU+wN+5Tfrd4W7gd3KpXa2KuU6OXvNdqv63ELPHtOmT/TGk3DnsiByNw3C1BYJmGu0+HnNwow/gaL/zFfsHnaXSZ88XAR2vd2ofOBLmxcmANTtQ5TlhiCMjGTR1bgqqn1WPVTDgYfb0f7Xm7osqT/mAKCM5c2ow4rf1AOrnf/rwSXvVAf/j49gQvNqh9zARj9j91/tPLaDXsjfwZVK5s2oH3db9l460blc5jzSiHmvBLINKu7tEOPNa3Mxq51gRNb6CSkRzkuGgw6vPdv5XuvnKC0lqQE6kO60NWTVXxZ5z0aE042/K59EVN31wHAb++FXxRX/5SDDr2tqP07/DPVhzzttJtK0e0QJw49KzCl8N3/K8a+rXr8e0YNDDuywsau+Y5vn+3L9fjykeBAXO3xU5Vg5Mz/GNGpnwudD3LD7YT/uDvtLlPYe+w51Ikeg11h53e0MU8Oq/AHrA8vNkTcT13vrPwhF3s2WdCulzuosecbPnHsdWaMuVI5j9VB2cynC+F2AAs/y8cBhzpwxUsNALS/DzVTrcBDY5X3fdRFFhx2ti2sIeG0hddpWxZn48spReg+yInzHjbi+5cTmzmupnU98nWxA8DGP5SDZM7UwGtorQW49pdszbL6qMfIxuqG3bkuc0KhzCkJaZr/QT5sRh3W/pqDEacFUlMznyzEb+/n4+HFBn8L0+frJwox4U6z//c/Y4w1W/BRHmaoKrV924IrU1/3h1Z3jd0skFso8dx5yknTc0ggFeVLJdft0uGEmy3Y9pcee7fosXdLYDD8l48UYeC4Gv/f7FyrvIa6BabOYiz+Kg+Vp9uwfXk2Oh/oijrO7fuXCtDxABfa9Qq+2m1fno0VP+RqDqgNbTGpuyr9+3gQ1j0ayyMnNH78lS9D6fPLO5ErGHWGzKe4whNx8HY8ARmAmJWw1tg3tS8eVo6vvZv1QceRVlDr+74jzdwKXRbk84cCLXutweer5uRoZrCCBvEn0WtXl2DvFj3On9KAX97Jx5p5kc8/o0FpdE18tT7sYhWrK8UXkAHA02cG9n3l8lKccrsJM58qDMtk+M4vAGHZJrVP7tXO4MTjuxcKMfoK7f5UrYk6O1ZkY8eKbOQWKRHPvq1KGZd8nRd0YdaSU+DBS5cGd1lKqYwX6nu4M6jB+ukDgffUuX8gDeM7NtU+vrfY3w2r5hurFIu5NvDd1O7UoU3nQDS3JmQM4DNnt0F+iQejr7Qg1J+f5WHMlVYYDQIOVQCyQDUkYeMfOVj3WzZmPlno/+wieeGfgc/ql3cKotYlaros5eD8e7U+LOPmcSuZtEi2/aVHhz5u7N2che6DXGETS7S4nIHek0im3Zy8iSYvXty4bu9UYFCW4XwpXkfIWCdful16ELbM7orvcoOCspVzAhcFc63Ag2PLMfHVOnQf7MLaX3KCAjJA6W7wibYMBADs2ZSFLH2gAFuXhWcV5k0rwAk3WzQHvZprdXjliugnV2hLXl2+aH58Vfuk1qqEfS3csRODK0at1n6ia4U1dVaeLwMSjx9eCgRHDquSPYpnNl0sS75KzTT8Lx9J/YKl6osxADw0ri3u/KYmaBB/Mm36U7noTr0qvuN0y+JsrJyTE9Y9HC0LEM3WZdmaY+IAYPXPzTPjLNLQBvX4zVB2U/BxWrcr9nHrsITv48syjbvGjLETtYNDdXCqRSsgA5QhEol67OS2uOKlehxwqBN/r87yz+5VszboMP99jUaIUOps31CSSHyZ2FC/vpeHmU8GyhxvIyzUsm98A+fDj8lYS+So6/3sPIkDj4w9CyvWNaE1E7IpC5NkgMrKSrlo0aKUPf8jSyOnoZuDL1joM8KBK19pCNt+8TP12LlOH3QxBgLdioBygPsqw9FXWPDT64mlnnsMcWKbRrAFAG27ulFTlf4ZK6nQ9zBHxG6clmDUZRbMTWD2FFE0ReWeiGPmMlXlaTYs+iI1DYpEXfRUg3+8VLzadHY3asFoarxlBhsGl6f2mBFCLJZSVmo9xkxZC7Hpzxw4rEBOSGPq7VtK0ffw8JbHj6/lw2kV2LI0uN890XVzAKBDH1fEoKy1BmRA5HE1LQUDMkqmlhaQAciYgAxAwgEZ7Z9a3lnWSs17O9+/xsqOlXo8fVZZ2DT3eW9rj7HZsCA8ePj+xUL8/GYBti3LDpp915jZMlozEomIKLWYJUuDNHceMihrJluXKesNabFbgG+eKcTUq5SFF9+/vRh7N+v9K+n72IyN+7oaO47Aj0EZERFRyjEoawbr52fjlcuV9Ya02M3K12Cq1uGew8r9QdRXT4RMP38/H69cXhrXavXJlKoVpImIiCiAQVkzUN/GR8s+1e051DOwtGb+bV2WnfByDERERBSbq4n3Fm4qBmUp1rAvdt9faccMWk6YiIhoP7V3d3pfn0FZI0kJvHFdCe4fFVhIz+UA1szLRsM+4R+kP2V88PoyvlukqFciaex6RERERJQ8Dnt6r8cMyhrpruEV2PB7TtDg+xmPFuHtW0oxZXx50G1htCyeEVjE0bcaPu1fzn3IGHsnalb3/FQdeyciarXmfpvesIhBWSNEWm839CbS0fhWlP7gzsbfzoRattB7WLZW6ltvxXLkP7VXYG8uBaUtezFtIorf2Q+EN4yz0lwtMyhrBK2bVGtZ/l3kNcEWfJiPe48sx/Lvmue2Jy3ZtW/V4eAxEe7b0gRn3JPeTFVW9v4RAFz9RvhNwiM5+V/mqI+fcHP0x9UOOFR7mvKQE22a20Pd9nlN2LZ2PYNHAZd14njQ/cE5/2VWO1RZksZCX/R0Q+ydNDww34ArXoq/btEy7OTw64o1/iomJRiUNYL0xN4HAD64M/oKzqH3s2zpBoxOfuAEKMHLhU/EVykKEX+gU1wR5xeZgPa945+6k5XgzRVy8pMTxHXq58Ktn9aGbT/1ThP6H+XAMZdb0Gdk8627otVajeToS6y48YNaXPly7Mr44qcbcNCo8GPyhJvDb/wMKPflU2vXI/z4OPWO4Bp76Il23PlNePCWTOdPCVy07p1bjfLu4RdD9W3VEnXNm3War5VqB/4j/mOs28DwbGvvyuY7RoeeZE9Z/RYqNPBPVN/DUv+53P1DNW77rDboXsGTZldjwDHBn1Hoewm96fqQE2zof1TjypudBxxwaPxZ+HiZzRxT1uLEmynb34y6JDldT6FZMeE9So+7LnoT5po363DW/SbNx9p0ceO+X4LHC+lzYgc6vSsdcc2OvWOmcmHuPihQCV38TD2Oukg7APCVySe0bFru/aUanfoFnj+/JHJQGekiffYDRtw0vQ7te7nRNeRCN+wkOy55tgHjb7DgypdjX5yve6cOp0824rq362LuG83Qk+wYfYUF172jPM9Dfxpw9CWRP7fOB7rRZ6QTt38dPRjKzgPczvAKtqRd+Of2n5+r8cB85TsI/Vx8bv6wNuwiUNjWg9IOHlz1qlL2HoOduGl6eMCbiCPODz6PBo0PXLTyiiUOGRt/cPCPC5XnKiyLfKz0GBw4pgaNd+DOb5XPtcuA5F/w1C59Lv4A8Lq3w4Pwq6Y2NCkYTVS7noHz9eHFBpx5b/yNCa2gsuMB2sGX0KFJx9DwCTY8MN+Aw89LvD6essSADn0C5Tr0LO3nKGorkZ0HjLvGgk79XOh6sBMl7WTYDe/b91Y+s/E3mDFliQHHXRd8Xp/7kAk6HdC5vwt9RsQfnOUVR29Q6/SJN2AL2yjPada+hDQbBmWNoDWmzNrQurJejVHWKTmZJ31O8Adc711M96BR0U/aHoNdGHayPaxCG3+DGVe8WI/cwuDnFQIYdop2V9aI05Xtl73QgNu/ro1ZAZd18uD6d+sw4c7AGd3vCCdOvNWCfz4efPGZssSAKUsMyCtSytP3MEdY2bTodPA/V5cBTvzn5+Cg5PTJsS8S6ixvl/6BynfKEkNYGc59OPyiebG3q6H/UQ50O9iFkWfY0W1g/C37C59swKXPB19ghQCOu96Cbgcrz6PLAgaPDwQeJe20g+I2nT2aXYxdD3b6s2/HXB58ETjxVu3APr8k8N6vfq0e985VArQz/qM8zx2zatCxr1KOia8GgtA872fW7WAXug9y4pTbTejUz+3/jqcsMeDE26LX8mc/YAzqBh1+ig03fhB8DI+5yoLDzlYukMdeFzlgVbvk2Xp/EJ/rPdaK2npijtsrbe/BlCUGHH5u4Nw44nwritpGPr9HXxFfmXyGa5x3h58bvVyRMiq3fhI7gLnmzTrc8F7wfuOuDT4W1EFSx77KzwPH2vHf35XAb4Cq/hECqJxg91/IY/Fo7HbCLdrH4oVPNviPIZ/QbvLQwL3HYKc/qNFlKQ2SU283o7yb9rlz0VOBc/uwc4Kf65aPA8f3aXeZYwZLN02vw/XvaGeuT73DhPt/M2DUZdG/2xvfr8OVr4TXN5F6HibPid4gq9B432fcY8QN79X6v/fjrg/+/I/0fqYjj0p+D0oiGJQ1gnSHB2BfPlqosWfLMvKMwInzn5+rUXlaoOIcdFxyUvfqAMV30XpokQEP/WnAg38YcP9vBvQ/KrhV6auQOvZ14+aPYlfAvsHavSsduO+XahxzuRXl3cJPtG6HOIMyTz4d+rhw+mQTHlpkgD5bCYYqJ8R+/10HuKDPAY6/STnZfRm+tl20K8ayjh7v+1LKMPJMq7/ckZR38+Cipxr8mSx1ADrsFDs693fh6jciZ67UQZnREP30H3K8wx+c+Hm7hyNNdonl4NEOHHhk7AxM5/5uPLzYgDtm1aBhX+SRt+16ePzHkU/Hvm7/WJFew1xBjx11UezsgT5HyUgBwIjT7JiyxOD/rgCg13AX+h2pfEd9RijvJTsPuPatenQ5KPy77jUs+Bi76OkG5BV7cPmL9bj6jToMO9keVK7O/d3ofKAbt31e4+8aPfZaCyZMUo4rXZbS0PA5634lcCwqDz7G+x/l9B+DXQe4MOpSC278oBYn/8uMBxbEzjC5vEsDtO/twgm3mHHVq/UoaR94fyepgs1jr7Pg2mmB465dTxfu/82Aa9/SPha1GnBHXWSNOvu1d6X2cdO+txsXP1OP428yR8yclbb3oMtBbtz1feD5j7rQisoJSh13yu0m3PxRHS56Wmk0tO+lvM/Bx9uh9w4NVmfBfXzB//E3mfHAfAMm/6hdfp3GIdxnhBPDTw0PTrW6zW8LGW5w4JHBdURBqcffqFK/1uDjteutAcc4/IFxafvw1/M1SgHgylcaGtV122OIkj3LyQ++f3JoI1VN3bMwaLwdQ08KvK76+Io19OPyF8NfY8TpdnQ5yI2xV1kxZYkBo68IrgtGX6lsH3dKeoOyBEe1EAAsmRk+OL+lrjU29CQbls5UZo2ePtmMsk4erJmXg/wSCV1W4MpbrNHlE0qd4cov9SArCxh1mQUznyzyb9cKBHS+TVlAVjYw5AQ7Prw7MCtVHUh0PCD8onfZC/Xofkigwizt4MG10+rQqa8L2REmxA4/1YacfGD4qXYYDTocfq4N/x2trCm3Z5MeQoTfiH3KEgMmDYt9N4VRl1ox6tLACd+hj3ZQ1qGPGze8W+vPwBx1kRULP83HsddasPJHN357Lx8PLTLg7srg1xxwTKBC7tTPjdu/rsG+bVnQZystTnV5pVSWb/FRd72POMMW1t0QKq9Y4u4fqvHQOOWziXRz+gsebcCuDXr89Jr2rcQi6dw/cpZNCCVwLe/uRvX2+KdESY2P+9Q7TLBbAoXvXelA5QQ7ug50oqYq8elWlz0ff9dbp34uDD/VhsUzlINxwCgH7p0b3NI/4jwbvnqsKGib1sXZ55jLrZj9P6UhOPwU5cI1/FQb5r4Z/Pn7zmEpgeNvClzwsnOBq16tQ473DmoXPtGAfduCP4eDRjkw+wUPLnjUCH020L6XGze+X4eHxpUjJ1+iyDsmc/DxNgiBoHNw2Ml25OQrgczoKyz46fXgcoms8Ki+qNyDbNXheN8v1Vj7a7b/eFcmbhRi4mt16DEk+Lg56GgnDjo6OGg7+wEj+h3hAARQ1EZ5veJyGRS4LfpS+U6+eqwIR5xn82fDOvd3oaDMg4OOjp4lOvBIJya+WoceQ13Q6cLHJfqc97AR86fnw2kFFn6Wj6En2ZCVDZx1nwnrfs2BqUaH/FIPrPXaDaWwekx1Hp5wsxnDJ9iwYHo+Vv8MlHUInABjr7bgqIuseOqMMhgNwd9vR2+DtMfg8GD3jHtMOOMe7QzvZf+LPJ6zqNwDU7XyHg47W7sXYuBYB8550Ai9xkSnsVdbsHJOLnLyJU66zQSPW2D288px7oqwftiQE2xY9k0epiwxoG6XDkKnXAPUmrObu6kYlDVCaOUJAJv+zE5DSYC7vq/Gw8cGFqh98A8DJh8a322Ypiwx4K/ZOf6gDABGX2H1tyB6DXdi4adKrf3be8H3vxx6sg1Lvw6uKQpKJa6aWo/O/V3+rjkAGHmGzb9um4gzN9vvSAfW/6Y0UZ0hJ+OYqyz48dVAJd/3MGdYsKC+QKidcLMZ3zxbiOO9s/iy9MDYicEtpkgpf7VLnq2HzaQLCh4jyYpyaHQZEHitiu4ef+XRc6graCZitG6SNp09aNNZ+/HQz6XX8MDn0meEEyXt3Th9cvTutaK2SgV5wGFO1O1SvsDQTNkhxzpwyLEOuOzAL+8UeF9b+sc0de7vQkWP8M81nhZ4WcfEgrKyzuGvo+6KA5TxSD7Rgp9kyNIrF9/FM/KijjFsquOut2DMlZagNRJ9WRBf5kett+pYOHhMePBR0s6D//wUHDz6vvecfInOByrPqW4k+Byk2jboOHtQUHb4uVb8Q6ML1Zfh+dcXNbA26JBbKDF4fHADJJ6La5+RDv9QhnhlhYxBKi6XmHBnePdiVrYMG6eoPqcA4MYPavH8+cFrT7bt4sHJ/zLD4wY6HODGyDMDx+PQk2z45Z0C3PR+HexxTv7q1NeFi55qQNuubn9DdcxVFhw0yh6UrdXpgLwiiZs+rMOeDXq8dk3gln9HXmBDnxFOdOrnxtWv10Wt90ZdasXqn5SIufeIyJluX0A2+AQbhpwQ+fMfeqL2Y7kFwO1fB7KCNtWIjN6VToydaMFhId3cZ91vwml3K3VYY4bQnHK7KWmTqJKBQVkS1FTpYDc1f09whz4uFJcHDqYH5huiBgD/+qIGUgJPnR64C8Gg4xyYPkl7/8HjHbDUmTD0RDueOK0NLHXKe+zc34UJd5jDgjJAu4shRxXP9RoW3+Dhy55v8GelQgOAHiHrXkXK3mg5+hIrjo4xIeHoi2NfOPsf5cSiL5pnOZNbP61FQZSB2vEKvaBl5wKTvo1vQPE/LlQuIr5saKTxPSfeasGRF9iwYUE2Kk8LVLzqDB4AXPlyPXRZEj2Gxh6PNvpyKzYtzMH4G6NP9Og5xImty7LRJ0I3V7rFCijOf6RBc2JCJGOvNmPN3MAxqNMFn2uAEtxPfK1Os+utMaRHKZ/QKYHef/9QuvhDdegduMB37Ov2Z5kPHmMPmsGqzqL5grKK7h4AjT/e45mkEio/zvXp7vmxBpb66N+RL1jVostSsqJqx11vweHn2uIOKHzHUWgwrMuCZvc5oGQKi0aG15ud+in794xxHnY/xIWH/jTAaROa37fPgf9wYN2vORioEeQ3Rk5B8Pcy7prwujlLr92dOXCsHSvn5KL7oOj1Qej3kW4MyhKkNWDz8VPbhm9sBteErP+UFXlZNAC+yk7putm8SNlZCOViVqgxiFeIwAE7/gYzPn+w2LvMgHLCXTW1HvociZcuLYtZ1tu/rkF2noTNlHg3rz7kfR0w0omjL7Zg3tuJdZXF0rGvC7s36NHviPgu6hU9Y2fUkkEry5GIcx40ouvByQlUKrp78J+51UGZ0FClHTxBAZmWPiPjL0+fkU5M/rEahWXRL5y+7jTRQtfkHXRcYheycVdbMe7q8AbGDe/WBk1cCB3T1hTZuYHxmgCiXqBDaQWl4661oHN/Fzof6EqocZVsoZOLIsktlHFNyvEFJ/98vME/AzHyayNipvvuOdWa3fGNdc2bdXFPTgily0LM9z7uGgv+XqNHr+HJqW+0xuLF69hrla7QM+9N83TKBDEoS9DnD4Z3XTa3SC1uXUiy7tLn6+F2CrxzW/B6aZf9ryFofE08i3uOON2OTge6/TPkgMgDb7X4Kp2CUom+hzsw7urY2ajDzrHi94/yURRSieiygBNuSX5QdvOHiS3t0HOIC5c8Vx9XZub0u434/KH03L0hUldBY+UXN3+qP1ZABijjYHoNcwYt8bA/UneJJ1t+icQtn9RGnLxy22e1MNfFH13pdMoYo3TzBZvJcuETDTBV65o8I903Fg4Abv6oFtU7mtbiSPW50XWAC3d/n9p1++LVvnd83d2ZhkFZnOxmgV3rs7Doi/hvpRSv0o5u/7IPjXH9u3XYsCC8yXrgkU7sWh/+vPqc+FuGPkIgKCBTO3i0HZYIA1RD6bKAy1+Ir3vh5P8z44jzrRErtsPOsWL1TzHSgynW/x/xBaYjz7Qjp1CmJaDZX+QXy4zrimiNOkTJ/LTr6Ua7ZixLskSaENRY+pzkLRHk0/EAt+ZEJ2pdGJTF6f07irF+fmoCgAseNeKlSwJdgBMmmSA9ytitly8L7hrUunVM1wEudB0QCJhuml7r716q0Fj9O9kufDI1tyDJ0kcfhD3hTrPmYNxMNeT49GcEiCjgipfq8fq1pbjg0ea7kwEl5p+PN6BDhIV2W6MmBWVCiLMB3AfgIAAjpZSLvNuPBfAIgBwADgD/llL+6H1sOIC3AOQDmAXgZimlFEK0BfAhgJ4AtgI4R0rZtKWxk8DtBOwWoZmJSpbQfvohJ9gjjtmZMCl2/7hv8CagtAAfXmxI63iN1uS6t+uwZUl6ZtoSUXIdcKizRXZx7U8yoXu7OTV1yuBKAGcAmBey3QDgFCnlIQAuAfCO6rGXAEwE0Nf773jv9jsBzJFS9gUwx/t72n10TzH+O7ocUqYuqlHf2PXG92ujDqL2DdZPBAOy5Ok20IWjL07O7aSIiCizSKR3iEmTgjIp5Rop5TqN7UullDu9v64CkCeEyBVCdAJQIqVcIKWUAN4GcJp3vwkApnl/nqbanlbLjooeZwAAIABJREFUv0v9sge5qvHqnftzzAAREdH+qDkW1zoTwFIppR1AFwBVqseqvNsAoIOUchcAeP9v3wxlyyhaNw0ec5UFYyembsFJIiIiygwxx5QJIX4A0FHjobullF/G+NuDATwK4DjfJo3dEs4VCiEmQukCRffu3RP987Q750EjPpocvDxCpHENx16rBGRzpiZ3+QciIiLKLDGDMinluMY8sRCiK4DPAVwspdzk3VwFoKtqt64AfN2ce4QQnaSUu7zdnHujlGkqgKkAUFlZ2eLWGBh6oh1fPVYIa0P8icq7vot8o14iIiJq+VLSfSmEKAMwE8AkKeVvvu3ebkmjEOIwIYQAcDEAX7ZtBpRJAfD+HzUL19KE3lfs1DuVWZRn3hvfchLFFRLFFS0u/iQiIqI4NSkoE0KcLoSoAnA4gJlCiNneh24AcACAe4QQy7z/fGPErgXwGoCNADYB+Ma7/REAxwohNgDwLanRahx5QfCMvcHjHbj+3ToMPzW5q60TERFRy9SkdcqklJ9D6aIM3f4ggAcj/M0iAAM1tlcDGNuU8mSCLgOc+Ht1YB2rAaPtWP1TLjod6MIlz9ajYa8SBwuBoAVfiYiIKL1kmjukuKJ/kl3xUgMeGFXu/33oiXZMuNOEknbseiQiIqLImmNJjFYpO087yMovljjh5sCtfzxuMCAjIiKimBiUNcKpd5jC7il54/u1/mUtjr4kMH7M7eJy+kRERBQbg7JGWPdbDoTqkyso80Rcid/DYWNEREQtQrpvS8igrBHW/ZqDYy4PrLI/5ITIMyjb9+Ztk4iIiCg2BmUx5BRo3wD8kHEO/1pj7ijZsG4DmSojIiJqCdI9+5JBWQwOS/hHdMrtSjCWV6R8e9mpv2c5ERERtXJcEqMRCrw3Dh883g7jPh0OO8ca4y+IiIiIomNQ1gg71+gx5HgHdFnBMy3VbvmkFnmFXAqDiIiI4sOgrBFcztjTMzpwgD8RERElgGPKEjBpdjW6HOTESbeaY+9MRERElABmyhJQ0k7ihvfq010MIiIiaoWYKSMiIiLKAAzKiIiIiDIAgzIiIiKiDMCgLIbcQu0V/YmIiKh1SfdCVgzKYqicoNzX8q7vq9NcEiIiImrNGJTFIbfQg+LydMfPRERE1JoxKItH7LViiYiIiJqEQVkM6b5jPBEREe0fGJTFgYkyIiIiSjWu6B9Dr2FO6HOYLiMiIqLUYlAWw8CxDgwc60h3MYiIiKiVY/clERERUQZgUEZEREQELh5LRERERGBQRkRERJQRmhSUCSHOFkKsEkJ4hBCVGo93F0KYhBD/p9p2vBBinRBioxDiTtX2XkKIP4QQG4QQHwohcppSNiIiIqKWpKmZspUAzgAwL8LjTwP4xveLECILwAsATgAwAMD5QogB3ocfBfC0lLIvgFoAVzSxbERERERxS/e6pE0KyqSUa6SU67QeE0KcBmAzgFWqzSMBbJRSbpZSOgBMBzBBCCEAjAHwiXe/aQBOa0rZiIiIiBLRKgf6CyEKAdwB4P6Qh7oA2KH6vcq7rRxAnZTSFbKdiIiIaL8Qc/FYIcQPADpqPHS3lPLLCH92P5SuSJOSBAs8nca+Msr2SGWaCGAiAHTv3j3SbkREREQtRsygTEo5rhHPeyiAs4QQjwEoA+ARQtgALAbQTbVfVwA7ARgAlAkh9N5smW97pDJNBTAVACorK9OdbSQiIiJqspTcZklKeZTvZyHEfQBMUsr/CSH0APoKIXoB+BvAeQAukFJKIcRPAM6CMs7sEgCRsnBERERErU5Tl8Q4XQhRBeBwADOFELOj7e/Ngt0AYDaANQA+klL6JgLcAeA2IcRGKGPMXm9K2YiIiIhakiZlyqSUnwP4PMY+94X8PgvALI39NkOZnUlERETU/NI8IIor+hMRERFlAAZlRERERBmAQRkRERER0t57yaCMiIiIKBMwKCMiIiLKAAzKiIiIiDIAgzIiIiKiDMCgjIiIiCgDMCgjIiIiygAMyoiIiIgyAIMyIiIiogzAoIyIiIgoAzAoIyIiIsoADMqIiIiIMgCDMiIiIqIMwKCMiIiICLwhORERERGBQRkRERFRRmBQRkRERJQBGJQRERERZQAGZUREREQZgEEZERERUQZgUEZERESUARiUEREREWUABmVEREREAKRM7/KxDMqIiIiIMgCDMiIiIiIAQoi0vn6TgjIhxNlCiFVCCI8QojLksUFCiAXex1cIIfK824d7f98ohHhOeD8BIURbIcT3QogN3v/bNKVsRERERC1JUzNlKwGcAWCeeqMQQg/gXQDXSCkPBnAMAKf34ZcATATQ1/vveO/2OwHMkVL2BTDH+zsRERFRs2jRY8qklGuklOs0HjoOwHIp5V/e/aqllG4hRCcAJVLKBVJ5528DOM37NxMATPP+PE21nYiIiKjVS9WYsn4ApBBithBiiRDidu/2LgCqVPtVebcBQAcp5S4A8P7fPkVlIyIiIso4+lg7CCF+ANBR46G7pZRfRnnefwAYAcACYI4QYjGABo19E84VCiEmQukCRffu3RP9cyIiIqKMEzMok1KOa8TzVgGYK6U0AIAQYhaAYVDGmXVV7dcVwE7vz3uEEJ2klLu83Zx7o5RpKoCpAFBZWZneDmAiIiKiJEhV9+VsAIOEEAXeQf+jAKz2dksahRCHeWddXgzAl22bAeAS78+XqLYTERERtXpNXRLjdCFEFYDDAcwUQswGACllLYCnAPwJYBmAJVLKmd4/uxbAawA2AtgE4Bvv9kcAHCuE2ADgWO/vRERERPuFmN2X0UgpPwfweYTH3oXSXRm6fRGAgRrbqwGMbUp5iIiIiFoqruhPRERElAEYlBERERFlAAZlRERERBmAQRkRERFRBmBQRkRERJQBGJQRERERAcgSIq2vz6CMiIiICECvkuy0vj6DMiIiIiIAAsyUEREREe33GJQRERERZQAGZUREREQZgEEZEREREYDS3PSGRQzKiIiIaL93ao9iLolBROmRld66h4iIQjAoIyIiIsoADMoopboXpXchPoqsc6E+3UUgIiIVBmWUUif3KEp3ESiCnsU56S4CpdhlB5aluwhElAAGZZRSeVk8xIjSpTwvK91FaDbt8/ef90qtF6+Y1OKV5aT+MG6T5mnS+5PzDyhJdxEojbIbeaqxAUitAY9iSikJme4iJMXVA9o26u9KsnVswSeoTW7459VWYxu1Hn1UN4G++ZDyNJaEImmOxq9ar+L9czwygzKiFLpuYFvkZujaE5lZKqAkJzwAmzigTVJf4zxm4zJKmSro1utEwsu1nNm7OKnl6bmfBgTRDCrPa5bX8QV/+fr9MzzZP981pd3RnQrS8rqtpRuyK2dOJlR5nd07OAgLneRQ0tg+M4rqxO6BiT4ndY8+6ee8A0rwz76ljXqdvqW5Sc3Kn3dAcDlCs0StpR5JpnP7ZF5D5/huLW+iGY8sSosuCQQVPZK4rMaEntoVR44u/XmjdGbUDiqLPBNTn+RiJTP+KYqzNd0uRhdyZfv8ZBQn48RanLx3EzNCiWSoDomRaelZnINu3nM9nvPxtJ7JzY5FM65r8MW9LCcroTosU53YvQhHdkzOsd+rpHGzucd2KQz6PSdJ9WDP4mwMqWie7F4yMSijjNc9xoUjkcqgY0HjK9JTehRhYNvchP/u4DbaFcN5B5TgiA6BCrEogWjlpB7FOKRtLnqXJCdg7VPafMtjdC5IXpAdrVszE7JfF/crxc2HNG48YjLEumXMKU0MbLJT1JhRF7swQqugsBm/36a+y9BzuzlKHm9jakCbyHVatMZasvUpycaYLoWobPf/7Z15kBzVfce/v+6572Pve1d7SNrVyVoIAeI0SFwCWYAwhzhsDgsSjI2Ri6qU/8gfIc5pxzFlF7ZxYgdsYmLK8YVtKk45MTaHQChCSNwCARa6JXSs9uWP7l71zPY53TPTu/v7VG1p9Gamp3/9ut/7vd/1/FESzcRP+L3K9Jn6j1oM45Glze4e4jV9Gdw4lHNtARouxHBJt/tJbEHReNDrSUcsSxaYDR59mTDyURkXd6dxVmvS8DOAc8vbaGMMI4XarSitJgG3mK2qm+Iy+ipcubtl/Yi5YkjwFhtT7QQHq3OrhvW4Ej3q2oGTtdaiMlXFomz0qEUt5D/VpWVV7/68sDOJu+dXP5kh4bPS6sQ57KVrZCIsaYr7tv1byKT/ZKKSxXDQYKWMqQt+rnKzERlnuohR689GJlnM/F50jxSiuHNEsZCQjxvcFqIyzmk7qYhZzffl2UvD+aihAmtk7dB/d1FAXQBWVkt9BqfT1X41FtDl97nbn7i8190iYH4FllwzOlP+u+fuGvGmjHx2fhF3zyvgCwu9HafBRf22TERCR9m1iHlQtBc1+KcQLA7Ys3mbzwk5ZpzlMSa5I8A7zbBSFlCqEa/Q6sF1V06jx6KUDTHn5yIslmhL1RWrmRvlU7PNK5o3xpVzWNYcx5kWFqdKBr64TK7ckfEQTbJMNMUnX6N1Q9mJ8y5Hb4EysrBc2pPG2W3mcuoH1Kv7s9iwqAEbFjXgnPYkbhzK4fMLqr+6d6oIfHZ+AStsAsc17NzfGp+aky8JDO7LhD2v2sszSStxfwPKQP3xDvO+0zCzDgSFiEyGCpGZkrSgGJ0UVE9EkGwWOsts4qQ+NSfvOB7u5tk5RMtqoMU83hh+JRb6URw4H5Uty/Zc3JXCFTaLA228cTPmOeGO4Tw+ZzDunNZir5RZuSk7ksZjgpfwFr/wdAWJ6Eoi2kxE40Q0qmsPE9HDRLSJiLYQ0Rd1760goq1EtJ2INujae4noaSLaRkSPEhHvAVMBZ7eZ36xDPsYHWI2JXuvZuHFPWD1ES5viaDBRYADgqlkZXNOfwfK2ZImlTBusU2EJt8/NO5oMK0XTN3vTkUkTk5MBN6ub9PVWkusH7bPYtMusxR0Z1QcDAIkILYmQrxP+ZSZu4Nk5Z0pLVJZsJ2Y72srunVxUxsKGGC5Q+zsVlnDvwgbb4+iTDa4fzGJJFZIGijEZp1QYa2PlhvPC/ELU1vJnF3PWHJexbjCLhSZJAMtbk7aWZi0TORM+ef+OmMRx6mnXTcz62LuVDpT9XFR2VDbDLMtcIsJ9Hq19fkDquazuNc+cnFeMYcjiuZxXiOKGIWdZs7eULZJbEyH0q/GswwYLlmxELrmH3LjUz2s378eITJOsyhsWNaAQgB0wvKq1LwFYDeC3Ze1XAogKIeYBOAXAbUTUQ0QygK8BWAlgLoBriGiu+p0HAPy9EGIAwB4At3g8t2nPBQbKwtJm76UmruhN4zIPAcC3D3sLbHYVGK0+o8LAnCapd7eZ9SUektBtsP9jWyKMq2ZlsG4oi1xUrsj9uMBkkhltNG6vdNo0UpS6U2FHcUynNMaxrDmOU3UuzXPbk47S/d2mv5crKnMNBuA/m1cwtEqeVuP4D7vgeD2EUvd0e1IJVjYjbWNJOL89iQ2LTiqCVlZiDbssRL9dSvO0viOgzcTioDE7F8FQLoLbLc6hNRn2xcV/ocvyB4mQNHG/6Rd3k55dkz7Qx2GaZTB2WrjJ9DK7UTYclxPSnbdTAxYB+JjJGGVGPipP7KZAAAazEVMDQKZswb5uKId8VMaGRQ2Wip/GZ4bzljGceuyyOP2OufMLT2clhNgihNhq9BaAJBGFAMQBHAOwH8ASANuFEK8JIY4BeATAKlLuznMBPKZ+/2EAl3s5t5nAYt3KeV4hWlITSKOSOJmhXNR28vCCkTlaj1cLiIaXbVf6MhGkw5WvmswsdOWp9U44R2f9tFIYtPglpyb4kESqlfDkMZc0xW13L2iKyxNWPYK1ZbSoDrhWigqgxLslQpLh5DxLDdh3434nAFr3+3U/lSMRcEGnRaKFwUR7uo3bpdVl2MInB7KYnY9autj9nnz0rh87SxgR4YreTElxWCdo1nKro2uf0Sy8EZkcLSj09dLiVgOki9vmzNYkih6SMpz+VH82gmW6e0g/VusVoQFdNvUdw3ncM79oqWxpj0g6LOG8Csaok8chrO7L4AoTy5vXSnKxkDRpXHZb89KyzwNAtRyojwFYBWAngASAzwohdhNRO4C3dZ/bAeBUAEUAe4UQY7r29iqdmys6kiHsODRm/0Eb4iHCR2POb8nzO5J4eOs+x59f2ZUynHy602G8uv+44+M4ZUlTHD9586Dt50LqOfVlwnhNPQ+jgfyCjiR+ueOQ5bGSIUJjPIQ3DvgvTyXMyUWwZe8xzMpU5xprSES4d2ERR8aEpQuxMR7CuqEsmi1ctgBw01Cu4sHx+sEsClEZY+PKEZJhCTcO5fD6geP48RsHJj43mI3glX3HkHbgynbqxrl2IIu/eeFD28+NNsZwWnMCIUmxQIwUojg8Nm75nUqG6S9YuDZvHMoZxtfIEqEYk/HhkRP4ZH8Wv915qGR8cXseXRaWmHk28WtelIhqc/WsLF7Zd2xCoRzMRia5tpviIazpy6DbgRtxdW8aP3pduT/9clHVcmq/fjCLE2Jyf6fCEtaPnFxE/dXzuwBMjnkjIl8TjuqBWZz10uY4QhLhN+8Yzx8jhShe2n104v9SYPcyUbBVyojoVwBaDN66XwjxY5OvLQFwAkAbgDyA/1aPY3Q1hEW72TndCuBWAOjq6jI/eR+YX4xhxyF75cOOxQ0x/O69jxx9dklTHK0uazmZWQNmZSKuFIb1w85Mw04DTGXpZOzEAxuNJ9TmuIzFjXFbpaw7HcFlPemJgafeDBdi2LL3mOvv3TiUM3S3WiETIRm2H0yc3DfNHoJZtTgcTSlb3ppALCRNWMuKMRk3DGYRlSVs2XPUUdyN0WTRlgjh3cOliyG7mLY7hvM4MV466Z6lJjakwzLObU+aDtxei0x+rDFWEt/nxFqZCJGSCKAqZac1xx1bA68dyNrWWzJ6RpviMj746ASiMuHTVc6UazFZHKzqSeM/Xj+AD4+eMP1uLiqXuLxX9xlbXvrL6utd2JnCr3ccQjYi4ZbZOTz08l7FpZaLoi3x0aR7SrO6OAlQb0+G8M6hMZyhWqqyEQlntyUwx6LEi5YQtawlgQPHxicphJmwhP3HlQXD+pE8jp0Q+OaWvRPvr+nLYGxclMS/BYHZuQhedjj23TVSwFdf2u36N/Rj5F0jBVN3pKSW0jB7ti/qSuGMlgQe/L89rs+hHtiOAEKI8ys47icB/FwIcRzAB0T0OwCjUKxknbrPdQB4F8AuADkiCqnWMq3d7Jy+AeAbADA6Ohr4Ha8bYjJOb0k4Vsr8ojcdxqKGmK2yoydtsO+gGZd0p3Do+Dieevew5efsVmgru6pbmduJ/lM+uDtBc5V0p90pvvXI8PFzVwRAUZD0sU9adlpLPDTx2myycnKtbxjK4fvb9uGtg5Ovq5kukrW5d8sH7jNaE/jBq/sBWLvh7hwpYOveo3jS4jmyc/lcN5DFBx9ZW9zP0mXGnt2WsLxPrGKVjFjbn0FMVpTnf9hkP0Gu7c/gjx9UPl7dOiePnIkrsTEewqU9aXxn617D973Qk47gljnK/WW2cNSPBwuKUcRDhJhM2LznqOViU3OXaoozEZXE8BopDbGQVPKclHPdYBb/vHkP2pIhRUHUdWtHMlTRuKTRn43guV1HfEv00Me9LW1OOFbK3JY/IgMbjZcSShJVp7ZdtahW4NBbAM4lhSSApQBeBvBHAANqpmUEwFoATwhFJX4KwBr1++sAmFnhaoofBSiv7s+4imvxq1P6s5EShWjA4AG/biBrGNRfXlKhPBA1G5YxUojhVJeJBfrVvVap226VOpiLYG4+inPazX9LXzdIO1cr10455SnvTijGQrhzpOAoMHZ5awKXdNd2HzatD7tTYduUds+/FZOxtj/jqEyF0wH2ku4UTm2Kl7gtbhrKeUok6dc9z2bPtnZ+uchJK4oTF5kVHanwRAyo9hwmLJIxljYnJu3P6ZacTkntSU+uzWeF2W9bxQ+u0VmzZKl6sXyVYnQ6RIShXHRinIx7mLy17YLclKnIRGTcOJQzjMG6btC8nM+l3SlD97S+7fyOJNYP5z3VVNOzuDGGc9oSuHdBMRClI6Yrnq4sEV0B4KsAGgH8JxFtFEJcCCXD8ttQsjMJwLeFEC+q37kTwC8AyAC+JYTYrB7uPgCPENFfAngewENezs0vUmEJYQk4bh2SYspNQ7kJE7neVG1F3qeYh/Lg36JBbTCtiN5zf/qoZFWWDCsrvMNj4zg8No58RMaX1Xie+xYWK4pP+PyCoqU3/9Nzcth3bPL1CUtUojjeNjePh7bsgT5Eb34hip+9pbiZu9Lhkgmimjity7PMQV0dP2oO6TmjNYGudNjz5O4Uv38nE5FxTlmCgBfXK+Bsr8b+bARX9mXQ69MWVuUsb01gSVO8RCmzq6tVCbMd7pywfjiPcQBf32zu3ulNh7G6LwMCsFkXn6OnPxtxPMZNR7SxIB9RXK+v73dmSSpXcFZ2pmzj3oYLMQwb7MLRkw5j0+6jCEtKLTe956PZZv9XO2Qi14twjahEODouvEf66yAYH+7m2TkctLgHtXmuNx3G79+vrffKCZ5GOCHE4wAeN2g/CKUshtF3fgrgpwbtr0GJRQscrYnwJDfKFxYW8caB4xPuDzP0k8hNs3P4RweuA79woziZrcoSIWnSit7suLfPzVsGVNvFBBVjIRhVkih3P+ajyhY6r+w7Oeg5kdWu2vmKzhR+/vZBW1O3VaD8rXPycJO0qbmh5hej6EqF0Z4M43vbnCd4WCER1Uwhc8LKzhTqXdvU6TNRzb1AJaJJ8WBeg+570mE8t+vIhGvNbHsmTXz9vqBOQxac7HOpHd9lyOS0IBeVsbo3ja50GDFZMi2LY8cCD/GNc/JR7Dk6jo81TT7GcCGGoyeEq3AW354D3a2zrDmO//FBGbp9OG+4iG+Kh1BeKlDznpzRkpgoX9KdjuC+hUVs2n3UczFgP2EbpAOWtcTx1vZSpawS03yle+B9vCNpGc/iloFsBNv2uQ9QtyMXlV2nvtsx2hhzlObuhBGbQXJhQ8xRwLeVtcZtZlc2IpfEnOhjhYayUTz7pyOeXWdBwctkEySu6E2jzacdN7S6TWZjQz4qIywByy2KQgNKIPs98yM4cNw8eB5Q3PSretKOYtKcjnGzMuGJBJOrZmWwcdcRZD0WkPYDgjIZW4U9uMFJ/bpBh8WPq4VEhDMsSkSYFYgu58zWBPYdO1GVPXGXtyV9UcqyEdk2jlRDLouB1SAizK9Qea4WrJQ5wM2WQJUyJxfBrGwEP3nz4KQtL05pjFsqZW62PLp7XgFhmfBlk0zIoHBWawLjsK/r5ARthV//acIdXemwZZAwo7C8NVGVRYYZg2Wxml44syWB1kRo0j6lGhGZ8LkFzu6BiEyAg3wTq2xBPSs6UzhwfD/eOzxmGf925ayT1dyLsZCjOlea5aKaYysR4R6HW4NpvalXRK+elcHzu45MWM5XdKaQixyumlu7nmjJAANqrTM/xl07/NyndTrBSlkVcbJpbiYs4fTWBGbnIojKEvoyEcMB8PJeJY28nGsHsq5ikfwK+vSDlV1pPPXOIcNifk72Nivnoq4UfvrW5PIlF3ensXHXkarsJ8rUn2UtCUcxe35QrHCHBzNkiRxVMte4cSiHnYfNNS9tAWLmvnRDMixh3WAWL354FLPz/rpzCzEZa2dl0B6QjaHbkyGMNsZKynC0JcMlOxYkPRZWDSKaZyMWknDXSKFmhVXvXVj0fZE82hjDHosyK1MFnqV85o7hPH7y5gG8fXDMsflfH3ugV8g+0ZeeyApUCidOVsqM3BAt8RDes0m/L0ZlHDnhT0Du0qY4ThgEkZxqswdgfzZSccp3ayKEV/YdQ1YXG2MWF5AKS5Ym/aCxfjhf28qUzJShJRGyzHzLRGRc2ZdBh8ON3e0goqq5nXt8yGx3gza2GsW2SkQV7bYxVelOhfHxzmSJpbLSshNmm8nrGcpF8OKHRyGr197KFTyYi2D+wSiWt7rbc3i69B8rZR7oSoVL4rM0V9M1/Ur1ZSc0WmTEDGRLV9A3DGbx3Vfsg8C16s9WVFI4crQxhv0GgZVnG2yhU22329LmOGZlI2iyqV5fS/zazcZNrbipjtlG1LUiJlNNXDW1pNLg7OsGsvhXn5JMgsjFXSls2XvUcxbidIDIP9exkzi6FZ0pnNWadJQsEpIIF1W5dmWQCc6MFmASIUIhKuOstgQe17kQQxLhE32ZSRXmJSLTLLOYTDghxESJDTcbf9tt/qshS4RqDDtBWokQUaAUsku7U477h1GohgvDLXfPdxZzNBPocOhKjGr1BQMUCuGEWEjCoobabm4/nVnbn3G8kbrkcEcShpUyR0hEuFW1LN06J4R9x0r91rfNzTv2Nt09v4jDY+P4yqbduKgrVVHRUkB5IJxyWXcaHvbmnjLUs1alUc0gxhon2WxBIaPWOTmtCvXEgoadsjWUjeDirhTmOkwYYIKDlh3uNNnDiiCV25lOkNs9+ILG6OioeOaZZ+p9GjXj/cNj2Hl4zPNefdORE0LgVzsOYVlLfKJg70zg3UPHsf/4+KQNmxnGLe8dHkMmLE1sBM5MP8aFqMluC49u34fXDxznDHIDiOhZIcSo0XtsKZtiNCdCnquaT1dkIlzYGRwXa61oS4bRVu+TYKYFvH3O9KdW21+t6cvg+BQ3+tQDfgIZhmEYhvEVJbZ56oQoBAW2UTMMwzAMwwQAVsoYhmEYhmECACtlDMMwDMMwAYCVMoZhGIZhmADAShnDMAzDMEwAYKWMYRiGYRgmALBSxjAMwzAMEwBYKWMYhmEYhgkArJQxDMMwDMMEAFbKGIZhGIZhAsCU35CciP4E4M0q/0wDgF1V/o0gM5PlZ9lnLjNZ/pksOzCz5WfZq0+3EKLR6I0pr5TVAiJ6xmxH95nATJafZZ+ZsgMzW/6ZLDsws+Vn2esrO7svGYZhGIYrf7gFAAAGXElEQVRhAgArZQzDMAzDMAGAlTJnfKPeJ1BnZrL8LPvMZSbLP5NlB2a2/Cx7HeGYMoZhGIZhmADAljKGYRiGYZgAwEqZDUS0goi2EtF2ItpQ7/OpFCLqJKKniGgLEW0moj9X279ERO8Q0Ub17yLdd76oyr2ViC7UtRteEyLqJaKniWgbET1KRJHaSmkOEb1BRJtUGZ9R2wpE9KR6vk8SUV5tJyL6iirfi0S0WHecderntxHROl37Kerxt6vfpdpLORkiGtL17UYi2k9Ed0/nfieibxHRB0T0kq6t6n1t9hu1xET2LxPRy6p8jxNRTm3vIaKPdPfAg5XKaHUda4mJ/FW/14koqv5/u/p+T20kPomJ7I/q5H6DiDaq7dOq78l8fpt6z70Qgv9M/gDIAF4F0AcgAuAFAHPrfV4VytIKYLH6Og3gFQBzAXwJwOcNPj9XlTcKoFe9DrLVNQHwAwBr1dcPArij3nLr5HkDQENZ218D2KC+3gDgAfX1RQB+BoAALAXwtNpeAPCa+m9efZ1X3/sDgNPU7/wMwMp6y2xwDWQA7wHons79DmA5gMUAXqplX5v9RgBkvwBASH39gE72Hv3nyo7jSkaz6xgQ+at+rwP4DIAH1ddrATwaBNnL3v9bAH8xHfse5vPblHvu2VJmzRIA24UQrwkhjgF4BMCqOp9TRQghdgohnlNfHwCwBUC7xVdWAXhECHFUCPE6gO1QrofhNVFXDecCeEz9/sMALq+ONL6xCsp5AqXnuwrAd4XC7wHkiKgVwIUAnhRC7BZC7AHwJIAV6nsZIcT/CuXJ/C6CKft5AF4VQlgVW57y/S6E+C2A3WXNtehrs9+oGUayCyF+KYQYU//7ewAdVseoUEaz61hTTPreDD/vdf11eQzAeZolpVZYya6ey1UA/s3qGFO17y3mtyn33LNSZk07gLd1/98Ba0VmSqCa1hcBeFptulM14X5LZ3o1k92svQhgr27wD9q1EgB+SUTPEtGtaluzEGInoDzUAJrUdreyt6uvy9uDxlqUDsozod81atHXZr8RJG6GssrX6CWi54nov4joTLWtEhmDPlZW+16f+I76/j7180HhTADvCyG26dqmZd+XzW9T7rlnpcwao5XOlE5XJaIUgH8HcLcQYj+ArwOYBWAhgJ1QTNyAuexu24PC6UKIxQBWAlhPRMstPjvdZIca+3IZgB+qTTOl3+2YMfIS0f0AxgB8T23aCaBLCLEIwD0Avk9EGVQmY5CvSy3u9SDLDwDXoHRBNi373mB+M/2oQVsgnntWyqzZAaBT9/8OAO/W6Vw8Q0RhKDfs94QQPwIAIcT7QogTQohxAN+EYroHzGU3a98FxQQcKmsPBEKId9V/PwDwOBQ539fM7Oq/H6gfdyv7DpS6hAIlu8pKAM8JId4HZk6/66hFX5v9Rt1RA5YvAXCt6n6B6rb7UH39LJQ4qkFUJmNgx8oa3esT31Hfz8K5G7WqqOezGsCjWtt07Huj+Q1T8LlnpcyaPwIYICXjJgLF/fNEnc+pItSYgocAbBFC/J2uXe/7vwKAlrnzBIC1pGQV9QIYgBLoaHhN1IH+KQBr1O+vA/DjasrkFCJKElFaew0l8PklKDJq2TX6830CwA1qhs5SAPtUs/QvAFxARHnVBXIBgF+o7x0goqXqdb4BAZFdR8lKeSb0exm16Guz36grRLQCwH0ALhNCHNa1NxKRrL7ug9LXr1Uoo9l1rDs1utf112UNgN9oym8AOB/Ay0KICffbdOt7s/kNU/G5FzXOkphqf1CyNF6BspK4v97n40GOM6CYW18EsFH9uwjAvwDYpLY/AaBV9537Vbm3QpdNaHZNoGQr/QFKwOwPAUTrLbfuvF5Q/zZr5wwl5uPXALap/xbUdgLwNVW+TQBGdce6WZVvO4CbdO2jUAb7VwH8E9TCzEH4A5AA8CGArK5t2vY7FOVzJ4DjUFa4t9Sir81+IwCyb4cSJ6M991qW4CfU5+EFAM8BuLRSGa2uYwDkr/q9DiCm/n+7+n5fEGRX278D4Payz06rvof5/Dblnnuu6M8wDMMwDBMA2H3JMAzDMAwTAFgpYxiGYRiGCQCslDEMwzAMwwQAVsoYhmEYhmECACtlDMMwDMMwAYCVMoZhGIZhmADAShnDMAzDMEwAYKWMYRiGYRgmAPw/i9U/hd+xmGAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "average_returns = np.array(globalNet.average_returns[:])\n",
    "ep_returns = np.array(globalNet.ep_returns[:])\n",
    "nonzero_indices = average_returns!=0.0\n",
    "plt.plot(ep_returns[nonzero_indices], color='skyblue')\n",
    "plt.plot(average_returns[nonzero_indices], color='blue')\n",
    "plt.show()\n",
    "#fignum = len([f for f in os.listdir() if 'v3_Pendulum' in f and 'png' in f])\n",
    "#plt.savefig('A3C_v3_Pendulum_%d.png'%fignum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>running</th>\n",
       "      <th>EP</th>\n",
       "      <th>Loss</th>\n",
       "      <th>Return</th>\n",
       "      <th>LR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [running, EP, Loss, Return, LR]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
