{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gym.logger.set_level(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ENV_NAME = 'Pendulum-v0'\n",
    "input_dim = 3\n",
    "action_list = [4/10*i-2 for i in range(11)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A3C(nn.Module):\n",
    "    def __init__(self, input_dim, action_dim, max_ep=0, is_global=False):\n",
    "        super(A3C, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.max_ep = max_ep\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, action_dim)\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        \n",
    "        self.ep_counter = None\n",
    "        self.ep_returns = None\n",
    "        self.average_returns = None\n",
    "        \n",
    "        if is_global:\n",
    "            self.set_global()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        Q = self.fc3(x)\n",
    "        V = self.fc4(x)\n",
    "        return Q, V\n",
    "    \n",
    "    def set_global(self):\n",
    "        self.ep_counter = mp.Value('i')\n",
    "        self.ep_counter.value = 0\n",
    "        self.ep_returns = mp.Array('d', self.max_ep)\n",
    "        self.average_returns = mp.Array('d',self.max_ep)\n",
    "        \n",
    "    def log_episode(self, ep_return):\n",
    "        c = self.ep_counter.value\n",
    "        self.ep_returns[c] = ep_return\n",
    "        self.average_returns[c] = np.mean(self.ep_returns[max(0, c-99):c+1])\n",
    "        self.ep_counter.value += 1\n",
    "        return self.ep_counter.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_THREADS = 8\n",
    "\n",
    "#T_max = 10000\n",
    "MAX_EP = 10000\n",
    "t_max = 5\n",
    "print_freq = 500\n",
    "\n",
    "beta = 0.01   # entropy regularization\n",
    "gamma = 0.99\n",
    "alpha = 0.99   # RMSProb decay factor\n",
    "learning_rate = 1e-4\n",
    "decay_rate = 0.996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lock, globalNet, optimizer, tmax, pid):\n",
    "    t = 0\n",
    "    done = False\n",
    "    ep_return = 0\n",
    "    log_episode_return = []\n",
    "    cur_ep = 0\n",
    "    \n",
    "    buff_value = []\n",
    "    buff_q = []\n",
    "    buff_reward = []\n",
    "    buff_logp = []\n",
    "    buff_entropy = []\n",
    "    \n",
    "    localNet = A3C(input_dim, len(action_list))\n",
    "    localNet.load_state_dict(globalNet.state_dict())\n",
    "    env = gym.make(ENV_NAME)\n",
    "    obs = env.reset()\n",
    "    \n",
    "    while globalNet.ep_counter.value < MAX_EP:\n",
    "        t_start = t\n",
    "\n",
    "        while t_start-t < t_max:\n",
    "            Q, V = localNet(torch.tensor(obs.astype(np.float32)))\n",
    "            prob = F.softmax(Q, dim=0).data\n",
    "            [a] = np.random.choice(localNet.action_dim, 1, p=prob.detach().numpy())\n",
    "            log_prob = F.log_softmax(Q, dim=0)\n",
    "\n",
    "            obs, reward, done, _ = env.step([action_list[a]])\n",
    "            ep_return += reward\n",
    "            entropy = -log_prob*prob.sum()\n",
    "\n",
    "            buff_q.append(Q)\n",
    "            buff_value.append(V)\n",
    "            buff_reward.append(reward)\n",
    "            buff_logp.append(log_prob[a])\n",
    "            buff_entropy.append(entropy)\n",
    "            t += 1\n",
    "            \n",
    "            if done:\n",
    "                cur_ep = globalNet.log_episode(ep_return)\n",
    "                obs = env.reset()\n",
    "                ep_return = 0\n",
    "                break\n",
    "\n",
    "        R = V if not done else 0\n",
    "        policy_loss = 0\n",
    "        value_loss = 0\n",
    "        entropy_loss = 0\n",
    "        for i in range(-1, -(t-t_start)-1, -1): #range(t-1, t_start-1, -1):\n",
    "            R = buff_reward[i] + gamma*R\n",
    "            TD = R - buff_value[i]\n",
    "            policy_loss += buff_logp[i] * TD.detach()\n",
    "            value_loss += torch.pow(TD, 2)\n",
    "            entropy_loss += buff_entropy[i].sum()\n",
    "        loss = - policy_loss + value_loss - beta*entropy_loss\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        lock.acquire()\n",
    "        try:\n",
    "            for local_param, global_param in zip(localNet.parameters(), globalNet.parameters()):\n",
    "                global_param.grad = local_param.grad\n",
    "            optimizer.step()\n",
    "        finally:\n",
    "            lock.release()\n",
    "        localNet.load_state_dict(globalNet.state_dict())\n",
    "        \n",
    "        if cur_ep%print_freq==0: #globalNet.ep_counter.value%100==0:\n",
    "            print('[%d] Process'%pid)\n",
    "            print('%d/%d episodes. (%.2f%%)'%(cur_ep, MAX_EP, cur_ep/MAX_EP*100))\n",
    "            #print(globalNet.ep_counter.value-1, 'episodes.')\n",
    "            print('Total loss:\\t', loss.data.numpy()[0])\n",
    "            print('Entropy\\t\\tPolicy\\t\\tValue')\n",
    "            print('%.2f\\t\\t%.2f\\t\\t%.2f'%(entropy_loss.data.numpy(), policy_loss.data.numpy()[0], \\\n",
    "                  value_loss.data.numpy()[0]))\n",
    "            print('Epside Return: [%.1f]'%globalNet.average_returns[globalNet.ep_counter.value-1])\n",
    "            print()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Process Process-2:\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 23, in train\n",
      "    Q, V = localNet(torch.tensor(obs.astype(np.float32)))\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 23, in train\n",
      "    Q, V = localNet(torch.tensor(obs.astype(np.float32)))\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-3:\n",
      "Process Process-6:\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 23, in train\n",
      "    Q, V = localNet(torch.tensor(obs.astype(np.float32)))\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-4-0f2851772c09>\", line 22, in forward\n",
      "    x = F.relu(self.fc2(x))\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"<ipython-input-4-0f2851772c09>\", line 22, in forward\n",
      "    x = F.relu(self.fc2(x))\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"<ipython-input-4-0f2851772c09>\", line 22, in forward\n",
      "    x = F.relu(self.fc2(x))\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 87, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 87, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 23, in train\n",
      "    Q, V = localNet(torch.tensor(obs.astype(np.float32)))\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 59, in train\n",
      "    loss.backward()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/functional.py\", line 1372, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 87, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/tensor.py\", line 195, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-4-0f2851772c09>\", line 22, in forward\n",
      "    x = F.relu(self.fc2(x))\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 532, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/functional.py\", line 1372, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/functional.py\", line 1372, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/modules/linear.py\", line 87, in forward\n",
      "    return F.linear(input, self.weight, self.bias)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/nn/functional.py\", line 1372, in linear\n",
      "    output = input.matmul(weight.t())\n",
      "KeyboardInterrupt\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 59, in train\n",
      "    loss.backward()\n",
      "Process Process-8:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/tensor.py\", line 195, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0df1352c26b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprocesses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/gym/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/gym/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 59, in train\n",
      "    loss.backward()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/tensor.py\", line 195, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"<ipython-input-6-c1b369f78822>\", line 59, in train\n",
      "    loss.backward()\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/tensor.py\", line 195, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "  File \"/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/torch/autograd/__init__.py\", line 99, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "globalNet = A3C(input_dim, len(action_list), MAX_EP, is_global=True)\n",
    "globalNet.share_memory()\n",
    "optimizer = optim.Adam(globalNet.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate)\n",
    "lock = mp.Lock()\n",
    "\n",
    "processes = []\n",
    "for p_idx in range(NUM_THREADS):\n",
    "    p = mp.Process(target=train, args=(lock, globalNet, optimizer, t_max, p_idx))\n",
    "    p.start()\n",
    "    processes.append(p)\n",
    "for p in processes:\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(globalNet.ep_returns[:], color='orange')\n",
    "plt.plot(globalNet.average_returns[:], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
