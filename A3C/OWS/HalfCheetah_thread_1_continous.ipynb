{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseoko/anaconda3/envs/spinningup/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import threading\n",
    "import math\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "GITPATH = subprocess.run('git rev-parse --show-toplevel'.split(' '), \\\n",
    "        stdout=subprocess.PIPE).stdout.decode('utf-8').replace('\\n','')\n",
    "sys.path.append(GITPATH)\n",
    "import dobroEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5b81793c30>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyper parameters\n",
    "t_max = 1\n",
    "gamma = 0.95\n",
    "learning_rate = 0.001\n",
    "beta = 0.1\n",
    "\n",
    "seed = 0\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.93884313  0.5630308   0.24319178 -0.30374    -0.22571829 -0.28242505]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('DobroHalfCheetah-v0')\n",
    "env.unwrapped.initialize(is_render=False)\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class policy_net(nn.Module):\n",
    "    def __init__(self, input_feature , num_actions):\n",
    "        super(policy_net,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features = input_feature, out_features = 128)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear = nn.Linear(in_features = 128, out_features = 256)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features = 256, out_features = num_actions)\n",
    "        #self.linear3 = nn.Linear(in_features = 256, out_features = num_actions)\n",
    "        self.mean_act = nn.Tanh()\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.activation1(self.linear1(x))\n",
    "        x = self.activation2(self.linear(x))\n",
    "        mean = self.mean_act(self.linear2(x))\n",
    "        #variance = self.var_act(self.linear3(x)) + 0.0001\n",
    "        variance = torch.Tensor([0.25])\n",
    "        return mean , variance\n",
    "    \n",
    "class value_net(nn.Module):\n",
    "    def __init__(self, input_feature):\n",
    "        super(value_net,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features = input_feature, out_features = 128)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear = nn.Linear(in_features = 128, out_features = 256)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features = 256, out_features = 1)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.activation1(self.linear1(x))\n",
    "        x = self.activation2(self.linear(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_action(mean , variance, num_actions):\n",
    "    action = [np.random.normal(mean[i].detach().numpy(), variance[i].detach().numpy(), 1).item() for i in range(num_actions) ]\n",
    "    true_action = []\n",
    "    for i in range(len(mean)):\n",
    "        for j in range(10000):\n",
    "            action = np.random.normal(mean[i].detach(), variance[i].detach(), 1).item()\n",
    "            if(action >= -1 and action <=1):\n",
    "                true_action.append(action)\n",
    "        if( len(true_action) <= i):\n",
    "            true_actioin.append(mean[i])\n",
    "    return true_action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([ 0.4869,  0.8546,  0.3070,  0.3286, -0.9944,  0.3277],\n",
      "       requires_grad=True)\n",
      "[-94.92982]\n",
      "[196.18166]\n",
      "tensor(-354.2885, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 3.74401013e-04  1.57313219e-01 -5.81552007e-01 -3.80996105e-01\n",
      " -9.74862147e-02 -2.56028673e-01]\n",
      "variance_average : [1.30906618 0.76434    0.93892009 0.74878972 0.23234996 0.88940783]\n",
      "training idx 1 actor true_reward at iteration 0 : -30.306769011390994\n",
      "270\n",
      "Parameter containing:\n",
      "tensor([ 0.3093,  0.7831,  0.2113,  0.2713, -1.0607,  0.2434],\n",
      "       requires_grad=True)\n",
      "[136.38899]\n",
      "[185.36522]\n",
      "tensor(-417.0344, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.7065596  -0.65498747  0.23076656 -0.13014081  0.01102904  0.48719783]\n",
      "variance_average : [1.09786413 0.70622014 0.82376098 0.69709911 0.20327352 0.81318238]\n",
      "training idx 1 actor true_reward at iteration 10 : 45.15278892180968\n",
      "4885\n",
      "Parameter containing:\n",
      "tensor([ 0.2647,  0.7602,  0.1742,  0.2502, -1.0887,  0.2131],\n",
      "       requires_grad=True)\n",
      "[51.20078]\n",
      "[56.11221]\n",
      "tensor(-60.3562, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.46109316 -0.13685955 -0.01951152 -0.03506645 -0.79976765 -0.23697629]\n",
      "variance_average : [0.97889118 0.65016909 0.74631606 0.64091688 0.26554011 0.77135845]\n",
      "training idx 1 actor true_reward at iteration 20 : 21.74518740094058\n",
      "5400\n",
      "Parameter containing:\n",
      "tensor([ 0.2118,  0.6213,  0.1171,  0.1348, -1.0872,  0.2399],\n",
      "       requires_grad=True)\n",
      "[50.749165]\n",
      "[69.1005]\n",
      "tensor(-1032.1497, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89123046 -0.91130392  0.81558707  0.88346462 -0.70269579  0.66609088]\n",
      "variance_average : [0.97071502 0.56303605 0.73475857 0.57421723 0.19709198 0.80074412]\n",
      "training idx 1 actor true_reward at iteration 30 : 20.249125156478964\n",
      "13476\n",
      "Parameter containing:\n",
      "tensor([ 0.0460,  0.3930, -0.0432,  0.0143, -1.1430,  0.1854],\n",
      "       requires_grad=True)\n",
      "[53.090496]\n",
      "[53.0439]\n",
      "tensor(-792.9962, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.32500844 -0.73831373  0.62794782  0.26394465  0.49273754  0.04158641]\n",
      "variance_average : [0.77888592 0.38850273 0.57375796 0.47198638 0.17430948 0.74476418]\n",
      "training idx 1 actor true_reward at iteration 40 : 35.023662460852016\n",
      "19658\n",
      "Parameter containing:\n",
      "tensor([-0.1783,  0.1922, -0.2005, -0.0777, -1.2127,  0.0618],\n",
      "       requires_grad=True)\n",
      "[30.341026]\n",
      "[50.9049]\n",
      "tensor(-111.0002, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94361968 -0.9186861   0.87041282  0.8369949   0.86885797  0.0942263 ]\n",
      "variance_average : [0.55572865 0.27538936 0.44654973 0.41840552 0.1764289  0.62803646]\n",
      "training idx 1 actor true_reward at iteration 50 : 33.24695761365494\n",
      "25845\n",
      "Parameter containing:\n",
      "tensor([-0.3376,  0.0231, -0.3875, -0.1777, -1.3892, -0.0746],\n",
      "       requires_grad=True)\n",
      "[-2.7490742]\n",
      "[31.739216]\n",
      "tensor(-186.5463, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.13144422 -0.92889146  0.82784381 -0.28802307  0.98925201  0.19570218]\n",
      "variance_average : [0.42736474 0.2033509  0.32248294 0.34418322 0.10895217 0.50979992]\n",
      "training idx 1 actor true_reward at iteration 60 : -9.244945590753685\n",
      "34630\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a42860eee945>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    173\u001b[0m ''''''th4.start()'''\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m \u001b[0mth1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m '''th2.join()\n\u001b[1;32m    177\u001b[0m \u001b[0mth3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#multihtread\n",
    "num_actions = 6\n",
    "p_net_shared = policy_net(20,num_actions)\n",
    "v_net_shared = value_net(20)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "_lock = threading.Lock()\n",
    "\n",
    "reward_plot = [0 for i in range(5000)]\n",
    "\n",
    "def training(idx):\n",
    "    t_max = 5\n",
    "    gamma = 0.99\n",
    "    learning_rate = 0.001\n",
    "    beta = 0\n",
    "    step = 0\n",
    "    state = []\n",
    "    \n",
    "\n",
    "\n",
    "    global p_net_shared\n",
    "    global v_net_shared\n",
    "    p_optimizer = optim.Adam(p_net_shared.parameters(), lr=0.0001)\n",
    "    v_optimizer = optim.Adam(v_net_shared.parameters(), lr=0.001)\n",
    "    global reward_plot\n",
    "    \n",
    "    for iteration in range(5000):\n",
    "        done = False\n",
    "        env = gym.make('DobroHalfCheetah-v0')\n",
    "        env.unwrapped.initialize(is_render=False)\n",
    "        observation = env.reset()\n",
    "        state = observation\n",
    "        \n",
    "        p_net = policy_net(20,num_actions)\n",
    "        v_net = value_net(20)\n",
    "    \n",
    "        p_net.zero_grad()\n",
    "        v_net.zero_grad()\n",
    "        \n",
    "        t_update = 0\n",
    "        #beta -= 0.0002\n",
    "        #learning_rate -= 0.0009/2000\n",
    "        if(beta<=0):\n",
    "            beta = 0\n",
    "        reward_stack = []\n",
    "        prob_stack = []\n",
    "        value_stack = []\n",
    "        action_stack = []\n",
    "        entropy = 0\n",
    "        reward_sum = 0\n",
    "        policy_loss_sum=0\n",
    "        value_loss_sum = 0\n",
    "        entropy_sum = 0\n",
    "        \n",
    "        \n",
    "        mean_average = np.zeros(num_actions)\n",
    "        variance_average = np.zeros(num_actions)\n",
    "        \n",
    "        \n",
    "        for t in range(10000):\n",
    "\n",
    "            step = step+1\n",
    "\n",
    "            mean, variance= p_net(torch.Tensor(state))\n",
    "            value = v_net(torch.Tensor(state))            \n",
    "            \n",
    "            mean_average += mean.detach().numpy()\n",
    "            variance_average += variance.detach().numpy()\n",
    "            \n",
    "            action = get_action(mean,variance,num_actions)\n",
    "            \n",
    "            next_state , reward, done, info = env.step(action)\n",
    "            #reward /= 16.2736044\n",
    "            reward_sum += reward\n",
    "            t_update += 1\n",
    "\n",
    "            reward_stack.append(reward)\n",
    "            value_stack.append(value)\n",
    "            prob_stack.append((mean,variance))\n",
    "            action_stack.append(action)\n",
    "            \n",
    "            for i in range(num_actions):\n",
    "                entropy += -(torch.log(torch.clamp(2*math.pi*variance[i]*variance[i] , min = 1e-6)) + 1)/2\n",
    "\n",
    "            if(t_update >= t_max or done):\n",
    "                if(done):\n",
    "                    R=0\n",
    "                else:\n",
    "                    R = v_net(torch.Tensor(next_state))\n",
    "                policy_loss = 0\n",
    "                value_loss = 0\n",
    "                \n",
    "\n",
    "                for i in range(t_update):\n",
    "                    R = R*gamma + reward_stack.pop()\n",
    "                    value_temp = value_stack.pop()\n",
    "                    mu , var = prob_stack.pop()\n",
    "                    action_i = action_stack.pop()\n",
    "                    advantage = (R-value_temp).detach()\n",
    "                    for j in range(num_actions):\n",
    "                        policy_loss += ( (( (action_i[j] - mu[j]) )**2)/2 ) * advantage\n",
    "                    value_loss += (R-value_temp) * (R-value_temp)\n",
    "\n",
    "                entropy_sum += entropy / t_max\n",
    "                entropy = -entropy * beta\n",
    "                policy_loss = policy_loss + entropy \n",
    "                policy_loss = policy_loss / t_max\n",
    "                value_loss = value_loss /t_max\n",
    "\n",
    "                _lock.acquire()\n",
    "                \n",
    "                policy_loss.backward(retain_graph=True)\n",
    "                value_loss.backward()\n",
    "                policy_loss_sum += policy_loss.detach().numpy()\n",
    "                value_loss_sum += value_loss.detach().numpy()\n",
    "                \n",
    "                for p_param , s_p_param in zip(p_net.parameters(), p_net_shared.parameters()):\n",
    "                    s_p_param._grad = p_param.grad.detach()\n",
    "                    if((s_p_param != s_p_param).any()):\n",
    "                        print(\"explode !!!! \")\n",
    "                        \n",
    "                        \n",
    "                for v_param , s_v_param in zip(v_net.parameters(), v_net_shared.parameters()):\n",
    "                    s_v_param._grad = v_param.grad.detach()\n",
    "                    if((s_v_param != s_v_param).any()):\n",
    "                        print(\"explode !!!! \")\n",
    "                \n",
    "                p_optimizer.step()\n",
    "                v_optimizer.step()\n",
    "                p_net_shared.zero_grad()\n",
    "                v_net_shared.zero_grad()\n",
    "\n",
    "                _lock.release()\n",
    "                \n",
    "                \n",
    "                \n",
    "                p_net = policy_net(20,num_actions)\n",
    "                v_net = value_net(20)    \n",
    "\n",
    "                p_net.load_state_dict(p_net_shared.state_dict())\n",
    "                v_net.load_state_dict(v_net_shared.state_dict())\n",
    "                R=0\n",
    "                entropy = 0\n",
    "                t_update = 0\n",
    "            if(done):\n",
    "                mean_average /= t + 1\n",
    "                variance_average /= t+1\n",
    "                break\n",
    "\n",
    "            #env.render()\n",
    "            state = next_state[:]\n",
    "        reward_plot[iteration] += reward_sum\n",
    "        env.close()\n",
    "        if(iteration%10 ==0):\n",
    "            print(p_net_shared.variance_lin.bias)\n",
    "            print(policy_loss_sum)\n",
    "            print(value_loss_sum)\n",
    "            print(entropy_sum)\n",
    "            print(\"mean_average : {}\".format(mean_average))\n",
    "            print(\"variance_average : {}\".format(variance_average))\n",
    "            print(\"training idx {} actor true_reward at iteration {} : {}\".format(idx,iteration, reward_sum))\n",
    "            print(step)\n",
    "            beta = beta * 0.99\n",
    "th1 = threading.Thread(target = training , args = (1,))\n",
    "'''th2 = threading.Thread(target = training , args = (2,))\n",
    "th3 = threading.Thread(target = training , args = (3,))\n",
    "''''''th4 = threading.Thread(target = training , args = (4,))'''\n",
    "th1.start()\n",
    "'''th2.start()\n",
    "th3.start()\n",
    "''''''th4.start()'''\n",
    "\n",
    "th1.join()\n",
    "'''th2.join()\n",
    "th3.join()\n",
    "''''''th4.join()'''\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'reward')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA28AAANrCAYAAADRXqDqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdeZRd1X3m/WdXqTSVhAYQs0ACjQgDthkNHoDYxgMCbDxkmTQQO6TTWW3H8eqOE/tNOt1Zq92xO+msft8eAMez09jCRiZ2ggkG4mC3rBKDQTNCAyAVKgFCU42q/f6x71Hdqrrjufucs889389aWlV177nnbImi6jz399t7G2utAAAAAABh68h6AAAAAACA+ghvAAAAAJADhDcAAAAAyAHCGwAAAADkAOENAAAAAHKA8AYAAAAAOUB4AwCgTRhjbOnPY1mPBQDgH+ENAAAAAHKA8AYAAAAAOUB4AwAAAIAcILwBAAAAQA4Q3gAAAAAgBwhvAAAvjDHvKlvt8D+UHltujPlvxpjNxphDpefuqPDaq4wx/9MYs8kYc9AYM2CM2WOMuc8Y84Ea17y3dM5RY8yCKsf8Qdm4jhljplY57itlxy2v8PxbjTH/jzHmH0tjGzDG9BtjXjTGPGCMuc0Y01nn3+iOsmvcUXrs0tLf43ljzNHSc++q8NpzjTH/vXRcvzFmvzHm58aY3zXGTKl1XQBAe+CHPQAgEcaYfyXpf0maUeOYbklflfSxCk8vLP35qDHmx5J+01p7eMIxj0n6pCQj6V2Svl/hPNeWfT5D0hWSfl7juH3W2q0Txvlnkv5Dlb/G2aU/N0n6A2PMamvt3irHjmOM+bykv5BUL/TdLOnbkrrLHp4uaYGkayTdZoy5sZFrAgDyi/AGAEjC1ZK+IOm4XDh7QtKApOWSeiXJGDNN0j9JurL0mh2S7pO0WdKwpCWS/pWkZZI+IOkBY8y7rbWjZdd5tOzzazUhvBljOiS9Y8LYrtWE8GaMmSvpkgrnjMyQNCLpl6W/y/OSDkmaL2mxpNsknSXpraVxXm2tHa5wnnIfk3SDpDckfUPSBrl/r4tLj0Vju1rS9yR1lR56Qu7fab+kRZJulwtwf1vnegCAnDPW2qzHAABoA6VWv/Lg0yvpemvtpirH/7WkPyh9+WVJf2KtHZlwTJeke+VCnCT9nrX2f004Zrtc0NtirV054bm3SuopfflLSVdJesxae+2E41ZLWlv68i5r7T0Tnr9M0ovW2t4qf5epkv5S0mdKD91hrf1GhePukPS1soe2yP0bVazUldowN8qFXkn6T9baP61w7W9J+mjZw49ba99V6ZwAgPxizhsAICm/WyO4nSHp35S+/IG19t9PDG6SVKpefUrSC6WH/rDC6aLAuMIYc/qE56KQ9oqk/1H6/CpjzPQqx5Wfr3wc66sFt9LzQ5I+J2ln6aHfqnZs+cskfbxOi+WNGgtuj00MbmXXvlPSngauCQDIMcIbACAJuyU9WOP5j0qKFg75Sq0TlQLcfaUvlxpjFk045LGyz6+d8Ny1Zcf8rPT5NLkKXLl3lT6+ZK19vtZ4aozzuKR1pS8vN8aYOi/5ubX2mTrH3FL2+X+tce1jkv6/+qMEAOQZc94AAEn4F1u7L//tZZ+fXVqQo5Z5ZZ+vlLSr7OuJ897+TjrRcnhNdIy1dq8xZpvcHLpro9cZY+bLzTOTxgfBcUrz526W9GFJb5Z0pqTZqvxG6GxJJ6ls7loFlRZNmeiy0sdRVZ6LV+6RBs4HAMgxwhsAIAkv13l+Udnn32vy3OVBTtbafWWh7Lqyp94qF6CkseDzaNlxUQviO+RWqyw/bhxjzNmSHiids1H1wlu9fyPJBURJ6rXWHq1zbKyKIQAgPwhvAIAk9Nd5fk4L5660T1sUys43xiy01r6osZbJvdbabWXH/a5cW2N3KRDVnO9WWjTlIUkXlB46IOlHkp6Tm0s3IFcZk6RPl52v5vL/qv9vJEmzSh+PNXBsvXAHAMg5whsAIAtHSh+tpCkTlv+P4zG5UCa58PRNjYWoRyccJ7ll96+W9FONzXfbba3dqcl+U2PB7WFJt1SrghljPtH80Gs6Ihd0ZzZwbHf9QwAAecaCJQCALEQtg0Zuf7RWPVb2+bWlatmJ+W7RE9baV+T2kYuOO1nSmyqco9xvlH3+2Trti+c2OuAGRStRnl7a0LyWJZ6vDQAIDOENAJCFx8s+f0+rJyst47+l9OW1cgt9RGHnZxMOf7TsuHeqznw3SaeVfb6j2hiMMadqbKNvX35V+tihsQphNdd7vjYAIDCENwBAFv6PpKHS53/UQFWpEVH4OlfSb5c+r9QKGR33VkmrKzw+Ufl8s/NrXP+P5doxffph2eefrXaQMWaGpN/zfG0AQGAIbwCA1JUWFPnvpS+XSnqwwgbbJxhjOowxv2GM+WKN0z5W9vntpY+VAtljKs21kxTNUdtpra22yfX6ss//U2nLgInju0tusRLf/l7S1tLn1xtjJm3SXWoR/arGr+AJAGhDLFgCAMjKH8u1GV4v18L4gjHmfkm/lNQnt6rk6XJ7sL279Pkjkv6iyvkeK/s8+v02KbxZaw8YY56Tm+tW9bgyX5P0J3JtmLdIetIY8y1JL8m1VH5Irv2yV9KzpbF6Ya09boz5ZGl8XZL+3BjzbrlNy/fLVRnvkFtQ5Ycav6k3AKDNEN4AAJmw1g4bY94v6b/KtfzNkHRb6U81VfdGs9buN8Zs0tjKkFL1UPaoxhYqqXVctI/cJ+RaPafLhcmLJxz2slxw+v3qQ4/HWvuEMeZjkr4lFyCv0dhiLJGfy7WKEt4AoI3RNgkAyIy1dsha+28lrZD0JUnr5KpuI3JzzXZK+olc5esia+3t1c5VUh7CdpTaM+sdJ1VfaTIa51pJb5H0dUkvShqW9KqkDXKbfV9srV1f9QQtstb+UNIqSf+vpBckDcrtN/eEXPC9zlp7MKnrAwDCYKy1WY8BAAAAAFAHlTcAAAAAyAHCGwAAAADkAOENAAAAAHKA8AYAAAAAORDUVgGnnHKKXbRoUdbDAAAAAIBMbNiw4YC1dkGl54IKb4sWLVJPT0/WwwAAAACATBhjdld7jrZJAAAAAMgBwhsAAAAA5ADhDQAAAABygPAGAAAAADlAeAMAAACAHCC8AQAAAEAOEN4AAAAAIAcIbwAAAACQA4Q3AAAAAMgBwhsAAAAA5ADhDQAAAABygPAGAAAAADlAeAMAAACAHCC8AQAAAEAOEN4AAAAAIAcIbwAAAACQA4Q3AAAAAMgBwhsAAAAA5ADhDQAAAABygPAGAAAAADlAeAMAAACAHCC8AQAAAEAOEN4AAAAAIAcIbwAAAACQA4Q3AAAAAMgBwhsAAAAA5ADhDQAAAABygPAGAAAAADlAeAMAAACAHCC8AQAAAEAOEN4AAAAAIAcIbwAAAACQA4Q3AAAAAMgBwhsAAAAA5ADhDQAAAABygPCGRFx0kfTKK1mPAgAAAGgfhDd4d+iQ9Oyz0quvZj0SAAAAoH0Q3uDd5s3u47Fj2Y4DAAAAaCeEN3i3aZP7SHgDAAAA/CG8wTvCGwAAAOAf4Q3ebdokTZtGeAMAAAB8IrzBu02bpEsuIbwBAAAAPhHe4NXRo26LgFWrCG8AAACAT4Q3eLVli7RsmTR7NuENAAAA8InwBq82bZIuuECaOZPwBgAAAPg0JesBoL1E4U0ivAEAAAA+UXmDV1TeAAAAgGQQ3uAV4Q0AAABIBuEN3vT3Sy+9JJ1/PuENAAAA8I3wBm+2bXPBrauL8AYAAAD4RniDN+WLlRDeAAAAAL8Ib/CG8AYAAAAkh/AGbwhvAAAAQHIIb/CG8AYAAAAkh/AGL4aGpF27pKVL3deENwAAAMAvwhu82L5dOvdcado093V3N+ENAAAA8InwBi/KWyYlKm8AAACAb4Q3eDExvM2Y4cKbtdmNCQAAAGgnhDd4MTG8TZkidXZKw8PZjQkAAABoJ4Q3eDExvEm0TgIAAAA+Ed7QspER6fnnpeXLxz9OeAMAAAD8IbyhZTt2SGed5ea5lZs5Uzp6NJsxAQAAAO2G8IaWVWqZlKi8AQAAAD4R3tAywhsAAACQPMIbWkZ4AwAAAJJHeEPLCG8AAABA8ghvaMnx49LWrdKKFZOfI7wBAAAA/ngJb8aYzxpjNhpjnjPG/J0xZroxZrExZp0x5nljzH3GmKk+roWw7NolnXqqNGvW5OcIbwAAAIA/LYc3Y8xZkj4t6VJr7YWSOiV9XNJ/kfTX1tolkl6X9MlWr4XwVGuZlAhvAAAAgE++2ianSJphjJkiaaakfZKuk7Sm9Pw3JN3s6VoICOENAAAASEfL4c1a+7Kkr0jaIxfa3pC0QdJBa+1I6bCXJJ1V6fXGmLuMMT3GmJ6+vr5Wh4OUEd4AAACAdPhom5wn6SZJiyWdKalb0g2Nvt5ae7e19lJr7aULFixodThIGeENAAAASIePtsnfkLTTWttnrR2W9ANJV0uaW2qjlKSzJb3s4VoIyOiotHmztHJl5ecJbwAAAIA/PsLbHklXGmNmGmOMpOslbZL0qKRbS8fcLmmth2shIC++KM2dK82ZU/l5whsAAADgj485b+vkFiZ5UtKzpXPeLemPJP2hMeZ5SSdL+mqr10JYarVMSoQ3AAAAwKcp9Q+pz1r7Z5L+bMLDL0i63Mf5ESbCGwAAAJAeX1sFoIAIbwAAAEB6CG+IjfAGAAAApIfwhlisdeGt2kqTEuENAAAA8Inwhlj27pVmzJBOPrn6MYQ3AAAAwB/CG2KpV3WTCG8AAACAT4Q3xFJvvptEeAMAAAB8IrwhFsIbAAAAkC7CG2JpJLxNny4NDkqjo+mMCQAAAGhnhDc0zVpp48b64c0Yt6hJf3864wIAAADaGeENTdu/3wWzU0+tfyytkwAAAIAfhDc0LWqZNKb+sYQ3AAAAwA/CG5rWyHy3COENAAAA8IPwhqYR3gAAAID0Ed7QNMIbAAAAkD7CG5pGeAMAAADSR3hDUw4ckAYGpDPPbOx4whsAAADgB+ENTdm8ufGVJiXCGwAAAOAL4Q1NaaZlUiK8AQAAAL4Q3tAUwhsAAACQDcIbmkJ4AwAAALJBeENTCG8AAABANghvaNjBg9Ibb0gLFzb+GsIbAAAA4AfhDQ3bvFlauVLqaOK7hvAGAAAA+EF4Q8OabZmUCG8AAACAL4Q3NIzwBgAAAGSH8IaGEd4AAACA7BDe0DDCGwAAAJAdwhsacviw1NcnLVrU3OsIbwAAAIAfhDc0ZMsWaflyqbOzudcR3gAAAAA/CG9oSJyWSYnwBgAAAPhCeENDCG8AAABAtghvaAjhDQAAAMgW4Q0NIbwBAAAA2SK8oa5jx6S9e6Xzz2/+tV1d7uPwsN8xAQAAAEVDeENdW7dKS5ZIU6bEez3VNwAAAKB1hDfUFbdlMkJ4AwAAAFpHeENdhDcAAAAge4Q31EV4AwAAALJHeENde/dKCxfGfz3hDQAAAGgd4Q11DQy4ABYX4Q0AAABoHeENdfX3S9Onx3894Q0AAABoHeENdQ0MEN4AAACArBHeUNfAgDRjRvzXE94AAACA1hHeUBdtkwAAAED2CG+oy0fb5NGj/sYDAAAAFBHhDTWNjEjWSl1d8c/R3U3lDQAAAGgV4Q01tVp1k2ibBAAAAHwgvKEmwhsAAAAQBsIbaurvb22lSYnwBgAAAPhAeENNVN4AAACAMBDeUBPhDQAAAAgD4Q010TYJAAAAhIHwhpqovAEAAABhILyhJsIbAAAAEAbCG2qibRIAAAAIA+ENNVF5AwAAAMJAeENNhDcAAAAgDIQ31ETbJAAAABAGwhtq8lF5mz7dnWd01M+YAAAAgCIivKEmH+Gto2MswAEAAACIh/CGmny0TUq0TgIAAACtIryhJh+VN4nwBgAAALSK8IaaCG8AAABAGAhvqIm2SQAAACAMhDfUROUNAAAACAPhDTUR3gAAAIAwEN5QE22TAAAAQBgIb6iJyhsAAAAQBsIbaiK8AQAAAGEgvKEm2iYBAACAMBDeUBOVNwAAACAMhDfURHgDAAAAwkB4Q020TQIAAABhILyhJipvAAAAQBgIb6iJ8AYAAACEgfCGqqx1bZOENwAAACB7hDdUNTwsTZkidXa2fi7CGwAAANAawhuq8tUyKRHeAAAAgFYR3lCVr5UmJcIbAAAA0CrCG6qi8gYAAACEg/CGqghvAAAAQDgIb6iKtkkAAAAgHIQ3VEXlDQAAAAgH4Q1VEd4AAACAcBDeUJXPtsmuLml01O0dBwAAAKB5hDdU5bPyZoyrvvX3+zkfAAAAUDSEN1Q1MOCv8ibROgkAAAC0gvCGqvr7/VXeJMIbAAAA0ArCG6ry2TYpEd4AAACAVhDeUBVtkwAAAEA4CG+oirZJAAAAIByEN1RF2yQAAAAQDsIbqqJtEgAAAAgH4Q1V0TYJAAAAhIPwhqpomwQAAADCQXhDVbRNAgAAAOEgvKEq2iYBAACAcBDeUBVtkwAAAEA4CG+oirZJAAAAIByEN1RF2yQAAAAQDsIbqqJtEgAAAAgH4Q1V0TYJAAAAhIPwhqpomwQAAADCQXhDVUm0TR496u98AAAAQJEQ3lAVbZMAAABAOAhvqIq2SQAAACAchDdUZK00NCRNm+bvnIQ3AAAAID7CGyoaHHTBzRh/5yS8AQAAAPER3lCR75ZJifAGAAAAtILwhop8rzQpucVP+vtdSyYAAACA5hDeUFF/v9+VJiWps9O1Yg4M+D0vAAAAUASEN1SUROVNonUSAAAAiIvwhooIbwAAAEBYCG+oKIm2SYnwBgAAAMRFeENFVN4AAACAsBDeUBHhDQAAAAgL4Q0V0TYJAAAAhIXwhoqovAEAAABh8RLejDFzjTFrjDFbjDGbjTFXGWPmG2MeNsZsL32c5+NaSAfhDQAAAAiLr8rb30j6R2vtCkkXS9os6fOSHrHWLpX0SOlr5ARtkwAAAEBYWg5vxpg5kt4h6auSZK0dstYelHSTpG+UDvuGpJtbvRbSQ+UNAAAACIuPyttiSX2SvmaMecoYc68xplvSadbafaVjeiWdVunFxpi7jDE9xpievr4+D8OBD4Q3AAAAICw+wtsUSW+R9D+ttW+WdFQTWiSttVaSrfRia+3d1tpLrbWXLliwwMNw4ANtkwAAAEBYfIS3lyS9ZK1dV/p6jVyYe8UYc4YklT7u93AtpITKGwAAABCWlsObtbZX0ovGmOWlh66XtEnSjyTdXnrsdklrW70W0kN4AwAAAMIyxdN5/q2k7xhjpkp6QdKdcsHwe8aYT0raLemjnq6FFNA2CQAAAITFS3iz1j4t6dIKT13v4/xIH5U3AAAAICy+9nlDmyG8AQAAAGEhvKEi2iYBAACAsBDeUBGVNwAAACAshDdURHgDAAAAwkJ4Q0W0TQIAAABhIbyhIipvAAAAQFgIb6iI8AYAAACEhfCGimibBAAAAMJCeENFSVXepk6VRkbcHwAAAACNI7yhoqTCmzGu+tbf7//cAAAAQDsjvGGS48fdn66uZM5P6yQAACiC+++XHnww61GgnRDeMElUdTMmmfMT3gAAQBH80z9Ja9dmPQq0kylZDwDhSaplMkJ4AwAARbB/v7R3b9ajQDuh8oZJklppMkJ4AwAARbB/v7Rpk2Rt1iNBuyC8YRIqbwAAAK3r65MOHaL6Bn8Ib5iE8AYAANC6/fulN73JVd8AHwhvmIS2SQAAgNYMD0uHD0vXXEN4gz+EN0xC5Q0AAKA1Bw5I8+dLF15IeIM/hDdMQngDAABozf790qmnShdcQHiDP4Q3TELbJAAAQGvKw9vGjaw4CT8Ib5iEyhsAAEBr+vqkBQvcn44OF+aAVhHeMAnhDQAAoDVR5c2Yseob0CrCGyahbRIAAKA1UXiTpFWrmPcGPwhvmITKGwAAQGv6+sbCG4uWwBfCGyYZGKDyBgAA0Ir9+918N4nwBn8Ib5ikv5/KGwAAQCvK2yYJb/CF8IZJaJsEAABoTXl4O/10aXjYtVICrSC8YRLaJgEAAFoTbRUgja04uXlztmNC/hHeMAltkwAAAPH197s3w+fMGXuM1kn4QHjDJLRNAgAAxBetNGnM2GOEN/hAeMMktE0CAADEV94yGWGjbvhAeMMktE0CAADEV75YSYTKG3wgvGES2iYBAADiqxTezj5bOnpUeu21bMaE9kB4wyRJt03OmOHCm7XJXQMAACArldomWXESPhDeMEnSbZNTprg/g4PJXQMAACArlSpvEq2TaB3hDZMk3TYp0ToJAADaF+ENSSG8YZKk2yYlwhsAAGhfldomJcIbWkd4wyRJt01KhDcAANC+qLwhKYQ3TELbJAAAQHzVwts550ivvy4dOpT+mNAeCG+YhLZJAACAeKyt3jbZ0SGtWMGKk4iP8IZxrHVtk9OmJXsdwhsAAGhHR4+6j93dlZ+/4AJp48b0xoP2QnjDOCMj7l2hKVOSvQ7hDQAAtKOoZdKYys8z7w2tILxhnDRaJiXCGwAAaE99fZXnu0VWrSK8IT7CG8ZJY6VJifAGAADa0/79lee7Rai8oRWEN4yTxkqTEuENAAC0p2orTUYWLXLHHDmS2pDQRghvGIe2SQAAgPjqtU12dkrLl0tbtqQ3JrQPwhvGoW0SAAAgvnptkxKtk4iP8IZxaJsEAACIr17bpER4Q3yEN4zT359O22R3N+ENAAC0H8IbkkR4wzhU3gAAAOLr62usbZKNuhEH4Q3jEN4AAADia6Tydv750t693AuheYQ3jJNW2yThDQAAtBtrG6u8TZkiLVkibd2azrjQPghvGIfKGwAAQDxvvOHuoxq5l2LeG+IgvGEcwhsAAEA8jbRMRlatIryheYQ3jEPbJAAAQDzNhDcqb4iD8IZxqLwBAADE08h8twjhDXEQ3jAO4Q0AACCeZipvS5ZIe/ZIg4PJjgnthfCGcWibBAAAiKeZ8DZ1qrR4sbRtW7JjQnshvGEcKm8AAADx9PU1Ht4kNutG8whvGCet8DZtmjQ0JB0/nvy1AAAA0rB/f+Nz3iTmvaF5hDeMk1bbpDGu+tbfn/y1AAAA0tBM26REeEPzCG8YJ63Km0TrJAAAaC9x2iYJb2gG4Q3jEN4AAADiabZtctkyaedON5UEaAThDeOk1TYpEd4AAED7GB2VXn1VOuWUxl8zfbp0zjnS888nNy60F8IbxqHyBgAA0LzXXpPmzJG6upp7Ha2TaAbhDeMQ3gAAAJrXbMtkhPCGZhDeMA5tkwAAAM1rdqXJCOENzSC8YRwqbwAAAM1rdqXJCBt1oxmEN4xDeAMAAGhe3LbJ5cvdgiUjI/7HhPZDeMM4tE0CAAA0L27b5MyZ0plnSjt2+B8T2g/hDeNQeQMAAGhe3PAmMe8NjSO84QRrpcFBadq0dK5HeAMAAO2iry9e26REeEPjCG84YXBQmjpV6kjpu4LwBgAA2gWVN6SB8IYT0myZlAhvAID2Z23WI0BaWglvq1YR3tAYwhtOILwBAODPl78sfeELWY8CaYm7VYAkrVghbd0qHT/ud0xoP4Q3nJDmSpMS4Q0A0N7WrZO+8x2qb0UwPCy98YY0f36818+a5YLfrl1eh4U2RHjDCVTeAADwZ9Mm6bXXpPXrsx4JknbggHTyya2tG8Bm3WgE4Q0nEN4AAPBjaEjauVP61/9a+v73sx4NktZKy2SERUvQCMIbTqBtEgAAP7Ztk849V7rtNmnNGlon293+/fG3CYgQ3tAIwhtOoPIGAIAfmza5m/GLLpKmTJE2bMh6REhSKytNRghvaAThDScQ3gAA8GPjRrf8uzHSRz5C62S789E2uXKltHmzNDrqZ0xoT4Q3nEDbJAAAfkThTXLhjdbJ9uajbXLOHGnePGnPHj9jQnsivOEEKm8AAPhRHt4uucR9fOqp7MaDZPlom5RonUR9hDecQHgDAKB10UqTy5a5r6PWyTVrsh0XkuOjbVJygZ/whloIbzgh7bbJGTNceKONBADQTrZtkxYtkqZNG3vs1lvdvDd+57UnH22TEpU31Ed4wwlpV966utxmlsPD6V0TAICklbdMRt76VmlkRHrmmWzGhGT5bJtko27UQnjDCWmHN4nWSQBA+9m40d2ElzPGVd9onWxPvtomV650lTcqtKiG8IYT0m6blPIR3jZulP7zf856FACAvNi0aXLlTRrbMoAb8/YyMODuoebMaf1c8+dLs2ZJL73U+rnQnghvOIHKW2WPPSb9+MdZjwIAkBeV2iYl6bLL3O/a555Lf0xITl+fm+9mjJ/zMe8NtRDecALhrbItW6TXX896FACAPBgcHL/SZLmodZINu9uLr5bJyHnnSbt2+Tsf2gvhDSfQNlnZ1q2ENwBAY7Zvn7zSZDm2DGg/vlaajMyfz30HqiO84QQqb5VReQMANKpay2Tk8sulw4dZUbCd+FppMjJ/vvTaa/7Oh/ZCeMMJAwNU3iY6etS1Q4yOun8fAABqqRfeOjponWw3hDekifCGE/r7s6m8HT2a7jWbsW2btHSpNG8e1TcAQH2VtgmYiNbJ9uJ7zhvhDbUQ3nACbZOTbdkiLV9OeAMANKbaNgHlrrxSOnhQ2rw5nTEhWb7nvHHPgVoIbziBtsnJtmyRVqzgBykAoL7BQbdKYKWVJst1dEgf/jDVt3ZB2yTSRHjDCVm1TRLeAADtYNu22itNlmPeW/ugbRJpIrzhBNomJ9u6lfAGAGjMpk3157tFrr5aOnDA/Z5BvrFVANJEeMMJtE2ONzrq3kVdtozwBgCor95Kk+VonWwfvtsmu7uloSHXhgtMRHjDCbRNjrdnj3v3a/ZswhsAoL5mwptE62Q7iFbM7u72d05juO9AdYQ3nEDb5HhRy6TED1EAQH2NbBNQ7pprpN5eafv25MaEZEUtk8b4PS/z3lAN4Q0n0DY5XrRNgER4AwDU1uhKk+U6O6UPfYjWyTzz3TIZYd4bqiG8QZJ0/Lg0PCx1daV73dDDG5U3AEAjtm2TFi9ubKXJch/5SGutk9ZKX/2qtHdv/HMgPt8rTUbmzaPyhsoIb5Dk3jGcPt1/2b8ewhsAoB00O98t8va3Sy+/LO3Y0fxrjx2TfvM3pU99SvrFL5p/PVrne6XJCFExjTcAACAASURBVG2TqIbwBknZtExKYYc35rwBABrV7Hy3yJQp0i23NN86+eKLLvh1dbnqXbRwBtKVZNsk4Q2VEN4gKZuVJqVww9sbb7g/Z53lvia8AQBq2bQpXuVNcuGrmfD2i19IV1whffzj0je/KZ18cpi/S4sgqbZJ5ryhGsIbJGWz0qQUbnjbutUtVtJR+j+E8AYAqCVu26QkvfOdbrGTnTvrH/u3fyvdfLN0773Sv/t3brrDzJlU3rKSVNskc95QDeENkmibnKi8ZVJy4xwZYcNMAMBk0UqTS5fGe30jrZMjI9JnPyt96UvS449L73//2HPd3WH+Li0C2iaRNsIbJNE2OVH5NgESG2YCAKqLu9JkuVtvrR7eXn/dhbWNG6V166SVK8c/T+UtO0m2TRLeUAnhDZJom5yofKXJCOENAFBJKy2TkWuvdStO7t49/vHNm6XLL5cuvFD6yU/c76KJqLxlJ6nKG/ccqIbwBkmu8pZF2+T06a7dZHQ0/WvXQngDADTKR3jr6nJz2e6/f+yxH//YzYf7kz+R/uqvXHtlJVTesmGtq7yxVQDSRHiDpOwqbx0d7rr9/elfu5qREemFFybPXSC8AQAqibtNwES33uo27LZW+su/lH7nd6QHHpDuvLP266i8ZePQIdcqm8T9E+EN1VR5DwdFk1V4k8ZaJ7u7s7n+RLt2Saed5sZVjvAGAKiklW0Cyl1/vfSJT0gf+pC0Z4+b37ZwYf3XUXnLRlItk5I0d67bsmh0dGzla0Ci8oaSrNompfDmvVVqmZQIbwCAyaKVJpcta/1cXV3Sbbe534s//3ljwU1yb34S3tKX1DYBkmuR7e521T2gHJU3SMq28hZau8fEbQIihDcAwERbt7qVJqdO9XO+v/mb5l8T2u/Rokiy8iaNtU7OnZvcNZA/VN4gKYy2yVBM3CYgQngDAEzkq2WyFbRNZiOpbQIizHtDJYQ3SKJtshxtkwCARvlYabJVVN6ykWTbpER4Q2XewpsxptMY85Qx5u9LXy82xqwzxjxvjLnPGOOpoQBJoPI2hvAGAGhUCOGNyls2km6b5L4DlfisvH1G0uayr/+LpL+21i6R9LqkT3q8FjwjvDmvvioNDUmnnz75OX6IAgAm8rVNQCuovGWDtklkwUt4M8acLekDku4tfW0kXSdpTemQb0i62ce1kAzaJp2tW918N2MmP0d4AwCUGxx0S/r7WGmyFVHlzdpsx1E0tE0iC74qb/9N0r+XNFr6+mRJB621I6WvX5J0VqUXGmPuMsb0GGN6+vr6PA0HzaLy5lRrmZQIbwCA8XyvNBnXlCnuz9BQtuMomrRWmwTKtRzejDEflLTfWrshzuuttXdbay+11l66IMm3L1AT4c2ptk2ARHgDAIwXQstkhHlv6Uu6bZL7DlTio/J2taTVxphdkv6PXLvk30iaa4yJ9pE7W9LLHq6FhNA26VTbJkBycwqGh3lnEwDghLBYSYR5b+kaHXXz5E85JblrUHlDJS2HN2vtH1trz7bWLpL0cUk/s9Z+QtKjkm4tHXa7pLWtXgvJofLm1GqbNMZtlMm7YAAAKYw93iJU3tL12mvS7NlSV1dy1yC8oZIk93n7I0l/aIx5Xm4O3FcTvBZaRHhzVbXdu6UlS6ofQwsDACASWuWN8JaepFsmJRfeuOfARFPqH9I4a+1jkh4rff6CpMt9nh/JoW1S2rFDWrhQmjat+jGENwCA5N703L1bWro065E4tE2mK+nFSiR3z0HlDRMlWXlDjlB5qz3fLUJ4AwBI0rZt0nnnZb/SZIS2yXQlvU2ARNskKiO8QRLhTao93y1CeAMASGG1TEpU3tKWRtvkjBlu777+/mSvg3whvEESbZNS7W0CIoQ3AIAUXnij8pauNNomjWHeGyYjvEESlTeJtkkAQONC2uNNovKWtjTaJiXmvWEywhskEd6spW0SANC4kLYJkKi8pS2NtkmJeW+YjPAGSbRN9vVJHR31N9skvAEABgakPXvCWWlSovKWtjTaJiXCGyYjvEESlbeo6mZM7eMIbwCArVulxYvDWWlSovKWtjTbJrnvQDnCGzQy4j5O8brrX+NCCW/15rtJ/BAFAIS3WInEJt1po20SWSG8IdOWSSmc8FZvvptEeAMAhDffTaJtMk0jI9Ibb7hglTTCGyYivCHTlkkpjPDWyDYBEuENABBm5Y22yfQcOODuBzo7k78W4Q0TEd6QeXjr6nIfh4ezGwNtkwCARoW2TYBE5S1NaS1WInHfgckIb8i8bVLKtvo2MCC9/LJ03nn1j501SxoczDZoAgCyMzAgvfhiWCtNSlTe0pTWfDeJyhsmI7wh88qblG14e/55t2pYVAGsxRhp7lzeBQOAotq61b3ZF9JKkxKVtzSltdKkRHjDZIQ3FD68NbpYSYQWBgAorhBbJiUqb2lKs22S8IaJCG8ofNtko/PdIoQ3ACiuEBcrkai8pSnNtknuOTAR4Q1U3qi8AQAaFOI2ARKVtzSl2TY5Z450+LB0/Hg610P4CG8ofHhrdJuACOENAIqLyhvSbJvs7JROOkk6eDCd6yF8hDcUum3SWtomAQCNGRiQ9uyRlizJeiSTUXlLT5ptkxLz3jAe4Q2Frrzt3euuPW9e468hvAFAMW3dKp1/fngrTUpuTKOjbGWThjQrbxL3HRiP8IZCh7dmWyYlfogCQFGF2jIpua1saJ1MR5pz3iQqbxiP8IZCt002u1iJRHgDgKIKdZuACK2TyRscdPdNc+emd03CG8oR3lDoyluz890kwhsAFFXIlTeJylsa+vpc1c2Y9K5JeEM5whsKH96ovAEAGhHqNgERKm/JS7tlUuK+A+MR3lDotknmvAEAGjEwIL34orR0adYjqY7KW/LSXmlSovKG8QhvKGzl7ehR9w7auec29zrCGwAUz5Yt0nnnSV1dWY+kOipvyUt7pUmJ8IbxCG8IJryl/Qtn2za3V09nZ3OvI7wBQPFs3hz2YiUSlbc0ZNE2SXhDOcIbCts2GadlUpJmz3b/ZuylAwDFceCAdPrpWY+iNipvycuibZI3jVGO8IZgKm9ph7c4i5VIboWpuXOlgwf9jwkAEKZDh6STTsp6FLVReUsebZPIGuENhQ5vzW4TEOFdMAAoljyENypvyaNtElkjvKGwbZNxK28S4Q0AiiYP4a27m/CWtCzbJq1N97oIE+ENhay8jY5K27dTeQMANCYv4Y22yWRl0TY5fbpbXI3/tpAIb5ALb0WrvL34opu3Nnt2vNcT3gCgWPIQ3mibTF4WbZMSrZMYQ3iD+vuLV3lrpWVSIrwBQNHkIbxReUvW0aOuc2fWrPSvTXhDhPCGQrZNxt0mIEJ4A4BiyUN4o/KWrGi+mzHpX5v7DkQIbyhk2ySVNwBAM/IQ3qi8JSuL+W4RKm+IEN4QRNvkjBkuRI6OpnO9VrYJkAhvAFA0eQhvVN6SldV8N4nwhjGENwTRNtnR4caQ1juGtE0CAJqRh/BG5S1ZVN4QAsJbwVkbRniT3ATgI0eSv86hQ9LBg9LZZ8c/B+ENAIpjcNB9nDYt23HUQ+UtWU88IV18cTbX5r4DEcJbwQ0NSV1drvKVtdmz0wlvW7dKy5a19nfmhyiAPHvwQemNN7IeRX7koeomUXlL0siI9KMfSR/6UDbXp/KGSAC37MhSKFU3yVXeDh9O/jqtLlYiEd4A5NsXvyg9/HDWo8iPPIU3Km/JePxxadEi6dxzs7l+KOFt9+6sRwDCW8GFsNJkJM3KG+ENQJH19krPPZf1KPIjL+GNtsnkrFkj3XprdtcPIbwNDrr7p507sx1H0RHeCi6ElSYjs2fnp/I2e7ZrTRkZ8TMmAEjLyIjbr2rjxqxHkh95CW+0TSbj+HHphz+UPvzh7MYQwpvGv/61e9P///7fbMdRdIS3ggutbTKNylur2wRIbr7cnDlu4RMAyJP9+91iVVTeGpeX8DZ9uquOHD+e9Ujayy9+IZ12mrRkSXZjCKHy1tPj1kkgvGWL8FZwobVNJl15O35c2rHDLVjSqhDeBQOAZvX2ShdcIO3a5X4HoL68hDdjXOtkf3/WI2kv99+fbdVNCiO8rV/vWkfXrct2HEVHeCu4kNom06i87drl9miZObP1cxHeAORRb690zjnSeee5OcCoLy/hTWLem2+joy68ZTnfTXLff8eOScPD2Y1h/Xrp935PevbZse0zkD7CW8GF1DaZRuWtr0864ww/5yK8Acij3l7p9NOlCy9k3luj8hTemPfm1/r17s3lCy7IdhzGSHPnZjdd4+hR6YUXpCuucN1LTz+dzThAeCu8/v5w2ibTqLwdPuxCog+ENwB5VB7emPfWmDyFNypvfoXQMhnJsnXyySfdz4ypU12AY95bdghvBVe0ytvhwy4k+kB4A5BH+/a58LZqFeGtUXkKb1Te/LGW8BZZv1667DL3+ZVXMu8tS4S3ggspvFF5A4DkUXlrXp7CG5U3f555xn285JJsxxEJJbxRecsW4a3gQmqbTKvyRngDUGS9vW7u7/nnu8+TfNPsr/6qPZatz1N46+4mvPmyZo2ruhmT9UicLO87ysPb8uUuRO7fn81Yio7wVnBU3uIjvAHIo6jy1tkprVghbd6czHX27pU+97nk36E/eFC6995kr5G38EbbpB8htUxK2VXeoqAW7ZHb0eGqb7ROZoPwVnAhhTcqbwCQvCi8ScnOe9uwwX1cuzaZ80fWrJG+9KVkr5Gn8EbbpB+bNrk3lKNqUwiyCm89PdJb3uLe8IkQ3rJDeCu4kNomqbwBQLKOHHFtjNHPwSTnvfX0SO95j/SjHyVz/sgDD0hvvJHsNfIU3qi8+XH//dKHPuSqTKGYNy+b8FbeMhm58krmvWUloG9JZIHKW3yENwB5E1Xdojk8SYa3DRuku+5yP3eT2gz88GHp8cdd66S1yVxDyld4C6nyduyY2wx+aCjrkTRvzZrsN+aeaP78bO471q+XLr10/GOXX+4eb4c5rXlDeCu4kMIblTcASFa0WEkkyY26N2xw79bfeKP04IPJXOOhh6Srr5a6upKtNuUpvIVUeXv6aWnnTmnXrqxH0pznn5deeUV629uyHsl4WbVNVqq8nXKKdOqp0pYt6Y+n6AhvBRdS2ySVNwBIVvl8N0k65xzXcuj7Z9nevdLIiLRwobR6dXKtkw88IN18szRnTnKtkyMj0uCgq2jlQUiVt/Xr3cdt27IdR7Puv1+65Zbxc7xCkEV427vXff8vXjz5ObYMyAbhreBCqrxNm+bK70m2V/gMbyed5H5B0jIAIC8mhjdj3KIlvqtvGzZIb32rO/9117n9sg4c8HuN4WHpJz9x4XDuXNc6mYTo90Yoy8XXE1Llbf16999m+/asR9Kc0FaZjGTxpnFPj2uZrPT9z2bd2SC8FVxI4c0Y9wsyydZJn+Gto8MFuKRuGADAt4nhTUpm3lsU3iT3O+b6613Q8unxx6Vly6Qzz0w2vOWpZVIKr/L2kY/kK7zt3i298IL0zndmPZLJsqi8VWqZjFB5ywbhreBCapuUkp/35jO8SbROAsiXauEtqcpbJInWyahlUkq2bTJv4S2UytvBg67lbvXqfIW3H/xAuukmN48yNNE9R5KL80xUK7xdfLG0Y0fyU14wHuGt4EKqvEnJz3sjvAEosn37Joe3JPZ66+kZH94+8AHp4Yfd7xwfrB0f3qi8jQml8rZhg3TJJW4j+DyFt1BbJiVp6lR3z5ZWWLK2dnibOtUFuJ6edMYDh/BWcKGFtyQrb9YS3gAU28TVJiVXeXv2WX/v5u/d6+ajnXPO2GMLFkhvepP02GN+rrFhg/t9sWKF+5rwNqa7O4zwFi0vv2iR+77zFdyTtG+fq0Jff33WI6kuzfuOnTtdd9bEnxnlmPeWPsJbwYXWNplk5W1w0M1TmzrV3zkJbwDypFLb5Omnu+C2f7+fa2zYUHmBg5tu8tc6WV51k2ibLBdK22RUsZkyxQX5F17IekT1/fCH0gc/6BZQC1Wa895qVd0ibNadPsJbwRWp8ua76iYR3gDkx+io1Nfn9mYqZ4zfeW8T57tFonlvPip8E8MblbcxobRN9vSM3fgvW5aP1sk1a8JtmYyEFt6uuMJV3tKch1d0hLeCCy28JVl5O3KE8AaguF591YWQSt0HPue9VQtvy5e7qtCTT7Z2/u3b3d/l8svHHiO8jQmh8rZ/v/t3W7LEfb10afjhra/Pfe++971Zj6S20MJb1B69Z0/y44FDeCu40NomqbwBQDIqtUxGfG4XUC28SX5WnVy71rVgdpTdwdA2OSaEyls03y1qnV26NPyNuteudcEtpHuiStK67zh+XHrqKfffsRZj2DIgbVOyHgCyVaTK2+HDLhz6NG+e9Pzzfs8JAEmotNJk5MILpW9/u/Vr7N0rDQ2NX6yk3OrV0qc/Lf35n8e/xgMPSF/84vjHkq68Vfv7hCiEytvEis3SpdL3v5/deBpx//3SHXdkPYr60qq8bdkinXaau8+pJ1q05GMf83PtzZult73NzZecP7/2n3nzxj5fuDD88O0D4a3gQgtvs2YlG96ovAEoqkorTUZWrXJz3qydvNBIM6KqW7VzXHWV9OKLrsUqTiB65RVXIbz22vGP0zY5ZsYMF95a/W/ZivXrpU99auzr0NsmX39deuIJ6Xvfy3ok9c2f79qGkxZVTxtxxRXSF77g79r33ivddZf0uc+5oBr9ef31sc+3bRv/XF+fC5u//KW/cYSK8FZwobVNzp7tfrEngfAGoMhqtU2efLJrt3vpJffudVy1WiYl9076Bz4gPfig9Pu/3/z5H3xQuuGGyasB0jY5prPT/fsMDGTz+z3aG+x//++xxxYudIHj2DH3fRaaBx+UrrvO/z1CEubPTycINzLfLXLppdIzz7iqe6sreg8Puy6An//cLa40cYGlao4fdz/fdu+Wzj23tTGEjjlvBTY66v4n8bl0fquSbpskvAEoqlrhTfIz7y3aJqCWVua9TVxlMkLlbbws573t2ePmI5511thjnZ3S4sXhTjMIeWPuidK672gmvM2eLZ1/vgtwrfqHf3CV2mXLmntdZ6fb5sHXdiQhI7wV2OCge3cuq7aKSliwBACSkVZ4q1V5k6T3vMe1Nh061Ny5Dx+W/vmfpfe9b/JzhLfxspz3Ft30T7y3CLV18vBh6dFHpRtvzHokjUljztvQkPtZ8Ja3NP4aX5t1f+1r8ece3nyze4On3RHeCiy0lkmJyhsAJKXWgiVS63u97dtXe7GSyOzZ0jXXSA891Nz5H3rILWIwZ87k52bOdJ0kQ0PNnbMReQxvWVbeqlVsQg1vP/6x+36cOzfrkTQmjfD27LOuktbd3fhrfKw42dfngvRHPxrv9e9+t9tfsN3vywhvBRbaYiVS/ipvc+a48R4/7ve8AOBbvcpbq3u91VuspFyc1slqLZOSu2ZS897yGN66u8MLb6Fu1J2nlkkpnfDWTMtkxEfl7TvfcRXQuP+/zZwpvetd0k9+0to4Qkd4K7AQw1veKm8dHe6cSU2UBwBfaq02KUkXXOCW6I77ZlQjLZORD37Q3WCNjDR2/PCwO3716urHJNU6mdfwlkXb5Oio+z7IS+Xt2DHppz91+wbmRRodP3HC28qVbnP2AwfiX/frX5fuvDP+6yX333Lt2tbOETrCW4GF2DaZt8qbROskgPANDLgb1Vp7Np10krRggbRzZ7xr9PQ0Ht7OPtstYPHEE40d//jjrnJz5pnVj0mi8jY66n4n+d4jNGlZtU1u3+4qQ6ecMvm5EDfqfught8BOpfGGatYst2bB4GBy14gT3jo63Gt+9at413zqKffmy7veFe/1kRtvdIE8yX+frBHeCozKmx+ENwChe+UVtwdSvZbGVua9NVN5k5prnazVMhlJovJ29KgLQp2dfs+btKwqb7Vu+s880/0ebnahmiTdf790661Zj6I5xriAnNR9x9Gj0o4d0kUXNf/aK6+MP+/t61+Xbr/dhcBWLFggvelN0s9+1tp5QkZ4K7AQwxuVNwDwr958t0jceW/RYiXN7K+0erVrb7K29nHWZhfe8tgyKWVXeasV3jo63CIYoWwXMDjoFiu55ZasR9K8efOSm/f21FPu50CcbaSuuCLevLehIem733XhzYd2b50kvBVYiG2T0STr0VH/5ya8ASiqeitNRuJuF9DMYiWRiy92N22bN9c/96xZ0ooVtY9Lom0yr+EtxMqbFNa8t8cfdyGlkf8vQpNk5S1Oy2QkCm/N3sM9+KD7b3HeefGuO1EU3pK4lwwB4a3AQqy8dXa6QJnELx3CG4CiqrdYSaTV8NYMYxprnWyk6iZReSuXReVteNht0lxrb7CQwtuTT7o2vzxKcsXJVsLbqae6sW3d2tzrfCxUUm7pUjeO9ev9nTMkhLcCCzG8ScnNeyO8ASiqRtsmV6xwbW3Dw82dP054k9w75I2Et0ZWAyS8jcmi8rZxo9vjr9a/V0jh7dln3dyoPAo1vEnNbxnQ2yv9y7/4366hnVsnCW8FFmLbpJTcvDfCG4CiajS8zZghLVzY/A123PD2zne6tslXXqn8/PbtbunxK66ofy7aJsdkUXlr5KY/pL3ennsuv+EtqTlvr7/uflbUa1GupdnNur/9bTfv0PeKroQ3tKUiVd6sTW65Z8IbgNA1Gt6k5lsn9+1zv0+aWawkMnWq9J73uIUjKlm71t2ENbICHZW3MVlU3hoJb6FU3oaH3ThWrsx6JPEkNeetp0d685tbW121mcqbtdLXvibdcUf861Vz2WXu3yiE7zffCG8FFmp4S6Ly1t8vTZsmTZni97wS4Q1A+JIMb3EWKylXa95bo/PdJMJbuWjxrzQ1Et5OO83de2T9O3PbNldhDrH7qBFJtU222jIpSZdc4v59G/n+6+lx3w9vf3tr16yko2NsRdt2Q3grsFDbJpOovCXVMikR3gCEr9HVJqXm93rbsMFtdBzX+94nPfqo+51U7pVXXIi87rrGzkPb5Ji02yb7+90iFZdcUvs4Y8Kovj33nPs+z6uQw9u0aa4ddcOG+sdGVbe4b/zU066tk4S3AitS5Y3wBqCorG2u8tbsXm9x57tF5s93KxQ+8sj4xx98UHrve93NYCOovI1Ju23ymWfcPKlG7ilCCG95XqxESu6+o6en9fAmNbZZ98CAdN99/vZ2q+S669x/6/37k7tGFghvBRZqeEuq8pbEfDeJ8AYgbAcPui6LRjstli6V9uyZXAmrptXwJlVunWymZVIivJVLu/LWTMUmhPBG5W2y3l4X+H3stdbIZt1r17o3bc45p/XrVTNtmptT+/d/n9w1skB4K7BQ2yapvAGAP81U3SS3iMiSJdKWLfWPbWWxknKrV7tKW7Sp7uHD0j//s/T+9zd+Dtomx6RdectbeMt75S2J8LZ+vWt/9tHC2EjlLamFSiZqx9ZJwluBFa3yllR4mzPHnT+66QAAyYWR++7LehTNhzep8XlvrS5WEjn/fHdD2tPjvn7oIemqq9zP10addJL/n8V5DW9ZVN4anfeYdXg7csS96bBkSXZjaFVS4c1Hy6QkLVrkVvR86aXKz7/8svSrX7ktApL2/ve7ObVpL+CTJMJbgYUa3vJWeevsdGP2/Y4vgHz7j/9R+sEPsh5FvPDW6Lw3Hy2TkfJ3yJttmZTGfhYfOuRnPFJ+w1ualbdDh1yb7apVjR0fhTdrkx1XNZs2ufl5rSyHn7W5c909h883KnyGN2NqV9+++U3p1lvdmwxJmzfP/b0efjj5a6WF8FZgobZN5q3yJtE6CWC8J590rVlbt2Y9kuZWmow0ul2Az/AWzXsbHpZ+8hP3dbN8t07mNbylWXnbsEG6+GKpq6ux4085xX189dXkxlRL3lsmJbftUXe3vzcqrPUb3qTqm3VbK33969Kdd/q7Vj0339xerZOEtwKj8uYP4Q1AuXvukT79aVdhyLqlurdXOuOM5l7TTHhrZZuAcpdfLvX1ubkwS5dKZ53V/Dl8L1qS1/CWZuWt2Zv+rLcLyPtiJRGfrZO7drnFPc4808/5pOqbdf/yl2OVubSsXu0WLRkZSe+aSSK8FVio4Y3KG4A8O3LEzXX7zGfcjf/evdmOJ07b5OLFLkjV+lnc2+tnsZJIR4f0wQ9Kn/988y2TEcKbE1Xe0mhNjFOxyTK8tUPlTfIb3nxX3SR3vqeecpX0cknv7VbJuedKZ58t/eIX6V0zSYS3Agu1bZLKG4A8u+8+6e1vd5WjZcuyb52ME946O928oE2bqh/ja7GScqtXu5+lccObz7ZJa114S/J3R1K6ulwYnnjjnIQ4e4MtXSpt25bMeOp57rn2CG8+7zuaWXCmUSed5BYuefbZsceOHZPWrJF+67f8XqsR7bTqJOGtwKi8+UN4AxC5+27prrvc58uXZ3eTGokT3qT6rZM+57tF3v1u6S/+wgXHOHxW3gYG3NyiqVP9nC9t3d3Jz3vr63O/+5Yube51WVXe+vqkwUG/7YFZCb3yJk1etOQHP3CPxWmJblU07y2rhXJ8IrwVWKjhjcobgLx65hnXJnnDDe7rZcvaN7z19PgPbzNmSF/4Qvxqns/wlteWyUgai5ZE3wMdTd5NZhXeopbJNFv2kuIrvB0/7hZY8l15kyZv1p32QiXlLr7YzXlrZAuU0BHeCizUtkkqbwDy6p57pE99amwZ8qzD2/CwCzPRCn/NyKLy1iqfbZN5D29pLFoSt90uq+0C2mWxEslfeNu6VVqwQDr55NbPNVF55W33bunpp+OtIuuDMe7a7dA6SXgrsFArb4Q3AHl07Jj0d38n/fZvjz22fHm2c97273fBLc6eVqtWVX+XOlqsZNGilobnHZW3MWlU3uK2282b51Y3fOUV/2OqpV0WK5H83Xck1TIpSRdc4LYqee01t7fbxz6W7X1nu8x7I7wV2MBAmJU32iYB5NH3vie97W3SXOMN3gAAIABJREFUwoVjjy1eLL30kjQ0lM2Y4rZMSu7vceRI5f24klisxAfC25ikK2+t7g22bFn6rZNU3iZLMrx1drrK7Lp1rmXyjjuSuU6j3vEOaccO6eWXsx1HqwhvBdbfH2blbdo093Fw0N85CW8Aknb33dLv/M74x6ZOdSHohReyGVMr4c0Yd6NbqfoWYsukRNtkuaQrby+95PYwPOeceK9Pe97b6Kj7Xia8jRdntdBmXHGF9JWvuGJBEvPqmtHVJb3vfdKPfpTtOFpFeCuwUNsmJf/VN8IbgCQ9+6yb0/H+909+LsvWyVbCm1R93luo4Y3K25ikK29RxSZu9TXt8LZ7twv38+ald80kzZvXengbGnI/u97yFj9jquTKK6Wf/Sz9vd2qaYfWScJbQY2MuJaHrq6sR1KZ73lvR44Q3gAk5557pE9+0i0tP1GWi5a0Gt6qzXsjvIUv6cpbq+12ae/11k4tk5KrvLV63/Hcc661e9YsP2Oq5Mor3ffibbcld41m3HCD26z70KGsRxIf4a2gQq66SX4rb6Oj7t3H7m4/56uE8AYUV3+/9N3vuvBWSZbhbd8+6Ywz4r++UuWtt9f9nUNbrESibbJcWpW3uNKuvLXTYiWSn7bJJOe7RU47zf0cauVNJJ9mz5auuUb6h3/IeiTxEd4KKvTw5rPydvSoe9en2X1omjF3rvtFPzqa3DUAhGnNGunyy6Vzz638fJ4rb1F4K1/SfcMG12YVQgvURFTexiRZebPWfR+0Gt527Ejv92Y7Vt7yEN6k8P4/ynvrJOGtoEJdaTLis/J2+HCyLQGSW1GpuzvfZXgA8dx9t3TXXdWfz/Oct1NPdW989faOPbZhQ/YLD1QzZ44Lbz72D8t7eOvuTi68Pf+8+7c59dT455g92/3Zu9ffuGppt8rbjBku+Pb3xz/HunXphLfQ3Hij9I//6PbBzCPCW0GFutJkxGflLenFSiK0TgLFs2mTqx584APVjznzTPdmlK92vma0Gt6MmTzvLdT5bpJbrXjKlNZuaCPtEN6SapuMuzn3RGm1Tg4NucC5cmXy10qLMa3Ne9u3z60Y+uY3+x1XHpx5puuIePzxrEcSD+GtoEJvm/RdeSO8AUjCPfdId95Ze/EnY9Kf3xNpNbxJk+e9hRzeJH+tk3kPb0m2Tfpqt0vr/4tt21xbc8j3PXG00jr58MPS9ddXXmSpCG66SXrggaxHEQ/hraBCb5uk8gYgdAMD0re+JX3qU/WPzaJ18vBh1z7Yatt4eXh75ZVwFyuJEN6cpCtvPsJbWht1t1vLZKSV8PbQQ9J73+t3PHly001uvzcfLdZpI7wVVOhtk1TeAITu/vtdBWrx4vrHZrFoSW+vW2my1YVFysNbyIuVRHytOJn38JZU5W1kRHr6aT/V17Qqb+22WEkk7l5vo6Ou8vae9/gfU16sXOnarJ96KuuRNI/wVlCht03mtfLW6spPAPLjnntqL1RSLqvw5mN57lWr3Nw+a6WenrBbJiUqb5GkKm+bNklnneX+nVuVVnhr58pbnDeNn3rKvbbaCrlFYIx08835bJ0kvBVU6G2TVN4AhGzrVmnLFmn16saOX748v+Ft3jz3M3TPnvDnu0mEt0hSlTefy8svWSK98IJ0/Lif81XTrpW3uG2TRW+ZjHziE9J552U9iuYR3nLsT//UvfMbR+htk3mtvBHe2tNTT0lf/nLWo0BI7rlHuuOO2guVlFu61IW3NOdX+Apv0ljrZMjbBERom3SSqrz5DG8zZ0onnyy9+KKf81Vy+LCbq3n++cldIyuEt9Zccon7OZ43hLccW7dOeuKJeK8NvW2SyhtCsn699MMfZj0KhGJwUPrmNxtbqCQyd667Ud23L7lxTeQ7vD3ySPiLlUh+Km9DQ25uV8i/J+vJQ+VNSr51cuNGN7+pszO5a2Qlzn3H4cPSk09K73xnMmNC8ghvObZtm/TrX8d7bX9/2G2TVN4Qkt5e1zIGSC7IX3SRa/lqRtrz3vbt8xfeVq2Svvvd8BcrkfyEt8OHXdUt9L9rLUlU3gYGpM2bXcXCl6TDW7u2TErxKm+PPipdcYX7/kA+Ed5yamBA2rvXzbkYGYn3+pDfUaTyhpD09rob4eHhrEeCENx9d+MLlZRLe7uAaLVJHy680LWehT7fTfLTNpn3lknJ3Zz7rrz9+tcubM2c6e+cSYe3dl2sRIoX3h56qNirTLYDwltO7djhlqc+++x47+SGHt6ovCEk+/a5pZX37s16JMja9u2uDevmm5t/bdqVN59tkxdc4D7mIbz5qLy1Q3hLom3Sd8uklPxeb1TexmO+W/4R3nJq2zb3A++ii6Rnnmn+9aG3TVJ5Q0h6e6WpU5OdVI98uPde6fbb3fdDs/Ic3mbNkq67TrrqKj/nSxLhzUmibTKJ8EblLb5m7zt27HCB/qKLkhsTkkd4y6ny8BZn3huVN/8Ib+2rt1e6+GLmvRXd0JD09a83t1BJuTTbJo8fl/r6pFNP9XfORx5x3R6ho23SmTrVTauIM7Wimp4e/+HtvPOk3bv9jjOyf787r6/24dA0W3mLWibzPJcThLfcavfwlsfK29y57oZhdDT5ayE91rrwdtllhLeiW7vWtQ8uWxbv9eed576H0pg7+eqr7mdSo1sZtBMqb44x/qtvu3f7X3J/+nRXId692+95pbGqW7uGlTlz3D1Oo/vk/fSntEy2A8JbTkXh7eKL44W30Nsmo184PoLQkSPphLcpU9y4Dx1K/lpIz6FD7gZ45UraJosu7kIlkWnTpLPOknbu9Demavbta99qQz2EtzE+570NDbk3fpP4d4n2QfStnVsmJbf9wUknNfb9PjwsPfaY9O53Jz4sJKzl8GaMWWiMedQYs8kYs9EY85nS4/ONMQ8bY7aXPs5rfbiIROHt3HNdtafZCauhV946Ovz90kmr8ibROtmOopvghQupvBXZjh3S009Lt9zS2nmWL09n3pvP+W55Q9vkGJ+Vt1dfdW16SVSxkpr31s6LlUQave/45S9d1XTBguTHhGT5qLyNSPqctfYCSVdK+n1jzAWSPi/pEWvtUkmPlL6GBwcPulBzxhku5LzpTe7dpWaEHt4kf/PeCG9oRXQTfM45hLcie/xx6YYbWv+5uWxZOvPeihzeurvdRupDQ/HP0S7hzWfl7dVXpZNP9nOuiZIKb+1eeZMan/fGKpPto+XwZq3dZ619svT5YUmbJZ0l6SZJ3ygd9g1JMRZWRiXbt7sbgOjdrzgrTobeNin5mfc2MuJ+iaf1dyW8tZ/oJnjhQtomi+zAAT9hKK0VJ4sc3owZm4McV7uEN9+VtzyFt9FRadMmt8F8OyO8FY/XOW/GmEWS3ixpnaTTrLX7Sk/1SjqtymvuMsb0GGN6+vr6fA6nbW3dOn7CfJxFS4pSeTtyxIXAtCYrE97aT3QTfPLJ7v8bX6ugIl/6+qRTTmn9PLRNpqPV1sl2CW9Frrzt2uV+J8+d6/e8oZk3r3546+tz/7552OoD9XkLb8aYWZLul/QH1tpxSzZYa60kW+l19v9v787D9C7re49/7lmTTHZCQmaSQAgJEZBNyqZQRbQWbfUgp9Wi4FK32lO9Ti0g1utcxwOitpf2UG1xAyoigqDVI7VFqSv7IrKZhJgESDLZZkL2zExm7vPHPb9mMnnm2X7bff9+79d15Upme54b5pl5fp/n+72/t7VfsdaeYa0940gacesS7XeLFDm8xa28ZdkyKbknCcJbsUQXwca41kmqb+W0bVsye0Vom8xG3KElRQlvoVTeFi+WNmyI1+o6XhlaJiVXeat13fGTn0ivfnVz51PCP4mEN2NMu1xwu9Va+93Rd282xswf/fh8SVuSuC+48Hb88QfffvnLpWeeqX9UrBRO22TcKkfW4Y3KW/GMndpH62R5bduWTOWtp8eFirQruGWeNikR3iJdXWFU3jo63BmCSU5iLcOwEqm+tklaJosliWmTRtLXJf3WWvv5MR/6gaTLR/99uaTvx70vOOMrb9OnS/PmuWlo9Qql8kZ4Q97GVjAYWlJeSYW3lpb0hjOMVfbKG22TTihtk1LyPxdlqrxVC2/WuvPdXv/67NaEdCVReXulpHdKusAY88Ton4skfUbS64wxz0m6cPRtxGStC29Llx76/kZbJ0MIb0kMLCG8Ia7x4Y3KWzkltedNymbfW9nDG5U3J5S2SSn58FaWylutPW9PPeU6rY47Lrs1IV1tcW/AWvsrSRONg3ht3NvHoXp73S/j8Rtwo4mTl1xS3+2E0DZJ5Q0+GHsRvHCh9Itf5Lse5COpPW9S+vve9u1zf4o+qKEawpsTWuXt2WeTua3BQdeNtHx5Mrfns1p73miZLJ5Ep00ifeNbJiNU3iojvCGOAwfcK5rRRTttk+U0NOQugGfMSOb20j4uYPPmg0N2yoq2SaeslbcVK6RjjvH/OicJtdom77mH8FY0hLfAlCm8UXlD3rZsca1yra3ubdomy2nbNneB1JLQM2babZNlb5mU4lXehodd4OnqSnZNeQit8pZUeHv66XLsd5Oqh7e9e6UHH5Re85ps14R0Ed4CM1F4W7LE7cmo55VGa11Lje/hjcob8jb+InjBAhfeRkbyWxOyl9SwksjSpa5t0lY8QCe+sk+alOKFt+h80KTCep5CqrwdfbSrGu/fH/+2yjKsRKq+5+3nP5dOP70YVWQcVIBfTeUyUXhrbZVOPNG92lTL0JDU1nawmuArKm/I2/jwNmWKezxt3ZrfmpC9JPe7Se6V8s5Od6GaBipv8domi9IyKSVXebPWPbfNnh3/tibS1uZaHRuZnD2RsgwrkQ5ed1R6MYj9bsVEeAvMROFNqr91MoSWSSncytuOHVRmiqLSRTBnvZVP0pU3Kd3WScJbvMpbkcJbUpW3HTvckLO0D3lOqnWyTJW3yZPdi/GVvs//8R8cEVBEhLeADA1J69a5FslKoomTtYQwaVIKs/LW3u6CcdoH8CIbvb2HXwQztKR8kjwmIJLm0BLCG+EtklTlLe2WyUgS4W3nTvczu3hxMmsKQaV9by+84F54Ov30fNaE9BDeArJundTdPXHVjMrb4bIObxKtk0WyadPhe4cIb+WTRuUtzeMCCG+0TUaSqryFFN6eeUY64QT/t4YkqdK+t3vukV73umLs3cSh+JYGpFrLpORaBJ56qnbLXijhLcTKm5RteLvtNun227O5rzKibRJS8nvepPQrbwwsofImufAWWuUt7s9FmVomI5XOemO/W3ER3gJSK7zNnu2esNatq347obRNJlF527272OHt+uul971Puu669CbXlVml8EblrXxC2/NWqd23bKZPdy/eNbP/uEjhLcm2yTSHlUSSqLyVaVhJZHzb5IED0r33st+tqAhvAakV3iTplFNqt05SeUtXVuFt3z73vX7sMVd9+4u/cL+wkZyJwhuVt3JJY8/bkiXS2rXJ/8xa66ZYzpuX7O2GprXVVZ2aeQ4pUngLrW1y4UIXQuIEzrJW3saGt0cecf8vy16BLyrCW0DqCW/17HsLJbxFlbc4FaUih7fHHnN9/UuXSr/4hRuvfPHFyR3IisoVjIULqbyVTRqVt0mT3IVVrU6JRm3f7qotIfyOT1uzrZNFCm9JVd76+7MJby0t0rHHSqtXN/f11rrwVrbK2/jrDqZMFhvhLSD1hrdaEydDaZvs6HC/yAcGmr+NIoe3++6Tzj3X/Xv6dOnuu92rbxdcIG3Zkv79F130wsH4x8/8+e5ifnAwn3Uhe2nseZPSaZ1kWMlBhLfwKm9SvNbJ6OzEsv0MjK+83XMP+92KjPAWiD173AXEwoXVP69IlTcp/r63XbvcbWQpq/B2//3SK1958O32dummm9wv7HPPTeasnDKLLoKNOfT9ra0uwG3YkM+6kC1r06m8SelMnCS8HdTsxMkihbdJk9xzftyzR7MMb8uWNf/8FVXdxv/eLrqx4W37drfv71WvyndNSA/hLRCrV7s9ErVG3y5b5i4qqwWekMJbnH1vg4PuCauzM9k11ZJFeLPWhbeo8hYxRvrUp6Qrr5TOO0968MF011Fk1S6CGVpSHnv2uJ+rKVOSv+00Jk729rLPJULlzXWvTJ7sOm7iCKXy9vTT5dvvJh0a3u691wW3UK7z0DjCWyDqaZmUpLY2aflyd87JREJpm5TiVd6ilsmsX4HLIrytWuUuJhcsqPzx971PuvFG6Y/+SPr+99NdS1ER3iClV3WTaJtMG+HNSWLfWyjhrYzDSqRDrzs4IqD4CG+BqDe8SbUnTpal8pbHfjcpm/A2vmWykosukn70I+lDH5K+9KV011NE1SoYnPVWHmntd5PSqbwR3g6ibdJJYt9bluHtpJOkZ5+V/v7vG5/GWsZjAqSDlTdrCW9lQHgLxMqV7lXaetTa9xZSeEui8pa1LMLb2GEl1ZxxhvSrX7nz4K68Mv6+hzKh8gYp3crbwoXuojjJCbGEt4OovDlJHNSdZXibM0d6+GH34uPZZ0tPPFHf142MuNBX5vC2YoV7u97rRYSJ8BaIRipvtSZOhtQ2SeWtsnoqb5Fjj3Wf/6tfSZdeGm96Z5kQ3iClc8ZbpKVFOu64ZIcLEd4OIrw5cdsmBwfdi75Z/j9ZskT6yU/c+aWvf7109dW19+2tXesCZpG+d/WaNcuFt2jKZNkGtpQN4S0A1rrKWyPh7cknJz4fjcpbutIOb/390vr1jfX1H3GEeyIcHHS/2OMefl4G1S6CaZssjzQrb1LyrZOEt4Nom3Titk329bnKTtaBwBjpPe9x1zOrV7stIT//+cSfX9b9bpJ7vO7d644MomWy+AhvAejrc3/XewFx5JGusjbRxWVI4S3UyttLL8U7XLya+++XzjzTDadpxOTJ0h13HPwb1VF5g5Tunjcp+eMCmDZ5UDOVN2vze+5IS9zKW5Ytk5UcdZR7zvq7v3PdIx/4QOVQXsbDuSMtLe7x/vOfS699bd6rQdoIbwGIWiYbedWr2r63kNomQ6y8dXS44wnSqm410jI5Xmur9KY3cYRAPapdBM+c6fZXNPOqPsISUuVtcNBVjfK80PZJM+Ft7173+7vRF8d8lkTlzYfH1Jvf7CZpGyOdeKL0r/966MfLekxAZPZs6RWvcC8go9gIbwFoZL9bpNrESSpv6UuzdbLeYSUTOftswlstw8Nur9PcuZU/bgytk2WR5p43KdnjArZscVXCFp7ZJTXXNlm0lkkp/MrbWDNmSDfcIH3rW24I13//765LQip326TkrjtomSwHfsUHoJnwVq3yFlp4C63yJqUX3oaGpMcecwGsWSef7DZ2UzWaWF+fe9W+vX3iz6F1shyyqrwl0WbNfrdDNVN5K2J4K0rlbazzz3eD2ZYtc89pX/6ye14r85TFt75V+tM/zXsVyALhLQDNhreJJk6G1jZJ5e2gX//aTeGaMaP522hvl047TXrkkeTWVTT1XARTeSuHtPe8HXGEq5Rt3Rr/tghvhyK8OUWqvI01aZJ07bXSj38sfe1rbnJrZ2feq8rPFVdIy5fnvQpkgfAWgGbC2/Ll0rp1lUfrUnlLX1rhLW7LZOScc2idrKaei2Aqb+WQduVNSq51kvB2qKhtspGqZhHDWxErb2Odcor0wANuojJQBoQ3z42MuBG5S5c29nUdHe5rnn328I+FFN6ovB0qzrCSsdj3Vl09E/sIb8U3MuKO5pg9O937SWpoCZMmD9XZ6YY01TofbKwihreiVt7GamuT5s3LexVANghvnlu/3gWBqVMb/9qJ9r2F1DYZZ2DJ7t3FCm/WJld5i8JbWscZhI62SUjuZ3jatOp7H5OQ1HEBVN4O12jrZBHDW9Erb0DZEN48t2pV8xtwJ5o4GVrljbZJ5/nnXdhavDj+bXV3uyf01avj31YR0TYJKf39bhHaJtPT6MTJooa3olfegDIhvHlu5crG97tFJqq8hRTeQj4qoL8/2du87z7XMtnIeX/V0Do5sXoughcskDZscK11KKYs9rtJybVNEt4OR+WtHG2TQJkQ3jzXzLCSSDRxcnxrXEhtk6FW3s46y22eTrItMamWycjZZ7tN3jhcb2/ti+BJk9yF4ebN2awJ2Uv7jLfIccdJa9a48wXjILwdjvBG2yRQNIQ3z8UJb0cd5ao0vb2Hvp/KW/p+7/fcRvkkK1tJDSuJUHmb2KZN9Q1+oHWy2LJqm5w82R0I//zzzd+GtYS3SmibjFd5s9ZtAUh7aA+A+hHePBcnvBlTuXUypPA2ZYo0MNDcK9K7djU36CUJxkjvfKf0jW8kc3s7d7r9aaedlsztSdLpp7u23DjtNHnbskW66qrkb7fei2CGlhRbVm2TUvx9b7t2ufPi8vqd5ysqb/Eqbzt2uBcXOjqSXROA5hHePDYw4PbUxBlQUSm8hdQ2aYx74mm0ddLafCtvkvSOd0jf+Y77Psb10EMubCX5BNrZKb385dJjjyV3m1n7/Oelv/97aXAwudvct8/9mTmz9udSeSu2LMNb3H1vVN0qI7zFq7zRMgn4h/DmsTVr3MVhnDHV48Obte5Ct7Mz/vqy0sy+t/373bkvaY/4ruboo104uvvu+LcVDStJWsj73rZvl776VXdxtnZtcre7efPBluNaCG/FltWeNyn+cQGEt8pom4xXeSO8Af4hvHksTstkZPxxAQMDLrglNbEwC83se8u76ha57LJkWieTHlYSOeeccPe9felL0h//sXTmmclM6os0ctAxbZPFltWeNyl+2yThrTIqb1TegKIhvHksifB2wgnSc88dbN3bty+c/W6RZipvvoS3t75V+tnP3EVgs4aHXdvkOecktqz/Euph3Xv2SNdfL115pbR0abLhrZGLYCpvxUbbZPgIb1TegKIhvHksifA2aZLbM7dihXs7pGElkZArb9OnSxddJN1+e/O38dRT7lDtNC4iFy1yf8eZcpeHr35V+v3fl5Yvdz8jzz2X3G0T3hDJMrwtWuQG8DR7kV3vhNSyoW3SVd727m3uRTrCG+AfwpvHVq1yrTRxjd33tn9/OMNKIiFX3qT4rZNJHxEwljHhHRkwMOCGlHz84+7tpA44jjQS3ubNc6/q79+f3P3DH1nueWttlZYscVNlm1HP2YRlROXNPbba25sbnkV4A/xDePNYEpU36dDwFmLbZMiVN0m68EJXnYmqn41Ka1hJJLR9b9/4hhsEc/rp7u08w1tLi9TTI61fn9z9ww8DAy6Uz5iR3X3GeSzTNllZI+EtCjchDfSqV1dXc/veCG+Afwhvntq50wWQ7u74tzW+8hZaeAu98tbWJl16qXTLLc19fVrDSiIhVd4OHJA++1np6qsPvm/hQneB0ehjZCKNDCyJ7p/WyeKJLlqzHO5EeEteI22TRay6RZodWkJ4A/xDePPUqlVuEEMSFw5jJ06G2DYZeuVNcq2T3/ymNDLS2Ndt2OBCSRLtsxN5xSvcvroQWv++8x0XrM477+D7WlritZuN1+hF8KJFTJwsoiz3u0XiHBdAeKuskcpbkcNbs0NLCG+AfwhvnkqqZVKSFixwF+ZbtoTZNhl65U1y1c+ZM6Vf/KKxr7v/fld1S/PV/64uFw5//ev07iMJIyPSpz99aNUtkuTQkmbCG5W34slyv1uk2eMChodd2Jw7N/k1ha6ry7VDDg3V/twihzcqb0BxEN48lWR4M+Zg62SIbZNFqLxJzQ0uicJb2kLY93b33a4F9Q1vOPxjSe17s9Yd0j1vXv1fw1lvxZTlGW+RZh/H27ZJs2e7nw8cypj6WyeLHN6ovAHFQXjzVJLhTTo0vIXWNlmEypsk/dmfSd/7XmNPoGkPK4n4vu/NWunaa13VrVIVMqnwtn27e4W6kRc4qLwVUx5tk3PmuApzo+dCMmmyunpbJ4sc3qi8AcVBePNUWuEtxLbJolTe5s93Ien736/v8/fulZ55RjrjjHTXJbl1PfBA+vfTrJ/9zF18XXxx5Y8nFd4aHVYiEd6KKo/wZkxzrZPsd6uO8NZc5W1gwP3x7bkUKDvCm4esPTiwJCkht002U3nbvdvPJ5x3vrP+1slHHnEj8bOolB53nHti37Ah/ftqxqc/LV11lTuvqJKlS5MJb81cBEdtk80cgAt/5bHnTXIvRNx4o/TLX9b/e4/wVh1tk81V3vr6XDtulhNXAdRGePPQ5s3unJnZs5O7zZNOcueM7doVXttkUSpvkvSWt7j2xN7e2p+bVcukdPCw7oceyub+GvHwwy6YXXrpxJ8zd647RqCvL959NXMRPGOGm3jZyEHA8F8ee94k6cor3e//v/kbt/fyxBPdftnrr3d7YCtVTwhv1TVSefPxeSMJzVTeaJkE/ER489CqVcmPhu/qclMnf/ObclTefA1vU6ZI/+2/Sd/6Vu3PzWpYScTX1slPf9pdyLa3T/w5xiQzcbLZi2BaJ4snj7ZJyYW1L33Jvcjz0kvSrbdK558vPfus9Fd/5db08pdL73639MUvus9bt47wVg1tk81X3ghvgH8Ibx5Ker9b5OSTXRUjtPBWpMqb5F5Fr3Vg98hIPuHNt6ElTz/t1vTe99b+3CT2vTU7+IGJk8WTV9vkWO3t0qmnSn/+59INN0iPPuqG6tx8s/t5/c1vpA99SPr616XFi/Ndq89om6TyBhQJg4U9lGZ4++53w2ubbLbyNnVqOuuJ6/zz3QXYb37jDlCvZMUK92pxo8Mz4jjzTHfW29BQ9SpXlj7zGemjH63vMZtEeNu0aeLvSTVU3oonr8pbLZ2d0ite4f584APufT79zPqIypsLbzt3NvY1hDfAT1TePJRmeLOWylveWlqkd7yjevXt/vuz2+8WmT7dvXr/5JPZ3u9E1qyR/v3fXWWhHkkMLWm2bXLhQsJbkVjrb3irhOBWHeGNtkmgSAhvHlq5Mr3wJoUX3qLKWyPT/HwOb5KbOnnrrW7IRiVZDisZy6d9b5/7nPTBD7rgDUYsAAAgAElEQVSWp3rkveeNtsni2L3bBaLQuhRQGW2TzbVN9vcT3gAfEd48c+CAtHattGRJ8rd9zDEuCIV2QdLeLrW1uWMO6mGte4XR17ZJSVq+3F3w33tv5Y9nvd8tcs45fux727hRuuMO6SMfqf9rli514S3OyH4GlkDyY78bkkPljcobUCSEN888/7y7eEwjYLW0uOpbaJU3yVXR6t33tmeP+2+c6EwwX1x2WeUz37ZudcdFnHhi9mvyZWjJ5z/v/v80Mqp9xgwX2DdubO4+BwfdxVszFysMLCmWkFomURvhjYElQJEQ3jyT1n63yDXXSK9+dXq3n5apU+vf9+Z7y2TkT/9Uuvvuw/+77r9fOuusfMLn8uXuwnXLluzvO9LX5w4p/tjHGv/aOENLNm9258W1NPFbsafHhcbh4ebuG37J64w3pIO2SSpvQJEQ3jyTdnh7zWuynWCYlEaGloQS3ubMcUH6rrsOfX8ew0oiLS1u6mSeh3Vff7301re6cwkbFWdoSZyDjjs73feznsPX4T8qb8VC5Y3KG1AkhDfPpB3eQtXIcQGhhDepcutkXsNKInnue9u1S/qnf5KuuKK5r48ztCROeJNonSwS9rwVSz3h7cABt6+6qyubNWWNyhtQHIQ3z6xaJR1/fN6r8E8RK2+S9MY3utH8zz/v3h4YkJ54wlW/8pLnvrcbbpAuvNBV0JoRp20ybnhjaElxUHkrlunT3fPCyMjEnxM9bxiT3bqy1GjlzVp3Huns2emtCUBzCG+eofJWWVErb52d0p/8iTs2QJIef9x9//Nc/1lnSY88kv3+rX37pC98QbrqquZvI0546+2N11LMWW/FwZ63YmltdeGl2guARW6ZlNx/fyOVtx073OC0jo701gSgOYQ3j+zb5wZFLFqU90r8U9TKm+RaJ2+5xb3Sed99+RwRMNbs2VJ3t/TMM9ne7403SmecIZ1ySvO3sWSJtG7dxOfnVZNE5Y22yWKg8lY8tVonix7eGm2bpGUS8BfhzSOrV0vHHuv/iPs8FLXyJrlK1/Cw9Oij+Q4rGSvr1snBQemzn5U+8Yl4tzNpkgtgURtqI2ibRIQ9b8VTa+Jk0cNbo22ThDfAX4Q3j9AyObEiV96Mkd75Tulf/iX/YSWRs8+WHnggu/u75RZ3TMFZZ8W/rWZbJ5MYWEJ4KwYqb8VT9spbe7v7e3Cwvs8nvAH+Irx5ZOVKwttEilx5k6R3vEO66Sb3BLtwYd6rybbyduCAdN110t/+bTK3l1d4o22yONjzVjxlD29SY9U3whvgL8KbR6i8TayRytvu3eGFt8WL3X6vV77Sj2lnJ50krV/vpo2l7fbb3R67889P5vaaCW/WuoElccLbkUe6x2ijZynBL8PD7iJ/1qy8V4Iklb1tUmps3xvhDfAX4c0jhLeJFb3yJkmf+Yz0kY/kvQqnrc2FyYcfTvd+Rkaka6+VPvnJ5G6zmfC2c6eresY546mlxR0svn5987eB/PX3uwv9tra8V4IkUXmj8gYUBeHNI4S3iRV5z1vknHPynzQ5Vhb73r77Xfe9uvDC5G5z6dLGD+qO2zIZYWhJ+NjvVkyENypvQFEQ3jzR1ycNDUlz5+a9Ej+VofLmm3POSXffm7XSNde4vW5JtooefbQLY/v21f81hDdE2O9WTLRNUnkDioLw5onnnnNVNx/2O/moDJU335x1lvTQQ661MQ133+3+ftObkr3dtja3h/B3v6v/a5IKbwsXMrQkdFTeionKG5U3oCgIb55YtUo6/vi8V+GvRitvU6emu54ymDfPDW1YuTL5246qbp/4RDovWDS67623V5o/P/79UnkLH2e8FRPhjcobUBSEN08884w75wqVUXnLR1pHBtx7r2thuvji5G9bajy8JVl5I7yFjcpbMdE26cIblTcgfIQ3Tzz2mPSKV+S9Cn+x5y0fae17u+Ya6eqrpdbW5G9banxoSZJ73mibDBt73oqJyhttk0BREN48YK30+OPS6afnvRJ/UXnLRxqVt1/+0lWn3v72ZG93rLwrb9bGvy3kg8pbMRHe6m+bHBiQBgd5HgV8RXjzwLp17hWxefPyXom/Jk92TyYHDlT/vOFhaf/+eOd14aBTTpFWr64/ONfj2mulj3883XO0mtnzlkR4mzZN6ux0r1ojTOx5KybaJuuvvPX1SbNnM0AN8BXhzQNU3Wozpr7Wyd27XXDjSScZHR3SqadKjzySzO098oj07LPS5Zcnc3sTmT/fXaRUe6V9rE2bkhlYItE6GTraJotpxgz3+2CiqngZwlu9lTdaJgG/Ed48QHirTz3hjZbJ5CW57+2aa6QrrnChME3G1L/v7cABqb8/uQt2Jk6GjbbJYpo0ye2xrXT+48iIe24p+nNHI5U3whvgL8KbBxhWUp969r0R3pJ39tnSAw/Ev53f/EZ6+GHpve+Nf1v1WLasvvC2dau7UElqeApnvYWN8FZcE7VO7tnjWvPTGqDkCypvQDEQ3nLGsJL6UXnLRzS0JO4Qjk9/Wvrrv3YXSVmod99bUsNKIlTewrV/P4MaimyioSVlaJmUqLwBRUF4y9n69VJLi9TdnfdK/EflLR8LFriWozvvbP42VqyQfvpT6YMfTG5dtdQb3pI6oDvCWW/hiqpu7JktprKHNypvQDEQ3nIWVd24WKht2jQqb3m55Rbpb/9WeuMbG5viGLnuOumv/spVT7OSZ+WNtskw0TJZbBO1TZYlvFF5A4qB8JYzWibrN3Uqlbe8vPrV0lNPSa95jXTuudKVV9Z/fMCaNdIPfyj95V+musTDLF3qwlutdk/aJhEhvBUblTcqb0AREN5yxrCS+lF5y1dHh/Sxj7kQt3mztHy5q8iNjFT/us9+VvrQh9yFU5Zmz3Zr3rKl+uclHd66u93/n1pnEsI/nPFWbIQ3Km9AERDeckblrX71VN7KMO45b/PnSzffLN11l3T99dKrXuVehKhk/XrpO9+RPvrRTJf4X+ppnUw6vLW3S3PnShs3JnebyAZnvBUbbZONHdINwE+Etxz19rrJZosW5b2SMDCwxC9nny099JAb/f/GN0rvf7+rXIz1uc+5j+dVzagnvCU9sESidTJUtE0WG5U32iaBIiC85YhhJY3hqAD/tLS4cLZihbswOPFE6R//0bUMbtokffOb7niAvORReZOYOBkqwluxlT28MbAEKAbCW45omWwMlTd/zZwpfeEL0s9+Jn3/+9Kpp0p/8RfSpZcmH4waEQ0tqSaN8MbEyTCx563Yyt42WU/lbWRE2r6dtknAZ4S3HDGspDFU3vx3wgnSj38sfepTLhT9zd/ku55ly6Tnnpv447t3S8PDyT9maJsME3veiq3slbfOTmloyP3Om8iOHa5C19GR3boANIbwliMqb42h8hYGY6SLL5buvz///ZzHHSf97ncTX6xs3uyqbkm3Li9cSOUtRLRNFlvZw5sxLphVq77RMgn4j/CWk61b3RPGscfmvZJw1Ft5y/IgaPitq8tdjE8UpNIYViJReQsV4a3Yyt42KdXe90Z4A/xHeMsJw0oaR+UNzag2tCSN/W4SA0tCZC3hrejKXnmTau97I7wB/iO85YSWycax5w3NqDa0JK3wNmeOtG9f7ccr/LFzpzRpktsXhGIivNU+qJvwBviP8JYThpU0jsobmlFtaEla4c0YJk6Ghqpb8XV1SQMDbmjHWGUKb+x5A8JHeMsJlbfGUXlDM/Jom5RonQwN4a34jKm8761M4a1W5a2/n/AG+I7wloPt292FwtKlea8kLFF4s7byx4eG3OHQkyZluy74rVp4S2tgiUTlLTSc8VYO41snrXXhrSwv+jGwBAgf4S0Hjz/uDjFu4f9+Q9ra3Nkz+/ZV/nhUdWMIDMZavFjasMG1S42XZuVt0SLp+efTuW0kjzPeymF85W3/fqm1tTx7HRlYAoSP+JADWiabV23fGy2TqKS93bUwrllz+MfSDG/nny/demv1V7nhD9omy2F85a1MLZMSlTegCAhvOWBYSfOq7XsjvGEilYaWjIy4Vrm5c9O5zwsukM49V/rkJ9O5fSSL8FYOZQ9vVN6A8BHeckDlrXlU3tCMSvvetm1zF20dHend7z/8g/Stb0kPPZTefSAZ7Hkrh/Ftk2ULb1TegPAR3jK2c6e0caN0/PF5ryRMVN7QjErhbdOm9IaVRObMkb7wBem975UGB9O9L8TDnrdyoPJG5Q0IHeEtY7/+tXTyyW74BhpH5Q3NmCi8pbXfbay3vc0NTbnuuvTvC82jbbIcyh7eqlXeBgbci0w8jwJ+I7xljJbJeKpV3nbv5kkHlS1dml94M0b653+WvvhF6Zln0r8/NIe2yXIoe9tktcpbX580ezYTmwHfEd4y9thjhLc4qLyhGQsWuFfbxwb/rMJbdP//5/+49snh4WzuE42h8lYOZa+8VTukm5ZJIAyEt4w9/jiTJuNgzxua0dIiHXfcoRMn0zygu5L3v9+dJfWP/5jdfaI+Bw64i/hZs/JeCdJW9vBWrW2S8AaEgfCWoT173KG9J5yQ90rCReUNzRq/7y3LypvkAuRXvypdc420dm1294va+vtdcGttzXslSBttk9XbJglvgP8Ibxl64gnpxBPdocFoDpU3NCvv8Bat4YorXBXO2mzvGxNjv1t5UHmj8gaEjvCWIYaVxEflDc0aP7Qkj/AmSf/zf7pKz803Z3/fqIz9buVR9vBG5Q0IH+EtQwwriW/atOqVt6lTs10PwrFs2aF73vIKb21t0te/Ll15pdt3h/xxxlt5lL1tksobED7CW4YYVhLf1KlU3tCcZcuklStdu+K+fe5PXgMqTj1Vet/7pP/xP/K5/6y86U3VDwT2BZW38pg+3QW2kRH3dtnCG5U3IHyEt4zs2yetXi2ddFLeKwlbrcob4Q0TiS7O+/qkzZulefPyPc/ok5+Unn5auuuu/NaQph07pLvvltaty3sltbHnrTza2lyAiV4ELFt4o/IGhI/wlpEnn5SWL3ejwtE8Km9oljEHh5bk1TI51qRJ0te+5qpv27fnu5Y0PP+8+/vFF/NdRz2ovJXL2NbJsoU3Km9A+AhvGWFYSTKovCGOaGiJD+FNkl71Kunii6WPfSzvlSQvqriFEt7Y81YeY4eWlC28TZ7sOoGittGxCG9AGAhvGWFYSTKovCGOaGiJL+FNkq67TvrJT9yfIgktvFF5K48yh7eWFlf137//8I8R3oAwEN4ywrCSZEx0VIC1hDfUFrVN9vZK8+fnvRpn2jTphhvc2W8T7UUJ0bp10vHHS+vX572S2tjzVi5R2+TgoDQ05KpRZdLVdfjvmpER1749e3Y+awJQP8JbBgYGpBUrpJNPznsl4ZvokO6BAfeKYkdH9mtCOHza8zbWH/6h9MpXuiEmRbFunXTeeVTe4J+o8rZrl6u65Tm4KA+Vhpbs2OFCXXt7PmsCUD/CWwaeflpasqR8r+6lYdIk6cAB92rpWFTdUI+lS13b5MaNfoU3SfrCF6TbbpMefjjvlSQjtPDGnrfyiMJb2VomI5WGltAyCYSD8JYBWiaTY0zl6hvhDfWYNs21TD32mH/hbc4c6cMflu64I++VJGPt2oPhzdq8VzOxvXul4WF3QYtyiNomyxreKlXeCG9AOAhvGWBYSbIq7XsjvKFey5a5PW++hTfJnQO5YkXeq4jvpZdchfyYY1w7czQcwkdRy2TZWufKjMoblTcgZIS3DFB5SxaVN8SxbJn728fwtnx5McLb88+74GaMtHCh362T7Hcrn7KHNypvQNhSD2/GmDcYY1YaY1YbY65K+/58MzTk9rydckreKymOSpW33bsJb6jPsmXu4m3SpLxXcrglS9x0xoGBvFcSz7p1LrxJYYQ39ruVS9nbJqm8AWFLNbwZY1olfUnSH0o6QdLbjTEnpHmfvnn2Wenoo121CMmg8oY4li71s+omuUlvxxwjrV6d90riCS28UXkrFypvlStvHBMAhCHtytuZklZba9dYawclfVvSm1O+T6/QMpk89rwhjvPPl66+Ou9VTOz448NvnRwf3nw+640z3sqn7OGNyhsQtrTDW4+ksa+5rh99338xxrzfGPOoMebRrVu3pryc7DGsJHlU3hDH7NnSO9+Z9yomVoR9b6FV3mibLBfaJtnzBoQs94El1tqvWGvPsNaecWQBn0GpvCWPyhuKbPlyaeXKvFcRz7p10uLF7t8hhDcqb+VS9srblClU3oCQpR3eNkhaOObtBaPvK4XhYenJJ6VTT817JcVC5Q1FVoTK29q1YVXeCG/lMmOGC287dpQzvFF5A8KWdnh7RNJSY8xiY0yHpLdJ+kHK9+mNFSuk+fPdEwWSQ+UNRRbtefP5YOtqXnpJGhmRZs1yby9Y4Pa8+frfw5638pk0yZ0/uGVLOcMbRwUAYUs1vFlrD0j6S0n/Iem3ku6w1j6T5n36hJbJdExUeWOiJ4pg9mx3cdnbm/dKmhPtd4sOve7qkiZPdhUuH7HnrZxmzpReeKGc4Y2BJUDY2tK+A2vtv0n6t7Tvx0cMK0kHlTcUXdQ62d2d90oaN3ZYSSRqnfQxJNE2WU5lDm/jK2/797szaXkOBcKQ+8CSInv8ccJbGtjzhqILeWhJtfDmG2upOJTVjBnueaOM4W185S064y2qlgPwG+EtJSMj0hNPEN7SQOUNRRfy0JKJwpuPZ7299JKrQnR05L0SZG3mTPd3GcPb+MobL2AAYSG8peS559wvw9mz815J8VB5Q9GFfFB3SJU39ruVV5nDW6XKG+ENCAfhLSUMK0kPlTcUXRErb76GN/a7lVM0BbqMg66ovAFhI7ylhGEl6aHyhqI75hg3xnz8RLgQjD2gO0J4g29mznTPGS0lvAqi8gaErYS/trLBsJL0jK+8WevCXBlfQUUxtbZKxx0nrVqV90oas327+3mMWtIiCxb4Gd444628Zs4sZ8ukdPgh3YQ3ICyEtxRYS3hL07Rph1be9u6VOjulttQPvgCyE2Lr5Pgz3iILFkgbN7pBTj5hz1t5zZhR3vA2Zcqhlbf+fsIbEBLCWwrWrHEBY+7cvFdSTNGrhta6t2mZRBGFOLSk0n43yR06PmOGtHlz1iuqjrbJ8ipz5S3a8xY9h1J5A8JCeEvBE09Ip52W9yqKq7XVXQxGrxwS3lBEIVfeKvFx3xvhrbzmzStv1bWtzf0ZGHBvE96AsBDeUtDb69qEkJ6pUw/ue9u9m/CG4gnxoO5a4c23s97Y81ZeF1wgffvbea8iP2OHlhDegLAQ3lJA/3j6xu57o/KGIjr+eDewxLd9YtWEWHkra/Wl7FpaXIApq7HHBRDegLAQ3lLQ18fh3GkbW3kjvKGIpk2TZs3yL/BUE2J4o/KGMqLyBoSL8JYCfhGmj8obyiCkoSXWVg9vPh4XQHhDWUWVt5ERd8QHLzgD4SC8pYC2yfRReUMZhDS05KWX3BEBs2ZV/rhvlbehIfcC0Pgz6YAyiCpvO3a4f7e3570iAPUivKWAtsn0jT2om/CGogppaMnatRNX3ST/wlv0e7qFZ0GUUFR5o1MICA9PWymg8pa+qVNpm0TxhVR5q9YyKUk9Pe6ctwMHslpRdbRMosyiyhvhDQgP4S0F/DJM3/jK29Sp+a4HSENIe95qhbf2dheWenuzWlF1hDeUWVcXlTcgVIS3hA0PSzt3so8ibVTeUAYLFrg9KTt35r2S2mqFN8mvs9444w1lRtskEC7CW8JeekmaPl1qbc17JcXGnjeUQUuLq76FsO+t3vDmy743znhDmdE2CYSL8JYwfhFmg8obyiKUfW8hhjcqbygrKm9AuAhvCWPSZDaovKEsQghvtc54i/h01httkygzKm9AuAhvCWPSZDaovKEsQhhasn27a/GstdeXyhvgBypvQLgIbwmj8pYNKm8oixAqb+vWSYsX1/4838Ibe95QVlTegHAR3hLGL8JsUHlDWSxdKq1Z48/5aJXUOqA74lt4o/KGsqLyBoSL8JYw2iazQeUNZTFlinTUUa665at69rtJ0vz57mJxcDDtFdXGnjeUGZU3IFyEt4TRNpmNqPI2MiLt2+eeiICi8r11st7w1trqgujGjWmvqDprqbyh3Ki8AeEivCWMX4TZiCpvu3e7J6EWHskoMN+HltQb3iQ/Wif37pWM4UUflFdXl+sUGhpyL4YCCAeXvAmjbTIbUeVt925aJlF8Ram8SX6EN6puKLuuLvdzeMQR7oUMAOEgvCWMtslsdHa6lsm+PsIbim/5cmnlyrxXUVl0xtvRR9f3+T6c9cZ+N5TdlCnu54DrFSA8hLeEUXnLhjGu+tbbS3hD8flceevvl9raap/xFvGh8vbQQ9LLXpbvGoA8RS3DXK8A4SG8JYw9b9mZNo3whnKYN89NaNy2Le+VHK7eM94iPoS3m26SLr883zUAeZoyxf3N9QoQHsJbggYHpf37CRNZmTrVTa3j/zeKzhh/WyfrPeMtknd4e/JJafNm6bWvzW8NQN6ovAHhIrwlqL/f9Y+z+TcbVN5QJr6Gt0aGlUj5h7ebbpLe9S53bAFQVu3t7meA8AaEpy3vBRQJLZPZmjbNVd4YPIAy8HXf27p10rJl9X/+3LnSzp2uS2HSpNSWVdHgoHTrrdIDD2R7v4BvoqMyuGYBwkPlLUFMmswWA0tQJj6Ht0Yqby0tUk+PtH59Wiua2A9/KJ1wgrRkSfb3DfhmyhTCGxAiwluCmDSZrajyxgGjKANfD+puNLxJ+bVO3nij9O53Z3+/gI+ovAFhIrwliMpbtqi8oUyWLJFeeMG1/vmi0TPeInmc9bZxo3TffdIll2R7v4CvCG9AmAhvCWLPW7amTZMGBghvKIfOTmnRIul3v8t7JQf19UkdHdKMGY19XR6Vt1tukd761oNT9oCy++IXpTPPzHsVABpFeEsQbZPZitolCW8oC9/2vTXTMillH96sdVMm3/Oe7O4T8N1557kXhQCEhfCWINomsxWFNsIbysLH8NbIAd2RrMNbNF3ynHOyu08AANJAeEsQbZPZovKGsvFtaEmjB3RHsg5v0dlunMEJAAgd4S1BtE1mi8obysa3g7rjtE1mdVTAnj3SnXdKl12Wzf0BAJAmwluCaJvMFpU3lE3UNmlt3itxmg1vRxzhDunesyfpFR3urrukc8+VurvTvy8AANJGeEsQlbdsUXlD2RxxhNTeLm3enPdKnGbDmzHZHRfAoBIAQJEQ3hJiLXveskblDWXky763Zs94i2QR3taskZ5+WvqjP0r3fgAAyArhLSF797pXkydPznsl5TFtmtTSwv9zlIsvEye3bZMmTZKmT2/u67MYWnLzzdKll7qz6AAAKIK2vBdQFLRMZm/aNPeHCXIoE1+GljTbMhlJO7wND7vw9v/+X3r3AQBA1qi8JYSWyewddZR0zz15rwLIli+VN9/D23/+p3TkkdIpp6R3HwAAZI3wlhAmTWbPGOnMM/NeBZAtn8JbMwd0R9IObzfeKL373endPgAAeSC8JYS2SQBZOOYYqbfX7bPNU7MHdEfSDG/bt0s/+pH0Z3+Wzu0DAJAXwltCaJsEkIW2NmnJEum55/JdRxJtk2kd1H3bbdIf/AHdEACA4iG8JYS2SQBZ8WFoSdzwNmOGO25gx46kVnQQZ7sBAIqK8JYQ2iYBZCXvfW9xz3iT0juo+6mnpE2bpAsvTPZ2AQDwAeEtIVTeAGQl74O6t26VpkxxR3XEkca+t5tuki6/XGptTfZ2AQDwAeEtIVTeAGQl78pb3JbJSNLhbXBQ+uY3pXe9K7nbBADAJ4S3hDCwBEBWjj9eWrVKGhnJ5/59DW933y297GXScccld5sAAPiE8JYQ2iYBZGXGDGn6dGnDhnzu39fwdtNNnO0GACg2wltCaJsEkKU8WyfjHtAdSTK8bdok/fKX0iWXJHN7AAD4iPCWAGvdobBU3gBkJc+hJXEP6I4kedbbLbdIF18sTZ2azO0BAOAjwlsCduyQJk+W2tvzXgmAssi78pZEeIuOCrA23u1YK914I2e7AQCKj/CWAFomAWQtr4O6rZWefz7eGW+RadOkjg73OzSOhx5yw1vOPTf+mgAA8BnhLQFMmgSQtbwqb1u2SF1dybUnJrHv7cYb3fEAxiSyJAAAvEV4SwCTJgFkbeFCt9d2165s7zeplslI3PC2d690553SZZcltyYAAHxFeEsAbZMAstbSIi1dmn3rpG/h7fbbXbtkT09yawIAwFeEtwTQNgkgD3nse/MtvH35y9IHPpDcegAA8BnhLQG0TQLIQx773pI64y0SJ7w98YS0caN00UXJrQcAAJ8R3hJA2ySAPOQR3pI64y0S56y3L39Z+vM/l1pbk1sPAAA+a8t7AUXQ1yf93u/lvQoAZZPHQd2+tE3u2uX2uz31VHJrAQDAd1TeEkDlDUAeli2TVq+Whoezub8kz3iL9PRIGza4c9oacdtt0u//PoNKAADlQnhLAANLAOShq0uaO9cFqixs3uwO1u7qSu42p0xxZ8Zt3drY1zGoBABQRoS3BDCwBEBeli+XfvvbbO4r6ZbJSKOtk48+6joeXv/65NcCAIDPCG8JoG0SQF6OPdYNEcmCL+Hthhuk97/fnXUHAECZMLAkpgMH3Mb5mTPzXgmAMurpcePys+BDeNuxQ7rrruwHtQAA4ANet4xp+3ZpxgxeAQaQj2jgRxZ8CG/f/Kb0utdJ8+Ylvw4AAHxH5IiJlkkAeeruzja8JXlAd6Tes96sZVAJAKDcCG8xMWkSQJ6ybJtM+oDuSL2VtwcflPbvl17zmuTXAABACAhvMTFpEkCesmqbHBmRXngh2TPeIgsW1BfeGFQCACg7ngJjom0SQJ5mzpSGhqTdu9O9n82bpenT3blsSevpkXp7qx823t8v/eAH0rvelfz9AwAQCsJbTLRNAsiTMW7fW9qtk2kNK5Gkzk7XwbBp08Sf841vSBddJHlNoU0AABFGSURBVM2Zk84aAAAIAeEtJtomAeQti9bJNMObVH3fG4NKAABwCG8x0TYJIG9FD2+//KWrMJ53Xnr3DwBACAhvMVF5A5C30Nsmperh7YYbXNXNmPTuHwCAEBDeYqLyBiBvRam8VTrrbetW6d/+TbrssvTuGwCAUBDeYmJgCYC8FSW8Vaq83Xyz9Ja3SLNmpXffAACEoi3vBYSOtkkAeUu7bdJad8bbwoXp3Uels95GRqSvfMVNmgQAAFTeYqNtEkDe0q68bdvmznebOjW9+6hUefvpT939nn12evcLAEBICG8xDAxIg4PpXtAAQC3d3e6Q65GRdG7/xRfTrbpJ7r9h61Z34HiEQSUAAByK8BZD1DLJhQWAPHV2StOnu/CThhdekBYtSue2I21t0ty5B9s/N22SfvIT6dJL071fAABCQniLgZZJAL7o6Ulv31sW4U06tHXyxhulSy6RZsxI/34BAAgF4S0GJk0C8EWa+96yaJuUDoa3kRHpq191LZMAAOAgwlsMTJoE4Is0w1uWlbf166V77nEvjJ1xRvr3CQBASDgqIAbaJgH4Is3jArIMb2vWSPfdR9UNAIBKqLzFQNskAF8UoW1ywQLpwQelX/xCevvb078/AABCQ3iLgbZJAL5IK7wNDUlbtrjKXtoWLpQeeUR629s4ggUAgEoIbzHQNgnAF2m1TW7YIB11lBvln7aoukfLJAAAlRHeYqBtEoAv0qq8ZdUyKUnz50vf+550yinZ3B8AAKEhvMXQ30/bJAA/zJkj7dol7d+f7O1mNaxEkoyR3vKWbO4LAIAQEd5ioPIGwBctLa69sbc32dvNMrwBAIDqCG8xMLAEgE/SaJ3Msm0SAABUR3hrkrUMLAHglzTCG5U3AAD8QXhr0p49bvrapEl5rwQAnO5uwhsAAEVGeGsSLZMAfNPTk/xxAbRNAgDgD8Jbk2iZBOCbpNsmd+6UBgd5oQoAAF8Q3prEpEkAvkk6vL34omuZNCa52wQAAM0jvDWJtkkAvunuTrZtkpZJAAD8QnhrEm2TAHwTVd6sTeb2GFYCAIBfCG9Nom0SgG+6uqTOTmn79mRuj/AGAIBfCG9Nom0SgI+SbJ2kbRIAAL8Q3ppE2yQAHyU5tITKGwAAfiG8NYm2SQA+IrwBAFBchLcm9ffTNgnAP0m1TY6MuBC4YEH82wIAAMkgvDWJyhsAHyVVeduyRZo+XZo8Of5tAQCAZBDemsTAEgA+Siq80TIJAIB/CG9NGBmRXnqJ8AbAP93dyYQ3Jk0CAOAfwlsTduyQpk6V2tryXgkAHKqnJ5k9b1TeAADwD+GtCbRMAvDVvHnStm3S0FC82yG8AQDgH8JbEzjjDYCv2tqkI4+UNm2Kdzu0TQIA4J9Y4c0Y83fGmBXGmCeNMd8zxswc87GPG2NWG2NWGmP+IP5S/cGkSQA+S6J1ksobAAD+iVt5+7Gkk6y1J0taJenjkmSMOUHS2ySdKOkNkv7JGNMa8768QdskAJ8lMXGS8AYAgH9ihTdr7T3W2gOjbz4oKTrO9c2Svm2tHbDWrpW0WtKZce7LJ7RNAvBZ3PA2MCBt3+72zwEAAH8kueftPZJ+NPrvHkkvjvnY+tH3FQJtkwB81t0dr21y/Xp3G62F6ZcAAKAYaoY3Y8xPjDFPV/jz5jGf8wlJByTd2ugCjDHvN8Y8aox5dOvWrY1+eS76+2mbBOCvuJU3WiYBAPBTzZPKrLUXVvu4MeZdkt4k6bXWWjv67g2Sxs4pWzD6vkq3/xVJX5GkM844w1b6HN/09Ulnn533KgCgsrjhjUmTAAD4Ke60yTdIukLSH1tr94750A8kvc0Y02mMWSxpqaSH49yXT2ibBOCzuG2TVN4AAPBTzcpbDV+U1Cnpx8YYSXrQWvtBa+0zxpg7JD0r1075YWvtcMz78gZtkwB8lkTb5GmnJbceAACQjFjhzVp7XJWPXSvp2ji37ysqbwB8NmOGNDws7dolTZvW+Ne/+KL05jfX/jwAAJCtJKdNlgbnvAHwmTHxWidpmwQAwE+EtwYNDUl79rhXtgHAV822TlrrwhsDSwAA8A/hrUHbt0uzZkkt/J8D4LFmw9uOHa5yxwtUAAD4hwjSIFomAYSgu7u58Ba1TLoZVAAAwCeEtwb19zOsBID/enqa2/NGyyQAAP4ivDWISZMAQtBs2+SLLzKsBAAAXxHeGkTbJIAQNBvemDQJAIC/CG8Nom0SQAiaPSqAtkkAAPxFeGsQbZMAQtDdLW3aJI2MNPZ1tE0CAOAvwluD+vtpmwTgv44OaeZMacuWxr6OtkkAAPxFeGsQlTcAoWi0dXJ42H1+T096awIAAM0jvDWI8AYgFI0OLdm0yf1+6+xMb00AAKB5hLcG0TYJIBSNhjdaJgEA8BvhrUFU3gCEotG2SSZNAgDgN8JbgwhvAELRaOWNSZMAAPiN8NaAffvchv4pU/JeCQDURtskAADFQnhrQHRAtzF5rwQAauvubjy80TYJAIC/CG8N6OtjWAmAcPT0NLbnjbZJAAD8RnhrQFR5A4AQzJkj7dnjWr7rQdskAAB+I7w1gGElAEJijDR/fn3Vt717pV27pCOPTH9dAACgOYS3BtA2CSA09R4XsH69tGCB1MKzAgAA3uJpugG0TQIITb0TJ2mZBADAf4S3BtA2CSA0jYQ3Jk0CAOA3wlsD+vtpmwQQlnrbJpk0CQCA/whvDaDyBiA0tE0CAFAchLcGEN4AhIa2SQAAioPw1gDaJgGEhrZJAACKg/DWACpvAELT0+PCm7UTf461VN4AAAgB4a1O1lJ5AxCeKVOkSZPc76+J9PVJnZ3StGnZrQsAADSO8Fan3buljg53gQMAIenurr7vjZZJAADCQHirEy2TAEIVtU5OhEmTAACEgfBWp74+WiYBhKnWxEn2uwEAEAbCW536+6m8AQhTrfBG2yQAAGEgvNWJtkkAoap1XABtkwAAhIHwVifaJgGEirZJAACKgfBWJ9omAYSKtkkAAIqB8FYn2iYBhKpa2+TQkLR5s/scAADgN8JbnTigG0Co5s1zv8OGhg7/2MaN0ty5Unt79usCAACNIbzVicobgFC1trqA1tt7+MdomQQAIByEtzoR3gCEbKLWSSZNAgAQDsJbnWibBBCyiYaWMGkSAIBwEN7qROUNQMgmCm+0TQIAEA7CWx2Gh6UdO6RZs/JeCQA0p7ubyhsAAKEjvNVhxw5p2jS36R8AQtTTw543AABCR3irAy2TAEJH2yQAAOEjvNWhr49hJQDCVim87dol7d/Pi1MAAISC8FaH/n4ubgCErdJRAS++6Pa7GZPPmgAAQGMIb3WgbRJA6KZPl6yVdu48+D5aJgEACAvhrQ6c8QYgdMYc3jrJpEkAAMJCeKsDlTcARTC+dZJJkwAAhIXwVgfCG4AiGF95o20SAICwEN7qQNskgCKgbRIAgLAR3upA5Q1AEdA2CQBA2AhvdSC8ASiCsZW3kRFp/XoqbwAAhITwVgfaJgEUwdjwtnWrNHWqNGVKvmsCAAD1I7zVgcobgCIY2zZJyyQAAOEhvNUwOCjt2+cOuAWAkM2fL23eLA0PM2kSAIAQEd5q2L5dmjXLHXALACHr6HC/z7ZsYdIkAAAhIrzVQMskgCKJ9r3RNgkAQHgIbzUQ3gAUSbTvjbZJAADCQ3ir4WUvkz73ubxXAQDJGFt5o20SAICwtOW9AN/NmeP+AEAR0DYJAEC4qLwBQIl0d0tr17qW8Pnz814NAABoBOENAEqkp0d6+GEX3Fpb814NAABoBOENAEqkp0davZqWSQAAQkR4A4AS6e52fxPeAAAID+ENAErkiCOkzk4mTQIAECLCGwCUiDGu+kblDQCA8BDeAKBkFi2Sjjkm71UAAIBGcc4bAJTMbbdJc+fmvQoAANAowhsAlAznuwEAECbaJgEAAAAgAIQ3AAAAAAgA4Q0AAAAAAkB4AwAAAIAAEN4AAAAAIACENwAAAAAIAOENAAAAAAJAeAMAAACAABDeAAAAACAAhDcAAAAACADhDQAAAAACQHgDAAAAgAAQ3gAAAAAgAIQ3AAAAAAgA4Q0AAAAAAkB4AwAAAIAAEN4AAAAAIACENwAAAAAIAOENAAAAAAJAeAMAAACAABDeAAAAACAAhDcAAAAACADhDQAAAAACQHgDAAAAgAAQ3gAAAAAgAIQ3AAAAAAgA4Q0AAAAAAkB4AwAAAIAAEN4AAAAAIACENwAAAAAIAOENAAAAAAJAeAMAAACAABDeAAAAACAAhDcAAAAACADhDQAAAAACYKy1ea/hvxhjtkp6Pu91VDBH0ra8F4Fc8RgAjwHwGACPAfAYQBaPgaOttUdW+oBX4c1XxphHrbVn5L0O5IfHAHgMgMcAeAyAxwDyfgzQNgkAAAAAASC8AQAAAEAACG/1+UreC0DueAyAxwB4DIDHAHgMINfHAHveAAAAACAAVN4AAAAAIACENwAAAAAIAOGtBmPMG4wxK40xq40xV+W9HqTPGHOjMWaLMebpMe+bbYz5sTHmudG/Z+W5RqTLGLPQGPNTY8yzxphnjDEfGX0/j4OSMMZMMsY8bIz5zehj4H+Pvn+xMeah0eeE240xHXmvFekxxrQaY35tjPnh6Nt8/0vGGLPOGPOUMeYJY8yjo+/juaAkjDEzjTF3GmNWGGN+a4w5J+/vP+GtCmNMq6QvSfpDSSdIersx5oR8V4UM3CzpDePed5Wke621SyXdO/o2iuuApL+21p4g6WxJHx792edxUB4Dki6w1p4i6VRJbzDGnC3ps5K+YK09TtJ2Se/NcY1I30ck/XbM23z/y+k11tpTx5ztxXNBefxfSf9urV0u6RS53we5fv8Jb9WdKWm1tXaNtXZQ0rclvTnnNSFl1tpfSOof9+43S/qX0X//i6S3ZLooZMpa22utfXz037vkfln3iMdBaVhn9+ib7aN/rKQLJN05+n4eAwVmjFkg6Y2Svjb6thHffzg8F5SAMWaGpPMlfV2SrLWD1tqXlPP3n/BWXY+kF8e8vX70fSifedba3tF/b5I0L8/FIDvGmGMknSbpIfE4KJXRlrknJG2R9GNJv5P0krX2wOin8JxQbP8g6QpJI6NvHyG+/2VkJd1jjHnMGPP+0ffxXFAOiyVtlXTTaPv014wxXcr5+094Axpk3fkanLFRAsaYqZLukvRRa+3OsR/jcVB81tpha+2pkhbIdWIsz3lJyIgx5k2StlhrH8t7Lcjdq6y1p8ttofmwMeb8sR/kuaDQ2iSdLumfrbWnSdqjcS2SeXz/CW/VbZC0cMzbC0bfh/LZbIyZL0mjf2/JeT1ImTGmXS643Wqt/e7ou3kclNBom8xPJZ0jaaYxpm30QzwnFNcrJf2xMWad3JaJC+T2vvD9Lxlr7YbRv7dI+p7cCzk8F5TDeknrrbUPjb59p1yYy/X7T3ir7hFJS0enS3VIepukH+S8JuTjB5IuH/335ZK+n+NakLLRvS1fl/Rba+3nx3yIx0FJGGOONMbMHP33ZEmvk9v7+FNJl4x+Go+BgrLWftxau8Bae4zcc/9/WmsvFd//UjHGdBljpkX/lvR6SU+L54JSsNZukvSiMeb40Xe9VtKzyvn7b1y1DxMxxlwk1/feKulGa+21OS8JKTPG3Cbp1ZLmSNos6X9J+ldJd0haJOl5SX9irR0/1AQFYYx5laRfSnpKB/e7XC23743HQQkYY06W24jeKvdC5x3W2k8ZY46Vq8TMlvRrSe+w1g7kt1KkzRjzakkfs9a+ie9/uYx+v783+mabpG9Za681xhwhngtKwRhzqtzQog5JayS9W6PPCcrp+094AwAAAIAA0DYJAAAAAAEgvAEAAABAAAhvAAAAABAAwhsAAAAABIDwBgAAAAABILwBAAAAQAAIbwAAAAAQgP8Pfc5eQ2zOOYQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.8039e-01,  2.6129e-02, -3.0395e-01, -7.0466e-04, -1.4103e+00,\n",
      "        -5.8889e-03], requires_grad=True)\n",
      "[18.596634]\n",
      "[62.596104]\n",
      "tensor(-299.1491, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.79729154 -0.88845851  0.74448894  0.27958895  0.87853621  0.31264165]\n",
      "variance_average : [0.40764192 0.20532133 0.38672474 0.46417315 0.10829722 0.56634515]\n",
      "training idx 1 actor true_reward at iteration 70 : 46.47554090324433\n",
      "44630\n",
      "Parameter containing:\n",
      "tensor([-0.5511, -0.1643, -0.4499, -0.0630, -1.5059, -0.1152],\n",
      "       requires_grad=True)\n",
      "[-1.735508]\n",
      "[35.53956]\n",
      "tensor(-15.0260, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.60016797 -0.85110284  0.84252605  0.05228457  0.64057553  0.10053841]\n",
      "variance_average : [0.29845166 0.14332352 0.29080191 0.42113579 0.08891442 0.47824234]\n",
      "training idx 1 actor true_reward at iteration 80 : 3.0173811224728664\n",
      "54630\n",
      "Parameter containing:\n",
      "tensor([-0.6893, -0.2796, -0.5009, -0.1430, -1.5391, -0.1553],\n",
      "       requires_grad=True)\n",
      "[-10.309963]\n",
      "[11.008103]\n",
      "tensor(146.1170, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96195155 -0.96574376  0.95463026  0.74631532  0.22954125  0.77807119]\n",
      "variance_average : [0.23559927 0.12004715 0.26798418 0.36304585 0.08470153 0.44781893]\n",
      "training idx 1 actor true_reward at iteration 90 : 2.4098088449637114\n",
      "64630\n",
      "Parameter containing:\n",
      "tensor([-0.8078, -0.4230, -0.5827, -0.2026, -1.5775, -0.3245],\n",
      "       requires_grad=True)\n",
      "[-5.384665]\n",
      "[22.824928]\n",
      "tensor(1.9549, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88765003 -0.71313588  0.53661256 -0.12623375 -0.8002176   0.53424589]\n",
      "variance_average : [0.21685592 0.29007539 0.2679512  0.32219982 0.22917447 0.46103025]\n",
      "training idx 1 actor true_reward at iteration 100 : 6.2831174069034015\n",
      "68954\n",
      "Parameter containing:\n",
      "tensor([-0.8220, -0.4631, -0.6510, -0.2461, -1.6249, -0.3839],\n",
      "       requires_grad=True)\n",
      "[-7.4359384]\n",
      "[14.553744]\n",
      "tensor(4.3784, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.61320829 -0.82868827  0.57678832 -0.43070715 -0.56026612  0.63096214]\n",
      "variance_average : [0.48629627 0.36398556 0.22589355 0.29682485 0.14978368 0.39824988]\n",
      "training idx 1 actor true_reward at iteration 110 : 0.07116322466210098\n",
      "69938\n",
      "Parameter containing:\n",
      "tensor([-0.8328, -0.5504, -0.7391, -0.2923, -1.7251, -0.4661],\n",
      "       requires_grad=True)\n",
      "[4.445345]\n",
      "[24.360582]\n",
      "tensor(17.3971, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8579427  -0.88860764  0.71924034  0.14863338 -0.84465677  0.8922535 ]\n",
      "variance_average : [0.22180523 0.10555177 0.36725157 0.33708813 0.12914728 0.2871877 ]\n",
      "training idx 1 actor true_reward at iteration 120 : -1.4097391995965218\n",
      "70567\n",
      "Parameter containing:\n",
      "tensor([-0.8653, -0.6005, -0.7887, -0.3466, -1.7985, -0.5395],\n",
      "       requires_grad=True)\n",
      "[24.473059]\n",
      "[38.260883]\n",
      "tensor(91.2772, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90258989 -0.91980188  0.50873084 -0.02628479 -0.69452173  0.91356272]\n",
      "variance_average : [0.20274559 0.09091326 0.19953003 0.26861038 0.05830399 0.2359114 ]\n",
      "training idx 1 actor true_reward at iteration 130 : 4.303753910143753\n",
      "71186\n",
      "Parameter containing:\n",
      "tensor([-0.8757, -0.6426, -0.8117, -0.3795, -1.8456, -0.5653],\n",
      "       requires_grad=True)\n",
      "[-24.320883]\n",
      "[7.53834]\n",
      "tensor(11.8122, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.80837679 -0.78764388  0.88079641 -0.76905155 -0.85206393  0.82788679]\n",
      "variance_average : [0.21397818 0.15715991 0.25510383 0.40345108 0.16460076 0.28855661]\n",
      "training idx 1 actor true_reward at iteration 140 : 8.183939568379015\n",
      "71685\n",
      "Parameter containing:\n",
      "tensor([-0.8808, -0.6553, -0.8178, -0.3926, -1.8606, -0.5739],\n",
      "       requires_grad=True)\n",
      "[-4.1677094]\n",
      "[17.376959]\n",
      "tensor(17.5486, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86032296 -0.89364236  0.63787998 -0.51733499 -0.80603976  0.73339134]\n",
      "variance_average : [0.27005868 0.07395876 0.25445289 0.43398605 0.14849559 0.2186446 ]\n",
      "training idx 1 actor true_reward at iteration 150 : -4.885938293992697\n",
      "72042\n",
      "Parameter containing:\n",
      "tensor([-0.8929, -0.6845, -0.8297, -0.4179, -1.9081, -0.5771],\n",
      "       requires_grad=True)\n",
      "[-11.629305]\n",
      "[7.4350367]\n",
      "tensor(17.5690, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.85301301 -0.77630791  0.42490275 -0.79788193 -0.83807134  0.51799414]\n",
      "variance_average : [0.17258666 0.11474409 0.24169245 0.22325275 0.34907927 0.229941  ]\n",
      "training idx 1 actor true_reward at iteration 160 : 6.5244969602321605\n",
      "72480\n",
      "Parameter containing:\n",
      "tensor([-0.8994, -0.7020, -0.8380, -0.4304, -1.9247, -0.5842],\n",
      "       requires_grad=True)\n",
      "[10.515273]\n",
      "[3.1425772]\n",
      "tensor(19.2544, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84152774 -0.84701321  0.49318511 -0.49600218 -0.81104181  0.600643  ]\n",
      "variance_average : [0.2365715  0.09632237 0.17344072 0.33708651 0.05631183 0.3021167 ]\n",
      "training idx 1 actor true_reward at iteration 170 : -1.7532358027523087\n",
      "72796\n",
      "Parameter containing:\n",
      "tensor([-0.9261, -0.7294, -0.8516, -0.4551, -1.9717, -0.6179],\n",
      "       requires_grad=True)\n",
      "[-58.397938]\n",
      "[25.266706]\n",
      "tensor(16.5503, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.66431616 -0.89253087  0.70702216 -0.72369592 -0.80591128  0.27623564]\n",
      "variance_average : [0.27978334 0.11475062 0.28411201 0.21269726 0.23425023 0.46970047]\n",
      "training idx 1 actor true_reward at iteration 180 : 11.507494447527474\n",
      "73238\n",
      "Parameter containing:\n",
      "tensor([-0.9561, -0.7510, -0.8450, -0.4440, -1.9962, -0.6271],\n",
      "       requires_grad=True)\n",
      "[-50.468975]\n",
      "[26.010345]\n",
      "tensor(43.3003, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88285082 -0.82415543  0.65947106 -0.4563731  -0.85694214  0.42220831]\n",
      "variance_average : [0.23234846 0.1908034  0.16439946 0.26720508 0.10692917 0.25535811]\n",
      "training idx 1 actor true_reward at iteration 190 : 12.77182163708653\n",
      "73758\n",
      "Parameter containing:\n",
      "tensor([-0.9763, -0.7708, -0.8662, -0.4834, -2.0258, -0.6358],\n",
      "       requires_grad=True)\n",
      "[8.440227]\n",
      "[3.4883368]\n",
      "tensor(19.8372, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.77513741 -0.82017     0.78630523 -0.71969402 -0.83915315  0.78036573]\n",
      "variance_average : [0.19578453 0.13862204 0.17231228 0.21073818 0.10101288 0.28490224]\n",
      "training idx 1 actor true_reward at iteration 200 : 4.360341317032541\n",
      "74380\n",
      "Parameter containing:\n",
      "tensor([-1.0133, -0.8136, -0.8886, -0.5379, -2.0643, -0.6666],\n",
      "       requires_grad=True)\n",
      "[-10.46315]\n",
      "[14.119232]\n",
      "tensor(55.2641, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.91284674 -0.81736533  0.4038564   0.13636131 -0.81482173  0.81348659]\n",
      "variance_average : [0.17741631 0.09556583 0.23908314 0.22371429 0.08841583 0.22981599]\n",
      "training idx 1 actor true_reward at iteration 210 : 0.6551172693746037\n",
      "75056\n",
      "Parameter containing:\n",
      "tensor([-1.0338, -0.8344, -0.9058, -0.5675, -2.0989, -0.6941],\n",
      "       requires_grad=True)\n",
      "[-25.655287]\n",
      "[14.483052]\n",
      "tensor(44.4785, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.60810214 -0.91303979  0.7679179  -0.37263388 -0.83235498  0.83954011]\n",
      "variance_average : [0.1371892  0.12160622 0.15208049 0.23706893 0.1738781  0.18167216]\n",
      "training idx 1 actor true_reward at iteration 220 : 9.989603565407606\n",
      "75609\n",
      "Parameter containing:\n",
      "tensor([-1.0325, -0.8498, -0.9134, -0.5788, -2.1143, -0.7137],\n",
      "       requires_grad=True)\n",
      "[1.0851902]\n",
      "[9.752215]\n",
      "tensor(42.3375, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.72594861 -0.80519697  0.63076702 -0.13837705 -0.87199973  0.82040869]\n",
      "variance_average : [0.28573849 0.15292193 0.13936807 0.17974698 0.04900334 0.16775385]\n",
      "training idx 1 actor true_reward at iteration 230 : -0.054591164651648705\n",
      "76131\n",
      "Parameter containing:\n",
      "tensor([-1.0365, -0.8799, -0.9309, -0.5616, -2.1316, -0.7442],\n",
      "       requires_grad=True)\n",
      "[-43.137512]\n",
      "[18.562239]\n",
      "tensor(61.6141, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.76347108 -0.88573745  0.81236158 -0.15711892 -0.90463105  0.70256324]\n",
      "variance_average : [0.12886209 0.08882986 0.17788344 0.21624075 0.05886038 0.16740384]\n",
      "training idx 1 actor true_reward at iteration 240 : 11.687584113222101\n",
      "76797\n",
      "Parameter containing:\n",
      "tensor([-1.0683, -0.8968, -0.9514, -0.5925, -2.1704, -0.7615],\n",
      "       requires_grad=True)\n",
      "[-35.643726]\n",
      "[15.178726]\n",
      "tensor(46.7787, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82332273 -0.81792627  0.62687395 -0.20757654 -0.85366372  0.7302578 ]\n",
      "variance_average : [0.14621657 0.07209975 0.14299863 0.21644637 0.08809783 0.23319809]\n",
      "training idx 1 actor true_reward at iteration 250 : 9.324278762543752\n",
      "77319\n",
      "Parameter containing:\n",
      "tensor([-1.1142, -0.9161, -0.9588, -0.6235, -2.1845, -0.7741],\n",
      "       requires_grad=True)\n",
      "[-27.179003]\n",
      "[15.27453]\n",
      "tensor(25.6408, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.72854754 -0.55061195  0.27852366 -0.35268295 -0.83156185  0.70298019]\n",
      "variance_average : [0.20372164 0.10958687 0.22302245 0.45124712 0.24223517 0.1879381 ]\n",
      "training idx 1 actor true_reward at iteration 260 : 6.539641906715847\n",
      "77765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.1178, -0.9128, -0.9582, -0.6351, -2.1910, -0.7577],\n",
      "       requires_grad=True)\n",
      "[4.323374]\n",
      "[10.592361]\n",
      "tensor(30.8080, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83806191  0.80727652 -0.71611885 -0.77182952 -0.88396416  0.94063746]\n",
      "variance_average : [0.22687171 0.24269853 0.24706273 0.3159     0.24035087 0.19601014]\n",
      "training idx 1 actor true_reward at iteration 270 : 3.9935869139618356\n",
      "78095\n",
      "Parameter containing:\n",
      "tensor([-1.1034, -0.8940, -0.9460, -0.6159, -2.1790, -0.7409],\n",
      "       requires_grad=True)\n",
      "[23.98696]\n",
      "[9.664177]\n",
      "tensor(24.0267, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.81721329  0.78638089 -0.41121017 -0.52290141 -0.5140852   0.78684821]\n",
      "variance_average : [0.14557753 0.16791787 0.16565814 0.23361818 0.10753461 0.22159839]\n",
      "training idx 1 actor true_reward at iteration 280 : -3.633765958745236\n",
      "78358\n",
      "Parameter containing:\n",
      "tensor([-1.0943, -0.8878, -0.9351, -0.6076, -2.1710, -0.7383],\n",
      "       requires_grad=True)\n",
      "[-13.656774]\n",
      "[9.433525]\n",
      "tensor(16.0479, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.78451968  0.79531177 -0.6812714   0.72808225 -0.75007189  0.77803047]\n",
      "variance_average : [0.22733495 0.06790113 0.42535196 0.43089774 0.16966005 0.27459186]\n",
      "training idx 1 actor true_reward at iteration 290 : 1.0330829696353168\n",
      "78596\n",
      "Parameter containing:\n",
      "tensor([-1.1025, -0.9022, -0.9326, -0.6184, -2.1785, -0.7456],\n",
      "       requires_grad=True)\n",
      "[-0.912035]\n",
      "[3.0331063]\n",
      "tensor(16.3540, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.72719498  0.75065969 -0.64181677  0.77009706 -0.72220974  0.81480704]\n",
      "variance_average : [0.16856805 0.11823374 0.53231998 0.19519976 0.16462509 0.24160913]\n",
      "training idx 1 actor true_reward at iteration 300 : 4.9064844344442875\n",
      "78816\n",
      "Parameter containing:\n",
      "tensor([-1.1041, -0.9089, -0.9327, -0.6165, -2.1726, -0.7383],\n",
      "       requires_grad=True)\n",
      "[-2.758162]\n",
      "[3.7619972]\n",
      "tensor(24.4942, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82485441  0.79654747 -0.29143248  0.60306872 -0.79059294  0.78649472]\n",
      "variance_average : [0.26100579 0.13563508 0.1614774  0.16721475 0.15116629 0.17288499]\n",
      "training idx 1 actor true_reward at iteration 310 : 2.0836591264060034\n",
      "79103\n",
      "Parameter containing:\n",
      "tensor([-1.1149, -0.9253, -0.9403, -0.6317, -2.1848, -0.7486],\n",
      "       requires_grad=True)\n",
      "[56.855835]\n",
      "[33.832363]\n",
      "tensor(38.6803, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84350619  0.84854714 -0.26734247  0.31595515 -0.92525475  0.16312661]\n",
      "variance_average : [0.23334426 0.06765197 0.29557847 0.15733599 0.26897094 0.19608646]\n",
      "training idx 1 actor true_reward at iteration 320 : -10.070123837700468\n",
      "79416\n",
      "Parameter containing:\n",
      "tensor([-1.1129, -0.9249, -0.9384, -0.6355, -2.1851, -0.7452],\n",
      "       requires_grad=True)\n",
      "[-1.5581009]\n",
      "[1.0730535]\n",
      "tensor(11.8114, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.69580731  0.69046507 -0.02151471  0.45892303 -0.72457336 -0.62985283]\n",
      "variance_average : [0.15606917 0.32535595 0.37116565 0.36609768 0.06687529 0.22605979]\n",
      "training idx 1 actor true_reward at iteration 330 : 7.0115317597741145\n",
      "79651\n",
      "Parameter containing:\n",
      "tensor([-1.1122, -0.9241, -0.9372, -0.6399, -2.1935, -0.7434],\n",
      "       requires_grad=True)\n",
      "[-16.792576]\n",
      "[13.470783]\n",
      "tensor(12.1313, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.73169497  0.78955032 -0.16483527  0.39709311 -0.76502303 -0.82599023]\n",
      "variance_average : [0.20935286 0.19274983 0.20686983 0.45129323 0.34564837 0.32392508]\n",
      "training idx 1 actor true_reward at iteration 340 : 2.6745358336409772\n",
      "79869\n",
      "Parameter containing:\n",
      "tensor([-1.1119, -0.9196, -0.9335, -0.6389, -2.1936, -0.7424],\n",
      "       requires_grad=True)\n",
      "[-9.685919]\n",
      "[8.969892]\n",
      "tensor(30.7956, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82840948  0.80038408 -0.33677108  0.84315765 -0.79428471 -0.84988034]\n",
      "variance_average : [0.26540835 0.15246037 0.33288673 0.28985526 0.06869798 0.34151441]\n",
      "training idx 1 actor true_reward at iteration 350 : 8.365969000234324\n",
      "80131\n",
      "Parameter containing:\n",
      "tensor([-1.1023, -0.9211, -0.9294, -0.6427, -2.1929, -0.7402],\n",
      "       requires_grad=True)\n",
      "[-14.277401]\n",
      "[2.442721]\n",
      "tensor(16.1745, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.73815987  0.75810416 -0.15588885  0.77641278 -0.73535835 -0.77497454]\n",
      "variance_average : [0.4119016  0.08610394 0.2098233  0.28142803 0.06410123 0.25709845]\n",
      "training idx 1 actor true_reward at iteration 360 : 7.995563593009449\n",
      "80431\n",
      "Parameter containing:\n",
      "tensor([-1.1137, -0.9272, -0.9396, -0.6470, -2.1992, -0.7462],\n",
      "       requires_grad=True)\n",
      "[5.7334204]\n",
      "[0.9736661]\n",
      "tensor(11.5128, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.68968943  0.79524745 -0.78379685  0.73412699 -0.75395448 -0.68568908]\n",
      "variance_average : [0.48517169 0.37363777 0.22058071 0.20848317 0.05621602 0.30900001]\n",
      "training idx 1 actor true_reward at iteration 370 : 1.8372772752619508\n",
      "80644\n",
      "Parameter containing:\n",
      "tensor([-1.1133, -0.9284, -0.9323, -0.6563, -2.1993, -0.7508],\n",
      "       requires_grad=True)\n",
      "[21.78381]\n",
      "[3.5987153]\n",
      "tensor(32.4482, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83976943  0.85459126 -0.37272114  0.82688775 -0.79814341 -0.82198756]\n",
      "variance_average : [0.12396489 0.20782813 0.24629879 0.18013634 0.1665572  0.16519379]\n",
      "training idx 1 actor true_reward at iteration 380 : 2.0135618054966886\n",
      "80936\n",
      "Parameter containing:\n",
      "tensor([-1.1262, -0.9349, -0.9375, -0.6701, -2.2100, -0.7533],\n",
      "       requires_grad=True)\n",
      "[-47.441193]\n",
      "[10.307402]\n",
      "tensor(40.1062, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87964904  0.82276259 -0.0886325   0.81866412 -0.2123908  -0.80858923]\n",
      "variance_average : [0.14557297 0.16308828 0.25946252 0.19133906 0.06293856 0.15623367]\n",
      "training idx 1 actor true_reward at iteration 390 : 12.01291260093846\n",
      "81192\n",
      "Parameter containing:\n",
      "tensor([-1.1237, -0.9404, -0.9435, -0.6759, -2.2141, -0.7548],\n",
      "       requires_grad=True)\n",
      "[-65.98741]\n",
      "[18.707327]\n",
      "tensor(33.5021, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86020715  0.81880776 -0.08918165  0.79475358 -0.20176971 -0.78719483]\n",
      "variance_average : [0.20586156 0.05653871 0.17530579 0.19005614 0.07691967 0.28222563]\n",
      "training idx 1 actor true_reward at iteration 400 : 14.563155536168045\n",
      "81426\n",
      "Parameter containing:\n",
      "tensor([-1.1277, -0.9459, -0.9465, -0.6812, -2.2180, -0.7489],\n",
      "       requires_grad=True)\n",
      "[-20.663897]\n",
      "[9.37108]\n",
      "tensor(21.3117, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87846127  0.73883556  0.05996651  0.81974078  0.1439123  -0.7135957 ]\n",
      "variance_average : [0.26061925 0.29467412 0.38639411 0.27828767 0.10376675 0.28438106]\n",
      "training idx 1 actor true_reward at iteration 410 : 1.0076362368028122\n",
      "81639\n",
      "Parameter containing:\n",
      "tensor([-1.1317, -0.9523, -0.9489, -0.6897, -2.2252, -0.7452],\n",
      "       requires_grad=True)\n",
      "[-24.738438]\n",
      "[2.4959989]\n",
      "tensor(19.1156, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.79537263  0.59285886  0.31602777  0.82040902  0.27830949 -0.78837116]\n",
      "variance_average : [0.22204872 0.20573446 0.22885575 0.33845492 0.08205254 0.32043691]\n",
      "training idx 1 actor true_reward at iteration 420 : 8.390417484287864\n",
      "81890\n",
      "Parameter containing:\n",
      "tensor([-1.1402, -0.9605, -0.9590, -0.7031, -2.2282, -0.7497],\n",
      "       requires_grad=True)\n",
      "[-18.263632]\n",
      "[5.1668344]\n",
      "tensor(13.7493, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88689559  0.75083307 -0.01546263  0.75097603 -0.30268271 -0.77230763]\n",
      "variance_average : [0.34176601 0.21729505 0.47063459 0.1945353  0.10097896 0.31518731]\n",
      "training idx 1 actor true_reward at iteration 430 : 7.557021912156358\n",
      "82140\n",
      "Parameter containing:\n",
      "tensor([-1.1448, -0.9589, -0.9564, -0.7041, -2.2325, -0.7533],\n",
      "       requires_grad=True)\n",
      "[-17.266325]\n",
      "[2.0900037]\n",
      "tensor(19.7784, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.68489206  0.74360552 -0.08033592  0.71379221 -0.06680024 -0.70002985]\n",
      "variance_average : [0.34577563 0.17043794 0.14278896 0.13984554 0.21340718 0.28707164]\n",
      "training idx 1 actor true_reward at iteration 440 : 8.21434510092779\n",
      "82371\n",
      "Parameter containing:\n",
      "tensor([-1.1625, -0.9710, -0.9650, -0.7190, -2.2507, -0.7634],\n",
      "       requires_grad=True)\n",
      "[-21.36199]\n",
      "[40.4947]\n",
      "tensor(16.2202, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.70925482  0.73186773 -0.08461621  0.75854892 -0.17579889 -0.79419464]\n",
      "variance_average : [0.33036586 0.44440135 0.33961725 0.35248024 0.28761497 0.20015599]\n",
      "training idx 1 actor true_reward at iteration 450 : -0.6091081026698051\n",
      "82616\n",
      "Parameter containing:\n",
      "tensor([-1.1540, -0.9610, -0.9491, -0.7180, -2.2308, -0.7537],\n",
      "       requires_grad=True)\n",
      "[4.307167]\n",
      "[3.0442123]\n",
      "tensor(19.1808, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.75107501  0.76415206 -0.20382036  0.76607669  0.14674931 -0.76691288]\n",
      "variance_average : [0.45553428 0.10913189 0.15484957 0.23778165 0.11321569 0.30984437]\n",
      "training idx 1 actor true_reward at iteration 460 : 6.039601900740398\n",
      "82968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.1498, -0.9606, -0.9504, -0.7276, -2.2400, -0.7542],\n",
      "       requires_grad=True)\n",
      "[8.818794]\n",
      "[5.347785]\n",
      "tensor(21.5877, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 7.51240660e-01  8.01817574e-01 -1.92145485e-01  8.01768806e-01\n",
      " -3.85393699e-05 -7.16457888e-01]\n",
      "variance_average : [0.21385836 0.10505706 0.25667422 0.30580767 0.09365587 0.31673472]\n",
      "training idx 1 actor true_reward at iteration 470 : 2.724288096891758\n",
      "83205\n",
      "Parameter containing:\n",
      "tensor([-1.1573, -0.9685, -0.9540, -0.7361, -2.2527, -0.7657],\n",
      "       requires_grad=True)\n",
      "[1.6375194]\n",
      "[3.3940601]\n",
      "tensor(20.3146, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.7001063   0.79221093  0.05811736  0.88839796  0.07810278 -0.72277436]\n",
      "variance_average : [0.14777662 0.25880755 0.33666136 0.16912096 0.12788174 0.37869233]\n",
      "training idx 1 actor true_reward at iteration 480 : 7.839189102592942\n",
      "83443\n",
      "Parameter containing:\n",
      "tensor([-1.1574, -0.9713, -0.9517, -0.7427, -2.2621, -0.7689],\n",
      "       requires_grad=True)\n",
      "[-54.164284]\n",
      "[22.04552]\n",
      "tensor(23.8403, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.69620995  0.74744923  0.25782684  0.90076399  0.4242787  -0.74068561]\n",
      "variance_average : [0.23479169 0.19719868 0.29840995 0.15026512 0.17516443 0.37527843]\n",
      "training idx 1 actor true_reward at iteration 490 : 14.74044303652583\n",
      "83713\n",
      "Parameter containing:\n",
      "tensor([-1.1760, -0.9818, -0.9647, -0.7526, -2.2771, -0.7835],\n",
      "       requires_grad=True)\n",
      "[-28.306686]\n",
      "[5.558565]\n",
      "tensor(16.7814, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82395686  0.70542499 -0.16727448  0.8148656  -0.08747626 -0.66190652]\n",
      "variance_average : [0.22284869 0.07045631 0.43273645 0.32093706 0.25876289 0.21271375]\n",
      "training idx 1 actor true_reward at iteration 500 : 11.63847086306243\n",
      "83960\n",
      "Parameter containing:\n",
      "tensor([-1.1815, -0.9864, -0.9661, -0.7596, -2.2800, -0.7927],\n",
      "       requires_grad=True)\n",
      "[12.121172]\n",
      "[8.794757]\n",
      "tensor(22.9767, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82734029  0.89736323  0.24175457  0.71500485  0.41988016 -0.86703138]\n",
      "variance_average : [0.1429457  0.28667666 0.26738575 0.26412003 0.15028978 0.37634884]\n",
      "training idx 1 actor true_reward at iteration 510 : -1.0485912985876085\n",
      "84193\n",
      "Parameter containing:\n",
      "tensor([-1.1733, -0.9790, -0.9607, -0.7553, -2.2851, -0.7992],\n",
      "       requires_grad=True)\n",
      "[3.4592676]\n",
      "[5.029171]\n",
      "tensor(18.7369, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8894341   0.73592632  0.16062138  0.83350542  0.25290635 -0.84250041]\n",
      "variance_average : [0.1808188  0.22153049 0.12956733 0.44278706 0.43583545 0.16861957]\n",
      "training idx 1 actor true_reward at iteration 520 : 3.1842793332940706\n",
      "84438\n",
      "Parameter containing:\n",
      "tensor([-1.1790, -0.9937, -0.9727, -0.7602, -2.2836, -0.8009],\n",
      "       requires_grad=True)\n",
      "[30.00701]\n",
      "[4.7245793]\n",
      "tensor(15.5507, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.64523008  0.73939221  0.3086517   0.76931972  0.24492963 -0.76695606]\n",
      "variance_average : [0.32165716 0.363721   0.3948957  0.2808301  0.3999066  0.55405713]\n",
      "training idx 1 actor true_reward at iteration 530 : 1.4110919838093037\n",
      "84679\n",
      "Parameter containing:\n",
      "tensor([-1.1458, -0.9679, -0.9516, -0.7253, -2.2548, -0.7794],\n",
      "       requires_grad=True)\n",
      "[-6.698899]\n",
      "[6.6160154]\n",
      "tensor(49.7133, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8433747   0.88777221  0.35192381  0.86020286  0.47736019 -0.81078537]\n",
      "variance_average : [0.26610371 0.09389147 0.16743473 0.2019484  0.09285882 0.24758847]\n",
      "training idx 1 actor true_reward at iteration 540 : 7.169550918678767\n",
      "85236\n",
      "Parameter containing:\n",
      "tensor([-1.1377, -0.9533, -0.9439, -0.7132, -2.2507, -0.7768],\n",
      "       requires_grad=True)\n",
      "[-12.043456]\n",
      "[7.7006254]\n",
      "tensor(20.9329, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.76449001  0.77225578 -0.08638365  0.67648737  0.10673903 -0.69423989]\n",
      "variance_average : [0.15147639 0.10660129 0.37376411 0.21379481 0.43108998 0.25121951]\n",
      "training idx 1 actor true_reward at iteration 550 : 5.711322782431273\n",
      "85587\n",
      "Parameter containing:\n",
      "tensor([-1.0993, -0.9230, -0.9154, -0.6875, -2.2300, -0.7443],\n",
      "       requires_grad=True)\n",
      "[3.6424255]\n",
      "[4.4774933]\n",
      "tensor(14.8592, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82278733  0.80984657  0.40258632  0.62129213  0.41562122 -0.86925872]\n",
      "variance_average : [0.29094983 0.16877406 0.33962643 0.17685947 0.29952564 0.43044832]\n",
      "training idx 1 actor true_reward at iteration 560 : 5.511316847639622\n",
      "86167\n",
      "Parameter containing:\n",
      "tensor([-1.0981, -0.9205, -0.9209, -0.6887, -2.2213, -0.7447],\n",
      "       requires_grad=True)\n",
      "[-10.455929]\n",
      "[2.056278]\n",
      "tensor(21.4690, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.79030508  0.74858361 -0.10896874  0.82232765 -0.18985829 -0.7858653 ]\n",
      "variance_average : [0.18023326 0.30243985 0.16147022 0.20401703 0.10288388 0.2438528 ]\n",
      "training idx 1 actor true_reward at iteration 570 : 4.744577749647698\n",
      "86440\n",
      "Parameter containing:\n",
      "tensor([-1.0927, -0.9147, -0.9253, -0.6869, -2.2124, -0.7380],\n",
      "       requires_grad=True)\n",
      "[7.4722567]\n",
      "[1.0492351]\n",
      "tensor(21.0886, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.77111614  0.84555198  0.29733016  0.77739349  0.18761199 -0.72273433]\n",
      "variance_average : [0.21405387 0.15095003 0.14832363 0.23966853 0.41773842 0.17260099]\n",
      "training idx 1 actor true_reward at iteration 580 : 5.250735886561816\n",
      "86675\n",
      "Parameter containing:\n",
      "tensor([-1.0953, -0.9164, -0.9367, -0.6972, -2.2158, -0.7390],\n",
      "       requires_grad=True)\n",
      "[14.634209]\n",
      "[5.896874]\n",
      "tensor(37.9975, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86407721  0.83675086  0.23287009  0.88925819 -0.08684585 -0.88223993]\n",
      "variance_average : [0.12977181 0.0901839  0.14995196 0.1543859  0.22458538 0.3406604 ]\n",
      "training idx 1 actor true_reward at iteration 590 : 6.178872609677787\n",
      "87005\n",
      "Parameter containing:\n",
      "tensor([-1.0890, -0.9101, -0.9321, -0.7027, -2.2124, -0.7363],\n",
      "       requires_grad=True)\n",
      "[-22.752441]\n",
      "[5.518307]\n",
      "tensor(23.9130, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.80835962  0.79860334  0.17722912  0.84181826  0.11308519 -0.81798335]\n",
      "variance_average : [0.23998146 0.14828428 0.29291827 0.29353274 0.07365858 0.2319001 ]\n",
      "training idx 1 actor true_reward at iteration 600 : 9.533030386984327\n",
      "87260\n",
      "Parameter containing:\n",
      "tensor([-1.0894, -0.9157, -0.9396, -0.7078, -2.2170, -0.7421],\n",
      "       requires_grad=True)\n",
      "[-6.194496]\n",
      "[4.866063]\n",
      "tensor(30.1055, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.79780872  0.8212469   0.47430792  0.83053998  0.43172627 -0.9045288 ]\n",
      "variance_average : [0.36774918 0.27431262 0.27008244 0.2169368  0.05503812 0.38277922]\n",
      "training idx 1 actor true_reward at iteration 610 : 6.83740856397627\n",
      "87493\n",
      "Parameter containing:\n",
      "tensor([-1.0736, -0.9103, -0.9378, -0.6894, -2.1929, -0.7364],\n",
      "       requires_grad=True)\n",
      "[-22.862913]\n",
      "[2.372345]\n",
      "tensor(22.7715, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87631288  0.862948    0.52331624  0.82119889  0.06046445 -0.75933072]\n",
      "variance_average : [0.29722071 0.10876643 0.44093717 0.17393852 0.05741197 0.31567585]\n",
      "training idx 1 actor true_reward at iteration 620 : 15.576535188098125\n",
      "87828\n",
      "Parameter containing:\n",
      "tensor([-1.0723, -0.9165, -0.9439, -0.6951, -2.1949, -0.7437],\n",
      "       requires_grad=True)\n",
      "[-24.927235]\n",
      "[5.790988]\n",
      "tensor(15.9343, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.73284942  0.75723508  0.43913548  0.76201262  0.1142922  -0.70813556]\n",
      "variance_average : [0.16166271 0.13992455 0.17118144 0.59489101 0.0847684  0.29454678]\n",
      "training idx 1 actor true_reward at iteration 630 : 15.406128374470265\n",
      "88039\n",
      "Parameter containing:\n",
      "tensor([-1.0702, -0.9131, -0.9492, -0.6929, -2.1889, -0.7405],\n",
      "       requires_grad=True)\n",
      "[26.034916]\n",
      "[5.826064]\n",
      "tensor(14.7492, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.76460137  0.73821996  0.11242453  0.68484629 -0.0731942  -0.76323854]\n",
      "variance_average : [0.27626899 0.24538676 0.41278542 0.25474915 0.21384657 0.21622683]\n",
      "training idx 1 actor true_reward at iteration 640 : -0.3092820879513607\n",
      "88306\n",
      "Parameter containing:\n",
      "tensor([-1.0650, -0.9162, -0.9410, -0.6842, -2.1852, -0.7392],\n",
      "       requires_grad=True)\n",
      "[14.67143]\n",
      "[2.6519904]\n",
      "tensor(8.0660, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.7103782   0.66837533  0.20797525  0.61040924 -0.04185104 -0.73133916]\n",
      "variance_average : [0.20797934 0.27721292 0.21073999 0.2532875  0.48960381 0.28844139]\n",
      "training idx 1 actor true_reward at iteration 650 : 1.7877745468906154\n",
      "88536\n",
      "Parameter containing:\n",
      "tensor([-1.0704, -0.9153, -0.9426, -0.6821, -2.1906, -0.7424],\n",
      "       requires_grad=True)\n",
      "[-26.871227]\n",
      "[7.7815914]\n",
      "tensor(19.1344, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9023013   0.77559965  0.10715832  0.79943908 -0.03548862 -0.81893813]\n",
      "variance_average : [0.13758808 0.1608824  0.27323005 0.24350437 0.15345302 0.30337   ]\n",
      "training idx 1 actor true_reward at iteration 660 : 13.210307152432474\n",
      "88764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-1.0730, -0.9128, -0.9467, -0.6672, -2.1907, -0.7386],\n",
      "       requires_grad=True)\n",
      "[99.15479]\n",
      "[41.233383]\n",
      "tensor(59.0858, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88090782  0.89473081 -0.15573226  0.88495632 -0.53303539 -0.90296649]\n",
      "variance_average : [0.13374871 0.07601206 0.18194835 0.16913431 0.06494432 0.20828512]\n",
      "training idx 1 actor true_reward at iteration 670 : -9.552772168672822\n",
      "89026\n",
      "Parameter containing:\n",
      "tensor([-1.0640, -0.9116, -0.9402, -0.6558, -2.1786, -0.7322],\n",
      "       requires_grad=True)\n",
      "[2.047759]\n",
      "[2.7007947]\n",
      "tensor(11.4313, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.68333838  0.67782062 -0.39321742  0.6854196  -0.21265106 -0.68716628]\n",
      "variance_average : [0.23237079 0.39467143 0.47396637 0.42881049 0.10664403 0.26326085]\n",
      "training idx 1 actor true_reward at iteration 680 : 2.402930466395107\n",
      "89232\n",
      "Parameter containing:\n",
      "tensor([-1.0612, -0.9229, -0.9492, -0.6595, -2.1884, -0.7305],\n",
      "       requires_grad=True)\n",
      "[-55.879967]\n",
      "[19.323528]\n",
      "tensor(51.8936, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88953627  0.86382446 -0.38013251  0.88544929 -0.46904601 -0.89896133]\n",
      "variance_average : [0.19244378 0.0645626  0.14958749 0.22943405 0.10882207 0.20605856]\n",
      "training idx 1 actor true_reward at iteration 690 : 19.755232338785998\n",
      "89486\n",
      "Parameter containing:\n",
      "tensor([-1.0579, -0.9103, -0.9477, -0.6519, -2.1811, -0.7270],\n",
      "       requires_grad=True)\n",
      "[49.765972]\n",
      "[18.288322]\n",
      "tensor(36.7908, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8863131   0.8308211  -0.12503657  0.8791954  -0.38050096 -0.85334446]\n",
      "variance_average : [0.22512588 0.12408805 0.12786794 0.22993574 0.13948037 0.16968535]\n",
      "training idx 1 actor true_reward at iteration 700 : -0.37577067950960397\n",
      "89743\n",
      "Parameter containing:\n",
      "tensor([-1.0514, -0.9108, -0.9480, -0.6442, -2.1629, -0.7241],\n",
      "       requires_grad=True)\n",
      "[8.877642]\n",
      "[6.482721]\n",
      "tensor(35.4205, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.80787977  0.08410441 -0.51165985  0.91227917 -0.79826189 -0.63983765]\n",
      "variance_average : [0.21219303 0.10254174 0.35246774 0.15271271 0.13124293 0.31229745]\n",
      "training idx 1 actor true_reward at iteration 710 : 9.273336660837264\n",
      "90090\n",
      "Parameter containing:\n",
      "tensor([-1.1504, -1.0140, -1.0308, -0.7412, -2.2462, -0.8091],\n",
      "       requires_grad=True)\n",
      "[-56.006]\n",
      "[15.299086]\n",
      "tensor(686.7344, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98786316 -0.98438513 -0.92071099  0.98831959 -0.97799326 -0.89087253]\n",
      "variance_average : [0.10712621 0.03919697 0.1106048  0.13550721 0.02544431 0.14996173]\n",
      "training idx 1 actor true_reward at iteration 720 : 18.51337499564332\n",
      "94043\n",
      "Parameter containing:\n",
      "tensor([-1.1972, -1.0642, -1.0655, -0.7820, -2.3117, -0.8677],\n",
      "       requires_grad=True)\n",
      "[63.35704]\n",
      "[23.590864]\n",
      "tensor(95.0537, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.13423867 -0.90967551 -0.67342756  0.92015268 -0.91082263 -0.12503496]\n",
      "variance_average : [0.1081005  0.04430237 0.17655504 0.22775251 0.14560198 0.16844081]\n",
      "training idx 1 actor true_reward at iteration 730 : -11.595752162616037\n",
      "98548\n",
      "Parameter containing:\n",
      "tensor([-1.1585, -1.0028, -0.9665, -0.7036, -2.2350, -0.7999],\n",
      "       requires_grad=True)\n",
      "[72.166725]\n",
      "[22.506563]\n",
      "tensor(45.3546, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.86405639 -0.90954154 -0.61090434  0.9330555  -0.8703079  -0.50919126]\n",
      "variance_average : [0.19337    0.12880534 0.28420354 0.199677   0.14821396 0.21283903]\n",
      "training idx 1 actor true_reward at iteration 740 : -17.521801228601\n",
      "98972\n",
      "Parameter containing:\n",
      "tensor([-1.1201, -0.9372, -0.9133, -0.6488, -2.1757, -0.7456],\n",
      "       requires_grad=True)\n",
      "[15.7341795]\n",
      "[2.3825407]\n",
      "tensor(20.9341, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.84265493 -0.90019684 -0.84361147  0.84105225 -0.80784872 -0.33855398]\n",
      "variance_average : [0.22265443 0.21205321 0.24815909 0.4048147  0.31912568 0.29768966]\n",
      "training idx 1 actor true_reward at iteration 750 : -2.904720093456592\n",
      "99279\n",
      "Parameter containing:\n",
      "tensor([-1.0678, -0.8937, -0.8754, -0.6075, -2.1318, -0.7086],\n",
      "       requires_grad=True)\n",
      "[-4.7314954]\n",
      "[4.1510296]\n",
      "tensor(24.0476, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.84996138 -0.84614115 -0.60338348  0.7780465  -0.82846611  0.03915872]\n",
      "variance_average : [0.1549346  0.0899083  0.25468608 0.19460064 0.07279728 0.29946781]\n",
      "training idx 1 actor true_reward at iteration 760 : -3.1628830047249075\n",
      "99641\n",
      "Parameter containing:\n",
      "tensor([-1.0242, -0.8619, -0.8364, -0.5745, -2.0914, -0.6706],\n",
      "       requires_grad=True)\n",
      "[-23.797659]\n",
      "[6.9504576]\n",
      "tensor(22.4318, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.82599105 -0.805928   -0.44832973  0.80160057 -0.78347636  0.19021875]\n",
      "variance_average : [0.23857709 0.10560891 0.24877682 0.27245475 0.11163706 0.24380944]\n",
      "training idx 1 actor true_reward at iteration 770 : -1.5826747801662144\n",
      "99966\n",
      "Parameter containing:\n",
      "tensor([-0.9683, -0.8265, -0.7842, -0.5290, -2.0355, -0.6191],\n",
      "       requires_grad=True)\n",
      "[54.378883]\n",
      "[15.519224]\n",
      "tensor(27.8797, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.82047302 -0.83029444 -0.7132434   0.83940804 -0.82525165 -0.5427707 ]\n",
      "variance_average : [0.23916912 0.12209428 0.24703656 0.19954808 0.06864416 0.2757613 ]\n",
      "training idx 1 actor true_reward at iteration 780 : -10.891473252504698\n",
      "100320\n",
      "Parameter containing:\n",
      "tensor([-0.9420, -0.8035, -0.7443, -0.4841, -2.0093, -0.5708],\n",
      "       requires_grad=True)\n",
      "[40.425896]\n",
      "[11.28553]\n",
      "tensor(48.6220, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.93090313 -0.89923666 -0.85325461  0.90135065 -0.91244622 -0.131355  ]\n",
      "variance_average : [0.17423682 0.0831242  0.23102762 0.20500878 0.09236683 0.28342676]\n",
      "training idx 1 actor true_reward at iteration 790 : -12.06451494965972\n",
      "100750\n",
      "Parameter containing:\n",
      "tensor([-0.8951, -0.7742, -0.7082, -0.4514, -1.9758, -0.5399],\n",
      "       requires_grad=True)\n",
      "[-0.700688]\n",
      "[3.9665048]\n",
      "tensor(8.5388, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.76849956 -0.75797594 -0.77868838  0.78289742 -0.64437872  0.4880665 ]\n",
      "variance_average : [0.23272549 0.24302245 0.249      0.32884112 0.10164609 0.2793368 ]\n",
      "training idx 1 actor true_reward at iteration 800 : -3.6205516766673145\n",
      "101084\n",
      "Parameter containing:\n",
      "tensor([-0.8672, -0.7417, -0.6881, -0.4300, -1.9566, -0.5177],\n",
      "       requires_grad=True)\n",
      "[3.939809]\n",
      "[15.546259]\n",
      "tensor(27.4689, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.91212699 -0.88268948 -0.82132798  0.88266935 -0.90847613  0.24356124]\n",
      "variance_average : [0.19735575 0.23994758 0.29003467 0.30425317 0.08868325 0.24874182]\n",
      "training idx 1 actor true_reward at iteration 810 : -10.571937031088616\n",
      "101454\n",
      "Parameter containing:\n",
      "tensor([-0.8273, -0.7076, -0.6576, -0.4083, -1.9226, -0.4872],\n",
      "       requires_grad=True)\n",
      "[30.403954]\n",
      "[10.955751]\n",
      "tensor(15.8880, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.83582466 -0.84678808 -0.7833841   0.85817265 -0.77517451 -0.29505161]\n",
      "variance_average : [0.28596113 0.26158212 0.19680094 0.27782962 0.08173804 0.36255095]\n",
      "training idx 1 actor true_reward at iteration 820 : -8.561739646708919\n",
      "101852\n",
      "Parameter containing:\n",
      "tensor([-0.7851, -0.6793, -0.6355, -0.3704, -1.8972, -0.4655],\n",
      "       requires_grad=True)\n",
      "[-30.560041]\n",
      "[13.895807]\n",
      "tensor(10.7807, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.87358287 -0.78753975 -0.51409987  0.86774554 -0.6871198  -0.05592865]\n",
      "variance_average : [0.261726   0.19534927 0.32222267 0.30090354 0.19746655 0.45513454]\n",
      "training idx 1 actor true_reward at iteration 830 : 4.113597577357406\n",
      "102903\n",
      "Parameter containing:\n",
      "tensor([-0.7246, -0.6226, -0.5966, -0.3020, -1.8489, -0.4016],\n",
      "       requires_grad=True)\n",
      "[21.161665]\n",
      "[22.740465]\n",
      "tensor(24.3211, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.92634887 -0.89245256 -0.66930881  0.89906291 -0.78517572 -0.31084412]\n",
      "variance_average : [0.23869229 0.09003974 0.23519055 0.33540856 0.08872194 0.33437667]\n",
      "training idx 1 actor true_reward at iteration 840 : -17.93386584969537\n",
      "103502\n",
      "Parameter containing:\n",
      "tensor([-0.6942, -0.5968, -0.5745, -0.2820, -1.8196, -0.3959],\n",
      "       requires_grad=True)\n",
      "[21.827791]\n",
      "[10.8810215]\n",
      "tensor(66.5491, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.94534297 -0.28733929 -0.15541157  0.97294912 -0.49221382 -0.55056606]\n",
      "variance_average : [0.26118127 0.12206186 0.23685644 0.28296624 0.06436653 0.32654183]\n",
      "training idx 1 actor true_reward at iteration 850 : -8.179840587628451\n",
      "104107\n",
      "Parameter containing:\n",
      "tensor([-0.6054, -0.5194, -0.4812, -0.1746, -1.7101, -0.2916],\n",
      "       requires_grad=True)\n",
      "[35.814873]\n",
      "[22.809206]\n",
      "tensor(51.3989, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.93432139 -0.48317268 -0.00915277  0.96741071 -0.60845305 -0.05428281]\n",
      "variance_average : [0.28259098 0.07589006 0.27673372 0.35542606 0.0905115  0.36449266]\n",
      "training idx 1 actor true_reward at iteration 860 : -24.5745746499418\n",
      "105176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.5976, -0.4975, -0.4819, -0.1718, -1.7197, -0.3045],\n",
      "       requires_grad=True)\n",
      "[-61.088203]\n",
      "[36.703865]\n",
      "tensor(90.4586, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.85648543  0.07275492  0.20231461  0.9781441   0.42257032 -0.00401736]\n",
      "variance_average : [0.29625766 0.07694901 0.30028524 0.35545944 0.08365635 0.35183873]\n",
      "training idx 1 actor true_reward at iteration 870 : 36.95609690854798\n",
      "109626\n",
      "Parameter containing:\n",
      "tensor([-0.6348, -0.5277, -0.5452, -0.2228, -1.7648, -0.3649],\n",
      "       requires_grad=True)\n",
      "[-10.507615]\n",
      "[20.863165]\n",
      "tensor(22.3035, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.10159763 -0.09909457  0.58073067  0.94673107  0.59619198 -0.04253917]\n",
      "variance_average : [0.28173749 0.14191312 0.27229261 0.35600623 0.11298873 0.35489435]\n",
      "training idx 1 actor true_reward at iteration 880 : -3.2230445885350654\n",
      "110880\n",
      "Parameter containing:\n",
      "tensor([-0.6139, -0.4968, -0.5250, -0.2053, -1.7491, -0.3309],\n",
      "       requires_grad=True)\n",
      "[-0.29231218]\n",
      "[39.83166]\n",
      "tensor(380.8614, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.04007498  0.06280019 -0.05489078  0.99615054 -0.00913883  0.02009252]\n",
      "variance_average : [0.26771388 0.07770051 0.25889943 0.3294266  0.054605   0.32868874]\n",
      "training idx 1 actor true_reward at iteration 890 : -10.965937834091081\n",
      "117666\n",
      "Parameter containing:\n",
      "tensor([-0.6566, -0.5426, -0.5737, -0.2939, -1.7629, -0.3440],\n",
      "       requires_grad=True)\n",
      "[-2.8702927]\n",
      "[14.395699]\n",
      "tensor(74.8094, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.36304468 -0.33986134  0.2355033   0.9626538   0.4905766   0.24164313]\n",
      "variance_average : [0.26048271 0.08983357 0.24738346 0.32576167 0.07001864 0.33806106]\n",
      "training idx 1 actor true_reward at iteration 900 : 12.236785440166619\n",
      "124244\n",
      "Parameter containing:\n",
      "tensor([-0.6599, -0.5430, -0.5652, -0.2574, -1.7455, -0.3602],\n",
      "       requires_grad=True)\n",
      "[-57.667786]\n",
      "[30.053486]\n",
      "tensor(21.4547, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.1056064  -0.66027603  0.46183386  0.94548435  0.68669025  0.32595931]\n",
      "variance_average : [0.35452069 0.11848127 0.33557138 0.38324998 0.08178001 0.3193695 ]\n",
      "training idx 1 actor true_reward at iteration 910 : 20.78509409731851\n",
      "125099\n",
      "Parameter containing:\n",
      "tensor([-0.6787, -0.5602, -0.5709, -0.2415, -1.7545, -0.3729],\n",
      "       requires_grad=True)\n",
      "[13.896507]\n",
      "[43.476616]\n",
      "tensor(243.6201, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.02487439 -0.31935863  0.16049145  0.99016041  0.2973432  -0.55539393]\n",
      "variance_average : [0.25237885 0.06862156 0.23943955 0.30625092 0.06630924 0.32297057]\n",
      "training idx 1 actor true_reward at iteration 920 : 1.8977767618107437\n",
      "127661\n",
      "Parameter containing:\n",
      "tensor([-0.6296, -0.5057, -0.5592, -0.1805, -1.7398, -0.3276],\n",
      "       requires_grad=True)\n",
      "[13.590802]\n",
      "[17.641045]\n",
      "tensor(-2.3370, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.60678937  0.08867165 -0.23048542  0.65076542  0.17968065 -0.58420524]\n",
      "variance_average : [0.33870346 0.64723032 0.73268739 0.38349096 0.11355522 0.4881861 ]\n",
      "training idx 1 actor true_reward at iteration 930 : -8.327969489171782\n",
      "131391\n",
      "Parameter containing:\n",
      "tensor([-0.6515, -0.5179, -0.5684, -0.1609, -1.7384, -0.2957],\n",
      "       requires_grad=True)\n",
      "[-91.01192]\n",
      "[102.607666]\n",
      "tensor(124.5975, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.07408164 -0.33077975  0.19278758  0.99269633  0.33266851 -0.39257441]\n",
      "variance_average : [0.27914095 0.07705647 0.24392976 0.35876428 0.06838043 0.35587302]\n",
      "training idx 1 actor true_reward at iteration 940 : 48.58371440068073\n",
      "134245\n",
      "Parameter containing:\n",
      "tensor([-0.6610, -0.5334, -0.5761, -0.1827, -1.7358, -0.3039],\n",
      "       requires_grad=True)\n",
      "[-18.886051]\n",
      "[6.2652326]\n",
      "tensor(84.5541, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.36401645 -0.16050134  0.12780624  0.97528195  0.30423784 -0.07463153]\n",
      "variance_average : [0.25292787 0.08914602 0.2498579  0.36674253 0.08188623 0.34827033]\n",
      "training idx 1 actor true_reward at iteration 950 : 12.60940288921726\n",
      "136146\n",
      "Parameter containing:\n",
      "tensor([-0.6876, -0.5789, -0.6115, -0.1899, -1.7689, -0.3094],\n",
      "       requires_grad=True)\n",
      "[-29.441832]\n",
      "[11.890956]\n",
      "tensor(38.6250, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.15427464 -0.37032971  0.1378416   0.95340912  0.43229999 -0.11201353]\n",
      "variance_average : [0.30500606 0.11061185 0.23138119 0.36441749 0.08168193 0.35123751]\n",
      "training idx 1 actor true_reward at iteration 960 : 19.077366001049626\n",
      "137917\n",
      "Parameter containing:\n",
      "tensor([-0.6986, -0.5926, -0.6462, -0.2141, -1.8043, -0.3221],\n",
      "       requires_grad=True)\n",
      "[-26.985756]\n",
      "[22.323214]\n",
      "tensor(83.5665, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.34690674 -0.33027724  0.15145799  0.97451143  0.30989296 -0.01215899]\n",
      "variance_average : [0.25962405 0.06983709 0.21078168 0.32786187 0.09487427 0.36655604]\n",
      "training idx 1 actor true_reward at iteration 970 : 21.42954348838736\n",
      "139557\n",
      "Parameter containing:\n",
      "tensor([-0.6759, -0.5686, -0.6123, -0.1514, -1.7673, -0.2878],\n",
      "       requires_grad=True)\n",
      "[-43.15849]\n",
      "[18.70268]\n",
      "tensor(60.1757, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.12443832 -0.61928428  0.33399513  0.9737607   0.44268363 -0.18298156]\n",
      "variance_average : [0.27239052 0.07683402 0.22153237 0.37607641 0.09107647 0.37953868]\n",
      "training idx 1 actor true_reward at iteration 980 : 19.511249996835847\n",
      "141806\n",
      "Parameter containing:\n",
      "tensor([-0.6276, -0.5878, -0.6097, -0.1248, -1.7303, -0.2478],\n",
      "       requires_grad=True)\n",
      "[-2.6742702]\n",
      "[19.134651]\n",
      "tensor(212.4368, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.70243472 -0.92711674  0.48006347  0.9932219   0.36654944  0.42676265]\n",
      "variance_average : [0.26352866 0.0671769  0.22261423 0.37854203 0.05987739 0.39134279]\n",
      "training idx 1 actor true_reward at iteration 990 : 6.9792723797040095\n",
      "145007\n",
      "Parameter containing:\n",
      "tensor([-0.6043, -0.5787, -0.6354, -0.1179, -1.7086, -0.2469],\n",
      "       requires_grad=True)\n",
      "[12.506245]\n",
      "[15.255635]\n",
      "tensor(26.8188, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.19064807 -0.34772554  0.25727476  0.9277357   0.81988371 -0.23008926]\n",
      "variance_average : [0.26996491 0.07671099 0.26342683 0.38354744 0.12261421 0.38013174]\n",
      "training idx 1 actor true_reward at iteration 1000 : -6.794534442290663\n",
      "146075\n",
      "Parameter containing:\n",
      "tensor([-0.5832, -0.5513, -0.6310, -0.0984, -1.6838, -0.2283],\n",
      "       requires_grad=True)\n",
      "[-9.953923]\n",
      "[13.831717]\n",
      "tensor(48.7097, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.20374046 -0.70101114  0.79418635  0.97450324  0.97092708  0.09725299]\n",
      "variance_average : [0.29017436 0.08750471 0.24048413 0.40993094 0.10513373 0.41163033]\n",
      "training idx 1 actor true_reward at iteration 1010 : 8.714846453931584\n",
      "148068\n",
      "Parameter containing:\n",
      "tensor([-0.6590, -0.6699, -0.6998, -0.1898, -1.7907, -0.3542],\n",
      "       requires_grad=True)\n",
      "[-73.65231]\n",
      "[61.079292]\n",
      "tensor(29.2451, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.42263454 -0.45904528  0.53537897  0.90265115  0.94985492  0.30925543]\n",
      "variance_average : [0.29176058 0.0907562  0.24074177 0.37834228 0.12776493 0.37052259]\n",
      "training idx 1 actor true_reward at iteration 1020 : 41.86107473086521\n",
      "149052\n",
      "Parameter containing:\n",
      "tensor([-0.7767, -0.7923, -0.8169, -0.3533, -1.9360, -0.4743],\n",
      "       requires_grad=True)\n",
      "[-9.561575]\n",
      "[33.64327]\n",
      "tensor(33.5548, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.60551683 -0.38743485  0.6089337   0.93337363  0.9652624   0.50503821]\n",
      "variance_average : [0.22156259 0.06277027 0.29556571 0.29188194 0.1253999  0.36664936]\n",
      "training idx 1 actor true_reward at iteration 1030 : 12.08294484448059\n",
      "149743\n",
      "Parameter containing:\n",
      "tensor([-0.8461, -0.8515, -0.8779, -0.4106, -1.9829, -0.5644],\n",
      "       requires_grad=True)\n",
      "[9.982349]\n",
      "[20.725605]\n",
      "tensor(36.9814, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.51416708 -0.49365223  0.5742489   0.92221509  0.88722728  0.55374665]\n",
      "variance_average : [0.23369297 0.1091508  0.22077561 0.25640811 0.14867172 0.31219312]\n",
      "training idx 1 actor true_reward at iteration 1040 : 10.17258109195972\n",
      "150461\n",
      "Parameter containing:\n",
      "tensor([-0.8828, -0.9040, -0.9008, -0.4517, -2.0283, -0.6271],\n",
      "       requires_grad=True)\n",
      "[-90.02037]\n",
      "[28.73027]\n",
      "tensor(65.4593, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.55298428 -0.43536039  0.5291487   0.95325687  0.93288214  0.59611143]\n",
      "variance_average : [0.23875805 0.08490033 0.13303119 0.25934285 0.1247459  0.23691849]\n",
      "training idx 1 actor true_reward at iteration 1050 : 38.390256764045205\n",
      "151112\n",
      "Parameter containing:\n",
      "tensor([-0.9566, -0.9917, -0.9702, -0.5543, -2.0992, -0.7105],\n",
      "       requires_grad=True)\n",
      "[-138.02237]\n",
      "[35.408848]\n",
      "tensor(92.8932, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.40600603 -0.45795338  0.4371034   0.96235828  0.97125228  0.51074694]\n",
      "variance_average : [0.17169423 0.12839023 0.14306443 0.21306626 0.05492382 0.1964336 ]\n",
      "training idx 1 actor true_reward at iteration 1060 : 48.76889830639402\n",
      "151830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-0.9997, -1.0215, -1.0232, -0.5926, -2.1186, -0.7536],\n",
      "       requires_grad=True)\n",
      "[-34.132492]\n",
      "[6.298138]\n",
      "tensor(79.4268, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.3941619  -0.68614     0.78920472  0.92521835  0.93843824  0.73512273]\n",
      "variance_average : [0.19746547 0.0688962  0.12873278 0.19073857 0.09170752 0.18983122]\n",
      "training idx 1 actor true_reward at iteration 1070 : 26.936253041215576\n",
      "152560\n",
      "Parameter containing:\n",
      "tensor([-1.0328, -1.0773, -1.0824, -0.6625, -2.1611, -0.8185],\n",
      "       requires_grad=True)\n",
      "[-180.7346]\n",
      "[64.640564]\n",
      "tensor(84.4038, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.46737753 -0.30730216  0.83066336  0.93017492  0.94463619  0.56744895]\n",
      "variance_average : [0.16777907 0.07891625 0.10698566 0.16673526 0.07844671 0.19093956]\n",
      "training idx 1 actor true_reward at iteration 1080 : 53.690993534820656\n",
      "153267\n",
      "Parameter containing:\n",
      "tensor([-1.0901, -1.1105, -1.1416, -0.7412, -2.2170, -0.8859],\n",
      "       requires_grad=True)\n",
      "[-157.97192]\n",
      "[40.938305]\n",
      "tensor(184.3321, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.65373167 -0.40975264  0.84205307  0.95147255  0.94414897  0.41745507]\n",
      "variance_average : [0.1444356  0.05702858 0.11522256 0.14135414 0.06614465 0.14804127]\n",
      "training idx 1 actor true_reward at iteration 1090 : 46.10682792686643\n",
      "154019\n",
      "Parameter containing:\n",
      "tensor([-1.1476, -1.1561, -1.1792, -0.7961, -2.2555, -0.9426],\n",
      "       requires_grad=True)\n",
      "[-159.13812]\n",
      "[57.920937]\n",
      "tensor(106.0112, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.48243908 -0.40410078  0.91673943  0.90321441  0.94600703  0.4475469 ]\n",
      "variance_average : [0.14983522 0.03761097 0.13263362 0.13012455 0.04577711 0.15250643]\n",
      "training idx 1 actor true_reward at iteration 1100 : 45.47917925417206\n",
      "154727\n",
      "Parameter containing:\n",
      "tensor([-1.1926, -1.2060, -1.2253, -0.8330, -2.3205, -1.0020],\n",
      "       requires_grad=True)\n",
      "[-98.09107]\n",
      "[27.720972]\n",
      "tensor(126.2928, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.30524967 -0.25399718  0.74652485  0.92014667  0.93654165 -0.15738359]\n",
      "variance_average : [0.18595356 0.04241168 0.09696806 0.11502233 0.04712586 0.12808829]\n",
      "training idx 1 actor true_reward at iteration 1110 : 43.58150549255393\n",
      "155459\n",
      "Parameter containing:\n",
      "tensor([-1.2014, -1.2318, -1.2367, -0.8400, -2.3272, -1.0195],\n",
      "       requires_grad=True)\n",
      "[-91.99205]\n",
      "[25.546583]\n",
      "tensor(154.4644, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.16652044 -0.36784976  0.77453426  0.95899418  0.94166087 -0.52242828]\n",
      "variance_average : [0.15088251 0.08995855 0.1124481  0.16447686 0.02762626 0.109817  ]\n",
      "training idx 1 actor true_reward at iteration 1120 : 23.06647964031473\n",
      "156149\n",
      "Parameter containing:\n",
      "tensor([-1.2430, -1.2686, -1.2826, -0.8948, -2.3744, -1.0573],\n",
      "       requires_grad=True)\n",
      "[-101.61742]\n",
      "[29.610065]\n",
      "tensor(163.0350, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.3487318  -0.40576112  0.8781245   0.92752231  0.96237709 -0.2624803 ]\n",
      "variance_average : [0.15162257 0.06178998 0.07267133 0.10568535 0.03117642 0.12495633]\n",
      "training idx 1 actor true_reward at iteration 1130 : 37.546840036569044\n",
      "156923\n",
      "Parameter containing:\n",
      "tensor([-1.2931, -1.3093, -1.3346, -0.9675, -2.4338, -1.1012],\n",
      "       requires_grad=True)\n",
      "[-92.898796]\n",
      "[26.547085]\n",
      "tensor(136.2190, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.20706667 -0.17337749  0.92497861  0.93680602  0.93320464 -0.366691  ]\n",
      "variance_average : [0.15641673 0.02611944 0.08855487 0.14291758 0.03440762 0.12540602]\n",
      "training idx 1 actor true_reward at iteration 1140 : 34.898460118631114\n",
      "157744\n",
      "Parameter containing:\n",
      "tensor([-1.3825, -1.4085, -1.4645, -1.0649, -2.5484, -1.2253],\n",
      "       requires_grad=True)\n",
      "[-270.4364]\n",
      "[69.16019]\n",
      "tensor(179.0028, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.01993441 -0.05730596  0.90852443  0.92148565  0.92420456 -0.13805689]\n",
      "variance_average : [0.13215715 0.04262621 0.07965939 0.07682452 0.08707092 0.14596488]\n",
      "training idx 1 actor true_reward at iteration 1150 : 60.911079609248326\n",
      "158626\n",
      "Parameter containing:\n",
      "tensor([-1.4615, -1.4985, -1.5411, -1.1358, -2.6297, -1.3082],\n",
      "       requires_grad=True)\n",
      "[109.73087]\n",
      "[89.45398]\n",
      "tensor(170.0368, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.27020619  0.24993381  0.95475013  0.92800121  0.92129686 -0.33074107]\n",
      "variance_average : [0.0898499  0.04377524 0.07567332 0.10766288 0.06284521 0.12372786]\n",
      "training idx 1 actor true_reward at iteration 1160 : 24.963194002325213\n",
      "159469\n",
      "Parameter containing:\n",
      "tensor([-1.4937, -1.5467, -1.5827, -1.1666, -2.6757, -1.3579],\n",
      "       requires_grad=True)\n",
      "[-193.1208]\n",
      "[26.341434]\n",
      "tensor(166.2469, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.01437934 -0.09551968  0.93583452  0.92080472  0.93780682 -0.19742695]\n",
      "variance_average : [0.14412033 0.02758768 0.13642524 0.16416167 0.06745327 0.14344679]\n",
      "training idx 1 actor true_reward at iteration 1170 : 37.97336841535747\n",
      "160197\n",
      "Parameter containing:\n",
      "tensor([-1.5647, -1.6402, -1.6533, -1.2653, -2.7697, -1.4581],\n",
      "       requires_grad=True)\n",
      "[-561.69385]\n",
      "[140.07532]\n",
      "tensor(243.8950, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.00790623 -0.05477005  0.94358735  0.94103494  0.9542503  -0.07416201]\n",
      "variance_average : [0.10051942 0.02981507 0.09040322 0.08390534 0.02556084 0.07960669]\n",
      "training idx 1 actor true_reward at iteration 1180 : 81.21426800945528\n",
      "161039\n",
      "Parameter containing:\n",
      "tensor([-1.6363, -1.7250, -1.7457, -1.3167, -2.8513, -1.5398],\n",
      "       requires_grad=True)\n",
      "[-3.8348541]\n",
      "[37.676315]\n",
      "tensor(201.0962, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.04677083  0.18014601  0.94036361  0.93993524  0.91948117 -0.32720729]\n",
      "variance_average : [0.07929376 0.04016566 0.09878004 0.07150533 0.05768461 0.08687047]\n",
      "training idx 1 actor true_reward at iteration 1190 : 30.056279744056706\n",
      "161791\n",
      "Parameter containing:\n",
      "tensor([-1.6818, -1.7650, -1.7789, -1.3603, -2.8919, -1.5811],\n",
      "       requires_grad=True)\n",
      "[-226.10468]\n",
      "[31.807314]\n",
      "tensor(284.6250, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.2052879   0.03195172  0.94482754  0.95409224  0.94915313 -0.22617602]\n",
      "variance_average : [0.05788133 0.01434341 0.06166921 0.05894596 0.0280324  0.05983342]\n",
      "training idx 1 actor true_reward at iteration 1200 : 52.10024832645995\n",
      "162582\n",
      "Parameter containing:\n",
      "tensor([-1.7686, -1.8410, -1.8489, -1.4274, -2.9577, -1.6448],\n",
      "       requires_grad=True)\n",
      "[-305.2478]\n",
      "[55.545845]\n",
      "tensor(202.6261, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.02136324  0.03938318  0.96335323  0.94093482  0.88638793 -0.10474126]\n",
      "variance_average : [0.11581327 0.02920561 0.10860733 0.06449358 0.07402557 0.06137053]\n",
      "training idx 1 actor true_reward at iteration 1210 : 50.201136896485465\n",
      "163409\n",
      "Parameter containing:\n",
      "tensor([-1.8289, -1.9056, -1.9127, -1.5029, -3.0208, -1.7043],\n",
      "       requires_grad=True)\n",
      "[-269.61755]\n",
      "[41.18109]\n",
      "tensor(236.4145, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.24323114  0.07771729  0.95052505  0.95217245  0.89881579 -0.34299961]\n",
      "variance_average : [0.06122259 0.03295736 0.05496712 0.06959301 0.07738438 0.09155825]\n",
      "training idx 1 actor true_reward at iteration 1220 : 41.169079926501794\n",
      "164271\n",
      "Parameter containing:\n",
      "tensor([-1.8975, -1.9518, -1.9717, -1.5809, -3.0733, -1.7680],\n",
      "       requires_grad=True)\n",
      "[-438.14636]\n",
      "[71.00767]\n",
      "tensor(258.2970, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.1739214   0.15670466  0.9385729   0.91032875  0.91807945 -0.21917753]\n",
      "variance_average : [0.07546118 0.02979501 0.03156493 0.06694999 0.03131579 0.08988133]\n",
      "training idx 1 actor true_reward at iteration 1230 : 58.90137004940259\n",
      "165081\n",
      "Parameter containing:\n",
      "tensor([-1.9567, -2.0087, -2.0377, -1.6523, -3.1382, -1.8255],\n",
      "       requires_grad=True)\n",
      "[-419.04404]\n",
      "[52.08291]\n",
      "tensor(273.4250, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.03218751 -0.00638517  0.96112462  0.94518369  0.9458956  -0.07337769]\n",
      "variance_average : [0.0628791  0.11499042 0.05412105 0.07226929 0.07017929 0.08217148]\n",
      "training idx 1 actor true_reward at iteration 1240 : 57.66161377746232\n",
      "165810\n",
      "Parameter containing:\n",
      "tensor([-2.0280, -2.0829, -2.1198, -1.7348, -3.2214, -1.8942],\n",
      "       requires_grad=True)\n",
      "[-73.438576]\n",
      "[22.099178]\n",
      "tensor(307.8849, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.24348091 -0.20266392  0.95344901  0.96504649  0.94542403  0.14607205]\n",
      "variance_average : [0.08283296 0.11899095 0.02495469 0.10107744 0.02232757 0.09442733]\n",
      "training idx 1 actor true_reward at iteration 1250 : 30.089026801810874\n",
      "166665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2.0606, -2.1076, -2.1627, -1.7739, -3.2561, -1.9375],\n",
      "       requires_grad=True)\n",
      "[-190.71265]\n",
      "[37.05776]\n",
      "tensor(284.4677, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.15180829  0.01970234  0.93664451  0.92526127  0.96637884 -0.11467496]\n",
      "variance_average : [0.02683883 0.09015778 0.03547935 0.08386965 0.0482011  0.08847347]\n",
      "training idx 1 actor true_reward at iteration 1260 : 35.96215646178161\n",
      "167235\n",
      "Parameter containing:\n",
      "tensor([-2.1159, -2.1591, -2.2309, -1.8522, -3.3199, -2.0080],\n",
      "       requires_grad=True)\n",
      "[-510.32803]\n",
      "[72.19861]\n",
      "tensor(349.6617, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.06982966  0.01169118  0.92300363  0.93785125  0.956848   -0.11656195]\n",
      "variance_average : [0.03190305 0.08325724 0.01849028 0.04705519 0.04156103 0.05421397]\n",
      "training idx 1 actor true_reward at iteration 1270 : 60.33564283834058\n",
      "168044\n",
      "Parameter containing:\n",
      "tensor([-2.1482, -2.1925, -2.2787, -1.8954, -3.3301, -2.0430],\n",
      "       requires_grad=True)\n",
      "[-58.907375]\n",
      "[27.391415]\n",
      "tensor(231.6290, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.06876845  0.07811963  0.96123819  0.95137963  0.88026378 -0.04812951]\n",
      "variance_average : [0.05610826 0.03631019 0.03989219 0.03867237 0.03502874 0.11843998]\n",
      "training idx 1 actor true_reward at iteration 1280 : 24.30760236840922\n",
      "168716\n",
      "Parameter containing:\n",
      "tensor([-2.1861, -2.2315, -2.3188, -1.9290, -3.3567, -2.0755],\n",
      "       requires_grad=True)\n",
      "[-1090.9705]\n",
      "[210.04605]\n",
      "tensor(461.1349, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.04128396  0.00420952  0.94771641  0.95032878  0.95009397 -0.09868526]\n",
      "variance_average : [0.05735427 0.01547184 0.02747249 0.03083054 0.03586871 0.04976101]\n",
      "training idx 1 actor true_reward at iteration 1290 : 98.93592865449446\n",
      "169445\n",
      "Parameter containing:\n",
      "tensor([-2.2393, -2.2956, -2.3856, -2.0002, -3.4155, -2.1588],\n",
      "       requires_grad=True)\n",
      "[-668.1481]\n",
      "[91.54318]\n",
      "tensor(334.1458, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.10000459 -0.07330126  0.9454225   0.94495385  0.94268635 -0.03519778]\n",
      "variance_average : [0.05046709 0.0584173  0.05391139 0.08036407 0.03521449 0.11112396]\n",
      "training idx 1 actor true_reward at iteration 1300 : 63.89959487914908\n",
      "170199\n",
      "Parameter containing:\n",
      "tensor([-2.3104, -2.3478, -2.4380, -2.0628, -3.4821, -2.2070],\n",
      "       requires_grad=True)\n",
      "[-877.9794]\n",
      "[122.97595]\n",
      "tensor(397.4748, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.07026577  0.16347253  0.9519347   0.95585854  0.93313533 -0.20441262]\n",
      "variance_average : [0.06698205 0.06934042 0.03886865 0.03324093 0.01631461 0.0290616 ]\n",
      "training idx 1 actor true_reward at iteration 1310 : 88.17479012224256\n",
      "170931\n",
      "Parameter containing:\n",
      "tensor([-2.3774, -2.4060, -2.4833, -2.1428, -3.5509, -2.2776],\n",
      "       requires_grad=True)\n",
      "[-1.0981216]\n",
      "[14.605515]\n",
      "tensor(139.5539, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.12556248  0.17119494  0.84458085  0.83730296  0.84248493 -0.15872762]\n",
      "variance_average : [0.10741253 0.0297993  0.05281734 0.06683832 0.04241502 0.07794366]\n",
      "training idx 1 actor true_reward at iteration 1320 : 28.373253010277622\n",
      "171693\n",
      "Parameter containing:\n",
      "tensor([-2.4362, -2.4561, -2.5153, -2.1799, -3.6051, -2.3272],\n",
      "       requires_grad=True)\n",
      "[-964.6464]\n",
      "[130.18802]\n",
      "tensor(458.2079, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.01432541  0.02650341  0.96378887  0.94683544  0.94798999 -0.16133562]\n",
      "variance_average : [0.03204243 0.0242231  0.0292442  0.05277489 0.03694984 0.06274192]\n",
      "training idx 1 actor true_reward at iteration 1330 : 90.83128905256945\n",
      "172468\n",
      "Parameter containing:\n",
      "tensor([-2.5064, -2.5471, -2.5650, -2.2443, -3.6522, -2.3942],\n",
      "       requires_grad=True)\n",
      "[120.0403]\n",
      "[77.237495]\n",
      "tensor(267.0018, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.28180683  0.25399576  0.93254056  0.96390216  0.89835109 -0.50090806]\n",
      "variance_average : [0.130424   0.06560138 0.04993514 0.0567291  0.09140456 0.10180092]\n",
      "training idx 1 actor true_reward at iteration 1340 : 26.148590517980068\n",
      "173298\n",
      "Parameter containing:\n",
      "tensor([-2.5480, -2.5990, -2.6029, -2.3018, -3.7067, -2.4453],\n",
      "       requires_grad=True)\n",
      "[-236.5547]\n",
      "[19.057951]\n",
      "tensor(378.7436, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.07874568  0.1776639   0.92806242  0.94318534  0.93529017 -0.22593049]\n",
      "variance_average : [0.05812991 0.01884691 0.03068793 0.02058063 0.04549644 0.06747575]\n",
      "training idx 1 actor true_reward at iteration 1350 : 40.74156449422415\n",
      "174097\n",
      "Parameter containing:\n",
      "tensor([-2.5903, -2.6241, -2.6401, -2.3288, -3.7535, -2.4775],\n",
      "       requires_grad=True)\n",
      "[-576.75775]\n",
      "[62.821873]\n",
      "tensor(507.2408, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.1527066  -0.12000412  0.93115703  0.93708928  0.95104931 -0.00704159]\n",
      "variance_average : [0.02298048 0.05179192 0.05412207 0.03435908 0.03387013 0.03012055]\n",
      "training idx 1 actor true_reward at iteration 1360 : 62.177780203612926\n",
      "174819\n",
      "Parameter containing:\n",
      "tensor([-2.6246, -2.6597, -2.6781, -2.3728, -3.7927, -2.5152],\n",
      "       requires_grad=True)\n",
      "[-44.023468]\n",
      "[18.654066]\n",
      "tensor(337.1073, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.04301622  0.12256002  0.92946436  0.92273418  0.94307084 -0.2204639 ]\n",
      "variance_average : [0.08191632 0.06352186 0.0255536  0.02829832 0.06322549 0.08833309]\n",
      "training idx 1 actor true_reward at iteration 1370 : 32.12179176171334\n",
      "175569\n",
      "Parameter containing:\n",
      "tensor([-2.6512, -2.6765, -2.7064, -2.3828, -3.8236, -2.5519],\n",
      "       requires_grad=True)\n",
      "[-648.7566]\n",
      "[71.91792]\n",
      "tensor(490.6570, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.17637417 -0.1032339   0.96083511  0.95650876  0.96763072 -0.05577422]\n",
      "variance_average : [0.03669262 0.02028991 0.01528832 0.04559371 0.0358316  0.05135992]\n",
      "training idx 1 actor true_reward at iteration 1380 : 60.42442476637568\n",
      "176209\n",
      "Parameter containing:\n",
      "tensor([-2.7455, -2.7610, -2.8172, -2.4759, -3.9340, -2.6377],\n",
      "       requires_grad=True)\n",
      "[-499.43665]\n",
      "[42.535492]\n",
      "tensor(476.7895, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.04188102  0.04401869  0.96522362  0.93216794  0.94986306 -0.09951313]\n",
      "variance_average : [0.03069359 0.0476129  0.02972656 0.06415587 0.01864903 0.03764354]\n",
      "training idx 1 actor true_reward at iteration 1390 : 57.96455697152662\n",
      "177036\n",
      "Parameter containing:\n",
      "tensor([-2.7859, -2.8038, -2.8758, -2.5252, -3.9872, -2.6822],\n",
      "       requires_grad=True)\n",
      "[-1284.1848]\n",
      "[159.45703]\n",
      "tensor(481.6089, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.27781319  0.057495    0.93781029  0.93054499  0.93803154 -0.09598709]\n",
      "variance_average : [0.01599741 0.05076044 0.01873801 0.06569936 0.01507739 0.04539088]\n",
      "training idx 1 actor true_reward at iteration 1400 : 104.02025264609887\n",
      "177758\n",
      "Parameter containing:\n",
      "tensor([-2.7984, -2.8223, -2.9040, -2.5488, -4.0097, -2.7144],\n",
      "       requires_grad=True)\n",
      "[-286.58368]\n",
      "[29.770905]\n",
      "tensor(414.1278, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.30968334 -0.29889746  0.91946851  0.91951226  0.93057107  0.14740632]\n",
      "variance_average : [0.04152613 0.10669226 0.1111848  0.02284998 0.08053135 0.10036089]\n",
      "training idx 1 actor true_reward at iteration 1410 : 37.8498052096795\n",
      "178392\n",
      "Parameter containing:\n",
      "tensor([-2.8261, -2.8634, -2.9640, -2.5818, -4.0501, -2.7551],\n",
      "       requires_grad=True)\n",
      "[-1318.0682]\n",
      "[166.66652]\n",
      "tensor(528.7979, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.08637093 -0.05501864  0.94170118  0.94540189  0.91661536 -0.02488945]\n",
      "variance_average : [0.02187058 0.03262642 0.01185286 0.02119216 0.03667    0.07238423]\n",
      "training idx 1 actor true_reward at iteration 1420 : 93.18883343970899\n",
      "179142\n",
      "Parameter containing:\n",
      "tensor([-2.8926, -2.9203, -3.0148, -2.6489, -4.1145, -2.8204],\n",
      "       requires_grad=True)\n",
      "[-577.35315]\n",
      "[66.64908]\n",
      "tensor(480.2109, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.12028402 -0.13506751  0.91927407  0.95470529  0.92583265  0.06992951]\n",
      "variance_average : [0.04742296 0.03022573 0.03213028 0.0900684  0.03645579 0.04187863]\n",
      "training idx 1 actor true_reward at iteration 1430 : 53.25042806984259\n",
      "179974\n",
      "Parameter containing:\n",
      "tensor([-2.9650, -2.9823, -3.1037, -2.7280, -4.1679, -2.9020],\n",
      "       requires_grad=True)\n",
      "[-816.12726]\n",
      "[82.44367]\n",
      "tensor(611.2324, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.08010871 -0.02102263  0.96511657  0.94302122  0.94915054 -0.01325048]\n",
      "variance_average : [0.03245169 0.02816635 0.02065663 0.03873051 0.01538619 0.02279805]\n",
      "training idx 1 actor true_reward at iteration 1440 : 74.41947908699318\n",
      "180839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-2.9912, -2.9969, -3.1191, -2.7524, -4.1893, -2.9214],\n",
      "       requires_grad=True)\n",
      "[-429.46942]\n",
      "[43.203957]\n",
      "tensor(481.1483, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.27731289 -0.28342827  0.92935206  0.94695425  0.9406302   0.22990466]\n",
      "variance_average : [0.03527525 0.01890061 0.01741951 0.07761125 0.04019619 0.03670125]\n",
      "training idx 1 actor true_reward at iteration 1450 : 49.39080354802566\n",
      "181545\n",
      "Parameter containing:\n",
      "tensor([-3.0220, -3.0230, -3.1484, -2.7725, -4.2283, -2.9419],\n",
      "       requires_grad=True)\n",
      "[-1349.0933]\n",
      "[167.08998]\n",
      "tensor(425.2323, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.36113024 -0.42359512  0.94610922  0.90692555  0.91387551  0.11425107]\n",
      "variance_average : [0.06309099 0.06566807 0.0893537  0.08315401 0.08546001 0.05181623]\n",
      "training idx 1 actor true_reward at iteration 1460 : 72.88707959732471\n",
      "182218\n",
      "Parameter containing:\n",
      "tensor([-3.0862, -3.0950, -3.2233, -2.8538, -4.2923, -3.0259],\n",
      "       requires_grad=True)\n",
      "[-1304.185]\n",
      "[132.88245]\n",
      "tensor(586.6674, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.07187427 -0.06980143  0.94320216  0.94516331  0.95835227  0.04224934]\n",
      "variance_average : [0.02399246 0.07162179 0.05771183 0.01779801 0.01030389 0.0216067 ]\n",
      "training idx 1 actor true_reward at iteration 1470 : 88.82961343509515\n",
      "183004\n",
      "Parameter containing:\n",
      "tensor([-3.1226, -3.1465, -3.2781, -2.9080, -4.3386, -3.0813],\n",
      "       requires_grad=True)\n",
      "[-825.25854]\n",
      "[101.73918]\n",
      "tensor(416.6729, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.43952666 -0.42166521  0.93269317  0.93870567  0.92769359  0.36037845]\n",
      "variance_average : [0.03597649 0.01723769 0.07672094 0.1276618  0.01481714 0.01834934]\n",
      "training idx 1 actor true_reward at iteration 1480 : 60.39082085998363\n",
      "183784\n",
      "Parameter containing:\n",
      "tensor([-3.2033, -3.2127, -3.3511, -2.9782, -4.3903, -3.1543],\n",
      "       requires_grad=True)\n",
      "[-1500.4236]\n",
      "[179.3726]\n",
      "tensor(586.5899, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.16480644 -0.10450808  0.93687676  0.94155801  0.96365067  0.01504952]\n",
      "variance_average : [0.01375977 0.05349273 0.0918171  0.06780472 0.03684333 0.05568421]\n",
      "training idx 1 actor true_reward at iteration 1490 : 99.59361126791502\n",
      "184614\n",
      "Parameter containing:\n",
      "tensor([-3.2260, -3.2401, -3.3649, -2.9986, -4.4095, -3.1846],\n",
      "       requires_grad=True)\n",
      "[-117.65959]\n",
      "[32.670845]\n",
      "tensor(480.6787, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.30891894 -0.21027945  0.95369896  0.9285851   0.929711    0.06280976]\n",
      "variance_average : [0.01721863 0.02480867 0.05323272 0.04018658 0.05330993 0.07197254]\n",
      "training idx 1 actor true_reward at iteration 1500 : 32.0880702561335\n",
      "185612\n",
      "Parameter containing:\n",
      "tensor([-3.2703, -3.2680, -3.4059, -3.0426, -4.4415, -3.2208],\n",
      "       requires_grad=True)\n",
      "[-1015.1467]\n",
      "[87.803734]\n",
      "tensor(463.3401, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.36778627 -0.35987313  0.90795127  0.961144    0.92272729  0.2517949 ]\n",
      "variance_average : [0.08320752 0.1145819  0.02673087 0.03350336 0.04452466 0.05593447]\n",
      "training idx 1 actor true_reward at iteration 1510 : 69.24508500436808\n",
      "186314\n",
      "Parameter containing:\n",
      "tensor([-3.2905, -3.2969, -3.4337, -3.0784, -4.4666, -3.2481],\n",
      "       requires_grad=True)\n",
      "[337.89243]\n",
      "[75.18193]\n",
      "tensor(516.9409, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.28981442 -0.29632533  0.93681411  0.94796335  0.95835071  0.18935188]\n",
      "variance_average : [0.0226156  0.00920799 0.03327347 0.02614668 0.0726227  0.08859561]\n",
      "training idx 1 actor true_reward at iteration 1520 : 7.520407623514322\n",
      "187025\n",
      "Parameter containing:\n",
      "tensor([-3.3167, -3.3260, -3.4589, -3.1109, -4.4939, -3.2734],\n",
      "       requires_grad=True)\n",
      "[-1076.7092]\n",
      "[93.007]\n",
      "tensor(505.7214, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.47491525 -0.47717934  0.94680279  0.96691262  0.92770223  0.45723833]\n",
      "variance_average : [0.09580647 0.02952653 0.04779296 0.01121166 0.01669068 0.05726558]\n",
      "training idx 1 actor true_reward at iteration 1530 : 76.39360660235626\n",
      "188036\n",
      "Parameter containing:\n",
      "tensor([-3.3940, -3.3822, -3.5442, -3.1821, -4.5671, -3.3369],\n",
      "       requires_grad=True)\n",
      "[-389.40045]\n",
      "[22.596216]\n",
      "tensor(449.2971, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.47194195 -0.40913011  0.91685378  0.90831971  0.91181244  0.43361583]\n",
      "variance_average : [0.11763185 0.06161294 0.04486048 0.07915008 0.02043399 0.06213884]\n",
      "training idx 1 actor true_reward at iteration 1540 : 51.0017550155551\n",
      "188847\n",
      "Parameter containing:\n",
      "tensor([-3.4315, -3.4187, -3.5772, -3.2160, -4.6102, -3.3941],\n",
      "       requires_grad=True)\n",
      "[-566.3843]\n",
      "[78.52337]\n",
      "tensor(519.3066, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.13653027 -0.14036574  0.92596084  0.93094971  0.94228048  0.11752512]\n",
      "variance_average : [0.01861549 0.01915246 0.0327692  0.04807483 0.013951   0.06827585]\n",
      "training idx 1 actor true_reward at iteration 1550 : 59.03306797034308\n",
      "189652\n",
      "Parameter containing:\n",
      "tensor([-3.4707, -3.4433, -3.6100, -3.2573, -4.6478, -3.4171],\n",
      "       requires_grad=True)\n",
      "[-486.6203]\n",
      "[31.54275]\n",
      "tensor(612.4692, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.3067055  -0.22812204  0.93019742  0.94365361  0.9373879   0.18185764]\n",
      "variance_average : [0.0911596  0.07626869 0.0118935  0.0151135  0.03990376 0.02819728]\n",
      "training idx 1 actor true_reward at iteration 1560 : 55.89343185908325\n",
      "190507\n",
      "Parameter containing:\n",
      "tensor([-3.5038, -3.4637, -3.6516, -3.3013, -4.6730, -3.4616],\n",
      "       requires_grad=True)\n",
      "[-172.02371]\n",
      "[24.77346]\n",
      "tensor(491.5743, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.40917157 -0.2851469   0.95157385  0.95687988  0.9263355   0.20137721]\n",
      "variance_average : [0.04650729 0.02449346 0.04301046 0.07671278 0.02768049 0.01206429]\n",
      "training idx 1 actor true_reward at iteration 1570 : 41.507452147382885\n",
      "191306\n",
      "Parameter containing:\n",
      "tensor([-3.5197, -3.4752, -3.6779, -3.3308, -4.6814, -3.4904],\n",
      "       requires_grad=True)\n",
      "[-999.68414]\n",
      "[106.67444]\n",
      "tensor(620.1646, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.27815521 -0.22509456  0.94191043  0.94307409  0.94482736  0.19126637]\n",
      "variance_average : [0.05710414 0.09590324 0.01541491 0.0166659  0.02819183 0.0397926 ]\n",
      "training idx 1 actor true_reward at iteration 1580 : 77.30463834955806\n",
      "192007\n",
      "Parameter containing:\n",
      "tensor([-3.5605, -3.5291, -3.7253, -3.3685, -4.7229, -3.5542],\n",
      "       requires_grad=True)\n",
      "[56.55202]\n",
      "[25.123476]\n",
      "tensor(430.0145, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.11058163  0.00292787  0.93276349  0.89309222  0.90783246 -0.11195484]\n",
      "variance_average : [0.13923624 0.03772799 0.10735366 0.10489727 0.04065587 0.06252072]\n",
      "training idx 1 actor true_reward at iteration 1590 : 33.791713190408345\n",
      "192719\n",
      "Parameter containing:\n",
      "tensor([-3.6163, -3.5579, -3.7725, -3.4064, -4.7548, -3.6162],\n",
      "       requires_grad=True)\n",
      "[169.26509]\n",
      "[59.183365]\n",
      "tensor(349.8702, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.08632613  0.16874906  0.91322073  0.90459121  0.92263958 -0.21662293]\n",
      "variance_average : [0.09897298 0.05049718 0.08981326 0.11515077 0.01735683 0.034265  ]\n",
      "training idx 1 actor true_reward at iteration 1600 : 27.40576610739567\n",
      "193427\n",
      "Parameter containing:\n",
      "tensor([-3.6347, -3.5696, -3.7949, -3.4208, -4.7779, -3.6356],\n",
      "       requires_grad=True)\n",
      "[-1471.8132]\n",
      "[157.99736]\n",
      "tensor(625.2241, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.14145028 -0.02445553  0.97387866  0.92906862  0.9255023  -0.03608826]\n",
      "variance_average : [0.06212483 0.04036044 0.02647433 0.03576828 0.09068808 0.03789035]\n",
      "training idx 1 actor true_reward at iteration 1610 : 93.68909442406019\n",
      "194087\n",
      "Parameter containing:\n",
      "tensor([-3.6522, -3.5658, -3.8093, -3.4358, -4.7841, -3.6397],\n",
      "       requires_grad=True)\n",
      "[-102.73897]\n",
      "[25.469227]\n",
      "tensor(527.5946, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.24776831 -0.12245517  0.92411671  0.93736326  0.93883001  0.06208742]\n",
      "variance_average : [0.01714748 0.07376314 0.02227423 0.01368207 0.06307225 0.0880521 ]\n",
      "training idx 1 actor true_reward at iteration 1620 : 30.588720698158212\n",
      "194660\n",
      "Parameter containing:\n",
      "tensor([-3.6649, -3.5709, -3.8270, -3.4730, -4.8038, -3.6534],\n",
      "       requires_grad=True)\n",
      "[-2499.3826]\n",
      "[308.2986]\n",
      "tensor(777.2250, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.26501953 -0.03985505  0.98672381  0.9481975   0.93080894 -0.03806674]\n",
      "variance_average : [0.0282505  0.01538096 0.01628833 0.03252464 0.06279979 0.0135288 ]\n",
      "training idx 1 actor true_reward at iteration 1630 : 122.08459900892487\n",
      "195234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-3.7318, -3.6371, -3.8836, -3.5364, -4.8561, -3.7235],\n",
      "       requires_grad=True)\n",
      "[-292.6057]\n",
      "[12.248863]\n",
      "tensor(359.1254, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.32580261 -0.03274204  0.91290902  0.86678347  0.96124483 -0.09363436]\n",
      "variance_average : [0.07299945 0.04446769 0.0358573  0.07197778 0.03411068 0.02272595]\n",
      "training idx 1 actor true_reward at iteration 1640 : 34.60474483959316\n",
      "195955\n",
      "Parameter containing:\n",
      "tensor([-3.7630, -3.6766, -3.9125, -3.5623, -4.8876, -3.7539],\n",
      "       requires_grad=True)\n",
      "[116.23813]\n",
      "[11.722885]\n",
      "tensor(356.8069, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.52511916 -0.02200185  0.89273555  0.89782931  0.89208542 -0.14161058]\n",
      "variance_average : [0.03331566 0.12005147 0.06603611 0.13313454 0.09796351 0.12966883]\n",
      "training idx 1 actor true_reward at iteration 1650 : 18.80323446040337\n",
      "196615\n",
      "Parameter containing:\n",
      "tensor([-3.8179, -3.7053, -3.9554, -3.6238, -4.9300, -3.7921],\n",
      "       requires_grad=True)\n",
      "[-667.44617]\n",
      "[35.95799]\n",
      "tensor(445.9190, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.33336451 -0.20760937  0.91048894  0.92430977  0.90314125  0.20113836]\n",
      "variance_average : [0.04774407 0.0743087  0.01860782 0.04223523 0.02963293 0.05208619]\n",
      "training idx 1 actor true_reward at iteration 1660 : 49.392269739710954\n",
      "197324\n",
      "Parameter containing:\n",
      "tensor([-3.8560, -3.7327, -4.0012, -3.6576, -4.9622, -3.8343],\n",
      "       requires_grad=True)\n",
      "[-1644.4019]\n",
      "[162.37538]\n",
      "tensor(778.3201, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.15796332 -0.17290685  0.96267533  0.93560514  0.94830583  0.14104313]\n",
      "variance_average : [0.02564071 0.04187284 0.04566931 0.01632535 0.03691854 0.03400001]\n",
      "training idx 1 actor true_reward at iteration 1670 : 92.89758305859952\n",
      "198040\n",
      "Parameter containing:\n",
      "tensor([-3.9504, -3.8115, -4.0912, -3.7511, -5.0444, -3.9401],\n",
      "       requires_grad=True)\n",
      "[453.04288]\n",
      "[45.271393]\n",
      "tensor(522.7626, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.40599511 -0.2248724   0.92748183  0.93281824  0.94566645  0.1835382 ]\n",
      "variance_average : [0.07854476 0.06704382 0.02035018 0.01852387 0.03691827 0.01869877]\n",
      "training idx 1 actor true_reward at iteration 1680 : 7.877893135284949\n",
      "198917\n",
      "Parameter containing:\n",
      "tensor([-4.0040, -3.8415, -4.1338, -3.7855, -5.0835, -3.9900],\n",
      "       requires_grad=True)\n",
      "[-368.18143]\n",
      "[46.894947]\n",
      "tensor(467.6144, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.15384826  0.0184542   0.92519454  0.91949417  0.93296315 -0.02126857]\n",
      "variance_average : [0.06927375 0.03493799 0.05204244 0.08580074 0.10215439 0.05417649]\n",
      "training idx 1 actor true_reward at iteration 1690 : 49.384992988949364\n",
      "199687\n",
      "Parameter containing:\n",
      "tensor([-4.0614, -3.8845, -4.1670, -3.8334, -5.1096, -4.0244],\n",
      "       requires_grad=True)\n",
      "[736.65985]\n",
      "[337.1804]\n",
      "tensor(104.3165, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.66374665  0.71350932  0.84575839  0.6854269   0.76508564 -0.7513732 ]\n",
      "variance_average : [0.08277674 0.09677212 0.13493837 0.10757575 0.14977833 0.09955176]\n",
      "training idx 1 actor true_reward at iteration 1700 : -7.1422881802828035\n",
      "200311\n",
      "Parameter containing:\n",
      "tensor([-4.1063, -3.9096, -4.2075, -3.9033, -5.1464, -4.0782],\n",
      "       requires_grad=True)\n",
      "[-907.6558]\n",
      "[103.405136]\n",
      "tensor(659.7573, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.0796452   0.03766539  0.94010759  0.92428673  0.97676351 -0.0709016 ]\n",
      "variance_average : [0.07746324 0.08048871 0.09254089 0.0218909  0.0597684  0.07084751]\n",
      "training idx 1 actor true_reward at iteration 1710 : 50.714123191194155\n",
      "201071\n",
      "Parameter containing:\n",
      "tensor([-4.1673, -3.9568, -4.2627, -3.9602, -5.1862, -4.1149],\n",
      "       requires_grad=True)\n",
      "[-2309.6829]\n",
      "[245.92801]\n",
      "tensor(831.7579, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.19563802 -0.12962047  0.94496593  0.95955032  0.96651904  0.10142749]\n",
      "variance_average : [0.03936723 0.06946293 0.02312504 0.03034994 0.0178018  0.02589791]\n",
      "training idx 1 actor true_reward at iteration 1720 : 112.18389631039695\n",
      "201796\n",
      "Parameter containing:\n",
      "tensor([-4.2357, -4.0078, -4.3263, -4.0215, -5.2253, -4.1808],\n",
      "       requires_grad=True)\n",
      "[-1265.4763]\n",
      "[94.71661]\n",
      "tensor(694.3333, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.06478963 -0.04430864  0.93366855  0.94704082  0.92988112 -0.03126037]\n",
      "variance_average : [0.02829507 0.03512105 0.0152806  0.04535921 0.04575437 0.02938045]\n",
      "training idx 1 actor true_reward at iteration 1730 : 75.42767312908165\n",
      "202608\n",
      "Parameter containing:\n",
      "tensor([-4.3030, -4.0696, -4.3736, -4.0995, -5.2847, -4.2521],\n",
      "       requires_grad=True)\n",
      "[-1128.5135]\n",
      "[74.092476]\n",
      "tensor(633.5349, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.08367546  0.12356217  0.95370309  0.94579237  0.93704895 -0.14228901]\n",
      "variance_average : [0.02471055 0.01899024 0.0487949  0.03177571 0.0400363  0.02605803]\n",
      "training idx 1 actor true_reward at iteration 1740 : 81.13611575146817\n",
      "203474\n",
      "Parameter containing:\n",
      "tensor([-4.3642, -4.0996, -4.4220, -4.1508, -5.3285, -4.3010],\n",
      "       requires_grad=True)\n",
      "[-1742.8495]\n",
      "[120.70071]\n",
      "tensor(816.7303, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.0343419  -0.02103535  0.95595327  0.94658476  0.96047855  0.00810259]\n",
      "variance_average : [0.04589237 0.04008091 0.02270148 0.02741274 0.01593687 0.03760284]\n",
      "training idx 1 actor true_reward at iteration 1750 : 106.37493566674819\n",
      "204315\n",
      "Parameter containing:\n",
      "tensor([-4.4043, -4.1438, -4.4709, -4.2005, -5.3633, -4.3405],\n",
      "       requires_grad=True)\n",
      "[657.9412]\n",
      "[61.98746]\n",
      "tensor(549.5900, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.27197092 -0.03919707  0.93450086  0.94083983  0.93090418  0.03493221]\n",
      "variance_average : [0.01899129 0.04546721 0.04438028 0.0374135  0.02183348 0.02842502]\n",
      "training idx 1 actor true_reward at iteration 1760 : 9.976997599089163\n",
      "205172\n",
      "Parameter containing:\n",
      "tensor([-4.4441, -4.1725, -4.5015, -4.2461, -5.3901, -4.3775],\n",
      "       requires_grad=True)\n",
      "[-28.486584]\n",
      "[30.08125]\n",
      "tensor(269.1266, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.11775805  0.35925673  0.8097587   0.90686479  0.90175572 -0.06978928]\n",
      "variance_average : [0.13799809 0.08597196 0.05787536 0.10880971 0.14485387 0.13453846]\n",
      "training idx 1 actor true_reward at iteration 1770 : 28.119584102852127\n",
      "205867\n",
      "Parameter containing:\n",
      "tensor([-4.4724, -4.1921, -4.5366, -4.2714, -5.4093, -4.4095],\n",
      "       requires_grad=True)\n",
      "[416.81824]\n",
      "[101.32358]\n",
      "tensor(640.2368, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.05830255  0.24080741  0.91377758  0.95745312  0.9481184  -0.27517508]\n",
      "variance_average : [0.06995917 0.01225755 0.02112301 0.06685206 0.06150351 0.02536344]\n",
      "training idx 1 actor true_reward at iteration 1780 : 20.743344833053794\n",
      "206517\n",
      "Parameter containing:\n",
      "tensor([-4.5133, -4.2166, -4.5636, -4.3057, -5.4310, -4.4444],\n",
      "       requires_grad=True)\n",
      "[-1679.2156]\n",
      "[141.37036]\n",
      "tensor(718.6226, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.10199386  0.01021705  0.92494747  0.94135557  0.95467133 -0.10656916]\n",
      "variance_average : [0.01479172 0.02667343 0.04351162 0.01629584 0.048215   0.01685042]\n",
      "training idx 1 actor true_reward at iteration 1790 : 96.89753288393163\n",
      "207241\n",
      "Parameter containing:\n",
      "tensor([-4.5328, -4.2461, -4.5898, -4.3425, -5.4668, -4.4727],\n",
      "       requires_grad=True)\n",
      "[-160.74956]\n",
      "[21.908667]\n",
      "tensor(488.6722, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.08491892  0.13916269  0.9481146   0.9091808   0.9010574  -0.17804194]\n",
      "variance_average : [0.07470183 0.01568251 0.0817353  0.01232238 0.05109037 0.01574493]\n",
      "training idx 1 actor true_reward at iteration 1800 : 41.04675344835592\n",
      "207978\n",
      "Parameter containing:\n",
      "tensor([-4.5506, -4.2608, -4.6103, -4.3568, -5.4750, -4.4853],\n",
      "       requires_grad=True)\n",
      "[494.67737]\n",
      "[288.78122]\n",
      "tensor(84.3737, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.67235383  0.73167721  0.66589666  0.71110908  0.50024693 -0.86882307]\n",
      "variance_average : [0.12734399 0.23173961 0.40972713 0.51053751 0.28040847 0.20270211]\n",
      "training idx 1 actor true_reward at iteration 1810 : -8.38762420954937\n",
      "208564\n",
      "Parameter containing:\n",
      "tensor([-4.5764, -4.2930, -4.6398, -4.3928, -5.4928, -4.5273],\n",
      "       requires_grad=True)\n",
      "[-1494.8733]\n",
      "[130.62572]\n",
      "tensor(595.9991, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.26281924 -0.08845132  0.93114689  0.91518039  0.94807686  0.17363555]\n",
      "variance_average : [0.02243006 0.03939666 0.01869657 0.0105414  0.11040892 0.02261877]\n",
      "training idx 1 actor true_reward at iteration 1820 : 78.49922063603941\n",
      "209289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-4.6008, -4.3185, -4.6709, -4.4115, -5.5250, -4.5667],\n",
      "       requires_grad=True)\n",
      "[-594.7101]\n",
      "[28.722557]\n",
      "tensor(554.6840, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.0278809   0.16113187  0.91256113  0.92326817  0.93198385 -0.01137404]\n",
      "variance_average : [0.07057072 0.02905189 0.07959384 0.02982702 0.04391573 0.05068494]\n",
      "training idx 1 actor true_reward at iteration 1830 : 47.31266623462425\n",
      "209971\n",
      "Parameter containing:\n",
      "tensor([-4.6473, -4.3518, -4.7051, -4.4482, -5.5610, -4.6037],\n",
      "       requires_grad=True)\n",
      "[-1959.6967]\n",
      "[142.47014]\n",
      "tensor(712.2760, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.00659506  0.01339958  0.93828724  0.94600003  0.94437478 -0.01501035]\n",
      "variance_average : [0.01198002 0.03318881 0.02446619 0.03039054 0.01271089 0.01680256]\n",
      "training idx 1 actor true_reward at iteration 1840 : 98.19020536909026\n",
      "210685\n",
      "Parameter containing:\n",
      "tensor([-4.6962, -4.3886, -4.7396, -4.4947, -5.5970, -4.6396],\n",
      "       requires_grad=True)\n",
      "[-365.5966]\n",
      "[27.606895]\n",
      "tensor(525.3841, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.19378298 -0.20084084  0.91542814  0.937914    0.91739968  0.13769198]\n",
      "variance_average : [0.06468847 0.10900713 0.02456984 0.01529695 0.10332895 0.01280066]\n",
      "training idx 1 actor true_reward at iteration 1850 : 42.072058598581584\n",
      "211474\n",
      "Parameter containing:\n",
      "tensor([-4.7675, -4.4395, -4.7953, -4.5534, -5.6522, -4.7115],\n",
      "       requires_grad=True)\n",
      "[-1525.7416]\n",
      "[136.02829]\n",
      "tensor(725.9838, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.06647458  0.04217166  0.9442543   0.93801058  0.94071877 -0.18377645]\n",
      "variance_average : [0.0436893  0.01245129 0.01940744 0.01703734 0.02398676 0.06798908]\n",
      "training idx 1 actor true_reward at iteration 1860 : 99.5657757464185\n",
      "212402\n",
      "Parameter containing:\n",
      "tensor([-4.8056, -4.4712, -4.8389, -4.5881, -5.6888, -4.7425],\n",
      "       requires_grad=True)\n",
      "[-631.52325]\n",
      "[76.28915]\n",
      "tensor(508.1625, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.22999154  0.35957219  0.9663723   0.91213548  0.9222454  -0.26213489]\n",
      "variance_average : [0.08697702 0.0968201  0.04215868 0.02098945 0.03776413 0.09123791]\n",
      "training idx 1 actor true_reward at iteration 1870 : 56.81884166972469\n",
      "213258\n",
      "Parameter containing:\n",
      "tensor([-4.8452, -4.4960, -4.8568, -4.6121, -5.7195, -4.7744],\n",
      "       requires_grad=True)\n",
      "[-273.33154]\n",
      "[16.467533]\n",
      "tensor(462.4439, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.18834007  0.3295219   0.89434381  0.93756418  0.96073289 -0.14012311]\n",
      "variance_average : [0.03238902 0.08909977 0.05051255 0.04589827 0.04998472 0.08506366]\n",
      "training idx 1 actor true_reward at iteration 1880 : 45.348890948008254\n",
      "214034\n",
      "Parameter containing:\n",
      "tensor([-4.8807, -4.5190, -4.8782, -4.6456, -5.7409, -4.8029],\n",
      "       requires_grad=True)\n",
      "[-125.20116]\n",
      "[11.439075]\n",
      "tensor(526.3051, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.09651898 -0.04631696  0.90406538  0.94026534  0.91787863  0.10301661]\n",
      "variance_average : [0.02175296 0.03899561 0.01702878 0.02192979 0.06087746 0.07193841]\n",
      "training idx 1 actor true_reward at iteration 1890 : 39.773021513535404\n",
      "214793\n",
      "Parameter containing:\n",
      "tensor([-4.9047, -4.5335, -4.8906, -4.6735, -5.7431, -4.8261],\n",
      "       requires_grad=True)\n",
      "[-1553.0924]\n",
      "[144.87903]\n",
      "tensor(730.7885, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.17418252  0.166974    0.95728925  0.95335505  0.94261031 -0.15856196]\n",
      "variance_average : [0.02534896 0.06529778 0.02931916 0.04617435 0.05558799 0.03904894]\n",
      "training idx 1 actor true_reward at iteration 1900 : 76.72160256409508\n",
      "215456\n",
      "Parameter containing:\n",
      "tensor([-4.9664, -4.5708, -4.9561, -4.7322, -5.7955, -4.8850],\n",
      "       requires_grad=True)\n",
      "[-1325.7422]\n",
      "[81.061035]\n",
      "tensor(654.9143, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.17306853  0.12840278  0.9554764   0.946857    0.94536076 -0.21228697]\n",
      "variance_average : [0.01237501 0.04468986 0.05966476 0.04420901 0.04298721 0.05252621]\n",
      "training idx 1 actor true_reward at iteration 1910 : 74.2825916162778\n",
      "216325\n",
      "Parameter containing:\n",
      "tensor([-5.0088, -4.6092, -5.0059, -4.7975, -5.8316, -4.9309],\n",
      "       requires_grad=True)\n",
      "[-1378.149]\n",
      "[79.02482]\n",
      "tensor(817.1997, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.16673917  0.19867336  0.88412343  0.96285265  0.93926435 -0.20261129]\n",
      "variance_average : [0.01542875 0.01910529 0.06775619 0.02855342 0.02939904 0.02529781]\n",
      "training idx 1 actor true_reward at iteration 1920 : 84.73520184521057\n",
      "217177\n",
      "Parameter containing:\n",
      "tensor([-5.0341, -4.6303, -5.0415, -4.8197, -5.8457, -4.9600],\n",
      "       requires_grad=True)\n",
      "[394.8146]\n",
      "[29.952145]\n",
      "tensor(518.3040, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.15649846  0.14782477  0.27396576  0.92663902  0.93817251 -0.53987831]\n",
      "variance_average : [0.06298254 0.04423952 0.04782343 0.01490219 0.02573698 0.04003099]\n",
      "training idx 1 actor true_reward at iteration 1930 : 13.871019746733547\n",
      "217941\n",
      "Parameter containing:\n",
      "tensor([-5.0276, -4.6363, -5.0518, -4.8212, -5.8536, -4.9650],\n",
      "       requires_grad=True)\n",
      "[-427.61188]\n",
      "[42.53625]\n",
      "tensor(1009.7471, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.05317737  0.07621516  0.0495884   0.96050818  0.95401442 -0.09689009]\n",
      "variance_average : [0.01967801 0.02222833 0.01463684 0.01442689 0.01678577 0.06011708]\n",
      "training idx 1 actor true_reward at iteration 1940 : 48.34627185278615\n",
      "218735\n",
      "Parameter containing:\n",
      "tensor([-5.0361, -4.6367, -5.0551, -4.8331, -5.8439, -4.9669],\n",
      "       requires_grad=True)\n",
      "[-1135.3049]\n",
      "[92.81002]\n",
      "tensor(716.6489, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.05027669 -0.0180529  -0.04203588  0.9386298   0.94900634 -0.00531331]\n",
      "variance_average : [0.07236216 0.02726303 0.03165659 0.03899808 0.03612321 0.01809896]\n",
      "training idx 1 actor true_reward at iteration 1950 : 56.96351274608804\n",
      "219453\n",
      "Parameter containing:\n",
      "tensor([-5.0437, -4.6349, -5.0625, -4.8440, -5.8511, -4.9812],\n",
      "       requires_grad=True)\n",
      "[-315.1261]\n",
      "[23.900183]\n",
      "tensor(470.6505, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.07159417  0.10578648  0.12840325  0.90842274  0.93071303 -0.20130133]\n",
      "variance_average : [0.07404982 0.03554068 0.05115289 0.05099902 0.02381534 0.09474902]\n",
      "training idx 1 actor true_reward at iteration 1960 : 31.023221425838592\n",
      "220267\n",
      "Parameter containing:\n",
      "tensor([-5.0556, -4.6323, -5.0690, -4.8583, -5.8604, -4.9884],\n",
      "       requires_grad=True)\n",
      "[180.7273]\n",
      "[14.048901]\n",
      "tensor(400.6711, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.02378497  0.1026092   0.11264731  0.91097653  0.8989888  -0.17443425]\n",
      "variance_average : [0.04498991 0.11522688 0.08729065 0.10497127 0.03361957 0.04988203]\n",
      "training idx 1 actor true_reward at iteration 1970 : 15.369329923413215\n",
      "221189\n",
      "Parameter containing:\n",
      "tensor([-5.0646, -4.6185, -5.0581, -4.8389, -5.8517, -4.9827],\n",
      "       requires_grad=True)\n",
      "[-306.9171]\n",
      "[25.3707]\n",
      "tensor(735.0779, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.0830125   0.0825452   0.00908086  0.94643753  0.96908726 -0.1546989 ]\n",
      "variance_average : [0.02295096 0.01275242 0.04003462 0.0180619  0.00905248 0.03551169]\n",
      "training idx 1 actor true_reward at iteration 1980 : 26.28161828163092\n",
      "221865\n",
      "Parameter containing:\n",
      "tensor([-5.0846, -4.6494, -5.0799, -4.8712, -5.8658, -5.0098],\n",
      "       requires_grad=True)\n",
      "[-431.10614]\n",
      "[18.351006]\n",
      "tensor(442.5237, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.04903523 -0.05581351 -0.07972405  0.92221872  0.89754847  0.03855386]\n",
      "variance_average : [0.03092286 0.04630179 0.05467879 0.0329186  0.03116628 0.02023396]\n",
      "training idx 1 actor true_reward at iteration 1990 : 31.796599410702548\n",
      "222686\n",
      "Parameter containing:\n",
      "tensor([-5.0803, -4.6479, -5.0798, -4.8670, -5.8807, -5.0166],\n",
      "       requires_grad=True)\n",
      "[1.9864998]\n",
      "[21.771923]\n",
      "tensor(635.5079, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 4.78477282e-02 -6.56134382e-02 -9.21912117e-01  9.43231819e-01\n",
      "  9.48654968e-01 -4.76976264e-04]\n",
      "variance_average : [0.00855452 0.01807679 0.00944155 0.07910745 0.02551154 0.03582189]\n",
      "training idx 1 actor true_reward at iteration 2000 : 15.486199734466409\n",
      "223586\n",
      "Parameter containing:\n",
      "tensor([-5.0735, -4.6377, -5.0659, -4.8623, -5.8670, -5.0127],\n",
      "       requires_grad=True)\n",
      "[158.20392]\n",
      "[24.532085]\n",
      "tensor(354.5518, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.2748     -0.2899618  -0.8824626   0.94063745  0.91144463  0.23418923]\n",
      "variance_average : [0.04433917 0.17191642 0.04769083 0.07477404 0.06084267 0.09111065]\n",
      "training idx 1 actor true_reward at iteration 2010 : 5.997329257469306\n",
      "224427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.0738, -4.6467, -5.0573, -4.8639, -5.8482, -4.9962],\n",
      "       requires_grad=True)\n",
      "[470.84558]\n",
      "[19.5221]\n",
      "tensor(648.7816, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.01526804  0.04976205 -0.93179688  0.94428051  0.92215286  0.0096568 ]\n",
      "variance_average : [0.03752713 0.06778697 0.04429723 0.02799145 0.02048699 0.01153299]\n",
      "training idx 1 actor true_reward at iteration 2020 : -2.0418784345817595\n",
      "225228\n",
      "Parameter containing:\n",
      "tensor([-5.0670, -4.6339, -5.0554, -4.8551, -5.8406, -4.9851],\n",
      "       requires_grad=True)\n",
      "[-15.6204605]\n",
      "[14.1988125]\n",
      "tensor(455.6952, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.05636508 -0.03650263 -0.92377754  0.93383747  0.93488667 -0.04869874]\n",
      "variance_average : [0.06398556 0.05247919 0.05949705 0.04246959 0.05627847 0.02549142]\n",
      "training idx 1 actor true_reward at iteration 2030 : 14.659758067771167\n",
      "226021\n",
      "Parameter containing:\n",
      "tensor([-5.0615, -4.6132, -5.0565, -4.8483, -5.8196, -4.9829],\n",
      "       requires_grad=True)\n",
      "[-161.11734]\n",
      "[12.873298]\n",
      "tensor(526.4393, grad_fn=<AddBackward0>)\n",
      "mean_average : [-2.06144818e-02  2.63886318e-02 -9.36082620e-01  9.53399488e-01\n",
      "  9.19034552e-01  2.84229732e-04]\n",
      "variance_average : [0.01852655 0.01694762 0.06686393 0.02984668 0.07426246 0.02601328]\n",
      "training idx 1 actor true_reward at iteration 2040 : 21.98877995548876\n",
      "226822\n",
      "Parameter containing:\n",
      "tensor([-5.0582, -4.6053, -5.0810, -4.8519, -5.8268, -4.9850],\n",
      "       requires_grad=True)\n",
      "[-235.9997]\n",
      "[14.231661]\n",
      "tensor(540.3101, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.05498703  0.03294018 -0.91017785  0.91379033  0.94037309 -0.044926  ]\n",
      "variance_average : [0.02634416 0.03799369 0.05906416 0.03008561 0.03019761 0.08615753]\n",
      "training idx 1 actor true_reward at iteration 2050 : 23.510896834899185\n",
      "227637\n",
      "Parameter containing:\n",
      "tensor([-5.0567, -4.6111, -5.0883, -4.8401, -5.8280, -4.9830],\n",
      "       requires_grad=True)\n",
      "[48.86561]\n",
      "[6.2342553]\n",
      "tensor(625.6511, grad_fn=<AddBackward0>)\n",
      "mean_average : [-3.42005941e-03 -1.69370353e-04 -9.38611421e-01  9.37069652e-01\n",
      "  9.46993477e-01  1.63479637e-02]\n",
      "variance_average : [0.03474271 0.01527575 0.03150249 0.06022762 0.01437436 0.06703622]\n",
      "training idx 1 actor true_reward at iteration 2060 : 15.076581823042817\n",
      "228463\n",
      "Parameter containing:\n",
      "tensor([-5.0468, -4.5956, -5.0916, -4.8328, -5.8192, -4.9742],\n",
      "       requires_grad=True)\n",
      "[-9.758739]\n",
      "[10.432064]\n",
      "tensor(465.2551, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.20883408  0.17129425 -0.94968466  0.9220879   0.94451019 -0.20750071]\n",
      "variance_average : [0.01731021 0.02093854 0.06601969 0.07340086 0.03178694 0.03089349]\n",
      "training idx 1 actor true_reward at iteration 2070 : 12.35521220390983\n",
      "229297\n",
      "Parameter containing:\n",
      "tensor([-5.0618, -4.5978, -5.1043, -4.8455, -5.8178, -4.9906],\n",
      "       requires_grad=True)\n",
      "[180.06927]\n",
      "[19.619843]\n",
      "tensor(1000.6232, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.06155808  0.10674171 -0.96269555  0.95647922  0.96127382 -0.11158265]\n",
      "variance_average : [0.03042463 0.01487201 0.02403679 0.03148953 0.05066784 0.02333739]\n",
      "training idx 1 actor true_reward at iteration 2080 : 12.755706146675134\n",
      "230259\n",
      "Parameter containing:\n",
      "tensor([-5.0543, -4.5590, -5.0775, -4.8129, -5.7981, -4.9681],\n",
      "       requires_grad=True)\n",
      "[369.0834]\n",
      "[18.80738]\n",
      "tensor(684.1977, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.1139233   0.10055108 -0.97119725  0.97259248  0.95662967 -0.09150098]\n",
      "variance_average : [0.06370536 0.06835289 0.06788559 0.01113917 0.04957815 0.0678368 ]\n",
      "training idx 1 actor true_reward at iteration 2090 : 5.524078939870233\n",
      "231168\n",
      "Parameter containing:\n",
      "tensor([-5.0412, -4.5424, -5.0693, -4.8023, -5.8031, -4.9581],\n",
      "       requires_grad=True)\n",
      "[-656.9181]\n",
      "[25.138416]\n",
      "tensor(554.8990, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.09505897  0.09760669 -0.9572647   0.97014135  0.90013104 -0.03554636]\n",
      "variance_average : [0.02779279 0.05987841 0.02715348 0.01821331 0.10178863 0.10426944]\n",
      "training idx 1 actor true_reward at iteration 2100 : 35.726867790047386\n",
      "232122\n",
      "Parameter containing:\n",
      "tensor([-5.0559, -4.5428, -5.0844, -4.8039, -5.8046, -4.9595],\n",
      "       requires_grad=True)\n",
      "[86.17674]\n",
      "[25.14978]\n",
      "tensor(469.3640, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.18498201  0.12423313 -0.94451833  0.9061064   0.93870857 -0.13596805]\n",
      "variance_average : [0.0464396  0.05692479 0.10853187 0.07806092 0.08764672 0.02850486]\n",
      "training idx 1 actor true_reward at iteration 2110 : 8.16070175679402\n",
      "232990\n",
      "Parameter containing:\n",
      "tensor([-5.0448, -4.5429, -5.1017, -4.8185, -5.7957, -4.9646],\n",
      "       requires_grad=True)\n",
      "[660.5003]\n",
      "[31.548748]\n",
      "tensor(987.4205, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.12368169  0.11085015 -0.96674479  0.96476559  0.95089908 -0.14306598]\n",
      "variance_average : [0.03097033 0.03007734 0.00967872 0.04212144 0.01738609 0.00775168]\n",
      "training idx 1 actor true_reward at iteration 2120 : -5.629060644430065\n",
      "233936\n",
      "Parameter containing:\n",
      "tensor([-5.0298, -4.5090, -5.0851, -4.7822, -5.7679, -4.9348],\n",
      "       requires_grad=True)\n",
      "[-147.20282]\n",
      "[12.524366]\n",
      "tensor(677.6394, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.03916496 -0.01707616 -0.96270566  0.97196292  0.94057722  0.01911188]\n",
      "variance_average : [0.02788725 0.08145408 0.01463055 0.03480144 0.09608538 0.03433858]\n",
      "training idx 1 actor true_reward at iteration 2130 : 10.311819161445419\n",
      "234873\n",
      "Parameter containing:\n",
      "tensor([-5.0232, -4.4938, -5.0957, -4.7710, -5.7746, -4.9098],\n",
      "       requires_grad=True)\n",
      "[-104.40088]\n",
      "[7.7560234]\n",
      "tensor(870.9214, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.1159801   0.10477432 -0.95399888  0.94425565  0.96871297 -0.13049018]\n",
      "variance_average : [0.07430937 0.03147133 0.03736225 0.02996698 0.01007406 0.01245527]\n",
      "training idx 1 actor true_reward at iteration 2140 : 19.371384678840947\n",
      "235905\n",
      "Parameter containing:\n",
      "tensor([-5.0147, -4.4969, -5.0811, -4.7687, -5.7741, -4.8869],\n",
      "       requires_grad=True)\n",
      "[-65.61418]\n",
      "[17.826168]\n",
      "tensor(941.2974, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.0650002   0.14229181 -0.95318459  0.94911709  0.94580147 -0.09047521]\n",
      "variance_average : [0.01540295 0.01637333 0.03437038 0.00741946 0.04203977 0.02457793]\n",
      "training idx 1 actor true_reward at iteration 2150 : 16.12545076392163\n",
      "236750\n",
      "Parameter containing:\n",
      "tensor([-5.0419, -4.4969, -5.0839, -4.7848, -5.7857, -4.9103],\n",
      "       requires_grad=True)\n",
      "[363.2622]\n",
      "[32.50756]\n",
      "tensor(494.7052, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 5.58202328e-04 -6.31434903e-02 -9.53047410e-01  9.19799690e-01\n",
      "  9.50678956e-01 -4.56763986e-03]\n",
      "variance_average : [0.07405685 0.02406434 0.0734348  0.04452095 0.06629549 0.01159523]\n",
      "training idx 1 actor true_reward at iteration 2160 : -2.7445401862427605\n",
      "237611\n",
      "Parameter containing:\n",
      "tensor([-5.0403, -4.4763, -5.0763, -4.7505, -5.7614, -4.9084],\n",
      "       requires_grad=True)\n",
      "[-280.19333]\n",
      "[14.16122]\n",
      "tensor(469.2852, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.08073131  0.0704408  -0.92394237  0.92744261  0.97142987 -0.04129866]\n",
      "variance_average : [0.08911239 0.04723162 0.05338964 0.03361848 0.09087391 0.08815074]\n",
      "training idx 1 actor true_reward at iteration 2170 : 17.955568432438522\n",
      "238633\n",
      "Parameter containing:\n",
      "tensor([-5.0694, -4.4901, -5.0900, -4.7737, -5.7624, -4.9120],\n",
      "       requires_grad=True)\n",
      "[-740.60034]\n",
      "[43.9077]\n",
      "tensor(701.4793, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.00776444  0.00987622 -0.92526046  0.92986394  0.9192498  -0.01579822]\n",
      "variance_average : [0.01593809 0.05192534 0.04380978 0.01644352 0.07015009 0.0350435 ]\n",
      "training idx 1 actor true_reward at iteration 2180 : 35.56932384999591\n",
      "239500\n",
      "Parameter containing:\n",
      "tensor([-5.0782, -4.4858, -5.0925, -4.7938, -5.7635, -4.9147],\n",
      "       requires_grad=True)\n",
      "[-126.19781]\n",
      "[15.347944]\n",
      "tensor(784.1655, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.0610587   0.1027729  -0.97865303  0.95938578  0.96147758 -0.07603669]\n",
      "variance_average : [0.02579157 0.05399575 0.0560365  0.03062596 0.06549242 0.03249635]\n",
      "training idx 1 actor true_reward at iteration 2190 : 15.563157998397939\n",
      "240450\n",
      "Parameter containing:\n",
      "tensor([-5.0795, -4.4879, -5.0739, -4.7864, -5.7445, -4.9065],\n",
      "       requires_grad=True)\n",
      "[-549.3235]\n",
      "[23.17383]\n",
      "tensor(949.2163, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.05386058 -0.05148928 -0.96565046  0.97125857  0.96900164  0.06042443]\n",
      "variance_average : [0.01124123 0.03320307 0.01184574 0.04007195 0.00855538 0.03326626]\n",
      "training idx 1 actor true_reward at iteration 2200 : 29.45909733748422\n",
      "241226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.0903, -4.4954, -5.0801, -4.7862, -5.7403, -4.9144],\n",
      "       requires_grad=True)\n",
      "[-382.06314]\n",
      "[12.244175]\n",
      "tensor(680.7678, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.02108325  0.01568931 -0.95267733  0.95113988  0.95761285  0.00752551]\n",
      "variance_average : [0.03884395 0.01158761 0.02164254 0.01650448 0.04954696 0.02124133]\n",
      "training idx 1 actor true_reward at iteration 2210 : 27.398484078365346\n",
      "242265\n",
      "Parameter containing:\n",
      "tensor([-5.0799, -4.4693, -5.0605, -4.7693, -5.7242, -4.9114],\n",
      "       requires_grad=True)\n",
      "[-33.16279]\n",
      "[7.3800035]\n",
      "tensor(548.2946, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.09944515 -0.0208171  -0.92924109  0.91411132  0.92552944  0.01347742]\n",
      "variance_average : [0.02222696 0.0400305  0.0130165  0.05156229 0.09295827 0.05766733]\n",
      "training idx 1 actor true_reward at iteration 2220 : 14.12589918385756\n",
      "243118\n",
      "Parameter containing:\n",
      "tensor([-5.0865, -4.4807, -5.0703, -4.7690, -5.7231, -4.9136],\n",
      "       requires_grad=True)\n",
      "[347.20935]\n",
      "[31.991161]\n",
      "tensor(463.6149, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.16441553  0.11601295 -0.94034242  0.94978229  0.94303543 -0.09211393]\n",
      "variance_average : [0.01319736 0.01600837 0.04924507 0.06862254 0.08668226 0.14365579]\n",
      "training idx 1 actor true_reward at iteration 2230 : -4.134803430843229\n",
      "243976\n",
      "Parameter containing:\n",
      "tensor([-5.1039, -4.4850, -5.0723, -4.7775, -5.7191, -4.9139],\n",
      "       requires_grad=True)\n",
      "[-107.10515]\n",
      "[22.029741]\n",
      "tensor(616.0074, grad_fn=<AddBackward0>)\n",
      "mean_average : [-0.01609001  0.02892398 -0.9500654   0.91170034  0.9387831   0.01704835]\n",
      "variance_average : [0.05579757 0.02237522 0.06007566 0.06590368 0.05185724 0.02840662]\n",
      "training idx 1 actor true_reward at iteration 2240 : 14.640554217074511\n",
      "245098\n",
      "Parameter containing:\n",
      "tensor([-5.1029, -4.4921, -5.0699, -4.7900, -5.6956, -4.8999],\n",
      "       requires_grad=True)\n",
      "[103.75786]\n",
      "[18.906855]\n",
      "tensor(1023.0582, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.05050203 -0.00457417 -0.96708649  0.96500761  0.95891129  0.02675441]\n",
      "variance_average : [0.01385694 0.02385033 0.03360616 0.05981204 0.01618239 0.0622767 ]\n",
      "training idx 1 actor true_reward at iteration 2250 : 12.557363036119938\n",
      "246137\n",
      "Parameter containing:\n",
      "tensor([-5.0977, -4.4896, -5.0685, -4.7750, -5.6853, -4.8997],\n",
      "       requires_grad=True)\n",
      "[-317.84857]\n",
      "[17.411495]\n",
      "tensor(523.9208, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.09187591 -0.05391102 -0.91100303  0.89320398  0.95064933  0.04413254]\n",
      "variance_average : [0.02170863 0.04741858 0.04747637 0.06407137 0.04915025 0.09668898]\n",
      "training idx 1 actor true_reward at iteration 2260 : 22.171176769702683\n",
      "247058\n",
      "Parameter containing:\n",
      "tensor([-5.0861, -4.4919, -5.0679, -4.7827, -5.6738, -4.8930],\n",
      "       requires_grad=True)\n",
      "[-279.8578]\n",
      "[26.318089]\n",
      "tensor(908.7348, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.06605047  0.01280818 -0.95914913  0.95139983  0.95868955  0.02812182]\n",
      "variance_average : [0.02141345 0.02774216 0.01914576 0.02817813 0.02993575 0.05003657]\n",
      "training idx 1 actor true_reward at iteration 2270 : 21.81349001347466\n",
      "248049\n",
      "Parameter containing:\n",
      "tensor([-5.1054, -4.4983, -5.0756, -4.8099, -5.6822, -4.9122],\n",
      "       requires_grad=True)\n",
      "[100.21924]\n",
      "[12.468733]\n",
      "tensor(433.9307, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.10199779 -0.01755402 -0.94228392  0.95195158  0.92290672  0.06325155]\n",
      "variance_average : [0.07651595 0.02410912 0.02699772 0.09821414 0.05478989 0.01648292]\n",
      "training idx 1 actor true_reward at iteration 2280 : 9.703369899674128\n",
      "249077\n",
      "Parameter containing:\n",
      "tensor([-5.0900, -4.4835, -5.0631, -4.8107, -5.6802, -4.8829],\n",
      "       requires_grad=True)\n",
      "[-184.6793]\n",
      "[14.923397]\n",
      "tensor(615.7059, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.08427531 -0.09822593 -0.91889674  0.93118012  0.91833674  0.12217029]\n",
      "variance_average : [0.05777232 0.02670903 0.05891793 0.03945478 0.03152059 0.08695203]\n",
      "training idx 1 actor true_reward at iteration 2290 : 19.260056772617514\n",
      "249999\n",
      "Parameter containing:\n",
      "tensor([-5.1325, -4.5115, -5.0933, -4.8291, -5.7082, -4.8990],\n",
      "       requires_grad=True)\n",
      "[-326.05804]\n",
      "[15.35626]\n",
      "tensor(494.3666, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.16573458 -0.14245998 -0.90995149  0.93829889  0.97289372  0.1211241 ]\n",
      "variance_average : [0.0250679  0.01350295 0.04588852 0.07995096 0.07902834 0.06384658]\n",
      "training idx 1 actor true_reward at iteration 2300 : 23.88921698262854\n",
      "250806\n",
      "Parameter containing:\n",
      "tensor([-5.1342, -4.5256, -5.0977, -4.8345, -5.7293, -4.9104],\n",
      "       requires_grad=True)\n",
      "[178.49265]\n",
      "[18.715982]\n",
      "tensor(846.0545, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.04469663 -0.05391682 -0.95942715  0.94344896  0.97087387  0.00246147]\n",
      "variance_average : [0.02474307 0.04192133 0.05192643 0.02431099 0.03242753 0.05375718]\n",
      "training idx 1 actor true_reward at iteration 2310 : 8.80388303927529\n",
      "251745\n",
      "Parameter containing:\n",
      "tensor([-5.1363, -4.5458, -5.1012, -4.8290, -5.7336, -4.9133],\n",
      "       requires_grad=True)\n",
      "[-457.02594]\n",
      "[21.953197]\n",
      "tensor(627.1691, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.04005551  0.0094574  -0.95610862  0.9512894   0.93710912  0.02016114]\n",
      "variance_average : [0.03929157 0.01596952 0.02140624 0.10586759 0.01053269 0.01435139]\n",
      "training idx 1 actor true_reward at iteration 2320 : 30.636650539235415\n",
      "252610\n",
      "Parameter containing:\n",
      "tensor([-5.1664, -4.5464, -5.1277, -4.8717, -5.7484, -4.9526],\n",
      "       requires_grad=True)\n",
      "[253.1456]\n",
      "[11.342236]\n",
      "tensor(604.2881, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.38127441 -0.10066855 -0.93514541  0.93905237  0.92959623  0.15516097]\n",
      "variance_average : [0.01443537 0.0619224  0.01845106 0.0256324  0.03742614 0.01386716]\n",
      "training idx 1 actor true_reward at iteration 2330 : 9.89363603642342\n",
      "253438\n",
      "Parameter containing:\n",
      "tensor([-5.1695, -4.5641, -5.1516, -4.9017, -5.7661, -4.9882],\n",
      "       requires_grad=True)\n",
      "[-470.41544]\n",
      "[25.633244]\n",
      "tensor(616.7547, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.17245069 -0.01227843 -0.92921197  0.93122413  0.93394334  0.04648554]\n",
      "variance_average : [0.03264863 0.02014055 0.08215381 0.01610221 0.10601133 0.03757595]\n",
      "training idx 1 actor true_reward at iteration 2340 : 31.06932067476327\n",
      "254255\n",
      "Parameter containing:\n",
      "tensor([-5.2206, -4.6071, -5.2027, -4.9675, -5.8054, -5.0432],\n",
      "       requires_grad=True)\n",
      "[352.1695]\n",
      "[20.475773]\n",
      "tensor(456.0258, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.08471128  0.00947379 -0.91125301  0.93982702  0.90456671 -0.01837253]\n",
      "variance_average : [0.07096948 0.01642688 0.02876938 0.05639903 0.0806084  0.05747719]\n",
      "training idx 1 actor true_reward at iteration 2350 : 9.851193989681263\n",
      "255204\n",
      "Parameter containing:\n",
      "tensor([-5.2183, -4.6093, -5.2006, -4.9697, -5.8133, -5.0357],\n",
      "       requires_grad=True)\n",
      "[-99.938225]\n",
      "[15.379051]\n",
      "tensor(523.7125, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.27686265 -0.19725733 -0.92776517  0.90056768  0.90926058  0.16490868]\n",
      "variance_average : [0.04046753 0.04726114 0.04333171 0.08697738 0.11005595 0.02307986]\n",
      "training idx 1 actor true_reward at iteration 2360 : 17.4457475831932\n",
      "256033\n",
      "Parameter containing:\n",
      "tensor([-5.2097, -4.6213, -5.1963, -4.9947, -5.8161, -5.0318],\n",
      "       requires_grad=True)\n",
      "[-51.862324]\n",
      "[20.580482]\n",
      "tensor(877.6385, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.09809292 -0.02673681 -0.97025284  0.94784206  0.95497314 -0.02741745]\n",
      "variance_average : [0.02282241 0.04617588 0.03393493 0.00955407 0.06297659 0.03814834]\n",
      "training idx 1 actor true_reward at iteration 2370 : 14.811503807592432\n",
      "256921\n",
      "Parameter containing:\n",
      "tensor([-5.2462, -4.6379, -5.2293, -5.0214, -5.8246, -5.0630],\n",
      "       requires_grad=True)\n",
      "[-200.77516]\n",
      "[13.408886]\n",
      "tensor(670.0726, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.06937874 -0.02526983 -0.95100694  0.94591031  0.95998476  0.04626614]\n",
      "variance_average : [0.01331888 0.08673458 0.05655235 0.0326123  0.0459679  0.03669319]\n",
      "training idx 1 actor true_reward at iteration 2380 : 20.7401924954929\n",
      "257786\n",
      "Parameter containing:\n",
      "tensor([-5.2372, -4.6310, -5.2078, -5.0035, -5.8119, -5.0497],\n",
      "       requires_grad=True)\n",
      "[260.428]\n",
      "[20.52227]\n",
      "tensor(100.3936, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.57337628 -0.55130042 -0.69459567  0.66125823  0.62417911  0.67539583]\n",
      "variance_average : [0.3641559  0.34279297 0.12443293 0.23973846 0.10641316 0.23914819]\n",
      "training idx 1 actor true_reward at iteration 2390 : 1.8643465160078998\n",
      "258515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.2724, -4.6753, -5.2402, -5.0466, -5.8439, -5.0854],\n",
      "       requires_grad=True)\n",
      "[-477.4637]\n",
      "[13.824074]\n",
      "tensor(432.7108, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.35582036 -0.21863663 -0.92887981  0.9287544   0.91745033  0.18077024]\n",
      "variance_average : [0.03642472 0.05228906 0.02207422 0.10169163 0.06779453 0.05126548]\n",
      "training idx 1 actor true_reward at iteration 2400 : 26.832636539741795\n",
      "259300\n",
      "Parameter containing:\n",
      "tensor([-5.3189, -4.7180, -5.2943, -5.0892, -5.8714, -5.1250],\n",
      "       requires_grad=True)\n",
      "[-344.35092]\n",
      "[15.626716]\n",
      "tensor(399.3129, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.63104086 -0.45704491 -0.9270962   0.93754077  0.8861449   0.38798808]\n",
      "variance_average : [0.15445425 0.09820115 0.05077391 0.1515336  0.07872811 0.03363851]\n",
      "training idx 1 actor true_reward at iteration 2410 : 23.08930882578425\n",
      "260005\n",
      "Parameter containing:\n",
      "tensor([-5.3230, -4.7298, -5.3192, -5.1016, -5.8727, -5.1341],\n",
      "       requires_grad=True)\n",
      "[-41.64758]\n",
      "[41.41681]\n",
      "tensor(4013.8164, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.7839436  -0.91661721 -0.99189871  0.9925236   0.98990605  0.7251491 ]\n",
      "variance_average : [0.00648693 0.01436065 0.01349737 0.00454164 0.01229042 0.00497805]\n",
      "training idx 1 actor true_reward at iteration 2420 : 33.37882508392636\n",
      "261405\n",
      "Parameter containing:\n",
      "tensor([-5.3254, -4.7342, -5.3396, -5.1061, -5.8671, -5.1428],\n",
      "       requires_grad=True)\n",
      "[-127.35721]\n",
      "[4.935132]\n",
      "tensor(685.9419, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.59428299 -0.8742019  -0.95983975  0.9580013   0.95039059  0.18966448]\n",
      "variance_average : [0.01964813 0.0507615  0.05576025 0.08126656 0.0325751  0.0131798 ]\n",
      "training idx 1 actor true_reward at iteration 2430 : 22.64666833667745\n",
      "262570\n",
      "Parameter containing:\n",
      "tensor([-5.3310, -4.7539, -5.3327, -5.1043, -5.8514, -5.1674],\n",
      "       requires_grad=True)\n",
      "[149.61461]\n",
      "[6.8174424]\n",
      "tensor(570.5721, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.49552011 -0.82419013 -0.95827996  0.91211533  0.9166105   0.41632147]\n",
      "variance_average : [0.05325984 0.05248428 0.01263436 0.0474626  0.0433864  0.07676068]\n",
      "training idx 1 actor true_reward at iteration 2440 : 10.640291943598971\n",
      "263540\n",
      "Parameter containing:\n",
      "tensor([-5.3652, -4.7920, -5.3841, -5.1481, -5.9130, -5.2061],\n",
      "       requires_grad=True)\n",
      "[-842.6936]\n",
      "[33.31979]\n",
      "tensor(755.8712, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96436228 -0.98011268 -0.96682151  0.97863219  0.97476647  0.9327145 ]\n",
      "variance_average : [0.01808909 0.04261546 0.04567536 0.02559098 0.0574034  0.01060074]\n",
      "training idx 1 actor true_reward at iteration 2450 : 45.1787002832295\n",
      "264643\n",
      "Parameter containing:\n",
      "tensor([-5.3858, -4.8090, -5.4272, -5.1858, -5.9273, -5.2430],\n",
      "       requires_grad=True)\n",
      "[-1217.3975]\n",
      "[62.178772]\n",
      "tensor(1109.8306, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96869566 -0.96389731 -0.96538839  0.96421438  0.97088941  0.97122651]\n",
      "variance_average : [0.00678253 0.0149562  0.00849756 0.02376486 0.04640306 0.05078788]\n",
      "training idx 1 actor true_reward at iteration 2460 : 50.64208317757478\n",
      "265545\n",
      "Parameter containing:\n",
      "tensor([-5.4431, -4.8441, -5.4956, -5.2391, -5.9744, -5.2986],\n",
      "       requires_grad=True)\n",
      "[-576.01794]\n",
      "[15.695794]\n",
      "tensor(640.3660, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94424515 -0.93316769 -0.93878496  0.95160178  0.96042852  0.94921525]\n",
      "variance_average : [0.02044155 0.05566114 0.03721217 0.04520042 0.02804228 0.03043188]\n",
      "training idx 1 actor true_reward at iteration 2470 : 35.129070611481225\n",
      "266613\n",
      "Parameter containing:\n",
      "tensor([-5.4599, -4.8783, -5.5133, -5.2625, -5.9995, -5.3370],\n",
      "       requires_grad=True)\n",
      "[-24.81674]\n",
      "[9.260697]\n",
      "tensor(378.2552, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86411966 -0.93127028 -0.88940718  0.93045688  0.92087729  0.85209454]\n",
      "variance_average : [0.03537945 0.12097713 0.0411578  0.05468773 0.12139287 0.04877399]\n",
      "training idx 1 actor true_reward at iteration 2480 : 20.471608346341608\n",
      "268750\n",
      "Parameter containing:\n",
      "tensor([-5.4986, -4.9183, -5.5530, -5.3029, -6.0315, -5.3763],\n",
      "       requires_grad=True)\n",
      "[-776.6556]\n",
      "[32.828106]\n",
      "tensor(617.5803, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94468166 -0.94657641 -0.95140209  0.94075453  0.94172755  0.90499462]\n",
      "variance_average : [0.06184414 0.01914435 0.02243739 0.04408982 0.03443401 0.03751837]\n",
      "training idx 1 actor true_reward at iteration 2490 : 48.89847296076754\n",
      "269883\n",
      "Parameter containing:\n",
      "tensor([-5.5111, -4.9306, -5.5535, -5.3032, -6.0443, -5.3871],\n",
      "       requires_grad=True)\n",
      "[-80.2855]\n",
      "[14.674834]\n",
      "tensor(622.6041, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96801711 -0.93935019 -0.93544909  0.95276912  0.93870152  0.94672338]\n",
      "variance_average : [0.08116264 0.05923125 0.04277089 0.02329455 0.04874072 0.08634813]\n",
      "training idx 1 actor true_reward at iteration 2500 : 23.79853017633363\n",
      "271327\n",
      "Parameter containing:\n",
      "tensor([-5.5290, -4.9271, -5.5577, -5.2907, -6.0582, -5.3988],\n",
      "       requires_grad=True)\n",
      "[-734.28296]\n",
      "[19.242392]\n",
      "tensor(876.4595, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96249746 -0.96383487 -0.95244373  0.95503225  0.93705772  0.96151423]\n",
      "variance_average : [0.03760991 0.05606423 0.02024725 0.05506096 0.03173291 0.03539073]\n",
      "training idx 1 actor true_reward at iteration 2510 : 39.85807254413048\n",
      "273290\n",
      "Parameter containing:\n",
      "tensor([-5.5574, -4.9836, -5.5969, -5.3502, -6.0751, -5.4566],\n",
      "       requires_grad=True)\n",
      "[-667.6789]\n",
      "[23.275753]\n",
      "tensor(1101.6593, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9644992  -0.96923975 -0.96428328  0.95375339  0.97036324  0.96377308]\n",
      "variance_average : [0.05823858 0.01170878 0.03833314 0.01561434 0.00806526 0.0244931 ]\n",
      "training idx 1 actor true_reward at iteration 2520 : 45.27561858094183\n",
      "275543\n",
      "Parameter containing:\n",
      "tensor([-5.5569, -4.9735, -5.6415, -5.3597, -6.0921, -5.4704],\n",
      "       requires_grad=True)\n",
      "[-263.59747]\n",
      "[9.193186]\n",
      "tensor(1095.4554, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95654951 -0.97623343 -0.96522993  0.95962648  0.9667543   0.94991283]\n",
      "variance_average : [0.00945727 0.03632434 0.0112292  0.03116918 0.02203015 0.00724328]\n",
      "training idx 1 actor true_reward at iteration 2530 : 33.1603079846882\n",
      "277654\n",
      "Parameter containing:\n",
      "tensor([-5.5828, -5.0233, -5.6635, -5.3844, -6.1076, -5.5136],\n",
      "       requires_grad=True)\n",
      "[-575.38666]\n",
      "[16.968239]\n",
      "tensor(884.9534, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96800116 -0.94875721 -0.95314392  0.96115637  0.96028874  0.95015388]\n",
      "variance_average : [0.02066383 0.05147689 0.02965869 0.03838122 0.02333995 0.03984529]\n",
      "training idx 1 actor true_reward at iteration 2540 : 38.97956330766717\n",
      "278646\n",
      "Parameter containing:\n",
      "tensor([-5.5758, -5.0180, -5.6604, -5.4185, -6.0930, -5.5367],\n",
      "       requires_grad=True)\n",
      "[-525.60974]\n",
      "[14.928607]\n",
      "tensor(711.1377, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94365304 -0.94826554 -0.9488312   0.95138922  0.95180915  0.95271535]\n",
      "variance_average : [0.02377506 0.00974949 0.02169353 0.05047275 0.02918492 0.02603759]\n",
      "training idx 1 actor true_reward at iteration 2550 : 36.42949521226698\n",
      "281213\n",
      "Parameter containing:\n",
      "tensor([-5.6325, -5.0297, -5.6850, -5.4666, -6.1334, -5.5954],\n",
      "       requires_grad=True)\n",
      "[-851.08264]\n",
      "[34.62494]\n",
      "tensor(725.7910, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95005618 -0.94138677 -0.96303247  0.95088511  0.92826684  0.95650038]\n",
      "variance_average : [0.04130145 0.02375597 0.08379597 0.01189284 0.02155763 0.01671297]\n",
      "training idx 1 actor true_reward at iteration 2560 : 51.73300574460339\n",
      "282775\n",
      "Parameter containing:\n",
      "tensor([-5.6742, -5.0435, -5.7218, -5.4962, -6.1509, -5.6085],\n",
      "       requires_grad=True)\n",
      "[-606.72107]\n",
      "[23.751564]\n",
      "tensor(740.1017, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96119536 -0.94900256 -0.95700303  0.94785008  0.94997814  0.94737997]\n",
      "variance_average : [0.03736833 0.05133599 0.02395078 0.02829835 0.01403516 0.04957678]\n",
      "training idx 1 actor true_reward at iteration 2570 : 45.05746522274441\n",
      "284246\n",
      "Parameter containing:\n",
      "tensor([-5.7368, -5.0812, -5.7336, -5.5219, -6.1772, -5.6507],\n",
      "       requires_grad=True)\n",
      "[-963.98175]\n",
      "[35.20178]\n",
      "tensor(984.8388, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95885468 -0.97184436 -0.96372241  0.95669932  0.96059413  0.96909034]\n",
      "variance_average : [0.01082621 0.03797501 0.05220976 0.03060688 0.03160959 0.03182165]\n",
      "training idx 1 actor true_reward at iteration 2580 : 51.116246211500595\n",
      "285222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.7538, -5.1154, -5.7395, -5.5235, -6.1770, -5.6698],\n",
      "       requires_grad=True)\n",
      "[-306.25656]\n",
      "[8.681903]\n",
      "tensor(603.4141, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94646517 -0.94609538 -0.95362168  0.94398827  0.9494574   0.9354437 ]\n",
      "variance_average : [0.02615869 0.0299415  0.02081342 0.05365959 0.0133049  0.04470475]\n",
      "training idx 1 actor true_reward at iteration 2590 : 34.22039631197272\n",
      "287038\n",
      "Parameter containing:\n",
      "tensor([-5.7865, -5.1274, -5.7451, -5.5443, -6.1743, -5.6978],\n",
      "       requires_grad=True)\n",
      "[85.20598]\n",
      "[24.329966]\n",
      "tensor(983.4068, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96509087 -0.96690414 -0.96800799  0.96864511  0.95822848  0.98606525]\n",
      "variance_average : [0.0226059  0.04967105 0.04752937 0.05894682 0.06316806 0.01385788]\n",
      "training idx 1 actor true_reward at iteration 2600 : 23.438487460751478\n",
      "288329\n",
      "Parameter containing:\n",
      "tensor([-5.7809, -5.1408, -5.7678, -5.5745, -6.2009, -5.7131],\n",
      "       requires_grad=True)\n",
      "[-310.42126]\n",
      "[16.766966]\n",
      "tensor(560.0278, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90924622 -0.9413177  -0.95672577  0.95937832  0.91324928  0.89951747]\n",
      "variance_average : [0.07389415 0.0503357  0.06040412 0.04710245 0.08595194 0.11381388]\n",
      "training idx 1 actor true_reward at iteration 2610 : 36.52909975670271\n",
      "289300\n",
      "Parameter containing:\n",
      "tensor([-5.7771, -5.1336, -5.7858, -5.5834, -6.2049, -5.7292],\n",
      "       requires_grad=True)\n",
      "[-162.87215]\n",
      "[4.851954]\n",
      "tensor(739.4583, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96930909 -0.93852839 -0.96218859  0.95580084  0.93929649  0.95026477]\n",
      "variance_average : [0.03940112 0.02381559 0.03005356 0.03451809 0.04455334 0.03953569]\n",
      "training idx 1 actor true_reward at iteration 2620 : 34.13020806461859\n",
      "290376\n",
      "Parameter containing:\n",
      "tensor([-5.7749, -5.1352, -5.7813, -5.5801, -6.2022, -5.7398],\n",
      "       requires_grad=True)\n",
      "[2586.007]\n",
      "[65.56449]\n",
      "tensor(4168.0054, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.99011036 -0.99331332 -0.99112313  0.98851886  0.99195117  0.98902411]\n",
      "variance_average : [0.01028338 0.01114479 0.00285152 0.01115402 0.01063338 0.00483368]\n",
      "training idx 1 actor true_reward at iteration 2630 : 15.029979653037863\n",
      "292083\n",
      "Parameter containing:\n",
      "tensor([-5.7523, -5.1356, -5.7686, -5.5769, -6.1833, -5.7379],\n",
      "       requires_grad=True)\n",
      "[-353.32144]\n",
      "[20.28434]\n",
      "tensor(725.7576, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96153301 -0.9334232  -0.94627478  0.97114877  0.93276275  0.97505664]\n",
      "variance_average : [0.02054353 0.02831587 0.01353666 0.05769329 0.03544263 0.02256285]\n",
      "training idx 1 actor true_reward at iteration 2640 : 35.28249260789276\n",
      "293692\n",
      "Parameter containing:\n",
      "tensor([-5.7756, -5.1635, -5.8003, -5.6052, -6.1909, -5.7476],\n",
      "       requires_grad=True)\n",
      "[-198.97678]\n",
      "[2.777758]\n",
      "tensor(1824.3096, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98038365 -0.98048572 -0.98287575  0.9810217   0.98001813  0.97720746]\n",
      "variance_average : [0.00968536 0.01395291 0.03694639 0.02387944 0.00519541 0.00816267]\n",
      "training idx 1 actor true_reward at iteration 2650 : 38.64141663726131\n",
      "295170\n",
      "Parameter containing:\n",
      "tensor([-5.7879, -5.1768, -5.7821, -5.6085, -6.1744, -5.7684],\n",
      "       requires_grad=True)\n",
      "[-45.64367]\n",
      "[3.1215367]\n",
      "tensor(725.2776, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95173503 -0.95581903 -0.95404694  0.94643324  0.9480855   0.959282  ]\n",
      "variance_average : [0.04558605 0.02307729 0.01995895 0.02773799 0.0148945  0.06756844]\n",
      "training idx 1 actor true_reward at iteration 2660 : 36.590710804591126\n",
      "296489\n",
      "Parameter containing:\n",
      "tensor([-5.7653, -5.1662, -5.7574, -5.5852, -6.1710, -5.7333],\n",
      "       requires_grad=True)\n",
      "[-167.67317]\n",
      "[7.641156]\n",
      "tensor(739.4658, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97107123 -0.94120105 -0.96318849  0.96198752  0.93879787  0.96321754]\n",
      "variance_average : [0.02789912 0.04919815 0.01856718 0.08013771 0.02598055 0.03212366]\n",
      "training idx 1 actor true_reward at iteration 2670 : 39.871212686375536\n",
      "297962\n",
      "Parameter containing:\n",
      "tensor([-5.7543, -5.1581, -5.7796, -5.5914, -6.1807, -5.7356],\n",
      "       requires_grad=True)\n",
      "[-224.6059]\n",
      "[10.370233]\n",
      "tensor(641.7430, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97702263 -0.92991194 -0.97867859  0.97363088  0.93528092  0.91730964]\n",
      "variance_average : [0.02476019 0.02792124 0.01104458 0.02007714 0.05175635 0.0522423 ]\n",
      "training idx 1 actor true_reward at iteration 2680 : 39.40024002354506\n",
      "299016\n",
      "Parameter containing:\n",
      "tensor([-5.7609, -5.1717, -5.8126, -5.6170, -6.2138, -5.7514],\n",
      "       requires_grad=True)\n",
      "[-61.325336]\n",
      "[9.258462]\n",
      "tensor(616.7479, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95748892 -0.95158991 -0.94370902  0.93703073  0.92796736  0.93394628]\n",
      "variance_average : [0.04025385 0.0947442  0.04544287 0.01192867 0.0363847  0.04619714]\n",
      "training idx 1 actor true_reward at iteration 2690 : 34.33672535798264\n",
      "300163\n",
      "Parameter containing:\n",
      "tensor([-5.7601, -5.1652, -5.8040, -5.6500, -6.2413, -5.7596],\n",
      "       requires_grad=True)\n",
      "[-55.158085]\n",
      "[17.8674]\n",
      "tensor(1645.5787, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97016173 -0.97935853 -0.97673664  0.96898143  0.97022729  0.97465255]\n",
      "variance_average : [0.01619442 0.03503553 0.02908161 0.01731714 0.01138099 0.01798858]\n",
      "training idx 1 actor true_reward at iteration 2700 : 42.17229031569397\n",
      "301363\n",
      "Parameter containing:\n",
      "tensor([-5.7511, -5.1455, -5.7940, -5.6481, -6.2172, -5.7569],\n",
      "       requires_grad=True)\n",
      "[138.70245]\n",
      "[11.264345]\n",
      "tensor(840.2277, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94805029 -0.98024913 -0.95120423  0.95195382  0.957794    0.95861904]\n",
      "variance_average : [0.06860544 0.03170394 0.02121737 0.00757777 0.04636613 0.02320825]\n",
      "training idx 1 actor true_reward at iteration 2710 : 27.739176978142375\n",
      "302993\n",
      "Parameter containing:\n",
      "tensor([-5.7658, -5.1345, -5.8142, -5.6307, -6.2155, -5.7706],\n",
      "       requires_grad=True)\n",
      "[-536.3271]\n",
      "[27.493984]\n",
      "tensor(824.8430, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94904211 -0.95939921 -0.97579221  0.97534532  0.97236586  0.9799854 ]\n",
      "variance_average : [0.02085392 0.04384879 0.01259994 0.03542992 0.0301576  0.03399813]\n",
      "training idx 1 actor true_reward at iteration 2720 : 54.215619677347945\n",
      "304119\n",
      "Parameter containing:\n",
      "tensor([-5.7886, -5.1612, -5.8216, -5.6540, -6.2288, -5.7721],\n",
      "       requires_grad=True)\n",
      "[-376.11035]\n",
      "[12.321002]\n",
      "tensor(648.8146, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93517971 -0.9410311  -0.94168126  0.94225485  0.96196695  0.94677407]\n",
      "variance_average : [0.03801746 0.04120255 0.03355202 0.0640683  0.01161377 0.0183482 ]\n",
      "training idx 1 actor true_reward at iteration 2730 : 40.69710466920126\n",
      "305420\n",
      "Parameter containing:\n",
      "tensor([-5.8108, -5.1679, -5.8300, -5.6503, -6.2376, -5.7890],\n",
      "       requires_grad=True)\n",
      "[-389.25507]\n",
      "[5.4830246]\n",
      "tensor(842.0388, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95795291 -0.95979678 -0.93793387  0.94871753  0.96345388  0.96440297]\n",
      "variance_average : [0.02781134 0.00821447 0.03861272 0.02150264 0.02876873 0.01134649]\n",
      "training idx 1 actor true_reward at iteration 2740 : 47.058632831292485\n",
      "307173\n",
      "Parameter containing:\n",
      "tensor([-5.8226, -5.1536, -5.8044, -5.6477, -6.2418, -5.7963],\n",
      "       requires_grad=True)\n",
      "[-149.55217]\n",
      "[5.5424514]\n",
      "tensor(614.4373, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.91789688 -0.94333051 -0.9483515   0.93962296  0.93773594  0.94568046]\n",
      "variance_average : [0.07743326 0.07328923 0.06140801 0.03099239 0.05184587 0.0620454 ]\n",
      "training idx 1 actor true_reward at iteration 2750 : 36.10441332980447\n",
      "308433\n",
      "Parameter containing:\n",
      "tensor([-5.8034, -5.1547, -5.7768, -5.6300, -6.2471, -5.7924],\n",
      "       requires_grad=True)\n",
      "[-518.0362]\n",
      "[19.058619]\n",
      "tensor(785.5833, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97182908 -0.95853355 -0.96753844  0.94248796  0.96137138  0.93763066]\n",
      "variance_average : [0.0539901  0.02297751 0.01764451 0.02990661 0.03149654 0.05980203]\n",
      "training idx 1 actor true_reward at iteration 2760 : 47.93160376277316\n",
      "309553\n",
      "Parameter containing:\n",
      "tensor([-5.7998, -5.1466, -5.7684, -5.6181, -6.2282, -5.7676],\n",
      "       requires_grad=True)\n",
      "[-494.77716]\n",
      "[14.751381]\n",
      "tensor(1162.8831, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96883137 -0.94763725 -0.96636891  0.96361926  0.98084962  0.97025264]\n",
      "variance_average : [0.01825327 0.0547331  0.0100675  0.01208937 0.02602581 0.02480996]\n",
      "training idx 1 actor true_reward at iteration 2770 : 43.57027765121288\n",
      "311576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.7880, -5.1358, -5.7617, -5.6256, -6.2283, -5.7519],\n",
      "       requires_grad=True)\n",
      "[-890.6235]\n",
      "[37.39147]\n",
      "tensor(978.7609, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96604865 -0.96258267 -0.94292957  0.95267921  0.96360784  0.98838811]\n",
      "variance_average : [0.02348981 0.02877501 0.0512738  0.00987072 0.00632367 0.06467786]\n",
      "training idx 1 actor true_reward at iteration 2780 : 50.532635359486726\n",
      "312881\n",
      "Parameter containing:\n",
      "tensor([-5.8251, -5.1631, -5.7934, -5.6554, -6.2549, -5.7826],\n",
      "       requires_grad=True)\n",
      "[152.87787]\n",
      "[18.794764]\n",
      "tensor(346.5224, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93019412 -0.93903482 -0.93680414  0.87936673  0.87782884  0.87139924]\n",
      "variance_average : [0.07388502 0.05349442 0.07239085 0.05988887 0.10672971 0.12968773]\n",
      "training idx 1 actor true_reward at iteration 2790 : 18.272665653292673\n",
      "314084\n",
      "Parameter containing:\n",
      "tensor([-5.8334, -5.1621, -5.8174, -5.6666, -6.3014, -5.8030],\n",
      "       requires_grad=True)\n",
      "[-390.57666]\n",
      "[15.679015]\n",
      "tensor(711.2711, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94659139 -0.94752112 -0.94293668  0.95699282  0.93749602  0.94407897]\n",
      "variance_average : [0.00979379 0.07796843 0.04885243 0.0101415  0.02083982 0.02148722]\n",
      "training idx 1 actor true_reward at iteration 2800 : 37.51834478367253\n",
      "315901\n",
      "Parameter containing:\n",
      "tensor([-5.8603, -5.2224, -5.8363, -5.6777, -6.3088, -5.8107],\n",
      "       requires_grad=True)\n",
      "[-775.0805]\n",
      "[34.04519]\n",
      "tensor(916.6717, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97047838 -0.96504355 -0.9862401   0.95832795  0.97441028  0.96329405]\n",
      "variance_average : [0.05659019 0.01419661 0.01656916 0.04888511 0.01816941 0.03013379]\n",
      "training idx 1 actor true_reward at iteration 2810 : 40.89021603829524\n",
      "316746\n",
      "Parameter containing:\n",
      "tensor([-5.8658, -5.2124, -5.8488, -5.6802, -6.2925, -5.8011],\n",
      "       requires_grad=True)\n",
      "[-193.01108]\n",
      "[7.8199115]\n",
      "tensor(586.6874, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96136769 -0.95168459 -0.92132245  0.95903488  0.96735883  0.94078413]\n",
      "variance_average : [0.04442654 0.01041464 0.03303654 0.1067934  0.07535421 0.01878967]\n",
      "training idx 1 actor true_reward at iteration 2820 : 25.2970702320552\n",
      "318692\n",
      "Parameter containing:\n",
      "tensor([-5.8874, -5.2462, -5.8593, -5.7144, -6.3144, -5.8188],\n",
      "       requires_grad=True)\n",
      "[-539.08435]\n",
      "[12.162217]\n",
      "tensor(684.5570, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94203713 -0.94531995 -0.9480242   0.94452026  0.94481286  0.94859248]\n",
      "variance_average : [0.03974606 0.03413052 0.05027754 0.02379982 0.059347   0.07970199]\n",
      "training idx 1 actor true_reward at iteration 2830 : 39.88668299689181\n",
      "320472\n",
      "Parameter containing:\n",
      "tensor([-5.9134, -5.2606, -5.8951, -5.7076, -6.3436, -5.8227],\n",
      "       requires_grad=True)\n",
      "[-738.22754]\n",
      "[28.74537]\n",
      "tensor(671.1191, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95224305 -0.94526309 -0.93741106  0.93801971  0.92595133  0.95872064]\n",
      "variance_average : [0.0191064  0.01995518 0.05299869 0.0749093  0.05141296 0.01621148]\n",
      "training idx 1 actor true_reward at iteration 2840 : 49.19121338278901\n",
      "321668\n",
      "Parameter containing:\n",
      "tensor([-5.9386, -5.2444, -5.9057, -5.7454, -6.3358, -5.8369],\n",
      "       requires_grad=True)\n",
      "[-96.70874]\n",
      "[8.640087]\n",
      "tensor(823.7996, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9738765  -0.94238639 -0.97782895  0.95756122  0.97274359  0.94221753]\n",
      "variance_average : [0.07246849 0.06059564 0.04332294 0.02424871 0.02059993 0.01247605]\n",
      "training idx 1 actor true_reward at iteration 2850 : 31.001295731916205\n",
      "323920\n",
      "Parameter containing:\n",
      "tensor([-5.9630, -5.2601, -5.9315, -5.7635, -6.3825, -5.8453],\n",
      "       requires_grad=True)\n",
      "[-96.02818]\n",
      "[13.49897]\n",
      "tensor(672.5539, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96591768 -0.92647283 -0.95887523  0.94364261  0.95082383  0.93019207]\n",
      "variance_average : [0.01057745 0.03644018 0.02387298 0.05145221 0.02565355 0.0248549 ]\n",
      "training idx 1 actor true_reward at iteration 2860 : 35.27207133477672\n",
      "324834\n",
      "Parameter containing:\n",
      "tensor([-5.9409, -5.2359, -5.9072, -5.7514, -6.3589, -5.8401],\n",
      "       requires_grad=True)\n",
      "[-372.2197]\n",
      "[7.8401713]\n",
      "tensor(830.8024, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93080921 -0.95150619 -0.95026588  0.95391537  0.95880561  0.96687394]\n",
      "variance_average : [0.07347821 0.02917472 0.02849176 0.01324919 0.03423105 0.0804594 ]\n",
      "training idx 1 actor true_reward at iteration 2870 : 33.8420579394254\n",
      "327054\n",
      "Parameter containing:\n",
      "tensor([-5.9479, -5.2578, -5.9352, -5.7648, -6.3564, -5.8747],\n",
      "       requires_grad=True)\n",
      "[-524.2107]\n",
      "[18.942213]\n",
      "tensor(710.4890, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95020345 -0.93343104 -0.95536582  0.94287529  0.9345853   0.95254017]\n",
      "variance_average : [0.01324064 0.04267651 0.02115282 0.08041375 0.01477939 0.02589364]\n",
      "training idx 1 actor true_reward at iteration 2880 : 35.702930733590115\n",
      "328089\n",
      "Parameter containing:\n",
      "tensor([-5.9904, -5.2988, -5.9815, -5.7999, -6.3910, -5.9112],\n",
      "       requires_grad=True)\n",
      "[-595.67993]\n",
      "[9.048782]\n",
      "tensor(3177.3723, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98681814 -0.98812304 -0.98779063  0.99136149  0.98892451  0.98830002]\n",
      "variance_average : [0.00740521 0.01322962 0.00454087 0.00817188 0.01275763 0.00549722]\n",
      "training idx 1 actor true_reward at iteration 2890 : 40.665273489470444\n",
      "329253\n",
      "Parameter containing:\n",
      "tensor([-5.9749, -5.2452, -5.9353, -5.7524, -6.4137, -5.8640],\n",
      "       requires_grad=True)\n",
      "[-573.35333]\n",
      "[22.03523]\n",
      "tensor(993.5215, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97068275 -0.97030572 -0.95562442  0.96252287  0.95426018  0.97126629]\n",
      "variance_average : [0.02555776 0.06461843 0.02172734 0.04135434 0.01234893 0.01282629]\n",
      "training idx 1 actor true_reward at iteration 2900 : 35.49880718938251\n",
      "331756\n",
      "Parameter containing:\n",
      "tensor([-6.0130, -5.2576, -5.9438, -5.7588, -6.3944, -5.8532],\n",
      "       requires_grad=True)\n",
      "[-197.4526]\n",
      "[22.831522]\n",
      "tensor(468.5815, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96702146 -0.90102338 -0.87671479  0.91724119  0.90142691  0.89357446]\n",
      "variance_average : [0.04183682 0.11193386 0.09707562 0.06798613 0.10975673 0.03592512]\n",
      "training idx 1 actor true_reward at iteration 2910 : 21.631211004224138\n",
      "333803\n",
      "Parameter containing:\n",
      "tensor([-6.0521, -5.2818, -5.9748, -5.7849, -6.4093, -5.8773],\n",
      "       requires_grad=True)\n",
      "[-565.1778]\n",
      "[19.554234]\n",
      "tensor(723.8406, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94981659 -0.93703487 -0.97455401  0.93583296  0.94828678  0.92950849]\n",
      "variance_average : [0.04010399 0.01872569 0.04866812 0.03683168 0.04038123 0.04507291]\n",
      "training idx 1 actor true_reward at iteration 2920 : 40.21185139295484\n",
      "335145\n",
      "Parameter containing:\n",
      "tensor([-6.0787, -5.2993, -6.0160, -5.8007, -6.3993, -5.8737],\n",
      "       requires_grad=True)\n",
      "[-373.42303]\n",
      "[13.240509]\n",
      "tensor(722.9108, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95005286 -0.9472071  -0.96440083  0.94043171  0.94459872  0.94814624]\n",
      "variance_average : [0.07268249 0.04875918 0.0451707  0.03451699 0.03655241 0.03065758]\n",
      "training idx 1 actor true_reward at iteration 2930 : 31.96425447447454\n",
      "336316\n",
      "Parameter containing:\n",
      "tensor([-6.0894, -5.3086, -6.0474, -5.8110, -6.4017, -5.8823],\n",
      "       requires_grad=True)\n",
      "[-578.1631]\n",
      "[9.724839]\n",
      "tensor(956.3961, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94455059 -0.95824409 -0.94912273  0.9630179   0.95912678  0.96647814]\n",
      "variance_average : [0.0438889  0.05761628 0.01401482 0.00777494 0.01190347 0.02417782]\n",
      "training idx 1 actor true_reward at iteration 2940 : 45.39762865844755\n",
      "338589\n",
      "Parameter containing:\n",
      "tensor([-6.1058, -5.3227, -6.0620, -5.8276, -6.4127, -5.9057],\n",
      "       requires_grad=True)\n",
      "[778.46735]\n",
      "[355.33264]\n",
      "tensor(91.6867, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.61791272 -0.84840206 -0.74294671  0.83512232  0.72806266  0.8775751 ]\n",
      "variance_average : [0.11871928 0.1803957  0.46743712 0.35842583 0.44051983 0.22922708]\n",
      "training idx 1 actor true_reward at iteration 2950 : -12.36549246476077\n",
      "339575\n",
      "Parameter containing:\n",
      "tensor([-6.1200, -5.3435, -6.0619, -5.8489, -6.4263, -5.9343],\n",
      "       requires_grad=True)\n",
      "[-531.5404]\n",
      "[14.063777]\n",
      "tensor(711.2406, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95985502 -0.9370764  -0.95416856  0.94451078  0.96724295  0.95739181]\n",
      "variance_average : [0.01728987 0.02140529 0.04785663 0.02946257 0.02315937 0.01435972]\n",
      "training idx 1 actor true_reward at iteration 2960 : 37.708272035055685\n",
      "340608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-6.0989, -5.3543, -6.0831, -5.8416, -6.4373, -5.9275],\n",
      "       requires_grad=True)\n",
      "[-581.19244]\n",
      "[13.561215]\n",
      "tensor(649.3105, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94748046 -0.96550308 -0.93241457  0.94514127  0.94023369  0.924383  ]\n",
      "variance_average : [0.04246414 0.02826388 0.0809856  0.02560371 0.01215358 0.01447431]\n",
      "training idx 1 actor true_reward at iteration 2970 : 37.85368746632919\n",
      "344418\n",
      "Parameter containing:\n",
      "tensor([-6.0860, -5.3724, -6.0823, -5.8709, -6.4622, -5.9433],\n",
      "       requires_grad=True)\n",
      "[-763.0381]\n",
      "[23.998081]\n",
      "tensor(964.6008, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97935334 -0.95509731 -0.96016084  0.95327784  0.9756385   0.95531811]\n",
      "variance_average : [0.01050936 0.03779031 0.02833408 0.01575117 0.01539634 0.01654179]\n",
      "training idx 1 actor true_reward at iteration 2980 : 45.71122466122152\n",
      "345550\n",
      "Parameter containing:\n",
      "tensor([-6.0802, -5.3923, -6.1017, -5.8659, -6.4844, -5.9826],\n",
      "       requires_grad=True)\n",
      "[-560.26483]\n",
      "[35.798843]\n",
      "tensor(887.2766, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94846565 -0.97130118 -0.95195829  0.93692274  0.95931331  0.94810517]\n",
      "variance_average : [0.03914847 0.03325504 0.00606957 0.03546284 0.01174595 0.03404114]\n",
      "training idx 1 actor true_reward at iteration 2990 : 44.24425984583458\n",
      "347354\n",
      "Parameter containing:\n",
      "tensor([-6.0903, -5.4105, -6.1051, -5.8820, -6.4916, -5.9820],\n",
      "       requires_grad=True)\n",
      "[-273.05908]\n",
      "[5.6522293]\n",
      "tensor(1000.2283, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96522978 -0.9586765  -0.96576694  0.95773864  0.96197766  0.95439359]\n",
      "variance_average : [0.0298753  0.061233   0.03028841 0.02211075 0.04945655 0.00987575]\n",
      "training idx 1 actor true_reward at iteration 3000 : 34.29325542777309\n",
      "349797\n",
      "Parameter containing:\n",
      "tensor([-6.0833, -5.4560, -6.1055, -5.8779, -6.4978, -5.9935],\n",
      "       requires_grad=True)\n",
      "[-252.07175]\n",
      "[3.679706]\n",
      "tensor(1325.4471, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95892056 -0.97999276 -0.97425117  0.96253403  0.96693268  0.96162409]\n",
      "variance_average : [0.01882618 0.01119045 0.01299166 0.02090196 0.01191861 0.01836519]\n",
      "training idx 1 actor true_reward at iteration 3010 : 40.62904443643379\n",
      "351305\n",
      "Parameter containing:\n",
      "tensor([-6.0908, -5.4790, -6.1048, -5.8431, -6.4643, -5.9324],\n",
      "       requires_grad=True)\n",
      "[-416.40466]\n",
      "[14.349958]\n",
      "tensor(2278.2698, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97784458 -0.9746427  -0.98426567  0.98666567  0.97559517  0.98574523]\n",
      "variance_average : [0.00761419 0.00366187 0.01312752 0.02193283 0.01128072 0.01147626]\n",
      "training idx 1 actor true_reward at iteration 3020 : 41.00789606616502\n",
      "353050\n",
      "Parameter containing:\n",
      "tensor([-6.0645, -5.4629, -6.1061, -5.8109, -6.4389, -5.9407],\n",
      "       requires_grad=True)\n",
      "[-31.714067]\n",
      "[18.482021]\n",
      "tensor(437.5687, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90197541 -0.88468044 -0.96051385  0.90286272  0.93419162  0.92719868]\n",
      "variance_average : [0.02023201 0.1112039  0.09877036 0.10932999 0.07376578 0.12706808]\n",
      "training idx 1 actor true_reward at iteration 3030 : 35.03131013366987\n",
      "355060\n",
      "Parameter containing:\n",
      "tensor([-6.0574, -5.4571, -6.0787, -5.8269, -6.4405, -5.9218],\n",
      "       requires_grad=True)\n",
      "[7.442255]\n",
      "[5.1174197]\n",
      "tensor(973.1774, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96783835 -0.98396324 -0.95522735  0.97174287  0.97471622  0.97635478]\n",
      "variance_average : [0.02443943 0.01771892 0.00730325 0.02499575 0.0322831  0.00703037]\n",
      "training idx 1 actor true_reward at iteration 3040 : 34.218160486573126\n",
      "356330\n",
      "Parameter containing:\n",
      "tensor([-6.0591, -5.4568, -6.0740, -5.8294, -6.4377, -5.9150],\n",
      "       requires_grad=True)\n",
      "[-40.50874]\n",
      "[2.940646]\n",
      "tensor(1003.9002, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95642333 -0.96223174 -0.97512929  0.96982141  0.96670053  0.97696228]\n",
      "variance_average : [0.01221143 0.01551109 0.01051201 0.01960188 0.0159163  0.02486143]\n",
      "training idx 1 actor true_reward at iteration 3050 : 34.50408080593864\n",
      "357816\n",
      "Parameter containing:\n",
      "tensor([-6.0461, -5.4350, -6.0775, -5.8478, -6.4098, -5.9027],\n",
      "       requires_grad=True)\n",
      "[-50.719975]\n",
      "[13.325476]\n",
      "tensor(769.2936, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96846121 -0.96045375 -0.95704222  0.94338859  0.94064908  0.98076277]\n",
      "variance_average : [0.03520401 0.0320519  0.04219221 0.05743641 0.04220989 0.02958062]\n",
      "training idx 1 actor true_reward at iteration 3060 : 33.19206217928956\n",
      "359442\n",
      "Parameter containing:\n",
      "tensor([-6.0255, -5.4031, -6.0902, -5.8462, -6.4315, -5.8884],\n",
      "       requires_grad=True)\n",
      "[-113.660164]\n",
      "[3.0658278]\n",
      "tensor(816.9304, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95714741 -0.94869793 -0.9594929   0.95045313  0.96003515  0.95559375]\n",
      "variance_average : [0.04219398 0.03272048 0.02656792 0.05132434 0.00807892 0.03634149]\n",
      "training idx 1 actor true_reward at iteration 3070 : 32.91419366312483\n",
      "360919\n",
      "Parameter containing:\n",
      "tensor([-6.0181, -5.3954, -6.1226, -5.8223, -6.4096, -5.9363],\n",
      "       requires_grad=True)\n",
      "[-124.02835]\n",
      "[6.11734]\n",
      "tensor(717.0756, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96323486 -0.9668328  -0.9408586   0.94542626  0.94056924  0.93728116]\n",
      "variance_average : [0.06448231 0.03031739 0.02963693 0.03392937 0.0233747  0.02253036]\n",
      "training idx 1 actor true_reward at iteration 3080 : 37.31080290903178\n",
      "362426\n",
      "Parameter containing:\n",
      "tensor([-5.9678, -5.3644, -6.1268, -5.8130, -6.3751, -5.9238],\n",
      "       requires_grad=True)\n",
      "[-730.2144]\n",
      "[21.884567]\n",
      "tensor(955.4333, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94673032 -0.96584636 -0.97812499  0.95856822  0.97000888  0.95916141]\n",
      "variance_average : [0.03853507 0.02299772 0.0150999  0.02323416 0.01734602 0.03810337]\n",
      "training idx 1 actor true_reward at iteration 3090 : 51.251962459792175\n",
      "364289\n",
      "Parameter containing:\n",
      "tensor([-5.9895, -5.3858, -6.1383, -5.8315, -6.3817, -5.9479],\n",
      "       requires_grad=True)\n",
      "[231.00519]\n",
      "[3.8495445]\n",
      "tensor(2294.9424, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98808493 -0.9824825  -0.9843794   0.98773193  0.98310852  0.98329609]\n",
      "variance_average : [0.00904339 0.00273489 0.01733999 0.00743694 0.01057948 0.00827739]\n",
      "training idx 1 actor true_reward at iteration 3100 : 39.17459631179483\n",
      "365446\n",
      "Parameter containing:\n",
      "tensor([-5.9751, -5.3721, -6.1292, -5.8219, -6.3591, -5.9324],\n",
      "       requires_grad=True)\n",
      "[166.36336]\n",
      "[17.117943]\n",
      "tensor(4168.9780, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98967059 -0.99192197 -0.99153467  0.9890309   0.99276791  0.99093586]\n",
      "variance_average : [0.00712895 0.01173507 0.00669447 0.01517609 0.00301883 0.00281343]\n",
      "training idx 1 actor true_reward at iteration 3110 : 30.254558883755294\n",
      "367012\n",
      "Parameter containing:\n",
      "tensor([-5.9840, -5.3716, -6.1503, -5.8252, -6.3522, -5.9193],\n",
      "       requires_grad=True)\n",
      "[-187.61359]\n",
      "[5.967619]\n",
      "tensor(523.8325, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92953361 -0.95644506 -0.91591188  0.94431993  0.9354103   0.94031295]\n",
      "variance_average : [0.0770348  0.06724182 0.042651   0.09739146 0.05123747 0.01471203]\n",
      "training idx 1 actor true_reward at iteration 3120 : 33.555826066281945\n",
      "367995\n",
      "Parameter containing:\n",
      "tensor([-6.0415, -5.3901, -6.1715, -5.8318, -6.3760, -5.8994],\n",
      "       requires_grad=True)\n",
      "[-214.31339]\n",
      "[14.49001]\n",
      "tensor(768.1381, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93211555 -0.95561778 -0.9500382   0.9367023   0.94662636  0.93610252]\n",
      "variance_average : [0.0319057  0.0535245  0.04518063 0.04389334 0.04051967 0.07880182]\n",
      "training idx 1 actor true_reward at iteration 3130 : 34.715584187826906\n",
      "368977\n",
      "Parameter containing:\n",
      "tensor([-6.0365, -5.4046, -6.1668, -5.8304, -6.3709, -5.9016],\n",
      "       requires_grad=True)\n",
      "[797.7134]\n",
      "[14.743706]\n",
      "tensor(7643.6680, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.99588034 -0.9958711  -0.99633819  0.99528261  0.99462369  0.99581805]\n",
      "variance_average : [0.00444093 0.0056966  0.00326576 0.0070444  0.00212191 0.00407742]\n",
      "training idx 1 actor true_reward at iteration 3140 : 24.310343473198294\n",
      "371410\n",
      "Parameter containing:\n",
      "tensor([-6.0333, -5.4285, -6.1590, -5.8256, -6.3540, -5.8778],\n",
      "       requires_grad=True)\n",
      "[346.96432]\n",
      "[11.374779]\n",
      "tensor(1515.1964, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98478923 -0.98046946 -0.95747324  0.96192249  0.9756895   0.96548338]\n",
      "variance_average : [0.01631198 0.02935156 0.02044402 0.01453092 0.01966864 0.02413887]\n",
      "training idx 1 actor true_reward at iteration 3150 : 26.055173248037384\n",
      "373057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.9837, -5.3928, -6.1277, -5.7805, -6.3176, -5.8444],\n",
      "       requires_grad=True)\n",
      "[3937.7139]\n",
      "[158.4957]\n",
      "tensor(7643.9580, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.99538171 -0.99555752 -0.99546746  0.99582478  0.99713363  0.99371389]\n",
      "variance_average : [0.00374243 0.00433839 0.00413407 0.00675336 0.00359789 0.00231967]\n",
      "training idx 1 actor true_reward at iteration 3160 : 11.079872145392434\n",
      "375551\n",
      "Parameter containing:\n",
      "tensor([-5.9748, -5.3701, -6.1209, -5.7694, -6.3158, -5.8586],\n",
      "       requires_grad=True)\n",
      "[-635.5018]\n",
      "[17.968906]\n",
      "tensor(1069.8866, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95240159 -0.98796541 -0.98983693  0.97635006  0.96181451  0.9515179 ]\n",
      "variance_average : [0.02586114 0.01634005 0.0404923  0.05302156 0.00784656 0.03652043]\n",
      "training idx 1 actor true_reward at iteration 3170 : 43.753893143430396\n",
      "378306\n",
      "Parameter containing:\n",
      "tensor([-5.9803, -5.4337, -6.1578, -5.8090, -6.3661, -5.9163],\n",
      "       requires_grad=True)\n",
      "[-358.16364]\n",
      "[12.940424]\n",
      "tensor(469.6323, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93104796 -0.93073845 -0.92135449  0.92619293  0.916613    0.9293664 ]\n",
      "variance_average : [0.07834919 0.02528059 0.10919227 0.08641171 0.03885313 0.05880118]\n",
      "training idx 1 actor true_reward at iteration 3180 : 36.67032896346851\n",
      "379395\n",
      "Parameter containing:\n",
      "tensor([-6.0252, -5.4311, -6.2120, -5.8329, -6.3712, -5.9263],\n",
      "       requires_grad=True)\n",
      "[-486.05792]\n",
      "[21.409033]\n",
      "tensor(769.7715, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92392948 -0.95462458 -0.96357922  0.96382491  0.95574137  0.97644924]\n",
      "variance_average : [0.08086491 0.02116481 0.01629304 0.06472989 0.03075937 0.03826789]\n",
      "training idx 1 actor true_reward at iteration 3190 : 36.63073007516803\n",
      "381263\n",
      "Parameter containing:\n",
      "tensor([-6.0319, -5.4293, -6.2222, -5.8536, -6.4037, -5.9633],\n",
      "       requires_grad=True)\n",
      "[-155.6811]\n",
      "[4.234667]\n",
      "tensor(576.7392, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9343959  -0.93446695 -0.936311    0.93797991  0.93351667  0.93848143]\n",
      "variance_average : [0.04461652 0.08800432 0.02481916 0.08916687 0.06064583 0.04472576]\n",
      "training idx 1 actor true_reward at iteration 3200 : 32.92050210246165\n",
      "382660\n",
      "Parameter containing:\n",
      "tensor([-6.0547, -5.4321, -6.2302, -5.8618, -6.4154, -5.9745],\n",
      "       requires_grad=True)\n",
      "[-582.1674]\n",
      "[14.047463]\n",
      "tensor(686.3911, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94956096 -0.95446351 -0.93271129  0.94987675  0.9607083   0.93443052]\n",
      "variance_average : [0.03226823 0.01743772 0.0957158  0.0293546  0.05085678 0.01536223]\n",
      "training idx 1 actor true_reward at iteration 3210 : 47.81642055508844\n",
      "384044\n",
      "Parameter containing:\n",
      "tensor([-6.0357, -5.4253, -6.2265, -5.8395, -6.3977, -5.9630],\n",
      "       requires_grad=True)\n",
      "[3958.4126]\n",
      "[160.83122]\n",
      "tensor(7644.8921, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.99494175 -0.99525144 -0.99572196  0.99348393  0.99449969  0.99675898]\n",
      "variance_average : [0.00162598 0.00564879 0.00124356 0.00333884 0.0057336  0.00725956]\n",
      "training idx 1 actor true_reward at iteration 3220 : 13.603225659414258\n",
      "386417\n",
      "Parameter containing:\n",
      "tensor([-6.0474, -5.4076, -6.2479, -5.8202, -6.4073, -5.9817],\n",
      "       requires_grad=True)\n",
      "[-592.75616]\n",
      "[24.779512]\n",
      "tensor(992.0782, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95388898 -0.95384994 -0.96512436  0.96178623  0.979329    0.96832765]\n",
      "variance_average : [0.05207013 0.03488805 0.02159072 0.02409458 0.03346323 0.03118838]\n",
      "training idx 1 actor true_reward at iteration 3230 : 47.999579050447394\n",
      "387722\n",
      "Parameter containing:\n",
      "tensor([-6.0353, -5.4404, -6.2583, -5.8367, -6.4170, -5.9845],\n",
      "       requires_grad=True)\n",
      "[-108.74694]\n",
      "[7.836585]\n",
      "tensor(452.9205, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92876951 -0.96958443 -0.87056209  0.95129079  0.90379491  0.9311749 ]\n",
      "variance_average : [0.03052273 0.08882521 0.1161176  0.124615   0.06902086 0.0715493 ]\n",
      "training idx 1 actor true_reward at iteration 3240 : 32.65883131136046\n",
      "388840\n",
      "Parameter containing:\n",
      "tensor([-6.0322, -5.4489, -6.2452, -5.8364, -6.4249, -6.0006],\n",
      "       requires_grad=True)\n",
      "[-595.8264]\n",
      "[14.921802]\n",
      "tensor(541.3547, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92887124 -0.94907245 -0.95092099  0.93809157  0.93184331  0.95209543]\n",
      "variance_average : [0.03813512 0.010671   0.07946367 0.02185013 0.09050877 0.02553444]\n",
      "training idx 1 actor true_reward at iteration 3250 : 47.36234689725089\n",
      "391364\n",
      "Parameter containing:\n",
      "tensor([-6.0261, -5.4384, -6.2198, -5.8049, -6.4020, -6.0129],\n",
      "       requires_grad=True)\n",
      "[-170.83493]\n",
      "[8.368023]\n",
      "tensor(425.3046, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94842912 -0.93393159 -0.8974886   0.89235869  0.92879579  0.93132054]\n",
      "variance_average : [0.12264091 0.05825285 0.03910048 0.02439185 0.03041273 0.05945243]\n",
      "training idx 1 actor true_reward at iteration 3260 : 32.79923552222447\n",
      "393553\n",
      "Parameter containing:\n",
      "tensor([-6.0317, -5.4268, -6.2204, -5.8063, -6.4034, -6.0054],\n",
      "       requires_grad=True)\n",
      "[-871.63635]\n",
      "[35.521603]\n",
      "tensor(609.5933, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95725519 -0.93694418 -0.95743445  0.94311943  0.96051124  0.94697774]\n",
      "variance_average : [0.05103462 0.02135075 0.04879328 0.03228199 0.06735595 0.01887064]\n",
      "training idx 1 actor true_reward at iteration 3270 : 45.982385500489514\n",
      "395387\n",
      "Parameter containing:\n",
      "tensor([-6.0531, -5.4406, -6.2458, -5.8257, -6.4408, -6.0365],\n",
      "       requires_grad=True)\n",
      "[-421.70813]\n",
      "[39.435722]\n",
      "tensor(2446.0430, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98879718 -0.97651455 -0.97823941  0.99250854  0.98742352  0.9832664 ]\n",
      "variance_average : [0.01807178 0.01381394 0.00859425 0.00662633 0.02066756 0.00918539]\n",
      "training idx 1 actor true_reward at iteration 3280 : 56.49636255720046\n",
      "396914\n",
      "Parameter containing:\n",
      "tensor([-6.1143, -5.4322, -6.2722, -5.8540, -6.4722, -6.0490],\n",
      "       requires_grad=True)\n",
      "[-747.7971]\n",
      "[35.941048]\n",
      "tensor(691.5455, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.91958364 -0.97390903 -0.93012572  0.92707325  0.95407612  0.94202127]\n",
      "variance_average : [0.08064131 0.0539624  0.03855405 0.04639725 0.04669338 0.03988661]\n",
      "training idx 1 actor true_reward at iteration 3290 : 49.07316649924012\n",
      "398748\n",
      "Parameter containing:\n",
      "tensor([-6.1278, -5.4223, -6.2732, -5.8714, -6.4720, -6.0467],\n",
      "       requires_grad=True)\n",
      "[-691.17206]\n",
      "[21.234348]\n",
      "tensor(622.9814, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95470061 -0.93573495 -0.95997112  0.90880201  0.95005512  0.95524722]\n",
      "variance_average : [0.0457482  0.01371834 0.08506924 0.04309821 0.06535935 0.09205723]\n",
      "training idx 1 actor true_reward at iteration 3300 : 46.52232859359486\n",
      "400344\n",
      "Parameter containing:\n",
      "tensor([-6.1100, -5.4697, -6.2591, -5.8710, -6.4725, -6.0307],\n",
      "       requires_grad=True)\n",
      "[18.805012]\n",
      "[10.025517]\n",
      "tensor(393.4806, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95954564 -0.93748939 -0.91629731  0.88434245  0.92579163  0.90864826]\n",
      "variance_average : [0.06575114 0.02779311 0.02532051 0.07857972 0.09930039 0.14863248]\n",
      "training idx 1 actor true_reward at iteration 3310 : 29.128870375217172\n",
      "402470\n",
      "Parameter containing:\n",
      "tensor([-6.1402, -5.4807, -6.2403, -5.8837, -6.4978, -6.0521],\n",
      "       requires_grad=True)\n",
      "[-403.09732]\n",
      "[6.8930225]\n",
      "tensor(1016.5608, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97363762 -0.97179262 -0.96937829  0.95490834  0.97108916  0.98332998]\n",
      "variance_average : [0.01449368 0.02602    0.0237617  0.02146196 0.02310821 0.04756721]\n",
      "training idx 1 actor true_reward at iteration 3320 : 35.51816690152681\n",
      "403666\n",
      "Parameter containing:\n",
      "tensor([-6.1595, -5.4673, -6.2396, -5.9029, -6.5019, -6.0509],\n",
      "       requires_grad=True)\n",
      "[137.94302]\n",
      "[9.977906]\n",
      "tensor(439.8865, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93635075 -0.89227435 -0.91597356  0.92346686  0.92080927  0.86397669]\n",
      "variance_average : [0.0366378  0.13084472 0.11686452 0.02626642 0.03611316 0.0423427 ]\n",
      "training idx 1 actor true_reward at iteration 3330 : 18.250469047667526\n",
      "405746\n",
      "Parameter containing:\n",
      "tensor([-6.1727, -5.4581, -6.2347, -5.8950, -6.5371, -6.0657],\n",
      "       requires_grad=True)\n",
      "[-500.72696]\n",
      "[10.893675]\n",
      "tensor(849.4446, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96650325 -0.94219423 -0.95529851  0.94594746  0.95057028  0.94236798]\n",
      "variance_average : [0.01065357 0.03153535 0.02185292 0.02674363 0.0126888  0.03118872]\n",
      "training idx 1 actor true_reward at iteration 3340 : 38.33173312933252\n",
      "407498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-6.1768, -5.4479, -6.2288, -5.8611, -6.5537, -6.0811],\n",
      "       requires_grad=True)\n",
      "[-717.64233]\n",
      "[15.459406]\n",
      "tensor(1001.3187, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96322977 -0.96876354 -0.96735251  0.96542862  0.95653281  0.9633065 ]\n",
      "variance_average : [0.06122724 0.01538939 0.02032272 0.01081506 0.02887621 0.03375272]\n",
      "training idx 1 actor true_reward at iteration 3350 : 49.52157179705609\n",
      "408815\n",
      "Parameter containing:\n",
      "tensor([-6.1860, -5.4545, -6.2410, -5.8626, -6.5688, -6.1017],\n",
      "       requires_grad=True)\n",
      "[-749.96564]\n",
      "[25.319084]\n",
      "tensor(638.4199, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93613446 -0.9654222  -0.93960411  0.94353929  0.96647801  0.91455692]\n",
      "variance_average : [0.01865059 0.09199262 0.06755334 0.03337281 0.05631888 0.05217839]\n",
      "training idx 1 actor true_reward at iteration 3360 : 52.84139824852251\n",
      "410011\n",
      "Parameter containing:\n",
      "tensor([-6.1640, -5.4761, -6.2390, -5.8712, -6.5634, -6.1298],\n",
      "       requires_grad=True)\n",
      "[-220.49307]\n",
      "[5.301588]\n",
      "tensor(520.1979, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9359953  -0.92682814 -0.9205545   0.93086361  0.94165462  0.91722571]\n",
      "variance_average : [0.05240972 0.01970698 0.01136454 0.03693315 0.03513245 0.02025577]\n",
      "training idx 1 actor true_reward at iteration 3370 : 39.36705454778946\n",
      "410991\n",
      "Parameter containing:\n",
      "tensor([-6.1677, -5.4705, -6.2178, -5.8505, -6.5667, -6.1039],\n",
      "       requires_grad=True)\n",
      "[3160.979]\n",
      "[101.229904]\n",
      "tensor(5336.9854, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9938217  -0.98855335 -0.99669702  0.996845    0.99474752  0.98990205]\n",
      "variance_average : [0.00487588 0.01199682 0.00164049 0.01157534 0.00247652 0.01356938]\n",
      "training idx 1 actor true_reward at iteration 3380 : 12.669738381010793\n",
      "412586\n",
      "Parameter containing:\n",
      "tensor([-6.1673, -5.4734, -6.2231, -5.8469, -6.5716, -6.0901],\n",
      "       requires_grad=True)\n",
      "[337.67596]\n",
      "[17.642248]\n",
      "tensor(702.5052, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93517429 -0.92870485 -0.94958486  0.95506258  0.92116023  0.92797033]\n",
      "variance_average : [0.08024456 0.02344422 0.02518329 0.01563528 0.02814668 0.02509198]\n",
      "training idx 1 actor true_reward at iteration 3390 : 16.93262547377231\n",
      "414379\n",
      "Parameter containing:\n",
      "tensor([-6.2021, -5.4800, -6.2100, -5.8628, -6.5643, -6.1056],\n",
      "       requires_grad=True)\n",
      "[-293.76074]\n",
      "[10.536483]\n",
      "tensor(1036.9971, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97665952 -0.9467994  -0.94478493  0.98070948  0.96746095  0.96616419]\n",
      "variance_average : [0.04793393 0.03164766 0.02012628 0.06350826 0.0572331  0.02307622]\n",
      "training idx 1 actor true_reward at iteration 3400 : 30.640241199449328\n",
      "415771\n",
      "Parameter containing:\n",
      "tensor([-6.2165, -5.5045, -6.2191, -5.8745, -6.5846, -6.1512],\n",
      "       requires_grad=True)\n",
      "[-690.91583]\n",
      "[18.567472]\n",
      "tensor(839.7549, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95146721 -0.93087964 -0.93759933  0.96001731  0.96394269  0.92997852]\n",
      "variance_average : [0.07252782 0.0309462  0.03435324 0.01915758 0.0242146  0.01675869]\n",
      "training idx 1 actor true_reward at iteration 3410 : 50.96321934543688\n",
      "416823\n",
      "Parameter containing:\n",
      "tensor([-6.2051, -5.4683, -6.2237, -5.8904, -6.5907, -6.1350],\n",
      "       requires_grad=True)\n",
      "[-213.66322]\n",
      "[7.372775]\n",
      "tensor(586.5367, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94316983 -0.92556765 -0.92014188  0.93482567  0.95319312  0.95695638]\n",
      "variance_average : [0.03010456 0.04509535 0.03903044 0.03070469 0.04383713 0.03742521]\n",
      "training idx 1 actor true_reward at iteration 3420 : 40.08284839853229\n",
      "418267\n",
      "Parameter containing:\n",
      "tensor([-6.1871, -5.4988, -6.2203, -5.8898, -6.5820, -6.1236],\n",
      "       requires_grad=True)\n",
      "[-426.50275]\n",
      "[5.6254063]\n",
      "tensor(1296.7991, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97062283 -0.97249771 -0.9704786   0.97319983  0.97089425  0.97416138]\n",
      "variance_average : [0.0191953  0.00533992 0.00867126 0.00971441 0.01594452 0.0128977 ]\n",
      "training idx 1 actor true_reward at iteration 3430 : 50.94560445390849\n",
      "419500\n",
      "Parameter containing:\n",
      "tensor([-6.1884, -5.5093, -6.2071, -5.8849, -6.5598, -6.1206],\n",
      "       requires_grad=True)\n",
      "[-638.91986]\n",
      "[16.692125]\n",
      "tensor(716.6658, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95217821 -0.94188359 -0.95714255  0.95540807  0.94593926  0.95334233]\n",
      "variance_average : [0.06373141 0.03243466 0.02411163 0.03470578 0.01979021 0.04550705]\n",
      "training idx 1 actor true_reward at iteration 3440 : 52.07874855826816\n",
      "420627\n",
      "Parameter containing:\n",
      "tensor([-6.1620, -5.5353, -6.1860, -5.8738, -6.5531, -6.1098],\n",
      "       requires_grad=True)\n",
      "[26.553173]\n",
      "[31.972591]\n",
      "tensor(582.5752, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9403956  -0.92670702 -0.95462876  0.97310132  0.9339387   0.92192522]\n",
      "variance_average : [0.06968758 0.08462359 0.05907678 0.06005668 0.0665574  0.09993519]\n",
      "training idx 1 actor true_reward at iteration 3450 : 37.91067399810623\n",
      "421830\n",
      "Parameter containing:\n",
      "tensor([-6.1572, -5.5299, -6.2133, -5.8746, -6.5387, -6.1183],\n",
      "       requires_grad=True)\n",
      "[267.9984]\n",
      "[143.29744]\n",
      "tensor(77.0781, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86287236 -0.6310523  -0.55889849  0.80723027  0.73063848  0.83812488]\n",
      "variance_average : [0.32838777 0.23635596 0.28983354 0.25601933 0.24554312 0.24040382]\n",
      "training idx 1 actor true_reward at iteration 3460 : -4.121036266094214\n",
      "423197\n",
      "Parameter containing:\n",
      "tensor([-6.1778, -5.5229, -6.2209, -5.8819, -6.5411, -6.1094],\n",
      "       requires_grad=True)\n",
      "[-286.38446]\n",
      "[5.259524]\n",
      "tensor(934.3275, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95212408 -0.97125833 -0.96137881  0.95440589  0.96447119  0.97340891]\n",
      "variance_average : [0.0219927  0.01302482 0.04060944 0.00932639 0.01426944 0.02169123]\n",
      "training idx 1 actor true_reward at iteration 3470 : 41.21084070364675\n",
      "424636\n",
      "Parameter containing:\n",
      "tensor([-6.1736, -5.5249, -6.2130, -5.8778, -6.5358, -6.1103],\n",
      "       requires_grad=True)\n",
      "[-235.48923]\n",
      "[38.57319]\n",
      "tensor(1244.2833, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97244832 -0.96636956 -0.96750153  0.95780858  0.97740604  0.94816907]\n",
      "variance_average : [0.0364253  0.03441081 0.04536432 0.06191334 0.01595128 0.02211635]\n",
      "training idx 1 actor true_reward at iteration 3480 : 54.715772155181625\n",
      "425942\n",
      "Parameter containing:\n",
      "tensor([-6.1628, -5.5281, -6.2236, -5.8813, -6.5611, -6.1168],\n",
      "       requires_grad=True)\n",
      "[990.22766]\n",
      "[441.60736]\n",
      "tensor(147.4744, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.74267081 -0.78394571 -0.73995867  0.757549    0.75367175  0.75682127]\n",
      "variance_average : [0.27842788 0.34631447 0.02677446 0.21646471 0.08849491 0.14391405]\n",
      "training idx 1 actor true_reward at iteration 3490 : -0.4508336923101073\n",
      "427884\n",
      "Parameter containing:\n",
      "tensor([-6.1516, -5.5264, -6.2211, -5.8847, -6.5785, -6.1291],\n",
      "       requires_grad=True)\n",
      "[-594.2954]\n",
      "[12.201614]\n",
      "tensor(945.8240, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95930543 -0.958383   -0.96943228  0.95225663  0.95778459  0.9617431 ]\n",
      "variance_average : [0.07475119 0.01433173 0.02915606 0.06061289 0.03211104 0.0240066 ]\n",
      "training idx 1 actor true_reward at iteration 3500 : 43.37989017317685\n",
      "429054\n",
      "Parameter containing:\n",
      "tensor([-6.1460, -5.5517, -6.2379, -5.8975, -6.5808, -6.1201],\n",
      "       requires_grad=True)\n",
      "[-496.08984]\n",
      "[9.327011]\n",
      "tensor(924.1839, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96331036 -0.93819185 -0.95565853  0.95393196  0.96122954  0.95806374]\n",
      "variance_average : [0.04315328 0.00865293 0.06088349 0.02843439 0.04262167 0.01474111]\n",
      "training idx 1 actor true_reward at iteration 3510 : 41.184378083391465\n",
      "431128\n",
      "Parameter containing:\n",
      "tensor([-6.1358, -5.5430, -6.2315, -5.8961, -6.5559, -6.1365],\n",
      "       requires_grad=True)\n",
      "[-317.5251]\n",
      "[6.1920977]\n",
      "tensor(955.9456, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97449004 -0.9455332  -0.97633528  0.95575825  0.97102721  0.97949688]\n",
      "variance_average : [0.04381137 0.01084775 0.05543316 0.00547624 0.01594573 0.05424113]\n",
      "training idx 1 actor true_reward at iteration 3520 : 34.43582151249867\n",
      "433313\n",
      "Parameter containing:\n",
      "tensor([-6.1826, -5.5784, -6.2478, -5.9228, -6.5607, -6.1267],\n",
      "       requires_grad=True)\n",
      "[56.05655]\n",
      "[8.900485]\n",
      "tensor(323.1664, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8780947  -0.81898793 -0.8832441   0.92231509  0.87517344  0.79994517]\n",
      "variance_average : [0.12260943 0.13268843 0.08200637 0.1825735  0.04571921 0.04085527]\n",
      "training idx 1 actor true_reward at iteration 3530 : 20.696076407871548\n",
      "434080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-6.1875, -5.5724, -6.2698, -5.9278, -6.5555, -6.1202],\n",
      "       requires_grad=True)\n",
      "[-963.60944]\n",
      "[37.75371]\n",
      "tensor(1110.6929, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96490243 -0.9557828  -0.97207661  0.96609338  0.96012613  0.95294962]\n",
      "variance_average : [0.00601105 0.01827609 0.01617044 0.02951736 0.0333088  0.01162255]\n",
      "training idx 1 actor true_reward at iteration 3540 : 54.05651413438803\n",
      "436239\n",
      "Parameter containing:\n",
      "tensor([-6.1963, -5.5906, -6.2721, -5.9178, -6.5358, -6.1266],\n",
      "       requires_grad=True)\n",
      "[-567.9309]\n",
      "[25.898542]\n",
      "tensor(1829.9631, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.98057142 -0.97846343 -0.97808464  0.97145867  0.97733055  0.97940683]\n",
      "variance_average : [0.03163143 0.01137208 0.01174866 0.01507745 0.01937378 0.02989921]\n",
      "training idx 1 actor true_reward at iteration 3550 : 44.17024005297141\n",
      "438942\n",
      "Parameter containing:\n",
      "tensor([-6.1887, -5.5850, -6.2357, -5.8715, -6.5103, -6.1012],\n",
      "       requires_grad=True)\n",
      "[-385.7056]\n",
      "[7.961425]\n",
      "tensor(838.8895, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95135398 -0.97449409 -0.97601736  0.94438017  0.97235702  0.95162999]\n",
      "variance_average : [0.02657774 0.03467309 0.01764011 0.05924212 0.0603803  0.0244182 ]\n",
      "training idx 1 actor true_reward at iteration 3560 : 39.14595381975224\n",
      "441186\n",
      "Parameter containing:\n",
      "tensor([-6.1678, -5.5676, -6.2071, -5.8649, -6.4999, -6.0714],\n",
      "       requires_grad=True)\n",
      "[96.05212]\n",
      "[10.712682]\n",
      "tensor(193.4721, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83134342  0.05902175 -0.77721115  0.86707519  0.8234708   0.65985719]\n",
      "variance_average : [0.14406737 0.12157058 0.04806819 0.0814564  0.12321107 0.26595895]\n",
      "training idx 1 actor true_reward at iteration 3570 : 20.192267993008112\n",
      "441907\n",
      "Parameter containing:\n",
      "tensor([-6.1488, -5.5682, -6.2146, -5.8633, -6.4743, -6.0520],\n",
      "       requires_grad=True)\n",
      "[-55.048325]\n",
      "[11.912469]\n",
      "tensor(220.3161, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8837739   0.11311894 -0.91510892  0.80049509  0.93123476  0.68791804]\n",
      "variance_average : [0.02503115 0.0640576  0.17564689 0.05840106 0.02440273 0.07419263]\n",
      "training idx 1 actor true_reward at iteration 3580 : 13.275976215573607\n",
      "442231\n",
      "Parameter containing:\n",
      "tensor([-6.1585, -5.5643, -6.1970, -5.8526, -6.4715, -6.0418],\n",
      "       requires_grad=True)\n",
      "[365.9419]\n",
      "[14.504135]\n",
      "tensor(230.9778, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86251858 -0.17777034 -0.80485994  0.8603035   0.80398135  0.8453739 ]\n",
      "variance_average : [0.06640726 0.27064256 0.09573844 0.10133979 0.10235172 0.13151739]\n",
      "training idx 1 actor true_reward at iteration 3590 : 0.19961306797283931\n",
      "442636\n",
      "Parameter containing:\n",
      "tensor([-6.1583, -5.5482, -6.1911, -5.8370, -6.4843, -6.0238],\n",
      "       requires_grad=True)\n",
      "[-230.78581]\n",
      "[12.532875]\n",
      "tensor(256.4155, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82460928 -0.14977311 -0.85223752  0.81786732  0.85418378  0.60329741]\n",
      "variance_average : [0.11812039 0.1351876  0.06415297 0.0368603  0.02814577 0.12828794]\n",
      "training idx 1 actor true_reward at iteration 3600 : 22.791364430094355\n",
      "443121\n",
      "Parameter containing:\n",
      "tensor([-6.1630, -5.5432, -6.1997, -5.8414, -6.5073, -6.0463],\n",
      "       requires_grad=True)\n",
      "[92.03084]\n",
      "[9.241419]\n",
      "tensor(533.1193, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9449365  -0.09566566 -0.93599849  0.91232404  0.92963559  0.92017904]\n",
      "variance_average : [0.09532742 0.09156624 0.02210132 0.01526336 0.02521502 0.04097766]\n",
      "training idx 1 actor true_reward at iteration 3610 : 14.036283312255177\n",
      "443549\n",
      "Parameter containing:\n",
      "tensor([-6.1521, -5.5400, -6.2027, -5.8356, -6.5257, -6.0548],\n",
      "       requires_grad=True)\n",
      "[-100.65846]\n",
      "[13.336252]\n",
      "tensor(330.1289, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88970775 -0.27184442 -0.95143806  0.93684133  0.93194617  0.84274728]\n",
      "variance_average : [0.08576957 0.06396794 0.10990721 0.07231416 0.13862081 0.13739125]\n",
      "training idx 1 actor true_reward at iteration 3620 : 16.782858145501272\n",
      "443976\n",
      "Parameter containing:\n",
      "tensor([-6.1472, -5.5343, -6.2076, -5.8571, -6.5295, -6.0556],\n",
      "       requires_grad=True)\n",
      "[-313.62616]\n",
      "[9.334833]\n",
      "tensor(394.9133, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.91560769 -0.25460083 -0.89904138  0.93466043  0.91350775  0.74122076]\n",
      "variance_average : [0.08028564 0.06438923 0.04117117 0.08374014 0.02360782 0.0304942 ]\n",
      "training idx 1 actor true_reward at iteration 3630 : 29.826558020008314\n",
      "444490\n",
      "Parameter containing:\n",
      "tensor([-6.1488, -5.5552, -6.2020, -5.8497, -6.5179, -6.0606],\n",
      "       requires_grad=True)\n",
      "[-95.667755]\n",
      "[8.8197565]\n",
      "tensor(355.4475, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9445784  -0.58409613 -0.91200756  0.8929326   0.88830306  0.89909985]\n",
      "variance_average : [0.0329251  0.16617829 0.08460312 0.09270005 0.04021716 0.03564577]\n",
      "training idx 1 actor true_reward at iteration 3640 : 21.908121730051125\n",
      "445078\n",
      "Parameter containing:\n",
      "tensor([-6.1389, -5.5440, -6.1940, -5.8572, -6.5237, -6.0472],\n",
      "       requires_grad=True)\n",
      "[-374.01114]\n",
      "[11.562751]\n",
      "tensor(300.0283, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94595601 -0.20118496 -0.89086387  0.83037017  0.92545733  0.80439681]\n",
      "variance_average : [0.07834294 0.06612909 0.14930333 0.08687169 0.09200585 0.11612617]\n",
      "training idx 1 actor true_reward at iteration 3650 : 32.84058136965896\n",
      "445665\n",
      "Parameter containing:\n",
      "tensor([-6.1238, -5.5380, -6.1728, -5.8437, -6.5095, -6.0310],\n",
      "       requires_grad=True)\n",
      "[-86.63524]\n",
      "[3.773438]\n",
      "tensor(385.5464, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95731348 -0.65985764 -0.91814655  0.8961681   0.92141224  0.90866654]\n",
      "variance_average : [0.03163724 0.06008011 0.07090274 0.12783188 0.06926508 0.0637644 ]\n",
      "training idx 1 actor true_reward at iteration 3660 : 23.51101746771206\n",
      "446229\n",
      "Parameter containing:\n",
      "tensor([-6.1263, -5.5230, -6.1679, -5.8130, -6.4804, -6.0191],\n",
      "       requires_grad=True)\n",
      "[379.55188]\n",
      "[20.059855]\n",
      "tensor(453.1500, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93289188 -0.4310271  -0.94828291  0.92389788  0.90702099  0.92653367]\n",
      "variance_average : [0.05191732 0.05691172 0.11400884 0.07461771 0.0790236  0.07749882]\n",
      "training idx 1 actor true_reward at iteration 3670 : 0.3513559825367381\n",
      "447871\n",
      "Parameter containing:\n",
      "tensor([-6.1247, -5.5216, -6.1699, -5.8137, -6.4885, -6.0169],\n",
      "       requires_grad=True)\n",
      "[-212.59702]\n",
      "[3.9644773]\n",
      "tensor(449.1172, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93395393 -0.60265287 -0.9232161   0.92443216  0.92640353  0.92052747]\n",
      "variance_average : [0.019562   0.02899095 0.05617231 0.12605046 0.02010343 0.05453783]\n",
      "training idx 1 actor true_reward at iteration 3680 : 26.795675796900245\n",
      "448514\n",
      "Parameter containing:\n",
      "tensor([-6.1239, -5.5128, -6.1650, -5.8138, -6.4860, -6.0195],\n",
      "       requires_grad=True)\n",
      "[-5.6176796]\n",
      "[15.192016]\n",
      "tensor(510.7375, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9131906  -0.57220275 -0.90917681  0.95870759  0.92328418  0.86911132]\n",
      "variance_average : [0.04594386 0.03851272 0.06063913 0.05893378 0.03061159 0.01012675]\n",
      "training idx 1 actor true_reward at iteration 3690 : 19.21112763611464\n",
      "449170\n",
      "Parameter containing:\n",
      "tensor([-6.1125, -5.4956, -6.1534, -5.7871, -6.4600, -6.0060],\n",
      "       requires_grad=True)\n",
      "[88.86273]\n",
      "[4.1457806]\n",
      "tensor(386.2884, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89780087 -0.24418087 -0.90378766  0.92999198  0.91510213  0.80155749]\n",
      "variance_average : [0.10047576 0.08613946 0.02375842 0.06085208 0.04192664 0.06918289]\n",
      "training idx 1 actor true_reward at iteration 3700 : 17.07989654395228\n",
      "449731\n",
      "Parameter containing:\n",
      "tensor([-6.0979, -5.4898, -6.1480, -5.7790, -6.4582, -5.9971],\n",
      "       requires_grad=True)\n",
      "[-2.6001282]\n",
      "[5.5170307]\n",
      "tensor(304.1443, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8931485  -0.45830023 -0.90740335  0.94780779  0.90675346  0.83953625]\n",
      "variance_average : [0.01622786 0.01881143 0.12522115 0.13935229 0.09196155 0.02416435]\n",
      "training idx 1 actor true_reward at iteration 3710 : 15.754140434804839\n",
      "450197\n",
      "Parameter containing:\n",
      "tensor([-6.1026, -5.4931, -6.1485, -5.7757, -6.4507, -5.9989],\n",
      "       requires_grad=True)\n",
      "[-154.14969]\n",
      "[3.9879954]\n",
      "tensor(215.2040, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86754271  0.04010254 -0.85628195  0.86344692  0.83408695  0.85651566]\n",
      "variance_average : [0.10239105 0.10536735 0.135387   0.11782156 0.16777722 0.16991445]\n",
      "training idx 1 actor true_reward at iteration 3720 : 19.464016234898573\n",
      "450554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-6.0990, -5.4844, -6.1437, -5.7770, -6.4436, -5.9980],\n",
      "       requires_grad=True)\n",
      "[-62.663803]\n",
      "[11.327857]\n",
      "tensor(447.9799, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90915961 -0.18495444 -0.9245498   0.93783933  0.93978559  0.93696627]\n",
      "variance_average : [0.06330312 0.05644116 0.02098617 0.0655449  0.06739722 0.04127021]\n",
      "training idx 1 actor true_reward at iteration 3730 : 14.865390383106783\n",
      "450936\n",
      "Parameter containing:\n",
      "tensor([-6.0793, -5.4819, -6.1292, -5.7693, -6.4503, -5.9918],\n",
      "       requires_grad=True)\n",
      "[-191.67915]\n",
      "[7.9401393]\n",
      "tensor(270.3373, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90562383  0.16781814 -0.86844231  0.90500036  0.91780481  0.89072067]\n",
      "variance_average : [0.13519376 0.05609883 0.07990042 0.0387899  0.15533966 0.11847054]\n",
      "training idx 1 actor true_reward at iteration 3740 : 20.092390350213325\n",
      "451332\n",
      "Parameter containing:\n",
      "tensor([-6.0661, -5.4749, -6.1061, -5.7507, -6.4244, -5.9731],\n",
      "       requires_grad=True)\n",
      "[-649.7012]\n",
      "[38.478527]\n",
      "tensor(483.2768, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90787211  0.08381734 -0.93285396  0.93764815  0.93261234  0.93381581]\n",
      "variance_average : [0.0985357  0.05976076 0.06241323 0.13257524 0.03384655 0.12258284]\n",
      "training idx 1 actor true_reward at iteration 3750 : 34.99800967725528\n",
      "451751\n",
      "Parameter containing:\n",
      "tensor([-6.0526, -5.4649, -6.1175, -5.7344, -6.4145, -5.9661],\n",
      "       requires_grad=True)\n",
      "[-122.59919]\n",
      "[8.493142]\n",
      "tensor(378.5738, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93310704 -0.09429033 -0.87437406  0.95112002  0.87617941  0.8990155 ]\n",
      "variance_average : [0.06714639 0.03654613 0.07535361 0.03680468 0.06537301 0.09314104]\n",
      "training idx 1 actor true_reward at iteration 3760 : 18.89666410508359\n",
      "452116\n",
      "Parameter containing:\n",
      "tensor([-6.0508, -5.4537, -6.1141, -5.7283, -6.4113, -5.9601],\n",
      "       requires_grad=True)\n",
      "[-203.4721]\n",
      "[9.628689]\n",
      "tensor(186.3992, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82788808  0.01531013 -0.85540191  0.85004475  0.78370357  0.90315197]\n",
      "variance_average : [0.11790293 0.20543042 0.15280855 0.11947582 0.07701682 0.0433878 ]\n",
      "training idx 1 actor true_reward at iteration 3770 : 22.870094350239235\n",
      "452482\n",
      "Parameter containing:\n",
      "tensor([-6.0603, -5.4542, -6.1167, -5.7428, -6.4070, -5.9698],\n",
      "       requires_grad=True)\n",
      "[-114.700935]\n",
      "[3.5130749]\n",
      "tensor(208.3893, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89239886  0.22642155 -0.81860077  0.87570855  0.80655416  0.83668683]\n",
      "variance_average : [0.21755169 0.09049066 0.21227842 0.05821397 0.10037262 0.10031945]\n",
      "training idx 1 actor true_reward at iteration 3780 : 18.75525911384183\n",
      "452807\n",
      "Parameter containing:\n",
      "tensor([-6.0477, -5.4348, -6.0984, -5.7333, -6.3926, -5.9579],\n",
      "       requires_grad=True)\n",
      "[-97.027336]\n",
      "[7.6861143]\n",
      "tensor(501.1636, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.91803366 -0.22363775 -0.95990332  0.92840189  0.93225655  0.94712541]\n",
      "variance_average : [0.02008296 0.04934043 0.06326364 0.03289596 0.12839294 0.05265448]\n",
      "training idx 1 actor true_reward at iteration 3790 : 14.408541313965284\n",
      "453230\n",
      "Parameter containing:\n",
      "tensor([-6.0488, -5.4299, -6.0930, -5.7171, -6.3971, -5.9504],\n",
      "       requires_grad=True)\n",
      "[-118.77528]\n",
      "[7.5429554]\n",
      "tensor(242.4358, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84979789  0.1236963  -0.79446792  0.81230386  0.85155075  0.81570995]\n",
      "variance_average : [0.04598445 0.0443136  0.03543472 0.10098988 0.0709886  0.08921532]\n",
      "training idx 1 actor true_reward at iteration 3800 : 21.982125935706765\n",
      "453656\n",
      "Parameter containing:\n",
      "tensor([-6.0584, -5.4171, -6.0786, -5.7133, -6.3794, -5.9336],\n",
      "       requires_grad=True)\n",
      "[-217.20996]\n",
      "[8.784521]\n",
      "tensor(317.0193, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90652336 -0.33576675 -0.86087789  0.92094768  0.93693973  0.78625723]\n",
      "variance_average : [0.05450699 0.03961945 0.13167142 0.10743194 0.06421186 0.05637931]\n",
      "training idx 1 actor true_reward at iteration 3810 : 22.488412328014867\n",
      "454061\n",
      "Parameter containing:\n",
      "tensor([-6.0436, -5.4099, -6.0700, -5.7064, -6.3738, -5.9247],\n",
      "       requires_grad=True)\n",
      "[-561.09235]\n",
      "[23.63834]\n",
      "tensor(380.4973, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92579827 -0.18828106 -0.90324158  0.91973351  0.90699622  0.87753906]\n",
      "variance_average : [0.01985817 0.08018181 0.04414684 0.03191918 0.03022093 0.08973351]\n",
      "training idx 1 actor true_reward at iteration 3820 : 31.130160311641045\n",
      "454442\n",
      "Parameter containing:\n",
      "tensor([-6.0380, -5.4059, -6.0812, -5.7114, -6.3784, -5.9141],\n",
      "       requires_grad=True)\n",
      "[-112.6136]\n",
      "[4.3008766]\n",
      "tensor(210.6022, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.75161828  0.07192208 -0.78558968  0.76713836  0.7895489   0.79472679]\n",
      "variance_average : [0.0578027  0.12401806 0.04117813 0.14329242 0.07880188 0.08056285]\n",
      "training idx 1 actor true_reward at iteration 3830 : 18.500840629408938\n",
      "454818\n",
      "Parameter containing:\n",
      "tensor([-6.0329, -5.3899, -6.0573, -5.7216, -6.3799, -5.8829],\n",
      "       requires_grad=True)\n",
      "[-186.61932]\n",
      "[5.0228148]\n",
      "tensor(209.4886, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83965298  0.17773364 -0.83802797  0.863119    0.83347629  0.86703715]\n",
      "variance_average : [0.07233637 0.08568456 0.27991831 0.07999862 0.0698941  0.08418698]\n",
      "training idx 1 actor true_reward at iteration 3840 : 20.596878153700505\n",
      "455235\n",
      "Parameter containing:\n",
      "tensor([-6.0337, -5.3870, -6.0463, -5.7175, -6.3793, -5.8711],\n",
      "       requires_grad=True)\n",
      "[71.10301]\n",
      "[0.73489434]\n",
      "tensor(192.8741, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83380013  0.37121327 -0.82223998  0.8026171   0.82435066  0.89444706]\n",
      "variance_average : [0.0448223  0.20140783 0.12638173 0.07916809 0.2834456  0.15960016]\n",
      "training idx 1 actor true_reward at iteration 3850 : 9.767964930186162\n",
      "455555\n",
      "Parameter containing:\n",
      "tensor([-6.0411, -5.3934, -6.0509, -5.7016, -6.3781, -5.8770],\n",
      "       requires_grad=True)\n",
      "[-214.13321]\n",
      "[4.918633]\n",
      "tensor(208.4633, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88518216  0.16625441 -0.85373909  0.80027733  0.9037957   0.81301632]\n",
      "variance_average : [0.09440559 0.10197384 0.177886   0.04555579 0.2253116  0.12945361]\n",
      "training idx 1 actor true_reward at iteration 3860 : 17.860589512041628\n",
      "455859\n",
      "Parameter containing:\n",
      "tensor([-6.0307, -5.3795, -6.0409, -5.6952, -6.3654, -5.8597],\n",
      "       requires_grad=True)\n",
      "[-82.36893]\n",
      "[4.6885047]\n",
      "tensor(240.3017, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.776608    0.11940869 -0.91561799  0.7966881   0.90309614  0.88163334]\n",
      "variance_average : [0.04043897 0.05350643 0.21391479 0.07795807 0.11467212 0.09407619]\n",
      "training idx 1 actor true_reward at iteration 3870 : 14.716986095457422\n",
      "456249\n",
      "Parameter containing:\n",
      "tensor([-6.0319, -5.3733, -6.0389, -5.6899, -6.3598, -5.8584],\n",
      "       requires_grad=True)\n",
      "[-254.10263]\n",
      "[9.373631]\n",
      "tensor(257.5223, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88947904  0.08557656 -0.87097171  0.85170346  0.88307786  0.8068313 ]\n",
      "variance_average : [0.11634075 0.03997024 0.07555308 0.04556934 0.04008663 0.07028344]\n",
      "training idx 1 actor true_reward at iteration 3880 : 19.377100601601224\n",
      "456641\n",
      "Parameter containing:\n",
      "tensor([-6.0283, -5.3798, -6.0318, -5.6870, -6.3615, -5.8455],\n",
      "       requires_grad=True)\n",
      "[142.54123]\n",
      "[3.5943673]\n",
      "tensor(225.2038, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88126135 -0.0194132  -0.86663281  0.84912501  0.87041189  0.80663864]\n",
      "variance_average : [0.07632091 0.24712102 0.12511762 0.05400336 0.03218226 0.10008333]\n",
      "training idx 1 actor true_reward at iteration 3890 : 10.35996720428743\n",
      "456950\n",
      "Parameter containing:\n",
      "tensor([-6.0206, -5.3969, -6.0312, -5.6920, -6.3535, -5.8470],\n",
      "       requires_grad=True)\n",
      "[-109.18612]\n",
      "[4.2082124]\n",
      "tensor(369.9092, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87391129  0.09431783 -0.92455987  0.93934779  0.94064182  0.86145601]\n",
      "variance_average : [0.07658669 0.07875875 0.04733254 0.02154252 0.16295025 0.12240287]\n",
      "training idx 1 actor true_reward at iteration 3900 : 16.66681214697639\n",
      "457307\n",
      "Parameter containing:\n",
      "tensor([-6.0148, -5.3958, -6.0073, -5.6740, -6.3613, -5.8348],\n",
      "       requires_grad=True)\n",
      "[20.95288]\n",
      "[8.684477]\n",
      "tensor(230.8733, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86419068  0.26239167 -0.82965201  0.84812429  0.88646194  0.87644213]\n",
      "variance_average : [0.12992839 0.14039973 0.10404502 0.12270664 0.10332992 0.10823974]\n",
      "training idx 1 actor true_reward at iteration 3910 : 11.273733784814237\n",
      "457657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-6.0166, -5.3937, -6.0058, -5.6725, -6.3678, -5.8375],\n",
      "       requires_grad=True)\n",
      "[-179.72531]\n",
      "[10.896787]\n",
      "tensor(242.9126, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83926902  0.19551884 -0.87548951  0.88889956  0.8123169   0.80950858]\n",
      "variance_average : [0.05427954 0.0571466  0.07928624 0.04409076 0.02946681 0.08980039]\n",
      "training idx 1 actor true_reward at iteration 3920 : 16.313499205201897\n",
      "457986\n",
      "Parameter containing:\n",
      "tensor([-5.9991, -5.3943, -6.0026, -5.6601, -6.3681, -5.8326],\n",
      "       requires_grad=True)\n",
      "[54.541]\n",
      "[1.719204]\n",
      "tensor(85.0611, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.69504264 -0.1942999  -0.69892416  0.69430379  0.62198147  0.62764233]\n",
      "variance_average : [0.36744291 0.37597042 0.05713822 0.40349044 0.29224682 0.18944146]\n",
      "training idx 1 actor true_reward at iteration 3930 : 12.543391449578989\n",
      "458412\n",
      "Parameter containing:\n",
      "tensor([-5.9914, -5.3763, -5.9936, -5.6647, -6.3668, -5.8201],\n",
      "       requires_grad=True)\n",
      "[-96.88356]\n",
      "[3.8762019]\n",
      "tensor(187.5415, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87037178  0.22810103 -0.80675723  0.84154705  0.84858251  0.79535775]\n",
      "variance_average : [0.05010497 0.0711623  0.144018   0.06091315 0.19236946 0.07843965]\n",
      "training idx 1 actor true_reward at iteration 3940 : 17.386076232174936\n",
      "458742\n",
      "Parameter containing:\n",
      "tensor([-5.9757, -5.3706, -6.0067, -5.6613, -6.3745, -5.8129],\n",
      "       requires_grad=True)\n",
      "[75.15143]\n",
      "[9.421035]\n",
      "tensor(139.5378, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.74396246  0.51981769 -0.90998867  0.67884334  0.86486355  0.75841265]\n",
      "variance_average : [0.1024059  0.20881157 0.06431307 0.14891402 0.2778773  0.20424522]\n",
      "training idx 1 actor true_reward at iteration 3950 : 12.247623456576306\n",
      "459085\n",
      "Parameter containing:\n",
      "tensor([-5.9731, -5.3696, -6.0105, -5.6773, -6.3713, -5.8160],\n",
      "       requires_grad=True)\n",
      "[-114.37007]\n",
      "[12.463522]\n",
      "tensor(254.7537, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89207302  0.26588302 -0.81217513  0.81500067  0.95219301  0.83219888]\n",
      "variance_average : [0.22639946 0.11275804 0.07484275 0.03242382 0.10759347 0.10753025]\n",
      "training idx 1 actor true_reward at iteration 3960 : 18.106211672093433\n",
      "459441\n",
      "Parameter containing:\n",
      "tensor([-5.9653, -5.3584, -6.0238, -5.6707, -6.3830, -5.8072],\n",
      "       requires_grad=True)\n",
      "[-70.95602]\n",
      "[11.192107]\n",
      "tensor(556.0362, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90056882  0.10206044 -0.98413119  0.95634756  0.94690742  0.90418195]\n",
      "variance_average : [0.07462719 0.02237633 0.04396113 0.08024583 0.04017565 0.01182862]\n",
      "training idx 1 actor true_reward at iteration 3970 : 13.211510690303113\n",
      "459815\n",
      "Parameter containing:\n",
      "tensor([-5.9599, -5.3443, -6.0231, -5.6703, -6.3881, -5.7989],\n",
      "       requires_grad=True)\n",
      "[-95.14242]\n",
      "[2.2689452]\n",
      "tensor(207.0921, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.81418069  0.15325462 -0.88087046  0.80000049  0.82073062  0.851847  ]\n",
      "variance_average : [0.17003443 0.30763281 0.08290168 0.06649088 0.2163797  0.1435389 ]\n",
      "training idx 1 actor true_reward at iteration 3980 : 18.198910399997455\n",
      "460217\n",
      "Parameter containing:\n",
      "tensor([-5.9482, -5.3407, -6.0228, -5.6528, -6.3844, -5.7999],\n",
      "       requires_grad=True)\n",
      "[-1.2000405]\n",
      "[0.6507127]\n",
      "tensor(163.1245, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87508618  0.08795159 -0.79481564  0.78218028  0.80329773  0.84595711]\n",
      "variance_average : [0.18878196 0.05626482 0.20720571 0.10206119 0.10504677 0.14476785]\n",
      "training idx 1 actor true_reward at iteration 3990 : 17.11896061330899\n",
      "460590\n",
      "Parameter containing:\n",
      "tensor([-5.9434, -5.3373, -6.0296, -5.6633, -6.3781, -5.8030],\n",
      "       requires_grad=True)\n",
      "[-75.540665]\n",
      "[27.819681]\n",
      "tensor(631.7624, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93013807 -0.06189333 -0.92995899  0.91965308  0.94623664  0.92501863]\n",
      "variance_average : [0.02771013 0.08415462 0.0584443  0.04267078 0.04531484 0.01649713]\n",
      "training idx 1 actor true_reward at iteration 4000 : 19.964054115111043\n",
      "461031\n",
      "Parameter containing:\n",
      "tensor([-5.9499, -5.3389, -6.0344, -5.6652, -6.3751, -5.8012],\n",
      "       requires_grad=True)\n",
      "[20.960598]\n",
      "[18.699965]\n",
      "tensor(322.7316, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9081883   0.01653774 -0.92496332  0.90477417  0.87130562  0.85050729]\n",
      "variance_average : [0.19464197 0.07259913 0.0580725  0.17454034 0.07118206 0.06888403]\n",
      "training idx 1 actor true_reward at iteration 4010 : 13.778276001101286\n",
      "461411\n",
      "Parameter containing:\n",
      "tensor([-5.9607, -5.3481, -6.0290, -5.6654, -6.3746, -5.8128],\n",
      "       requires_grad=True)\n",
      "[-330.55212]\n",
      "[8.642332]\n",
      "tensor(301.7439, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.91499119 -0.05959758 -0.87889977  0.9133928   0.90202245  0.86537724]\n",
      "variance_average : [0.05684152 0.02852067 0.07857199 0.14542799 0.14528891 0.04813488]\n",
      "training idx 1 actor true_reward at iteration 4020 : 27.77281028770708\n",
      "461728\n",
      "Parameter containing:\n",
      "tensor([-5.9704, -5.3471, -6.0198, -5.6602, -6.3746, -5.8189],\n",
      "       requires_grad=True)\n",
      "[195.27805]\n",
      "[12.201725]\n",
      "tensor(72.3571, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.61242458  0.45368087 -0.5322907   0.68588062  0.61598755  0.51007284]\n",
      "variance_average : [0.36588477 0.12246987 0.07509184 0.13001777 0.20882091 0.28202204]\n",
      "training idx 1 actor true_reward at iteration 4030 : 8.906562277884879\n",
      "462191\n",
      "Parameter containing:\n",
      "tensor([-5.9575, -5.3286, -6.0121, -5.6563, -6.3638, -5.8115],\n",
      "       requires_grad=True)\n",
      "[-4.4624367]\n",
      "[7.567051]\n",
      "tensor(238.7711, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82164296  0.21582784 -0.86789305  0.88345162  0.83718537  0.86038411]\n",
      "variance_average : [0.06676847 0.21725742 0.04129004 0.0920562  0.18898213 0.17240028]\n",
      "training idx 1 actor true_reward at iteration 4040 : 13.131561058566994\n",
      "462597\n",
      "Parameter containing:\n",
      "tensor([-5.9405, -5.3394, -6.0070, -5.6555, -6.3582, -5.7986],\n",
      "       requires_grad=True)\n",
      "[14.352339]\n",
      "[4.327598]\n",
      "tensor(209.5558, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86614895  0.34998428 -0.80457998  0.94086877  0.8596901   0.87314204]\n",
      "variance_average : [0.03938231 0.1899881  0.07608243 0.07846401 0.20299142 0.08427213]\n",
      "training idx 1 actor true_reward at iteration 4050 : 13.086370703713733\n",
      "462907\n",
      "Parameter containing:\n",
      "tensor([-5.9196, -5.3386, -5.9814, -5.6492, -6.3664, -5.8146],\n",
      "       requires_grad=True)\n",
      "[-169.00754]\n",
      "[7.4479446]\n",
      "tensor(233.6573, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87184519  0.19828791 -0.88496728  0.80214468  0.83428001  0.87205598]\n",
      "variance_average : [0.03617951 0.12631795 0.14514198 0.1561359  0.03167508 0.04928463]\n",
      "training idx 1 actor true_reward at iteration 4060 : 16.608735103651142\n",
      "463293\n",
      "Parameter containing:\n",
      "tensor([-5.9188, -5.3383, -5.9764, -5.6486, -6.3670, -5.8139],\n",
      "       requires_grad=True)\n",
      "[-418.8631]\n",
      "[18.812675]\n",
      "tensor(531.5297, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92687066 -0.1996581  -0.91034147  0.96132272  0.95342182  0.86647624]\n",
      "variance_average : [0.05373648 0.06979687 0.04357554 0.04526374 0.04516595 0.04432513]\n",
      "training idx 1 actor true_reward at iteration 4070 : 30.233177083169576\n",
      "463682\n",
      "Parameter containing:\n",
      "tensor([-5.9016, -5.3309, -5.9736, -5.6455, -6.3635, -5.8094],\n",
      "       requires_grad=True)\n",
      "[63.21527]\n",
      "[5.820375]\n",
      "tensor(247.2811, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.77797735 -0.10252024 -0.8226737   0.77936302  0.82371461  0.85011435]\n",
      "variance_average : [0.07017261 0.11688139 0.15608274 0.04498912 0.12029657 0.09728759]\n",
      "training idx 1 actor true_reward at iteration 4080 : 9.67141632046071\n",
      "464046\n",
      "Parameter containing:\n",
      "tensor([-5.8973, -5.3178, -5.9651, -5.6408, -6.3553, -5.7985],\n",
      "       requires_grad=True)\n",
      "[-291.97055]\n",
      "[12.829332]\n",
      "tensor(178.5047, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.81974562 -0.07600059 -0.86473001  0.82123959  0.77861395  0.84307043]\n",
      "variance_average : [0.16586828 0.20013588 0.07893047 0.08023987 0.04147709 0.25498075]\n",
      "training idx 1 actor true_reward at iteration 4090 : 23.494627508911954\n",
      "464445\n",
      "Parameter containing:\n",
      "tensor([-5.8941, -5.3087, -5.9604, -5.6318, -6.3545, -5.7954],\n",
      "       requires_grad=True)\n",
      "[-8.523898]\n",
      "[2.6254482]\n",
      "tensor(188.5505, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93785942  0.00126331 -0.75330482  0.78818399  0.92743489  0.71863278]\n",
      "variance_average : [0.08899057 0.06391453 0.10833238 0.11088874 0.06375521 0.03954058]\n",
      "training idx 1 actor true_reward at iteration 4100 : 13.630747930272445\n",
      "464905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.8838, -5.3047, -5.9617, -5.6246, -6.3553, -5.7982],\n",
      "       requires_grad=True)\n",
      "[-385.32953]\n",
      "[18.320524]\n",
      "tensor(356.2577, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93536651 -0.34673128 -0.89397616  0.86751087  0.92485147  0.92474402]\n",
      "variance_average : [0.06478959 0.08200193 0.063294   0.0467479  0.11436981 0.01526247]\n",
      "training idx 1 actor true_reward at iteration 4110 : 23.071219259086433\n",
      "465263\n",
      "Parameter containing:\n",
      "tensor([-5.9047, -5.2875, -5.9629, -5.6322, -6.3675, -5.7917],\n",
      "       requires_grad=True)\n",
      "[17.573944]\n",
      "[16.792892]\n",
      "tensor(539.1085, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95546302 -0.52791034 -0.93786084  0.92348898  0.93093355  0.87777036]\n",
      "variance_average : [0.06174781 0.11185222 0.06819021 0.01319892 0.04741425 0.05201355]\n",
      "training idx 1 actor true_reward at iteration 4120 : 8.983717092710377\n",
      "465756\n",
      "Parameter containing:\n",
      "tensor([-5.9013, -5.2673, -5.9671, -5.6179, -6.3715, -5.7824],\n",
      "       requires_grad=True)\n",
      "[-297.46783]\n",
      "[9.441059]\n",
      "tensor(271.3008, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88244734 -0.25186812 -0.92826941  0.89101613  0.83060985  0.87510884]\n",
      "variance_average : [0.06016346 0.03423627 0.10944248 0.04795036 0.1014973  0.1506605 ]\n",
      "training idx 1 actor true_reward at iteration 4130 : 21.42081308298884\n",
      "466169\n",
      "Parameter containing:\n",
      "tensor([-5.9083, -5.2806, -5.9748, -5.6292, -6.3863, -5.7832],\n",
      "       requires_grad=True)\n",
      "[17.429043]\n",
      "[43.210934]\n",
      "tensor(222.2454, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8893465   0.12173686 -0.84710119  0.86851168  0.87184146  0.86102418]\n",
      "variance_average : [0.17326924 0.07932338 0.20342864 0.13686813 0.166948   0.12334704]\n",
      "training idx 1 actor true_reward at iteration 4140 : 6.824036260834074\n",
      "466596\n",
      "Parameter containing:\n",
      "tensor([-5.8843, -5.2845, -5.9499, -5.6191, -6.3717, -5.7774],\n",
      "       requires_grad=True)\n",
      "[-214.81793]\n",
      "[5.7341585]\n",
      "tensor(177.6397, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86112401  0.12374393 -0.81525758  0.84206131  0.84428404  0.78180976]\n",
      "variance_average : [0.04953873 0.26858378 0.15006427 0.14683037 0.17658607 0.10190502]\n",
      "training idx 1 actor true_reward at iteration 4150 : 20.12977276006342\n",
      "467000\n",
      "Parameter containing:\n",
      "tensor([-5.8924, -5.2857, -5.9492, -5.6209, -6.3730, -5.7839],\n",
      "       requires_grad=True)\n",
      "[-187.06293]\n",
      "[10.712568]\n",
      "tensor(210.3585, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86310645  0.28346481 -0.82992204  0.85592512  0.86377894  0.83357218]\n",
      "variance_average : [0.05994278 0.18986677 0.15801436 0.05556182 0.12973134 0.02645949]\n",
      "training idx 1 actor true_reward at iteration 4160 : 18.279112566038116\n",
      "467466\n",
      "Parameter containing:\n",
      "tensor([-5.8719, -5.2684, -5.9641, -5.6167, -6.3806, -5.7722],\n",
      "       requires_grad=True)\n",
      "[-176.31665]\n",
      "[9.560036]\n",
      "tensor(455.5991, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92806438 -0.06357337 -0.9543478   0.91158094  0.93506368  0.84679224]\n",
      "variance_average : [0.04588858 0.02393994 0.06952701 0.07271875 0.0695423  0.03460004]\n",
      "training idx 1 actor true_reward at iteration 4170 : 17.13222794051101\n",
      "467940\n",
      "Parameter containing:\n",
      "tensor([-5.8729, -5.2656, -5.9659, -5.6172, -6.3801, -5.7731],\n",
      "       requires_grad=True)\n",
      "[185.78497]\n",
      "[6.298781]\n",
      "tensor(440.2939, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93694409 -0.11392384 -0.94284545  0.92267872  0.91851223  0.90118247]\n",
      "variance_average : [0.06581492 0.09037479 0.08116108 0.02962143 0.01870482 0.05604843]\n",
      "training idx 1 actor true_reward at iteration 4180 : 8.722904015093441\n",
      "468334\n",
      "Parameter containing:\n",
      "tensor([-5.8701, -5.2531, -5.9602, -5.6122, -6.3777, -5.7649],\n",
      "       requires_grad=True)\n",
      "[137.57053]\n",
      "[5.8123074]\n",
      "tensor(209.3031, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82384269  0.1424389  -0.87242923  0.78827586  0.82021915  0.71206962]\n",
      "variance_average : [0.08985425 0.13900087 0.18697805 0.02768864 0.1323045  0.11502347]\n",
      "training idx 1 actor true_reward at iteration 4190 : 11.812461599138498\n",
      "468737\n",
      "Parameter containing:\n",
      "tensor([-5.8657, -5.2463, -5.9492, -5.6024, -6.3785, -5.7695],\n",
      "       requires_grad=True)\n",
      "[-13.46551]\n",
      "[6.8692946]\n",
      "tensor(179.0658, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.77902725  0.0566029  -0.76236721  0.79536047  0.8543054   0.83575304]\n",
      "variance_average : [0.18818944 0.18996841 0.09403528 0.05083426 0.03828844 0.19403855]\n",
      "training idx 1 actor true_reward at iteration 4200 : 14.46223350788462\n",
      "469051\n",
      "Parameter containing:\n",
      "tensor([-5.8753, -5.2534, -5.9591, -5.6153, -6.3907, -5.7733],\n",
      "       requires_grad=True)\n",
      "[-106.33991]\n",
      "[3.159262]\n",
      "tensor(199.4808, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.85471169  0.07996275 -0.80317784  0.80399127  0.89772687  0.9018561 ]\n",
      "variance_average : [0.05297419 0.21915525 0.18326513 0.20411388 0.10574677 0.2169608 ]\n",
      "training idx 1 actor true_reward at iteration 4210 : 20.162444090643667\n",
      "469498\n",
      "Parameter containing:\n",
      "tensor([-5.8757, -5.2485, -5.9651, -5.6089, -6.3935, -5.7771],\n",
      "       requires_grad=True)\n",
      "[-181.22519]\n",
      "[6.503946]\n",
      "tensor(247.2913, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88904306  0.03926086 -0.80348917  0.84230653  0.85582291  0.92462119]\n",
      "variance_average : [0.03447407 0.11613847 0.10848749 0.12912432 0.12207729 0.09747726]\n",
      "training idx 1 actor true_reward at iteration 4220 : 18.4000834216992\n",
      "469873\n",
      "Parameter containing:\n",
      "tensor([-5.8742, -5.2454, -5.9634, -5.5996, -6.3905, -5.7706],\n",
      "       requires_grad=True)\n",
      "[-115.0706]\n",
      "[1.4544383]\n",
      "tensor(240.2716, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92310894 -0.03836882 -0.87519735  0.83088517  0.85615965  0.88109641]\n",
      "variance_average : [0.11687226 0.0215975  0.13827249 0.08826079 0.10880038 0.11981981]\n",
      "training idx 1 actor true_reward at iteration 4230 : 16.695416301439035\n",
      "470194\n",
      "Parameter containing:\n",
      "tensor([-5.8755, -5.2370, -5.9645, -5.6036, -6.3921, -5.7887],\n",
      "       requires_grad=True)\n",
      "[-1227.1016]\n",
      "[89.70965]\n",
      "tensor(522.8391, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93138157  0.20654845 -0.95389103  0.9422971   0.93721381  0.97240386]\n",
      "variance_average : [0.06896911 0.05432687 0.11915816 0.02849028 0.05947113 0.05768844]\n",
      "training idx 1 actor true_reward at iteration 4240 : 52.76376506459904\n",
      "470574\n",
      "Parameter containing:\n",
      "tensor([-5.8699, -5.2426, -5.9622, -5.6044, -6.3922, -5.8033],\n",
      "       requires_grad=True)\n",
      "[-158.32013]\n",
      "[6.0328107]\n",
      "tensor(244.9760, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86853604  0.15473483 -0.82531799  0.80440796  0.86656197  0.84914939]\n",
      "variance_average : [0.06742776 0.15107597 0.16650884 0.10681605 0.147407   0.25248496]\n",
      "training idx 1 actor true_reward at iteration 4250 : 19.241087951082246\n",
      "470918\n",
      "Parameter containing:\n",
      "tensor([-5.8661, -5.2306, -5.9428, -5.6014, -6.3842, -5.8004],\n",
      "       requires_grad=True)\n",
      "[-137.9108]\n",
      "[4.744847]\n",
      "tensor(237.6204, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89000333  0.03177202 -0.86280836  0.85451685  0.86981061  0.82450245]\n",
      "variance_average : [0.22040006 0.06591739 0.0716817  0.17460216 0.18293103 0.17044245]\n",
      "training idx 1 actor true_reward at iteration 4260 : 19.59678311439833\n",
      "471240\n",
      "Parameter containing:\n",
      "tensor([-5.8648, -5.2224, -5.9425, -5.6023, -6.3822, -5.8022],\n",
      "       requires_grad=True)\n",
      "[144.35893]\n",
      "[5.874851]\n",
      "tensor(216.1094, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82640254  0.1563708  -0.85707624  0.84248087  0.83495412  0.84921539]\n",
      "variance_average : [0.26599011 0.10314611 0.0269781  0.24391349 0.09217185 0.11951719]\n",
      "training idx 1 actor true_reward at iteration 4270 : 8.134764458914738\n",
      "471656\n",
      "Parameter containing:\n",
      "tensor([-5.8489, -5.2080, -5.9325, -5.6055, -6.3710, -5.7831],\n",
      "       requires_grad=True)\n",
      "[-513.03625]\n",
      "[17.144188]\n",
      "tensor(407.7772, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88880047  0.03099512 -0.91741454  0.91866317  0.91753182  0.86663395]\n",
      "variance_average : [0.054937   0.12867409 0.12238938 0.06621735 0.05727915 0.03914395]\n",
      "training idx 1 actor true_reward at iteration 4280 : 34.77159220287893\n",
      "472137\n",
      "Parameter containing:\n",
      "tensor([-5.8422, -5.2158, -5.9352, -5.6122, -6.3739, -5.7848],\n",
      "       requires_grad=True)\n",
      "[-289.31265]\n",
      "[21.132372]\n",
      "tensor(319.2963, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89180206 -0.41987299 -0.90230121  0.86854846  0.89312475  0.87729451]\n",
      "variance_average : [0.05455773 0.04893104 0.04162296 0.16056248 0.01795553 0.03561949]\n",
      "training idx 1 actor true_reward at iteration 4290 : 29.033357207634044\n",
      "472453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.8449, -5.2113, -5.9547, -5.6064, -6.3888, -5.7921],\n",
      "       requires_grad=True)\n",
      "[38.497288]\n",
      "[4.54392]\n",
      "tensor(262.7063, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87453148 -0.12616875 -0.8780906   0.85233548  0.89060319  0.8667118 ]\n",
      "variance_average : [0.15084036 0.14326742 0.08479356 0.08210361 0.07763962 0.04050988]\n",
      "training idx 1 actor true_reward at iteration 4300 : 14.019251570044718\n",
      "472811\n",
      "Parameter containing:\n",
      "tensor([-5.8390, -5.2069, -5.9559, -5.6077, -6.3824, -5.7937],\n",
      "       requires_grad=True)\n",
      "[299.44305]\n",
      "[10.999596]\n",
      "tensor(216.6110, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82570767 -0.03873567 -0.84072846  0.84077811  0.83585479  0.84454575]\n",
      "variance_average : [0.24341916 0.11903566 0.17488534 0.04944146 0.0490222  0.09801905]\n",
      "training idx 1 actor true_reward at iteration 4310 : 8.27825226583528\n",
      "473277\n",
      "Parameter containing:\n",
      "tensor([-5.8639, -5.2088, -5.9618, -5.6098, -6.3802, -5.8038],\n",
      "       requires_grad=True)\n",
      "[-185.32816]\n",
      "[9.549185]\n",
      "tensor(518.8144, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94996104 -0.26155383 -0.94400125  0.96417964  0.92171561  0.9563807 ]\n",
      "variance_average : [0.04974101 0.02607506 0.01073577 0.06357217 0.10113572 0.01373735]\n",
      "training idx 1 actor true_reward at iteration 4320 : 19.89949204882149\n",
      "473686\n",
      "Parameter containing:\n",
      "tensor([-5.8563, -5.2121, -5.9584, -5.6067, -6.3678, -5.7981],\n",
      "       requires_grad=True)\n",
      "[163.73463]\n",
      "[14.173902]\n",
      "tensor(247.9789, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87490757  0.14156515 -0.86509773  0.8674701   0.8402816   0.87865856]\n",
      "variance_average : [0.07911625 0.07350255 0.07064021 0.09831963 0.14869664 0.05588491]\n",
      "training idx 1 actor true_reward at iteration 4330 : 8.421917477992368\n",
      "474085\n",
      "Parameter containing:\n",
      "tensor([-5.8520, -5.2108, -5.9453, -5.6136, -6.3678, -5.7994],\n",
      "       requires_grad=True)\n",
      "[-3.4620757]\n",
      "[9.248732]\n",
      "tensor(285.1880, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89145763  0.0109561  -0.86838112  0.87399844  0.88102447  0.86496877]\n",
      "variance_average : [0.11597433 0.06955301 0.08129505 0.0837124  0.10525439 0.0952952 ]\n",
      "training idx 1 actor true_reward at iteration 4340 : 15.912805864195128\n",
      "474548\n",
      "Parameter containing:\n",
      "tensor([-5.8417, -5.2129, -5.9434, -5.6126, -6.3575, -5.7972],\n",
      "       requires_grad=True)\n",
      "[72.870186]\n",
      "[4.5418725]\n",
      "tensor(192.6337, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84532478  0.16835311 -0.76835934  0.83634097  0.77013106  0.8542441 ]\n",
      "variance_average : [0.21844008 0.09012195 0.04512665 0.15814708 0.22436017 0.16481686]\n",
      "training idx 1 actor true_reward at iteration 4350 : 13.29750598618373\n",
      "474904\n",
      "Parameter containing:\n",
      "tensor([-5.8389, -5.2064, -5.9322, -5.6037, -6.3681, -5.7889],\n",
      "       requires_grad=True)\n",
      "[-47.29732]\n",
      "[7.8646293]\n",
      "tensor(271.0011, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89575952  0.08533306 -0.9019306   0.90328989  0.87430829  0.90261809]\n",
      "variance_average : [0.0573506  0.16624925 0.06658853 0.13328389 0.08124851 0.03243412]\n",
      "training idx 1 actor true_reward at iteration 4360 : 17.457389958809095\n",
      "475297\n",
      "Parameter containing:\n",
      "tensor([-5.8246, -5.1832, -5.9325, -5.6232, -6.3630, -5.7778],\n",
      "       requires_grad=True)\n",
      "[-158.93985]\n",
      "[4.1992316]\n",
      "tensor(283.9642, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92506082 -0.13664657 -0.8838833   0.94172365  0.92768615  0.82174355]\n",
      "variance_average : [0.11122662 0.08908804 0.17345204 0.07603518 0.1168866  0.1224358 ]\n",
      "training idx 1 actor true_reward at iteration 4370 : 26.859305005891517\n",
      "475674\n",
      "Parameter containing:\n",
      "tensor([-5.8286, -5.1834, -5.9383, -5.6054, -6.3648, -5.8079],\n",
      "       requires_grad=True)\n",
      "[-82.45472]\n",
      "[1.1735102]\n",
      "tensor(217.0123, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.8551663   0.12516295 -0.86389527  0.81398755  0.81557288  0.88078299]\n",
      "variance_average : [0.14730934 0.03926039 0.2461124  0.14266832 0.05399419 0.07354489]\n",
      "training idx 1 actor true_reward at iteration 4380 : 19.528711772317696\n",
      "476060\n",
      "Parameter containing:\n",
      "tensor([-5.8221, -5.1764, -5.9601, -5.5927, -6.3593, -5.8041],\n",
      "       requires_grad=True)\n",
      "[188.62035]\n",
      "[11.65348]\n",
      "tensor(53.3806, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.68951128 -0.06940729 -0.57643018  0.55396173  0.65306706  0.58802734]\n",
      "variance_average : [0.18048227 0.37074489 0.49595666 0.33120494 0.39835354 0.50631198]\n",
      "training idx 1 actor true_reward at iteration 4390 : 7.14467135791646\n",
      "476491\n",
      "Parameter containing:\n",
      "tensor([-5.8155, -5.1646, -5.9463, -5.5876, -6.3459, -5.7960],\n",
      "       requires_grad=True)\n",
      "[-97.83246]\n",
      "[3.3875167]\n",
      "tensor(218.4669, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84009806  0.0658107  -0.82113952  0.83932666  0.89125147  0.82263649]\n",
      "variance_average : [0.15162381 0.12166665 0.0830976  0.05187003 0.04855252 0.04882635]\n",
      "training idx 1 actor true_reward at iteration 4400 : 22.714116386355734\n",
      "476903\n",
      "Parameter containing:\n",
      "tensor([-5.8103, -5.1616, -5.9373, -5.5838, -6.3312, -5.7933],\n",
      "       requires_grad=True)\n",
      "[-162.9071]\n",
      "[5.842992]\n",
      "tensor(222.4403, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87521712  0.04579498 -0.83763202  0.90361817  0.85576879  0.81864731]\n",
      "variance_average : [0.17008924 0.06472687 0.2066897  0.20989158 0.11999871 0.11318638]\n",
      "training idx 1 actor true_reward at iteration 4410 : 23.977446464359364\n",
      "477304\n",
      "Parameter containing:\n",
      "tensor([-5.8027, -5.1464, -5.9284, -5.5813, -6.3187, -5.7859],\n",
      "       requires_grad=True)\n",
      "[-223.13974]\n",
      "[13.685588]\n",
      "tensor(271.4000, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9233276   0.09821806 -0.84976693  0.92532396  0.86307741  0.86040186]\n",
      "variance_average : [0.0654872  0.17241911 0.06961062 0.04381812 0.0315795  0.13770183]\n",
      "training idx 1 actor true_reward at iteration 4420 : 21.476713419339408\n",
      "477694\n",
      "Parameter containing:\n",
      "tensor([-5.7954, -5.1398, -5.9044, -5.5830, -6.2974, -5.7931],\n",
      "       requires_grad=True)\n",
      "[238.67706]\n",
      "[10.061523]\n",
      "tensor(247.6957, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90643065 -0.08228714 -0.87846431  0.84798384  0.88550647  0.86821815]\n",
      "variance_average : [0.22464726 0.0742962  0.10812318 0.05282218 0.07090963 0.06591087]\n",
      "training idx 1 actor true_reward at iteration 4430 : 7.691488706541058\n",
      "478106\n",
      "Parameter containing:\n",
      "tensor([-5.7812, -5.1382, -5.9002, -5.5859, -6.2937, -5.7866],\n",
      "       requires_grad=True)\n",
      "[-77.21725]\n",
      "[2.0921493]\n",
      "tensor(193.8083, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83649883  0.12608599 -0.8524695   0.82185909  0.83599182  0.84351364]\n",
      "variance_average : [0.06103355 0.12420337 0.15113823 0.0804603  0.11765655 0.14804325]\n",
      "training idx 1 actor true_reward at iteration 4440 : 17.852455895663056\n",
      "478495\n",
      "Parameter containing:\n",
      "tensor([-5.7817, -5.1322, -5.8976, -5.5906, -6.2894, -5.7836],\n",
      "       requires_grad=True)\n",
      "[194.3779]\n",
      "[5.6360693]\n",
      "tensor(524.9457, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.93914974 -0.47568075 -0.95079181  0.95324207  0.9278605   0.9440611 ]\n",
      "variance_average : [0.04319306 0.0574002  0.04779252 0.02198907 0.0901928  0.02270929]\n",
      "training idx 1 actor true_reward at iteration 4450 : 6.822238258429491\n",
      "479002\n",
      "Parameter containing:\n",
      "tensor([-5.7791, -5.1232, -5.8894, -5.5869, -6.2844, -5.7851],\n",
      "       requires_grad=True)\n",
      "[156.87825]\n",
      "[2.646879]\n",
      "tensor(394.1829, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96663453 -0.13929539 -0.8729931   0.94075925  0.94200532  0.86277514]\n",
      "variance_average : [0.0363022  0.06768187 0.04066104 0.07326583 0.02508786 0.14495072]\n",
      "training idx 1 actor true_reward at iteration 4460 : 6.624976345762683\n",
      "479390\n",
      "Parameter containing:\n",
      "tensor([-5.7841, -5.1352, -5.8844, -5.5944, -6.2938, -5.7854],\n",
      "       requires_grad=True)\n",
      "[-180.92972]\n",
      "[9.688506]\n",
      "tensor(240.9296, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87814183  0.09735897 -0.81634513  0.88571632  0.87015034  0.9178193 ]\n",
      "variance_average : [0.09246977 0.03455748 0.05786138 0.07774987 0.27733584 0.05217844]\n",
      "training idx 1 actor true_reward at iteration 4470 : 22.581956046673085\n",
      "479730\n",
      "Parameter containing:\n",
      "tensor([-5.7655, -5.1337, -5.8756, -5.5803, -6.2771, -5.7734],\n",
      "       requires_grad=True)\n",
      "[249.83743]\n",
      "[18.052073]\n",
      "tensor(72.1398, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.81488057  0.33920278 -0.83199638  0.71741459  0.74896578  0.50527777]\n",
      "variance_average : [0.36609223 0.05695285 0.17342855 0.07514478 0.31522604 0.37398594]\n",
      "training idx 1 actor true_reward at iteration 4480 : 3.312806260198677\n",
      "480096\n",
      "Parameter containing:\n",
      "tensor([-5.7634, -5.1419, -5.8739, -5.5759, -6.2634, -5.7786],\n",
      "       requires_grad=True)\n",
      "[-153.1087]\n",
      "[3.5427384]\n",
      "tensor(240.5551, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90284579 -0.01216269 -0.89553976  0.89852629  0.83201322  0.87854245]\n",
      "variance_average : [0.24303237 0.03239187 0.08140262 0.1067175  0.09831032 0.04498234]\n",
      "training idx 1 actor true_reward at iteration 4490 : 18.29317189922218\n",
      "480514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.7639, -5.1362, -5.8757, -5.5747, -6.2566, -5.7871],\n",
      "       requires_grad=True)\n",
      "[-327.32867]\n",
      "[12.966717]\n",
      "tensor(403.8041, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89996868 -0.18810578 -0.90799577  0.89493768  0.88508447  0.88674144]\n",
      "variance_average : [0.02624499 0.0250471  0.07889471 0.05537874 0.04142736 0.02931296]\n",
      "training idx 1 actor true_reward at iteration 4500 : 24.60927211219906\n",
      "480939\n",
      "Parameter containing:\n",
      "tensor([-5.7599, -5.1286, -5.8790, -5.5693, -6.2459, -5.7914],\n",
      "       requires_grad=True)\n",
      "[-11.621117]\n",
      "[6.8756576]\n",
      "tensor(224.7539, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.80786307  0.61879321 -0.83349135  0.79704364  0.85692984  0.85077139]\n",
      "variance_average : [0.02506063 0.1259294  0.14787945 0.06446394 0.22010938 0.09722955]\n",
      "training idx 1 actor true_reward at iteration 4510 : 12.40539087670023\n",
      "481337\n",
      "Parameter containing:\n",
      "tensor([-5.7532, -5.1259, -5.8698, -5.5628, -6.2365, -5.7851],\n",
      "       requires_grad=True)\n",
      "[78.71414]\n",
      "[3.970493]\n",
      "tensor(232.2878, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86672248  0.20909109 -0.87255224  0.84181906  0.86950608  0.87135066]\n",
      "variance_average : [0.19204915 0.0683033  0.10074592 0.07804595 0.09277918 0.066269  ]\n",
      "training idx 1 actor true_reward at iteration 4520 : 10.644157104542744\n",
      "481676\n",
      "Parameter containing:\n",
      "tensor([-5.7474, -5.1212, -5.8659, -5.5691, -6.2267, -5.7843],\n",
      "       requires_grad=True)\n",
      "[150.1214]\n",
      "[10.490927]\n",
      "tensor(162.0095, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88807212 -0.08414042 -0.78312947  0.81428915  0.88813369  0.89034292]\n",
      "variance_average : [0.17004364 0.05913306 0.27652213 0.29246412 0.23292949 0.05499286]\n",
      "training idx 1 actor true_reward at iteration 4530 : 12.512407779932195\n",
      "482095\n",
      "Parameter containing:\n",
      "tensor([-5.7446, -5.1170, -5.8750, -5.5699, -6.2318, -5.7783],\n",
      "       requires_grad=True)\n",
      "[-140.27794]\n",
      "[5.80353]\n",
      "tensor(254.3352, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.89231886  0.07029093 -0.8594451   0.87980324  0.85859347  0.83255963]\n",
      "variance_average : [0.09153502 0.11983426 0.05931194 0.14786083 0.0926016  0.12212762]\n",
      "training idx 1 actor true_reward at iteration 4540 : 20.68567873394848\n",
      "482480\n",
      "Parameter containing:\n",
      "tensor([-5.7392, -5.1035, -5.8723, -5.5627, -6.2156, -5.7792],\n",
      "       requires_grad=True)\n",
      "[-255.68689]\n",
      "[10.787256]\n",
      "tensor(195.9087, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88537784 -0.06481446 -0.77863244  0.8529944   0.82462136  0.90358112]\n",
      "variance_average : [0.12808863 0.06131306 0.05499932 0.02464357 0.07388298 0.25087344]\n",
      "training idx 1 actor true_reward at iteration 4550 : 24.481772771254043\n",
      "482864\n",
      "Parameter containing:\n",
      "tensor([-5.7447, -5.1019, -5.8682, -5.5715, -6.2142, -5.7795],\n",
      "       requires_grad=True)\n",
      "[-66.520966]\n",
      "[1.9928415]\n",
      "tensor(203.6171, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84667203 -0.07296001 -0.85740495  0.87617243  0.81545485  0.8160702 ]\n",
      "variance_average : [0.05859672 0.07317061 0.11114372 0.06264174 0.16207527 0.03304964]\n",
      "training idx 1 actor true_reward at iteration 4560 : 16.889483575696687\n",
      "483176\n",
      "Parameter containing:\n",
      "tensor([-5.7486, -5.0976, -5.8699, -5.5803, -6.2151, -5.7787],\n",
      "       requires_grad=True)\n",
      "[-688.1901]\n",
      "[33.73516]\n",
      "tensor(332.5217, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95673248  0.34500133 -0.95175702  0.92783565  0.95515447  0.85536113]\n",
      "variance_average : [0.09276178 0.02538753 0.07715515 0.07866659 0.07001943 0.07612418]\n",
      "training idx 1 actor true_reward at iteration 4570 : 36.0440813440502\n",
      "483621\n",
      "Parameter containing:\n",
      "tensor([-5.7444, -5.0987, -5.8549, -5.5671, -6.1911, -5.7694],\n",
      "       requires_grad=True)\n",
      "[-102.719795]\n",
      "[4.3157797]\n",
      "tensor(230.8209, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92492707 -0.17636512 -0.86149546  0.82548206  0.86411302  0.8622988 ]\n",
      "variance_average : [0.04356797 0.16701172 0.05459398 0.21752461 0.23013033 0.13820581]\n",
      "training idx 1 actor true_reward at iteration 4580 : 17.843377046119056\n",
      "484014\n",
      "Parameter containing:\n",
      "tensor([-5.7379, -5.1035, -5.8491, -5.5726, -6.1902, -5.7652],\n",
      "       requires_grad=True)\n",
      "[-209.57095]\n",
      "[5.8756742]\n",
      "tensor(204.2129, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.849781    0.11583723 -0.8288038   0.84740771  0.84294087  0.71449445]\n",
      "variance_average : [0.06868458 0.0358419  0.13128978 0.05249296 0.06606934 0.07864874]\n",
      "training idx 1 actor true_reward at iteration 4590 : 23.82983343586885\n",
      "484446\n",
      "Parameter containing:\n",
      "tensor([-5.7224, -5.0988, -5.8393, -5.5644, -6.1725, -5.7592],\n",
      "       requires_grad=True)\n",
      "[-2.9445212]\n",
      "[7.616559]\n",
      "tensor(270.5919, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90967072 -0.16752749 -0.93172839  0.83867709  0.94744923  0.9219326 ]\n",
      "variance_average : [0.03751621 0.15034632 0.04474286 0.14300822 0.10167174 0.09145842]\n",
      "training idx 1 actor true_reward at iteration 4600 : 14.806443902911107\n",
      "484826\n",
      "Parameter containing:\n",
      "tensor([-5.7138, -5.0820, -5.8365, -5.5653, -6.1550, -5.7475],\n",
      "       requires_grad=True)\n",
      "[85.72735]\n",
      "[7.448836]\n",
      "tensor(225.6919, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82285037  0.22560858 -0.87444381  0.86243866  0.87222614  0.85286846]\n",
      "variance_average : [0.11638066 0.05306856 0.02450695 0.11961285 0.13180075 0.10569083]\n",
      "training idx 1 actor true_reward at iteration 4610 : 8.848585139692156\n",
      "485185\n",
      "Parameter containing:\n",
      "tensor([-5.7208, -5.0796, -5.8434, -5.5628, -6.1649, -5.7551],\n",
      "       requires_grad=True)\n",
      "[-282.95914]\n",
      "[21.17968]\n",
      "tensor(230.0876, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92441946  0.03995703 -0.86743434  0.89193942  0.79804228  0.77838461]\n",
      "variance_average : [0.17233471 0.19339147 0.11790298 0.17765903 0.11288324 0.0724966 ]\n",
      "training idx 1 actor true_reward at iteration 4620 : 20.55625490298748\n",
      "485509\n",
      "Parameter containing:\n",
      "tensor([-5.7248, -5.0754, -5.8484, -5.5653, -6.1800, -5.7599],\n",
      "       requires_grad=True)\n",
      "[64.12488]\n",
      "[1.5941789]\n",
      "tensor(207.9815, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82632836  0.12934543 -0.83754341  0.84210659  0.87837743  0.87870577]\n",
      "variance_average : [0.0749135  0.06007545 0.14021677 0.1129     0.23745693 0.21768655]\n",
      "training idx 1 actor true_reward at iteration 4630 : 12.911568877874888\n",
      "485892\n",
      "Parameter containing:\n",
      "tensor([-5.7203, -5.0707, -5.8473, -5.5829, -6.1766, -5.7713],\n",
      "       requires_grad=True)\n",
      "[-82.64463]\n",
      "[4.024826]\n",
      "tensor(181.1840, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84910908 -0.00308968 -0.89530134  0.75983179  0.82684707  0.86357635]\n",
      "variance_average : [0.08319481 0.06636367 0.12305792 0.07359859 0.0570836  0.0535497 ]\n",
      "training idx 1 actor true_reward at iteration 4640 : 18.878661317360265\n",
      "486221\n",
      "Parameter containing:\n",
      "tensor([-5.7203, -5.0745, -5.8454, -5.5889, -6.1765, -5.7770],\n",
      "       requires_grad=True)\n",
      "[-92.89044]\n",
      "[3.3939903]\n",
      "tensor(224.9418, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82508206 -0.06151493 -0.86739405  0.8934463   0.86037032  0.83359716]\n",
      "variance_average : [0.12097125 0.09558687 0.05014217 0.0736663  0.09017789 0.13832432]\n",
      "training idx 1 actor true_reward at iteration 4650 : 19.60878945962747\n",
      "486584\n",
      "Parameter containing:\n",
      "tensor([-5.7059, -5.0755, -5.8420, -5.5887, -6.1756, -5.7683],\n",
      "       requires_grad=True)\n",
      "[-43.53639]\n",
      "[6.2552695]\n",
      "tensor(217.7129, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90580217  0.11139533 -0.91529424  0.92845812  0.90941819  0.82736187]\n",
      "variance_average : [0.09419345 0.04698163 0.14252112 0.12700357 0.08358193 0.05978721]\n",
      "training idx 1 actor true_reward at iteration 4660 : 17.175404057588107\n",
      "486924\n",
      "Parameter containing:\n",
      "tensor([-5.7114, -5.0806, -5.8446, -5.5922, -6.1761, -5.7696],\n",
      "       requires_grad=True)\n",
      "[252.31871]\n",
      "[12.30918]\n",
      "tensor(184.7333, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90714485  0.46543999 -0.83100724  0.84069826  0.82616897  0.73947345]\n",
      "variance_average : [0.13251767 0.20795454 0.10185528 0.04732731 0.27321541 0.21516819]\n",
      "training idx 1 actor true_reward at iteration 4670 : 6.462329038404215\n",
      "487352\n",
      "Parameter containing:\n",
      "tensor([-5.7102, -5.0710, -5.8411, -5.5936, -6.1669, -5.7675],\n",
      "       requires_grad=True)\n",
      "[-0.19322515]\n",
      "[4.7577515]\n",
      "tensor(230.3150, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90809767  0.2094678  -0.87472681  0.90039551  0.86431588  0.85778303]\n",
      "variance_average : [0.17903664 0.18295439 0.07816607 0.1003049  0.12546131 0.14126591]\n",
      "training idx 1 actor true_reward at iteration 4680 : 15.86684592994021\n",
      "487733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.7045, -5.0716, -5.8406, -5.5906, -6.1668, -5.7634],\n",
      "       requires_grad=True)\n",
      "[-76.70998]\n",
      "[12.127002]\n",
      "tensor(307.5753, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.86497179 -0.32548474 -0.897964    0.90471208  0.87478528  0.92021911]\n",
      "variance_average : [0.10771599 0.05684291 0.13815709 0.0459976  0.09763953 0.19111457]\n",
      "training idx 1 actor true_reward at iteration 4690 : 22.57330029167596\n",
      "488110\n",
      "Parameter containing:\n",
      "tensor([-5.7038, -5.0614, -5.8396, -5.5982, -6.1658, -5.7660],\n",
      "       requires_grad=True)\n",
      "[-52.46454]\n",
      "[1.4832892]\n",
      "tensor(257.5648, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87411904 -0.05164402 -0.86900815  0.85321421  0.86854094  0.88145222]\n",
      "variance_average : [0.02543064 0.06519054 0.03158626 0.17771107 0.07863284 0.0591745 ]\n",
      "training idx 1 actor true_reward at iteration 4700 : 17.181444061133156\n",
      "488474\n",
      "Parameter containing:\n",
      "tensor([-5.7070, -5.0630, -5.8344, -5.6003, -6.1529, -5.7683],\n",
      "       requires_grad=True)\n",
      "[220.46802]\n",
      "[8.141012]\n",
      "tensor(255.7628, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.84986949  0.08903455 -0.83011825  0.90959324  0.88889666  0.72200885]\n",
      "variance_average : [0.06178933 0.1325113  0.11501133 0.07677166 0.02896808 0.12492984]\n",
      "training idx 1 actor true_reward at iteration 4710 : 9.415279803807865\n",
      "488862\n",
      "Parameter containing:\n",
      "tensor([-5.6841, -5.0512, -5.8109, -5.6115, -6.1402, -5.7496],\n",
      "       requires_grad=True)\n",
      "[-260.86493]\n",
      "[11.510346]\n",
      "tensor(410.1054, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90522078 -0.15564192 -0.90540753  0.9349856   0.97700583  0.82399848]\n",
      "variance_average : [0.04252441 0.03931619 0.026668   0.05294458 0.0840512  0.06336391]\n",
      "training idx 1 actor true_reward at iteration 4720 : 25.123802548238963\n",
      "489272\n",
      "Parameter containing:\n",
      "tensor([-5.6810, -5.0373, -5.8020, -5.6038, -6.1166, -5.7457],\n",
      "       requires_grad=True)\n",
      "[-54.63581]\n",
      "[5.643603]\n",
      "tensor(202.5695, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9052384   0.116646   -0.78585722  0.81675136  0.85883154  0.89377331]\n",
      "variance_average : [0.0336978  0.15642061 0.08059757 0.03204587 0.22622703 0.14799543]\n",
      "training idx 1 actor true_reward at iteration 4730 : 17.55547973024777\n",
      "489703\n",
      "Parameter containing:\n",
      "tensor([-5.6791, -5.0359, -5.8084, -5.6066, -6.1154, -5.7438],\n",
      "       requires_grad=True)\n",
      "[-157.50989]\n",
      "[6.3979273]\n",
      "tensor(171.9028, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.80561342  0.02278202 -0.79427432  0.81089917  0.8093288   0.81968671]\n",
      "variance_average : [0.21497994 0.15044322 0.10169828 0.06380429 0.07958454 0.05541088]\n",
      "training idx 1 actor true_reward at iteration 4740 : 22.42738451529879\n",
      "490062\n",
      "Parameter containing:\n",
      "tensor([-5.6593, -5.0299, -5.7857, -5.5980, -6.1047, -5.7299],\n",
      "       requires_grad=True)\n",
      "[-250.59015]\n",
      "[8.6959715]\n",
      "tensor(247.3699, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.9008553   0.12400979 -0.94333236  0.85120674  0.81064237  0.86820375]\n",
      "variance_average : [0.04280148 0.0981635  0.06489047 0.06448675 0.20629432 0.17016069]\n",
      "training idx 1 actor true_reward at iteration 4750 : 22.72752176298292\n",
      "490461\n",
      "Parameter containing:\n",
      "tensor([-5.6636, -5.0379, -5.7935, -5.6024, -6.1098, -5.7418],\n",
      "       requires_grad=True)\n",
      "[30.413445]\n",
      "[4.5899105]\n",
      "tensor(156.4700, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.80960141  0.07566362 -0.77344981  0.83007596  0.83882566  0.84278371]\n",
      "variance_average : [0.22593621 0.11457591 0.07394405 0.02899892 0.21011614 0.1307256 ]\n",
      "training idx 1 actor true_reward at iteration 4760 : 16.645016825643655\n",
      "490838\n",
      "Parameter containing:\n",
      "tensor([-5.6546, -5.0363, -5.7818, -5.6039, -6.1073, -5.7273],\n",
      "       requires_grad=True)\n",
      "[-101.08347]\n",
      "[6.1948166]\n",
      "tensor(233.7040, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.81428252 -0.15245356 -0.91421663  0.84020418  0.9101911   0.83882695]\n",
      "variance_average : [0.05097707 0.08976712 0.08668507 0.09892476 0.02469509 0.15924564]\n",
      "training idx 1 actor true_reward at iteration 4770 : 21.67795120563279\n",
      "491253\n",
      "Parameter containing:\n",
      "tensor([-5.6531, -5.0338, -5.7812, -5.6107, -6.1071, -5.7247],\n",
      "       requires_grad=True)\n",
      "[-8.023424]\n",
      "[3.1717775]\n",
      "tensor(327.2256, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.88385949 -0.26748026 -0.91688324  0.89794427  0.91061996  0.88953854]\n",
      "variance_average : [0.0195321  0.04767802 0.05934044 0.04185518 0.04724481 0.07239902]\n",
      "training idx 1 actor true_reward at iteration 4780 : 18.6084761545379\n",
      "491740\n",
      "Parameter containing:\n",
      "tensor([-5.6611, -5.0350, -5.7873, -5.6158, -6.1060, -5.7297],\n",
      "       requires_grad=True)\n",
      "[-74.15133]\n",
      "[15.40457]\n",
      "tensor(270.8664, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.85648256  0.27889214 -0.88312797  0.81718567  0.82852462  0.83594401]\n",
      "variance_average : [0.04843997 0.05728949 0.17497666 0.10576465 0.04249567 0.11690024]\n",
      "training idx 1 actor true_reward at iteration 4790 : 14.44307027355012\n",
      "492186\n",
      "Parameter containing:\n",
      "tensor([-5.6493, -5.0544, -5.7711, -5.5981, -6.0951, -5.7194],\n",
      "       requires_grad=True)\n",
      "[-445.51242]\n",
      "[18.011984]\n",
      "tensor(277.9733, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90810519 -0.10528111 -0.89539581  0.87788608  0.83737723  0.82819837]\n",
      "variance_average : [0.10455754 0.11930971 0.05045405 0.08833166 0.03931956 0.18071475]\n",
      "training idx 1 actor true_reward at iteration 4800 : 29.506912574852418\n",
      "493635\n",
      "Parameter containing:\n",
      "tensor([-5.6424, -5.0311, -5.7695, -5.5862, -6.0969, -5.7043],\n",
      "       requires_grad=True)\n",
      "[95.49106]\n",
      "[7.387888]\n",
      "tensor(217.7723, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.78112228  0.03209756 -0.89214016  0.88846     0.86791863  0.67903791]\n",
      "variance_average : [0.06217881 0.04304971 0.13705968 0.18419256 0.08913446 0.06264614]\n",
      "training idx 1 actor true_reward at iteration 4810 : 14.101993271302469\n",
      "494071\n",
      "Parameter containing:\n",
      "tensor([-5.6701, -5.0437, -5.7728, -5.5933, -6.1067, -5.7071],\n",
      "       requires_grad=True)\n",
      "[-38.229248]\n",
      "[8.508102]\n",
      "tensor(486.5774, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92079432 -0.46461235 -0.95045011  0.89594527  0.95399499  0.86414222]\n",
      "variance_average : [0.02678667 0.02921832 0.04955055 0.05460272 0.04885564 0.07247085]\n",
      "training idx 1 actor true_reward at iteration 4820 : 23.1230071839298\n",
      "494710\n",
      "Parameter containing:\n",
      "tensor([-5.6872, -5.0597, -5.7850, -5.6084, -6.1189, -5.7222],\n",
      "       requires_grad=True)\n",
      "[-360.59756]\n",
      "[8.444033]\n",
      "tensor(457.1340, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.92518588 -0.73508151 -0.88985061  0.96173121  0.91680516  0.90751748]\n",
      "variance_average : [0.09026461 0.02843406 0.11617399 0.02657209 0.02605407 0.01404746]\n",
      "training idx 1 actor true_reward at iteration 4830 : 32.72002624058314\n",
      "495701\n",
      "Parameter containing:\n",
      "tensor([-5.7212, -5.0864, -5.8143, -5.6269, -6.1399, -5.7507],\n",
      "       requires_grad=True)\n",
      "[-107.282936]\n",
      "[20.647139]\n",
      "tensor(1083.4979, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.97836925 -0.96576997 -0.95743457  0.9647894   0.95859936  0.9605661 ]\n",
      "variance_average : [0.03638159 0.0395307  0.04103318 0.01293679 0.04355961 0.04176273]\n",
      "training idx 1 actor true_reward at iteration 4840 : 33.174370649333554\n",
      "496740\n",
      "Parameter containing:\n",
      "tensor([-5.7187, -5.0694, -5.8175, -5.6150, -6.1234, -5.7768],\n",
      "       requires_grad=True)\n",
      "[-386.47586]\n",
      "[16.047401]\n",
      "tensor(546.4558, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94291843 -0.7520822  -0.93685703  0.96102964  0.91082344  0.92808784]\n",
      "variance_average : [0.07085789 0.05534859 0.04147963 0.07908884 0.05160186 0.02995373]\n",
      "training idx 1 actor true_reward at iteration 4850 : 31.950369993804987\n",
      "499299\n",
      "Parameter containing:\n",
      "tensor([-5.7755, -5.0856, -5.8376, -5.6518, -6.1713, -5.7692],\n",
      "       requires_grad=True)\n",
      "[-479.77625]\n",
      "[30.644829]\n",
      "tensor(515.5200, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.95360433 -0.69765506 -0.95838872  0.90723955  0.95656588  0.92444069]\n",
      "variance_average : [0.03219227 0.04153739 0.12908225 0.10665142 0.02527269 0.07040969]\n",
      "training idx 1 actor true_reward at iteration 4860 : 40.09144853891403\n",
      "500426\n",
      "Parameter containing:\n",
      "tensor([-5.7836, -5.0875, -5.8252, -5.6588, -6.2118, -5.7593],\n",
      "       requires_grad=True)\n",
      "[-322.2511]\n",
      "[15.941352]\n",
      "tensor(701.8315, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96097743 -0.8067921  -0.92741282  0.93299849  0.95019258  0.95082095]\n",
      "variance_average : [0.03618153 0.01599297 0.05127066 0.01793029 0.02166119 0.089032  ]\n",
      "training idx 1 actor true_reward at iteration 4870 : 31.809553594361255\n",
      "501494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([-5.8054, -5.1070, -5.8376, -5.6680, -6.2078, -5.7737],\n",
      "       requires_grad=True)\n",
      "[4.269421]\n",
      "[5.424818]\n",
      "tensor(361.9420, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90292845 -0.6829968  -0.91561668  0.90316314  0.91840904  0.92754685]\n",
      "variance_average : [0.07941017 0.04216459 0.07777896 0.10064991 0.08340538 0.08269762]\n",
      "training idx 1 actor true_reward at iteration 4880 : 24.846236178666537\n",
      "502499\n",
      "Parameter containing:\n",
      "tensor([-5.8028, -5.1038, -5.8400, -5.6733, -6.2090, -5.7591],\n",
      "       requires_grad=True)\n",
      "[-256.54538]\n",
      "[12.65002]\n",
      "tensor(224.0631, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.80576627 -0.07352181 -0.80037518  0.76975721  0.84127058  0.80365983]\n",
      "variance_average : [0.04626981 0.12696284 0.21627768 0.1122829  0.065104   0.13806126]\n",
      "training idx 1 actor true_reward at iteration 4890 : 25.370207899348127\n",
      "503265\n",
      "Parameter containing:\n",
      "tensor([-5.7781, -5.0797, -5.8308, -5.6834, -6.2134, -5.7478],\n",
      "       requires_grad=True)\n",
      "[114.50564]\n",
      "[9.168663]\n",
      "tensor(385.5317, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.90412753 -0.1833813  -0.92970569  0.92263385  0.91733854  0.87565309]\n",
      "variance_average : [0.07968823 0.15147411 0.10210736 0.02922274 0.0637581  0.03366396]\n",
      "training idx 1 actor true_reward at iteration 4900 : 19.46366899168679\n",
      "503830\n",
      "Parameter containing:\n",
      "tensor([-5.7562, -5.0581, -5.8208, -5.6742, -6.2026, -5.7279],\n",
      "       requires_grad=True)\n",
      "[365.50607]\n",
      "[26.649044]\n",
      "tensor(276.7887, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.85320445 -0.14180637 -0.84056946  0.91872142  0.89319166  0.96392833]\n",
      "variance_average : [0.15294597 0.1020278  0.09502945 0.14477661 0.08532462 0.07036783]\n",
      "training idx 1 actor true_reward at iteration 4910 : 2.894373627604569\n",
      "504305\n",
      "Parameter containing:\n",
      "tensor([-5.7554, -5.0503, -5.7896, -5.6579, -6.1851, -5.7160],\n",
      "       requires_grad=True)\n",
      "[-465.46274]\n",
      "[16.838207]\n",
      "tensor(456.7546, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.96581158 -0.34401373 -0.90275036  0.90732599  0.92847647  0.89106116]\n",
      "variance_average : [0.07290527 0.01699188 0.15661605 0.01789149 0.03354688 0.03635371]\n",
      "training idx 1 actor true_reward at iteration 4920 : 33.30389386019329\n",
      "504796\n",
      "Parameter containing:\n",
      "tensor([-5.7543, -5.0580, -5.7981, -5.6453, -6.1831, -5.7092],\n",
      "       requires_grad=True)\n",
      "[289.93115]\n",
      "[21.896904]\n",
      "tensor(431.7823, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.87115779 -0.25335482 -0.92635014  0.94542561  0.91966204  0.9086703 ]\n",
      "variance_average : [0.03180295 0.08414332 0.02490863 0.10154668 0.06127538 0.09036341]\n",
      "training idx 1 actor true_reward at iteration 4930 : 4.850760803698402\n",
      "505318\n",
      "Parameter containing:\n",
      "tensor([-5.7507, -5.0534, -5.7954, -5.6510, -6.1748, -5.7092],\n",
      "       requires_grad=True)\n",
      "[-69.06218]\n",
      "[9.582311]\n",
      "tensor(448.6708, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.91670734 -0.17382036 -0.92976819  0.89930585  0.93298061  0.93506979]\n",
      "variance_average : [0.05207475 0.13825251 0.04770972 0.02907708 0.03500081 0.01965756]\n",
      "training idx 1 actor true_reward at iteration 4940 : 17.58625232869358\n",
      "505838\n",
      "Parameter containing:\n",
      "tensor([-5.7800, -5.0592, -5.8082, -5.6604, -6.1696, -5.6996],\n",
      "       requires_grad=True)\n",
      "[-138.05234]\n",
      "[13.303601]\n",
      "tensor(337.2426, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94138674 -0.42126232 -0.94352709  0.90334861  0.88571608  0.93448349]\n",
      "variance_average : [0.11851723 0.12147089 0.10032175 0.06563086 0.07962748 0.173295  ]\n",
      "training idx 1 actor true_reward at iteration 4950 : 19.399646198093212\n",
      "506287\n",
      "Parameter containing:\n",
      "tensor([-5.7730, -5.0720, -5.7957, -5.6504, -6.1810, -5.7197],\n",
      "       requires_grad=True)\n",
      "[-168.63947]\n",
      "[3.899959]\n",
      "tensor(225.6666, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83610199 -0.17394918 -0.81519352  0.94347392  0.83932336  0.86925296]\n",
      "variance_average : [0.06322249 0.05962646 0.17138759 0.08835599 0.03307535 0.13691177]\n",
      "training idx 1 actor true_reward at iteration 4960 : 24.10568263414601\n",
      "506768\n",
      "Parameter containing:\n",
      "tensor([-5.7496, -5.0598, -5.7868, -5.6366, -6.1870, -5.7015],\n",
      "       requires_grad=True)\n",
      "[83.55548]\n",
      "[2.4125822]\n",
      "tensor(186.4286, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.82790046  0.12027221 -0.78488048  0.88506199  0.85837463  0.74628213]\n",
      "variance_average : [0.22809541 0.05964868 0.04776375 0.1675671  0.08765187 0.15038535]\n",
      "training idx 1 actor true_reward at iteration 4970 : 19.465370508302993\n",
      "507222\n",
      "Parameter containing:\n",
      "tensor([-5.7446, -5.0582, -5.7905, -5.6355, -6.1862, -5.6827],\n",
      "       requires_grad=True)\n",
      "[-1.9327078]\n",
      "[16.726906]\n",
      "tensor(446.9027, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.94031087 -0.33293848 -0.91009201  0.94033255  0.92997402  0.87616284]\n",
      "variance_average : [0.06461788 0.06333347 0.09198753 0.06641574 0.06705267 0.02390535]\n",
      "training idx 1 actor true_reward at iteration 4980 : 16.26748572919086\n",
      "507711\n",
      "Parameter containing:\n",
      "tensor([-5.7491, -5.0596, -5.7935, -5.6307, -6.1935, -5.6821],\n",
      "       requires_grad=True)\n",
      "[115.53952]\n",
      "[4.4650774]\n",
      "tensor(226.6194, grad_fn=<AddBackward0>)\n",
      "mean_average : [ 0.83094221  0.12703811 -0.89664738  0.7878835   0.89422735  0.85932882]\n",
      "variance_average : [0.02812898 0.05097937 0.07926958 0.0988446  0.15706004 0.0565746 ]\n",
      "training idx 1 actor true_reward at iteration 4990 : 12.65628704447259\n",
      "508124\n"
     ]
    }
   ],
   "source": [
    "reward_np = np.array(reward_plot[:60])  \n",
    "fig, axe = plt.subplots(1, figsize = (15,15))\n",
    "axe.plot(list(range(len(reward_np))),reward_np, lw = 1, label = 'reward', color = 'blue')\n",
    "axe.set_title('reward', fontsize = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 31.45974749084725\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "state = []\n",
    "done = False\n",
    "reward_sum=0\n",
    "env = gym.make('DobroHalfCheetah-v0')\n",
    "env.unwrapped.initialize(is_render=True)\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "state = observation\n",
    "\n",
    "for t in range(10000):\n",
    "    env.render()\n",
    "    \n",
    "    mean, variance= p_net_shared(torch.Tensor(state))\n",
    "    value = v_net_shared(torch.Tensor(state))\n",
    "\n",
    "    action = get_action(mean,variance,num_actions)\n",
    "    \n",
    "    obs , reward, done, info = env.step(action)\n",
    "    \n",
    "    \n",
    "    reward_sum = reward_sum + reward\n",
    "    state=obs\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "print(\"reward {}\".format(reward_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = [np.random.normal(mean[i].detach(), variance[i].detach(), 1).item() for i in range(num_actions) ]\n",
    "    true_action = []\n",
    "    for i in range(len(mean)):\n",
    "        if(action[i]<-1):\n",
    "            true_action.append(-1)\n",
    "        elif(action[i]>1):\n",
    "            true_action.append(1)\n",
    "        else:\n",
    "            true_action.append(action[i])\n",
    "    return true_action"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6_spinningup",
   "language": "python",
   "name": "spinningup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
