{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wooseoko/anaconda3/envs/spinningup/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import gym\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import threading\n",
    "import math\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "GITPATH = subprocess.run('git rev-parse --show-toplevel'.split(' '), \\\n",
    "        stdout=subprocess.PIPE).stdout.decode('utf-8').replace('\\n','')\n",
    "sys.path.append(GITPATH)\n",
    "import dobroEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb30ae56ef0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hyper parameters\n",
    "t_max = 1\n",
    "gamma = 0.95\n",
    "learning_rate = 0.001\n",
    "beta = 0.1\n",
    "\n",
    "seed = 0\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.65888214 -0.8128141  -0.95716935  0.62324756  0.5711904  -0.85067934]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('DobroHalfCheetah-v0')\n",
    "env.unwrapped.initialize(is_render=False)\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class policy_net(nn.Module):\n",
    "    def __init__(self, input_feature , num_actions):\n",
    "        super(policy_net,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features = input_feature, out_features = 128)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear = nn.Linear(in_features = 128, out_features = 256)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features = 256, out_features = num_actions)\n",
    "        #self.linear3 = nn.Linear(in_features = 256, out_features = num_actions)\n",
    "        self.mean_act = nn.Tanh()\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.activation1(self.linear1(x))\n",
    "        x = self.activation2(self.linear(x))\n",
    "        mean = self.mean_act(self.linear2(x))\n",
    "        #variance = self.var_act(self.linear3(x)) + 0.0001\n",
    "        variance = torch.Tensor([0.25, 0.25, 0.25, 0.25, 0.25, 0.25])\n",
    "        return mean , variance\n",
    "    \n",
    "class value_net(nn.Module):\n",
    "    def __init__(self, input_feature):\n",
    "        super(value_net,self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features = input_feature, out_features = 128)\n",
    "        self.activation1 = nn.ReLU()\n",
    "        self.linear = nn.Linear(in_features = 128, out_features = 256)\n",
    "        self.activation2 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(in_features = 256, out_features = 1)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.activation1(self.linear1(x))\n",
    "        x = self.activation2(self.linear(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_action(mean , variance, num_actions):\n",
    "    true_action = []\n",
    "    for i in range(len(mean)):\n",
    "        for j in range(10000):\n",
    "            action = np.random.normal(mean[i].detach(), variance[i].detach(), 1).item()\n",
    "            if(action >= -1 and action <=1):\n",
    "                true_action.append(action)\n",
    "                break\n",
    "        if( len(true_action) <= i):\n",
    "            true_actioin.append(mean[i])\n",
    "    return true_action\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.60521]\n",
      "[366.92993]\n",
      "tensor(-39.1731)\n",
      "mean_average : [-0.00536839  0.05315022  0.08189185 -0.27888417  0.0899412   0.0478393 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 0 : 56.19736922552538\n",
      "1000\n",
      "[5.0120153]\n",
      "[435.14655]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.0010323   0.05860726  0.09566227 -0.29148956  0.08792027  0.05558522]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 0 : 50.4570366217023\n",
      "1000\n",
      "[6.5406537]\n",
      "[371.34937]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.01192016  0.05608866  0.09696835 -0.30071121  0.08454063  0.0572055 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 0 : 69.97200521992515\n",
      "1000\n",
      "[4.527835]\n",
      "[403.79922]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.00156254  0.05066252  0.07765667 -0.28440729  0.09522696  0.04560935]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 0 : 48.36166604249504\n",
      "1000\n",
      "[8.078105]\n",
      "[157.75122]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.12266041  0.0285196   0.12356901 -0.13018013 -0.09771488  0.03158094]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 10 : 141.5948730637343\n",
      "11000\n",
      "[5.3630314]\n",
      "[139.52925]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.12901116  0.02568598  0.13334961 -0.14416639 -0.09393342  0.02855377]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 10 : 104.37638177849574\n",
      "11000\n",
      "[10.063446]\n",
      "[144.79408]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.11636975  0.0265866   0.12002938 -0.12578999 -0.09441879  0.02795725]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 10 : 153.0334493363285\n",
      "11000\n",
      "[4.5297203]\n",
      "[183.22897]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.12818207  0.02851512  0.12226387 -0.13535053 -0.09660466  0.02958742]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 10 : 100.00146915414524\n",
      "11000\n",
      "[5.135269]\n",
      "[115.17711]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.1442019   0.00935125  0.13069996 -0.06350215 -0.1325684   0.05514152]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 20 : 169.104912318244\n",
      "21000\n",
      "[2.5257378]\n",
      "[207.3209]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.15314735  0.01056075  0.13529858 -0.06029532 -0.12052227  0.06150744]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 20 : 162.26487997208906\n",
      "21000\n",
      "[5.641819]\n",
      "[220.31053]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.15010506  0.0114304   0.14073329 -0.07354247 -0.1320232   0.07181934]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 20 : 184.88255679350723\n",
      "21000\n",
      "[10.886904]\n",
      "[244.87039]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.14959315  0.01428602  0.14647214 -0.06930268 -0.13427776  0.07124127]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 20 : 232.19768500470838\n",
      "21000\n",
      "[0.4352591]\n",
      "[269.61652]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.14010233 -0.03292295  0.15026814 -0.04360538 -0.15689204  0.07295155]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 30 : 216.26971356466456\n",
      "31000\n",
      "[3.844057]\n",
      "[244.07541]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.1376822  -0.03580481  0.13983522 -0.03850542 -0.14934909  0.06546056]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 30 : 229.48730537807035\n",
      "31000\n",
      "[-9.85873]\n",
      "[436.43277]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.14983768 -0.03397016  0.15492223 -0.03709999 -0.16597067  0.06666514]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 30 : 144.58060544480728\n",
      "31000\n",
      "[1.4809442]\n",
      "[230.0521]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.1374274  -0.03033228  0.14706041 -0.03575326 -0.1542788   0.06540408]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 30 : 216.2100112621975\n",
      "31000\n",
      "[-0.9604695]\n",
      "[359.73694]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.15634622 -0.07685319  0.13759716 -0.03654451 -0.18070942  0.07185501]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 40 : 249.11606549485006\n",
      "41000\n",
      "[1.3174245]\n",
      "[285.51593]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.15812962 -0.0828898   0.15561841 -0.03982284 -0.18969667  0.09150108]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 40 : 252.7382900717751\n",
      "41000\n",
      "[1.8337073]\n",
      "[357.46716]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.15778241 -0.08385047  0.15264189 -0.04224223 -0.18458415  0.0884362 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 40 : 255.40999045412602\n",
      "41000\n",
      "[-4.3804417]\n",
      "[389.19452]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.16173701 -0.08233096  0.1329569  -0.04324263 -0.18079102  0.06764435]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 40 : 214.0954467201442\n",
      "41000\n",
      "[1.411613]\n",
      "[499.48285]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.18640836 -0.14307384  0.17265834 -0.04909587 -0.21305998  0.09003912]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 50 : 309.47696336545016\n",
      "51000\n",
      "[7.1000047]\n",
      "[428.08154]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.19002157 -0.15298417  0.18258393 -0.05408135 -0.20819161  0.10465104]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 50 : 371.6593552126589\n",
      "51000\n",
      "[-2.6010594]\n",
      "[317.3358]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.1996706  -0.15067558  0.18734751 -0.06025482 -0.21886602  0.09881263]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 50 : 286.05885367937685\n",
      "51000\n",
      "[-5.5023146]\n",
      "[790.07574]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.19124335 -0.14717674  0.17747186 -0.05188671 -0.20802721  0.09641126]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 50 : 263.87254422337276\n",
      "51000\n",
      "[-0.318223]\n",
      "[654.0577]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.20809914 -0.20526698  0.18668279 -0.04523991 -0.23527008  0.08438805]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 60 : 292.5452069057042\n",
      "61000\n",
      "[5.2123804]\n",
      "[406.35532]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.21510486 -0.21068857  0.19526763 -0.04155936 -0.22821063  0.09303684]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 60 : 349.48824737028895\n",
      "61000\n",
      "[-8.320062]\n",
      "[743.5926]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.21531263 -0.20571463  0.18450511 -0.0427207  -0.23529639  0.08157085]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 60 : 253.8389824468978\n",
      "61000\n",
      "[5.889654]\n",
      "[355.71057]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.22635332 -0.22465678  0.20850127 -0.06244172 -0.24758295  0.1159464 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 60 : 325.755527787918\n",
      "61000\n",
      "[2.0591831]\n",
      "[745.821]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.24122352 -0.27384032  0.21138446 -0.03647562 -0.25319826  0.11694854]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 70 : 358.1205568697011\n",
      "71000\n",
      "[2.0082378]\n",
      "[841.96906]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.24271283 -0.27441398  0.21904142 -0.03199371 -0.25117403  0.11431528]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 70 : 357.25909537286714\n",
      "71000\n",
      "[1.6652014]\n",
      "[708.06494]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.23841795 -0.27535766  0.21658982 -0.02704323 -0.25052018  0.11617365]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 70 : 348.90075631113854\n",
      "71000\n",
      "[-3.7593856]\n",
      "[615.87836]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.2385237  -0.26927525  0.21390188 -0.04277144 -0.245778    0.10913583]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 70 : 311.03932671771946\n",
      "71000\n",
      "[-11.253353]\n",
      "[910.31323]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.29077434 -0.30801591  0.22300772 -0.06165645 -0.2987927   0.07427313]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 80 : 239.2164244500983\n",
      "81000\n",
      "[3.7339897]\n",
      "[657.7406]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.29665973 -0.31747999  0.22472899 -0.05069166 -0.30506509  0.08767293]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 80 : 349.3586263727068\n",
      "81000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.1644883][-1.0711486]\n",
      "[419.31097]\n",
      "\n",
      "[691.8176]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.29498131 -0.32130297  0.22653419 -0.06286371 -0.29923692  0.09248759]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 80 : 301.77843145760585\n",
      "81000\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.28866149 -0.30928236  0.21801838 -0.05086088 -0.2944559   0.07002851]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 80 : 292.3353108178085\n",
      "81000\n",
      "[1.6685159]\n",
      "[502.9514]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32233839 -0.34347812  0.23466061 -0.06785643 -0.31370325  0.08625637]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 90 : 274.98471406042415\n",
      "91000\n",
      "[-3.6597123]\n",
      "[459.2766]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34001013 -0.34735282  0.23162769 -0.07361049 -0.32416037  0.09698816]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 90 : 246.4244098366412\n",
      "91000\n",
      "[1.3943336]\n",
      "[457.08997]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32115726 -0.3299126   0.2198526  -0.05826262 -0.31024588  0.07405826]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 90 : 273.91832656953915\n",
      "91000\n",
      "[0.3444004]\n",
      "[359.40448]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32328395 -0.329974    0.21567493 -0.06507473 -0.31305272  0.0770354 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 90 : 268.03113170956243\n",
      "91000\n",
      "[-9.316537]\n",
      "[733.65656]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33974651 -0.3816323   0.23146776 -0.06546067 -0.33918391  0.09926962]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 100 : 229.83000565508206\n",
      "101000\n",
      "[-9.404561]\n",
      "[775.39703]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33443631 -0.37322886  0.23837825 -0.05890257 -0.32566657  0.09293869]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 100 : 236.99125353008984\n",
      "101000\n",
      "[-1.7941852]\n",
      "[526.15405]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34647938 -0.38908537  0.24018791 -0.05876891 -0.33150594  0.10870145]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 100 : 290.4288275497965\n",
      "101000\n",
      "[4.3787856]\n",
      "[375.16333]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34354118 -0.38245803  0.24015395 -0.06759219 -0.33140818  0.10354084]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 100 : 322.84152018335027\n",
      "101000\n",
      "[0.07163215]\n",
      "[635.78033]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34202499 -0.36735752  0.22486331 -0.02178349 -0.32258309  0.06982251]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 110 : 312.7641953283249\n",
      "111000\n",
      "[-2.3608687]\n",
      "[738.79663]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35795669 -0.38873899  0.24260481 -0.02695458 -0.33167343  0.08145791]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 110 : 289.8963225813842\n",
      "111000\n",
      "[2.164232]\n",
      "[725.08514]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36408408 -0.39622268  0.24591588 -0.02975065 -0.3432593   0.09209025]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 110 : 333.64461608413393\n",
      "111000\n",
      "[-1.4739785]\n",
      "[611.2423]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35879256 -0.39149334  0.23565446 -0.0287661  -0.32609036  0.08394572]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 110 : 304.3588916380756\n",
      "111000\n",
      "[-7.306563]\n",
      "[748.41705]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39643599 -0.42865737  0.25596726 -0.01344806 -0.33651893  0.10975772]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 120 : 235.82985738295784\n",
      "121000\n",
      "[3.8775754]\n",
      "[604.8202]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38077461 -0.40634592  0.24043328 -0.00082986 -0.3141604   0.08610306]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 120 : 328.91131427085617\n",
      "121000\n",
      "[-1.2361915]\n",
      "[497.1717]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38972416 -0.42310052  0.24463052 -0.01101327 -0.32800954  0.09748384]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 120 : 300.9691494393981\n",
      "121000\n",
      "[-5.9055004]\n",
      "[380.9626]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38351566 -0.41631028  0.24507516 -0.01077933 -0.32444545  0.0987992 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 120 : 243.73872157399373\n",
      "121000\n",
      "[1.0931377]\n",
      "[553.7079]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41019563 -0.44759976  0.27211311 -0.00430612 -0.33682496  0.1125342 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 130 : 324.3975024566654\n",
      "131000\n",
      "[-8.296741]\n",
      "[773.6942]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3917379  -0.42462647  0.24544576 -0.00312509 -0.31890134  0.09038443]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 130 : 279.77499499539016\n",
      "131000\n",
      "[-13.995893]\n",
      "[959.46875]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40474708 -0.43765108  0.26758199 -0.01092769 -0.32314208  0.09960423]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 130 : 214.6442434921552\n",
      "131000\n",
      "[1.2299123]\n",
      "[597.55804]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39055044 -0.42799775  0.25527554 -0.00062221 -0.31385667  0.09596745]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 130 : 349.38791487924124\n",
      "131000\n",
      "[-2.4193187]\n",
      "[404.59076]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40599357 -0.4470846   0.26940275  0.0072941  -0.3131184   0.1083697 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 140 : 287.74026114200257\n",
      "141000\n",
      "[-5.4806466]\n",
      "[546.436]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39633847 -0.43375795  0.2485952   0.00797119 -0.31164646  0.09586634]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 140 : 280.42440085229373\n",
      "141000\n",
      "[-10.152624]\n",
      "[532.0645]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 4.33451772e-01 -4.69208244e-01  2.91554040e-01  3.35635157e-04\n",
      " -3.29933893e-01  1.25586837e-01]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 140 : 240.95070631684194\n",
      "141000\n",
      "[-8.381492]\n",
      "[533.234]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41271377 -0.45186192  0.27316999  0.00122123 -0.31996132  0.11573077]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 140 : 239.79210286815484\n",
      "141000\n",
      "[-0.51601577]\n",
      "[391.59448]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41496525 -0.45249698  0.26418865  0.04253999 -0.29420693  0.10000163]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 150 : 323.1331776981433\n",
      "151000\n",
      "[-12.764193]\n",
      "[704.6861]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41283606 -0.45562092  0.26456569  0.02520476 -0.30534901  0.10862652]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 150 : 228.1867545435763\n",
      "151000\n",
      "[3.4987202]\n",
      "[496.3369]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40888167 -0.45047542  0.25924068  0.03684279 -0.30037162  0.10240876]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 150 : 352.4722636408332\n",
      "151000\n",
      "[-5.5401125]\n",
      "[739.32837]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41553976 -0.45305646  0.26127916  0.03847341 -0.30482446  0.09283604]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 150 : 297.9977088213021\n",
      "151000\n",
      "[-5.9349837]\n",
      "[761.3709]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.44254252 -0.47667369  0.28925328  0.06142247 -0.28690978  0.12451778]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 160 : 306.0336620090554\n",
      "161000\n",
      "[-0.40966415]\n",
      "[704.6427]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40876499 -0.44406511  0.25914313  0.06953149 -0.26814568  0.09977643]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 160 : 321.9479763015852\n",
      "161000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3571837]\n",
      "[601.36304]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42232617 -0.45836285  0.26555984  0.0624125  -0.28050334  0.1095586 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 160 : 363.7581708544995\n",
      "161000\n",
      "[-9.550883]\n",
      "[700.31165]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.43252131 -0.46994101  0.27562608  0.06081536 -0.2918462   0.11048928]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 160 : 257.9693444034381\n",
      "161000\n",
      "[1.6917362]\n",
      "[563.4794]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.46471363 -0.49157788  0.29931663  0.08524638 -0.29097325  0.13167315]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 170 : 346.82439914863994\n",
      "171000\n",
      "[-4.0424166]\n",
      "[880.18207]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.45840693 -0.47955637  0.29020618  0.0687861  -0.29760454  0.12513895]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 170 : 314.3303424475512\n",
      "171000\n",
      "[-8.634776]\n",
      "[681.0016]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.43245932 -0.45011605  0.26263035  0.0817231  -0.28228923  0.10709955]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 170 : 280.90107639488184\n",
      "171000\n",
      "[-3.2497344]\n",
      "[536.1856]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.44922494 -0.46965299  0.27954596  0.08352494 -0.29084575  0.11460146]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 170 : 317.37580757638193\n",
      "171000\n",
      "[-5.4234705]\n",
      "[409.156]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.45495088 -0.4717871   0.29488283  0.08763895 -0.27844573  0.1111762 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 180 : 244.97770047818926\n",
      "181000\n",
      "[-2.5240002]\n",
      "[389.03415]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.47007784 -0.49514475  0.30696967  0.08539699 -0.29045668  0.13222222]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 180 : 284.75674551202826\n",
      "181000\n",
      "[-8.315961]\n",
      "[289.19104]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.45371364 -0.47108919  0.28866118  0.07664633 -0.2812953   0.11650512]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 180 : 226.49206122115456\n",
      "181000\n",
      "[-3.4213042]\n",
      "[411.57306]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.46518559 -0.48718218  0.30733502  0.08012135 -0.28409334  0.12443603]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 180 : 249.07457005763644\n",
      "181000\n",
      "[-1.6369]\n",
      "[708.8391]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4895034  -0.49959096  0.31808787  0.11237592 -0.27771622  0.15837074]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 190 : 295.80234844358984\n",
      "191000\n",
      "[-7.379594]\n",
      "[680.85803]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.46693668 -0.47723748  0.29849986  0.10546039 -0.26558036  0.14145928]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 190 : 262.44032672967086\n",
      "191000\n",
      "[1.9860163]\n",
      "[442.37405]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.49025262 -0.49786248  0.32490402  0.11171466 -0.2787952   0.1630364 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 190 : 330.94516657561746\n",
      "191000\n",
      "[-2.1215308]\n",
      "[549.4587]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.46438024 -0.47241873  0.2942202   0.10676155 -0.26776251  0.13733568]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 190 : 308.1287833626391\n",
      "191000\n",
      "[3.1680462]\n",
      "[509.07657]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.47491002 -0.48437358  0.29298793  0.13265302 -0.26157633  0.13680974]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 200 : 374.2701877593912\n",
      "201000\n",
      "[-0.41042256]\n",
      "[557.00116]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.48593095 -0.4946863   0.30098948  0.12402707 -0.26584327  0.14707145]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 200 : 324.36164975910145\n",
      "201000\n",
      "[-2.7969153]\n",
      "[748.34894]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.48922483 -0.49122362  0.30930128  0.12119579 -0.26913301  0.15272416]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 200 : 311.4216434025364\n",
      "201000\n",
      "[-3.0696154]\n",
      "[561.9825]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.48687821 -0.4910505   0.31167091  0.12422691 -0.26357765  0.15188946]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 200 : 303.86734538442175\n",
      "201000\n",
      "[-5.6726875]\n",
      "[661.9138]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.48997784 -0.48197042  0.3035402   0.14114427 -0.27302888  0.12939631]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 210 : 243.73145505684423\n",
      "211000\n",
      "[-3.3578546]\n",
      "[456.85336]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.50329365 -0.49657443  0.32215999  0.13402311 -0.27437002  0.14379538]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 210 : 272.07738165079724\n",
      "211000\n",
      "[-2.85907]\n",
      "[399.69217]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.50368497 -0.49757999  0.31716104  0.14082801 -0.271629    0.14871306]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 210 : 272.91983640297104\n",
      "211000\n",
      "[-7.9382396]\n",
      "[387.89758]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.49940455 -0.49343324  0.31569106  0.13963836 -0.27421043  0.13768246]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 210 : 236.41386332986502\n",
      "211000\n",
      "[-4.7933617]\n",
      "[834.68713]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.50865057 -0.4890838   0.31386124  0.15693024 -0.26230908  0.13860608]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 220 : 287.5993743077484\n",
      "221000\n",
      "[-2.717896]\n",
      "[711.87164]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.50674852 -0.49509102  0.32727694  0.15565779 -0.2630721   0.15162039]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 220 : 311.5042926626053\n",
      "221000\n",
      "[2.154788]\n",
      "[555.1134]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.49618768 -0.48361197  0.31148622  0.16365913 -0.25803495  0.13408906]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 220 : 340.6142536328244\n",
      "221000\n",
      "[4.819299]\n",
      "[442.13403]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.51041703 -0.49970442  0.33830763  0.15754651 -0.26075104  0.14999091]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 220 : 350.2506359281798\n",
      "221000\n",
      "[-3.3870072]\n",
      "[435.11453]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.52882035 -0.49674165  0.33534841  0.15518745 -0.24836862  0.15357662]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 230 : 299.84537120593683\n",
      "231000\n",
      "[-6.0989437]\n",
      "[348.93222]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.52567766 -0.49437655  0.33044654  0.15950643 -0.25111118  0.15691266]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 230 : 283.55863985954807\n",
      "231000\n",
      "[-3.92538]\n",
      "[497.81192]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.54573076 -0.51083296  0.34785401  0.15986941 -0.25733308  0.17051582]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 230 : 284.5862864212599\n",
      "231000\n",
      "[0.09583974]\n",
      "[389.09058]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.53468538 -0.50428992  0.33607033  0.16844355 -0.25374141  0.16493093]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 230 : 322.70722969334184\n",
      "231000\n",
      "[6.951475]\n",
      "[371.90967]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.56830331 -0.53144077  0.37349978  0.16879366 -0.25086011  0.18843514]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 240 : 328.9133823853321\n",
      "241000\n",
      "[-7.094152]\n",
      "[506.18384]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.53662176 -0.50335518  0.33871653  0.17343384 -0.24087169  0.15372614]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 240 : 256.0335334201448\n",
      "241000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.98982537]\n",
      "[530.8358]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.54787341 -0.50470355  0.35351654  0.17010763 -0.2483568   0.16634875]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 240 : 265.04741395030516\n",
      "241000\n",
      "[-5.2128515]\n",
      "[491.9675]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.54599395 -0.50357929  0.34961886  0.17316624 -0.24223048  0.15805925]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 240 : 243.4605681951125\n",
      "241000\n",
      "[0.94364023]\n",
      "[352.11493]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55323719 -0.49961915  0.3616113   0.17545072 -0.23397766  0.15060716]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 250 : 323.7618281521408\n",
      "251000\n",
      "[-6.2666254]\n",
      "[460.48203]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.56148984 -0.51018809  0.36607226  0.17097042 -0.24157403  0.15288871]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 250 : 250.96253906860306\n",
      "251000\n",
      "[-6.5196247]\n",
      "[464.6765]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.54670153 -0.49664294  0.35009208  0.1710838  -0.23824513  0.14379994]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 250 : 242.38863065882708\n",
      "251000\n",
      "[-3.0771039]\n",
      "[393.68396]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.54830648 -0.49660492  0.34796843  0.17526895 -0.22819108  0.14148366]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 250 : 267.31460970182104\n",
      "251000\n",
      "[6.870987]\n",
      "[338.0268]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57755972 -0.52631114  0.37244232  0.20150222 -0.24282531  0.13587131]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 260 : 334.90154870844583\n",
      "261000\n",
      "[-8.61414]\n",
      "[485.563]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55966403 -0.50648654  0.36112797  0.19435256 -0.24314011  0.13356828]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 260 : 221.6886309635213\n",
      "261000\n",
      "[-3.5929108]\n",
      "[451.9985]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59263016 -0.53636583  0.39647931  0.18864833 -0.25231341  0.1567245 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 260 : 261.28595480825174\n",
      "261000\n",
      "[-6.117575]\n",
      "[452.03165]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55446963 -0.50379285  0.35518396  0.19169677 -0.2362229   0.1220723 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 260 : 244.37662013402095\n",
      "261000\n",
      "[-2.9687257]\n",
      "[289.1402]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57178928 -0.51420063  0.36536605  0.20280745 -0.24057696  0.13354095]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 270 : 253.71849600919532\n",
      "271000\n",
      "[-1.3248489]\n",
      "[341.2434]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57733661 -0.52666294  0.36406758  0.2045282  -0.24937348  0.12773138]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 270 : 259.94659570823785\n",
      "271000\n",
      "[-0.35728502]\n",
      "[273.6547]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55876544 -0.50305206  0.34174793  0.20704877 -0.23869371  0.10979983]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 270 : 281.0260357400466\n",
      "271000\n",
      "[-5.847764]\n",
      "[295.59857]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57312718 -0.52114806  0.36018625  0.2020563  -0.24558641  0.1262725 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 270 : 235.3244153297991\n",
      "271000\n",
      "[-4.813575]\n",
      "[289.2707]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58572869 -0.5243202   0.36932519  0.21349283 -0.25002026  0.1438864 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 280 : 238.2886508536178\n",
      "281000\n",
      "[-11.366819]\n",
      "[423.7747]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57765586 -0.51641608  0.3590803   0.20731551 -0.25657759  0.13615776]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 280 : 188.89300798455815\n",
      "281000\n",
      "[2.978849]\n",
      "[154.65135]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59714649 -0.53762675  0.38296678  0.21173399 -0.25836716  0.15188472]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 280 : 284.337295394083\n",
      "281000\n",
      "[-1.8700585]\n",
      "[255.25136]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58991253 -0.52406883  0.37485186  0.21566419 -0.25401774  0.14323941]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 280 : 243.4652723106912\n",
      "281000\n",
      "[-4.9822607]\n",
      "[494.0024]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58613643 -0.53255338  0.39192851  0.21633922 -0.25117714  0.15409494]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 290 : 244.82132024716873\n",
      "291000\n",
      "[4.925751]\n",
      "[235.45213]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59913868 -0.53766868  0.40382849  0.23063196 -0.25371969  0.16279918]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 290 : 322.09321234103766\n",
      "291000\n",
      "[-6.978058]\n",
      "[511.01562]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58654838 -0.5295769   0.39050352  0.22253417 -0.25878569  0.14792839]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 290 : 248.1885593262184\n",
      "291000\n",
      "[-2.136087]\n",
      "[318.74014]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.5854608  -0.52831025  0.39226985  0.22118121 -0.2458909   0.15235577]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 290 : 271.13608553248537\n",
      "291000\n",
      "[-9.317423]\n",
      "[428.28748]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58911097 -0.52072114  0.40529818  0.21563348 -0.26168579  0.14916747]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 300 : 221.6591508484336\n",
      "301000\n",
      "[2.833467]\n",
      "[237.20355]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59837208 -0.53396407  0.41032351  0.22240565 -0.26078383  0.15009936]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 300 : 290.33952596446073\n",
      "301000\n",
      "[-2.4325123]\n",
      "[307.26227]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59477395 -0.52822962  0.41383978  0.2205044  -0.25933943  0.15920456]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 300 : 258.7352707703636\n",
      "301000\n",
      "[-5.498131]\n",
      "[346.46503]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59432928 -0.52632711  0.41113829  0.22351961 -0.25830875  0.15107858]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 300 : 250.02174101614673\n",
      "301000\n",
      "[-3.9512258]\n",
      "[337.2032]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.60550127 -0.52872359  0.43577997  0.23510469 -0.26767138  0.14869561]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 310 : 246.5624512958992\n",
      "311000\n",
      "[-1.7315207]\n",
      "[359.2375]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59891807 -0.5271196   0.42209973  0.2336077  -0.25835174  0.13660317]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 310 : 263.43371491658377\n",
      "311000\n",
      "[-2.1129131]\n",
      "[316.8986]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59083449 -0.51209604  0.41570192  0.2277639  -0.25794697  0.13772971]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 310 : 269.94439593898994\n",
      "311000\n",
      "[-4.5887547]\n",
      "[501.23727]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59839785 -0.5184079   0.42460666  0.2286077  -0.26677155  0.14352264]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 310 : 252.12766595599047\n",
      "311000\n",
      "[-11.372202]\n",
      "[544.5025]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61087926 -0.52428444  0.43784946  0.23383807 -0.27134113  0.13832326]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 320 : 201.8586793675571\n",
      "321000\n",
      "[2.6466768]\n",
      "[237.63342]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61234837 -0.52234394  0.44918589  0.23847548 -0.26579396  0.14505366]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 320 : 305.9723675488133\n",
      "321000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69798255]\n",
      "[307.57407]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61680032 -0.52948186  0.45146007  0.23917661 -0.26592682  0.15433441]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 320 : 278.8794469173329\n",
      "321000\n",
      "[-4.9643497]\n",
      "[368.10278]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.6140726  -0.52440804  0.45070578  0.22881841 -0.2730792   0.15276206]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 320 : 234.9147096609846\n",
      "321000\n",
      "[-6.4170775]\n",
      "[409.96344]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62814079 -0.53224116  0.46478125  0.23464005 -0.2816499   0.15116414]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 330 : 236.65815480610394\n",
      "331000\n",
      "[-0.27815127]\n",
      "[303.82602]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.60106055 -0.50565258  0.43920443  0.23111312 -0.26665535  0.13060503]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 330 : 267.1836068349692\n",
      "331000\n",
      "[1.381058]\n",
      "[250.23956]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.6266501  -0.53390462  0.46847368  0.23180219 -0.27578104  0.15127563]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 330 : 284.71089032048707\n",
      "331000\n",
      "[-12.10228]\n",
      "[416.69135]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.6146395  -0.51960546  0.44806521  0.23068352 -0.26968726  0.14014542]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 330 : 185.74007470060528\n",
      "331000\n",
      "[-2.3987548]\n",
      "[286.2698]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63813182 -0.53553852  0.49908889  0.23756    -0.29071935  0.15949947]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 340 : 271.04845830994964\n",
      "341000\n",
      "[-12.04723]\n",
      "[571.6966]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62233782 -0.51536072  0.47497692  0.24064049 -0.28929581  0.15272954]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 340 : 197.45593949516015\n",
      "341000\n",
      "[-2.2173455]\n",
      "[216.0209]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62487376 -0.51579099  0.4763602   0.24140474 -0.2908589   0.13996978]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 340 : 262.8127668165869\n",
      "341000\n",
      "[7.88295]\n",
      "[178.54485]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63462978 -0.52811395  0.49521285  0.24355696 -0.29189984  0.15912972]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 340 : 342.69381730190463\n",
      "341000\n",
      "[-6.2237005]\n",
      "[557.92584]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.6141453  -0.51178945  0.47973305  0.23575674 -0.29503755  0.12685477]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 350 : 258.6139575789629\n",
      "351000\n",
      "[-3.4512405]\n",
      "[352.35342]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62894572 -0.52911738  0.5037548   0.23310898 -0.30142821  0.13755926]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 350 : 252.4353187724137\n",
      "351000\n",
      "[1.8993982]\n",
      "[310.15366]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63417256 -0.53112494  0.5109911   0.23729177 -0.29765164  0.14277615]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 350 : 290.50257070350716\n",
      "351000\n",
      "[-10.2844095]\n",
      "[458.62592]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61747648 -0.51870445  0.48475169  0.23620498 -0.29098797  0.12670932]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 350 : 222.35504362585255\n",
      "351000\n",
      "[-0.17666721]\n",
      "[518.20917]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62577504 -0.52324669  0.49482927  0.24754805 -0.30620926  0.12449921]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 360 : 289.8018681483694\n",
      "361000\n",
      "[-15.381776]\n",
      "[778.104]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61450118 -0.51010236  0.48347246  0.23987586 -0.30405218  0.12055092]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 360 : 209.62308591377175\n",
      "361000\n",
      "[2.5278344]\n",
      "[377.01328]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64267922 -0.53808338  0.52604817  0.24391219 -0.30795879  0.14849672]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 360 : 311.186572771685\n",
      "361000\n",
      "[-0.13521004]\n",
      "[342.92944]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64811937 -0.54339     0.52753059  0.24168753 -0.31143571  0.14230672]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 360 : 295.5748832843\n",
      "361000\n",
      "[-3.257149]\n",
      "[498.69946]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63500334 -0.52152884  0.51997319  0.24108089 -0.29394292  0.14499927]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 370 : 289.4379368845584\n",
      "371000\n",
      "[-2.108713]\n",
      "[529.0582]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63842418 -0.52471512  0.51848032  0.24008788 -0.30048583  0.14675371]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 370 : 303.4166928380961\n",
      "371000\n",
      "[-1.5358981]\n",
      "[375.1878]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65444905 -0.53677053  0.5406274   0.2441152  -0.30809325  0.16079405]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 370 : 303.93849896560573\n",
      "371000\n",
      "[-2.0923138]\n",
      "[448.25964]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64724229 -0.53262764  0.53481658  0.23758454 -0.29597832  0.16213781]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 370 : 293.273232081985\n",
      "371000\n",
      "[2.56034]\n",
      "[468.2163]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65464741 -0.52966561  0.54571834  0.24794878 -0.32061199  0.15716044]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 380 : 356.87435430227856\n",
      "381000\n",
      "[-10.843121]\n",
      "[560.4429]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64297843 -0.52237868  0.52873033  0.2518878  -0.30978573  0.14955604]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 380 : 250.2810529241897\n",
      "381000\n",
      "[-0.7833352]\n",
      "[574.35895]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64200751 -0.52174471  0.5365408   0.24432049 -0.31819474  0.15461684]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 380 : 319.1539881720757\n",
      "381000\n",
      "[-9.153079]\n",
      "[645.37946]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63589215 -0.51659463  0.52533601  0.24448835 -0.3086055   0.14981019]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 380 : 270.48548308163595\n",
      "381000\n",
      "[1.5076153]\n",
      "[747.75586]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64833833 -0.51130201  0.54501704  0.25987579 -0.32882201  0.14585403]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 390 : 368.356519746243\n",
      "391000\n",
      "[-5.894161]\n",
      "[874.1817]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63938123 -0.506818    0.5352098   0.24992442 -0.32456132  0.13729487]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 390 : 315.02794875713204\n",
      "391000\n",
      "[-13.630831]\n",
      "[948.9465]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63686518 -0.50435456  0.52764073  0.25215501 -0.3226425   0.13861658]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 390 : 283.7437269985569\n",
      "391000\n",
      "[-3.997036]\n",
      "[882.02203]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.66247124 -0.52852358  0.55972294  0.2598827  -0.33580051  0.15851288]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 390 : 331.70695269240076\n",
      "391000\n",
      "[-7.0450935]\n",
      "[1422.9733]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64719241 -0.49174308  0.55993116  0.24769719 -0.34389674  0.15911496]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 400 : 323.2975563504817\n",
      "401000\n",
      "[-0.38818455]\n",
      "[1311.0209]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65237417 -0.50287452  0.5721769   0.24296608 -0.34476867  0.17139646]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 400 : 374.06319579771565\n",
      "401000\n",
      "[-6.1315613]\n",
      "[1293.7069]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65553482 -0.5032514   0.57371616  0.24398159 -0.335978    0.16734294]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 400 : 325.3330000370011\n",
      "401000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.107349]\n",
      "[894.3026]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64745197 -0.5001162   0.56163195  0.24877464 -0.34048942  0.15628467]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 400 : 342.3931968890883\n",
      "401000\n",
      "[-7.6467566]\n",
      "[1285.1415]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64030908 -0.48971618  0.57739323  0.23468864 -0.34654507  0.15536141]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 410 : 356.97342961855634\n",
      "411000\n",
      "[-4.926402]\n",
      "[1242.0714]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64801237 -0.49457321  0.58238076  0.22931793 -0.35438764  0.1665841 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 410 : 356.1003378494931\n",
      "411000\n",
      "[-6.8571014]\n",
      "[878.63586]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64093866 -0.49181033  0.57521801  0.23331433 -0.34978796  0.15991386]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 410 : 320.3275781241115\n",
      "411000\n",
      "[-7.980331]\n",
      "[859.1713]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64288335 -0.49672323  0.56921462  0.23604634 -0.35561485  0.16397729]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 410 : 316.55792078310213\n",
      "411000\n",
      "[0.11360979]\n",
      "[1617.4363]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65777873 -0.49435081  0.61046512  0.22486692 -0.36260351  0.18161577]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 420 : 463.02002771094885\n",
      "421000\n",
      "[-7.345955]\n",
      "[1689.1881]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64189321 -0.48369971  0.58568913  0.2285319  -0.35894607  0.15928221]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 420 : 371.23155157817445\n",
      "421000\n",
      "[-2.8277767]\n",
      "[1603.3822]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65860086 -0.50101035  0.60802816  0.2250182  -0.35712195  0.17002153]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 420 : 393.6879202605792\n",
      "421000\n",
      "[-10.058605]\n",
      "[2189.184]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64461492 -0.49009632  0.58758386  0.22990066 -0.36095066  0.15438587]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 420 : 340.4459642622909\n",
      "421000\n",
      "[-5.790948]\n",
      "[1318.4714]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65114121 -0.50003043  0.61816941  0.21215505 -0.37532397  0.18584659]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 430 : 386.3564925400687\n",
      "431000\n",
      "[-6.467063]\n",
      "[1125.2916]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65308724 -0.49233797  0.62044094  0.20718803 -0.37854279  0.18684575]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 430 : 391.71710624212403\n",
      "431000\n",
      "[-3.8750606]\n",
      "[1175.1051]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64505313 -0.49077385  0.60997092  0.22340069 -0.37426942  0.17453956]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 430 : 402.25243442145165\n",
      "431000\n",
      "[-5.478885]\n",
      "[1340.8776]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63719706 -0.48115295  0.59618552  0.21352297 -0.37521774  0.16899857]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 430 : 395.46948281257687\n",
      "431000\n",
      "[-1.748986]\n",
      "[1134.4962]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64867415 -0.48677262  0.62546465  0.2062421  -0.40193445  0.17528456]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 440 : 457.9340396807635\n",
      "441000\n",
      "[-8.046148]\n",
      "[1373.5524]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64705079 -0.48581973  0.63054396  0.20080311 -0.40221662  0.18231837]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 440 : 408.7652125210518\n",
      "441000\n",
      "[-3.9757478]\n",
      "[1251.3582]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65154335 -0.49221019  0.63360243  0.19682107 -0.40121906  0.18583144]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 440 : 459.5323724854156\n",
      "441000\n",
      "[-13.049559]\n",
      "[1190.7936]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64329554 -0.49046219  0.61745279  0.2034919  -0.39793308  0.16950277]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 440 : 373.4799270357334\n",
      "441000\n",
      "[-3.431286]\n",
      "[3334.4685]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65264673 -0.49010253  0.66196276  0.19640122 -0.41734483  0.2155193 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 450 : 536.5571930829591\n",
      "451000\n",
      "[-13.034542]\n",
      "[2250.372]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64192039 -0.48369754  0.64495045  0.19909414 -0.41225389  0.20134069]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 450 : 452.70803765838036\n",
      "451000\n",
      "[3.0226502]\n",
      "[2216.3389]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.65649869 -0.49711643  0.67309277  0.20374286 -0.4232201   0.21496679]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 450 : 571.9530990548196\n",
      "451000\n",
      "[-15.459265]\n",
      "[2380.357]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.64088775 -0.48103886  0.63871994  0.20122384 -0.41260633  0.19331969]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 450 : 444.9455452886367\n",
      "451000\n",
      "[-2.4060009]\n",
      "[1307.1152]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62320876 -0.45720813  0.63242808  0.2103553  -0.38866182  0.17503297]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 460 : 498.8703852944876\n",
      "461000\n",
      "[-14.482321]\n",
      "[1463.0243]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61956807 -0.4589527   0.63065742  0.20961448 -0.38896462  0.1828012 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 460 : 415.33253377217187\n",
      "461000\n",
      "[-5.449299]\n",
      "[1684.0991]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63771656 -0.47266212  0.65732485  0.2045965  -0.40301053  0.19980382]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 460 : 478.75774769679504\n",
      "461000\n",
      "[-2.483639]\n",
      "[1389.5677]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63220464 -0.46431048  0.65131038  0.21331271 -0.39660441  0.19552055]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 460 : 492.37707197398214\n",
      "461000\n",
      "[-7.396111]\n",
      "[1451.6412]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.6161761  -0.45642152  0.64892122  0.20224788 -0.39397234  0.19630709]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 470 : 458.9827704676558\n",
      "471000\n",
      "[-6.725803]\n",
      "[1614.655]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62192388 -0.45497443  0.6610165   0.19600136 -0.40117221  0.21144258]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 470 : 450.77854660250887\n",
      "471000\n",
      "[-1.2977223]\n",
      "[1003.23016]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63112211 -0.46181914  0.67318924  0.1963254  -0.39814612  0.21775158]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 470 : 500.33845700546453\n",
      "471000\n",
      "[-8.964878]\n",
      "[1429.1123]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.6216227  -0.45566707  0.66004145  0.19023176 -0.39793319  0.20862002]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 470 : 403.33455213869956\n",
      "471000\n",
      "[-13.877811]\n",
      "[4031.6416]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61166448 -0.43557973  0.65992469  0.20799698 -0.40809789  0.19247066]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 480 : 494.8436546035413\n",
      "481000\n",
      "[-3.6531718]\n",
      "[2781.7039]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.63079614 -0.44870315  0.68412172  0.21520196 -0.42570939  0.21243328]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 480 : 592.9526736805194\n",
      "481000\n",
      "[-3.6977763]\n",
      "[3317.2407]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62795561 -0.45283655  0.6825678   0.21567168 -0.41566914  0.20835506]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 480 : 587.9158117691359\n",
      "481000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.001684]\n",
      "[2566.2595]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.6223054  -0.4495042   0.67987107  0.21760944 -0.41163668  0.2063632 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 480 : 543.6468811031582\n",
      "481000\n",
      "[-10.317665]\n",
      "[2523.8745]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.61393131 -0.43535586  0.67591997  0.2216663  -0.41937557  0.19685077]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 490 : 499.75125028636785\n",
      "491000\n",
      "[0.7072458]\n",
      "[2221.3425]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.62236744 -0.44540911  0.69066918  0.23695955 -0.42430973  0.20319837]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 490 : 619.2555455523511\n",
      "491000\n",
      "[-13.680241]\n",
      "[2171.425]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.60771743 -0.43121728  0.66110445  0.22886915 -0.41668056  0.18393745]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 490 : 482.8020299268118\n",
      "491000\n",
      "[-8.470599]\n",
      "[2152.2793]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.60889491 -0.42837375  0.67362246  0.22366775 -0.41208661  0.18992722]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 490 : 510.7487405754494\n",
      "491000\n",
      "[-9.476998]\n",
      "[2452.131]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.60307687 -0.43096893  0.66480421  0.23400797 -0.41918391  0.16956346]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 500 : 504.71313830750074\n",
      "501000\n",
      "[-1.3717952]\n",
      "[2191.0723]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.60698036 -0.43858543  0.67241361  0.23651676 -0.43110968  0.17522837]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 500 : 552.8823496068337\n",
      "501000\n",
      "[-8.807523]\n",
      "[2314.418]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59585862 -0.42126473  0.65873275  0.22932781 -0.41625854  0.17030335]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 500 : 490.98890354536496\n",
      "501000\n",
      "[-10.070644]\n",
      "[2679.0334]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.60165168 -0.43244755  0.66875696  0.2318751  -0.42426036  0.17526787]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 500 : 488.8056226846579\n",
      "501000\n",
      "[-0.7776203]\n",
      "[2101.7825]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59238776 -0.42401157  0.67894632  0.22353844 -0.44233186  0.1824427 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 510 : 556.392511796775\n",
      "511000\n",
      "[0.57259846]\n",
      "[1867.3529]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58964184 -0.42159781  0.67333733  0.2169772  -0.43288088  0.17908434]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 510 : 556.0639912151204\n",
      "511000\n",
      "[-9.671265]\n",
      "[2333.388]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.588077   -0.42021749  0.66704412  0.21426935 -0.4325692   0.17654895]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 510 : 453.710671877836\n",
      "511000\n",
      "[-11.013381]\n",
      "[2274.474]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58884278 -0.4159321   0.66939509  0.21494464 -0.43238673  0.17656343]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 510 : 473.02847805910943\n",
      "511000\n",
      "[-3.5125332]\n",
      "[3874.8125]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59111688 -0.40824683  0.68983122  0.21561121 -0.46517991  0.20452333]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 520 : 583.522151098758\n",
      "521000\n",
      "[-3.8779597]\n",
      "[4113.7627]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.58889664 -0.41022675  0.68991335  0.21449544 -0.45847854  0.18924318]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 520 : 591.1007673866579\n",
      "521000\n",
      "[-1.0710669]\n",
      "[2768.2969]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.59099187 -0.41376565  0.69565185  0.22633815 -0.45935004  0.18980489]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 520 : 627.5296950343206\n",
      "521000\n",
      "[-22.797981]\n",
      "[3716.7173]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57144692 -0.3978503   0.66289668  0.21341673 -0.44988417  0.17370288]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 520 : 458.96425857426976\n",
      "521000\n",
      "[-2.867476]\n",
      "[2145.1042]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57504086 -0.40129205  0.69219509  0.21225896 -0.46894635  0.18942345]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 530 : 584.0569255956623\n",
      "531000\n",
      "[-0.8220949]\n",
      "[2154.6592]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57929305 -0.40326252  0.69172924  0.21284572 -0.46422235  0.19038135]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 530 : 586.1572227591116\n",
      "531000\n",
      "[-9.993114]\n",
      "[2513.2236]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55705761 -0.39062402  0.65943016  0.21544577 -0.44911737  0.15974785]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 530 : 471.1340629746019\n",
      "531000\n",
      "[-7.670712]\n",
      "[1601.9922]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.57506802 -0.39860823  0.68433225  0.21956404 -0.46340522  0.17946754]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 530 : 526.0033458669934\n",
      "531000\n",
      "[-7.375183]\n",
      "[3803.6863]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55934224 -0.38515394  0.68188958  0.21847074 -0.46437582  0.18249502]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 540 : 583.7857851398106\n",
      "541000\n",
      "[-6.5010266]\n",
      "[4390.1978]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.56205479 -0.38465685  0.67108866  0.21086598 -0.47075761  0.17252833]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 540 : 586.8263568863772\n",
      "541000\n",
      "[-10.441175]\n",
      "[3109.5837]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.56093725 -0.38342602  0.67105795  0.22070532 -0.46283293  0.17074458]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 540 : 616.7740964516006\n",
      "541000\n",
      "[2.2832623]\n",
      "[3847.6094]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.5728297  -0.38041142  0.68830745  0.2115112  -0.47455722  0.18760939]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 540 : 691.779967836554\n",
      "541000\n",
      "[-11.473924]\n",
      "[3575.6155]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.54992637 -0.36447816  0.66893635  0.20384822 -0.45618548  0.19794608]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 550 : 559.1521665190817\n",
      "551000\n",
      "[-5.163066]\n",
      "[3929.1155]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55340091 -0.37152583  0.66859423  0.22559993 -0.46417547  0.18713326]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 550 : 616.2433940175317\n",
      "551000\n",
      "[-0.9916229]\n",
      "[3113.9473]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.5610472  -0.37174726  0.68035982  0.21434931 -0.47087769  0.19648598]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 550 : 624.9841889475862\n",
      "551000\n",
      "[-6.116513]\n",
      "[2843.0366]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55154077 -0.36505146  0.65901776  0.21018179 -0.45979074  0.17765314]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 550 : 576.8556941111925\n",
      "551000\n",
      "[-4.1873283]\n",
      "[5015.743]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55652506 -0.36118164  0.68523365  0.21639548 -0.49054297  0.19260948]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 560 : 665.6943871295755\n",
      "561000\n",
      "[-15.210752]\n",
      "[4224.841]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.55390786 -0.3610067   0.67889008  0.20886972 -0.48018405  0.19595341]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 560 : 561.9385328883974\n",
      "561000\n",
      "[-13.47977]\n",
      "[4477.1475]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.53808848 -0.35464587  0.65746232  0.21019718 -0.46610278  0.17578337]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 560 : 582.4240869597384\n",
      "561000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.086922]\n",
      "[4497.055]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.54862656 -0.35519643  0.6832687   0.21638035 -0.48644098  0.19191751]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 560 : 615.8683265684243\n",
      "561000\n",
      "[-5.9053793]\n",
      "[3061.3286]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.51642848 -0.32865015  0.68529038  0.22192992 -0.47237792  0.22328055]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 570 : 677.3406356965514\n",
      "571000\n",
      "[-7.1133184]\n",
      "[2784.4363]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.51095676 -0.32851536  0.67285432  0.23356863 -0.46885479  0.19925974]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 570 : 667.8165813276762\n",
      "571000\n",
      "[-1.2665954]\n",
      "[2163.6843]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.52841162 -0.3346613   0.69807299  0.2249017  -0.48819952  0.2281486 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 570 : 705.037160544673\n",
      "571000\n",
      "[-16.747023]\n",
      "[2782.452]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.51050843 -0.32770991  0.6604517   0.23051521 -0.46707993  0.19327022]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 570 : 596.2431196415542\n",
      "571000\n",
      "[-16.965004]\n",
      "[9557.939]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.51490628 -0.32999352  0.70170026  0.205736   -0.48498996  0.24290795]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 580 : 718.7639504218802\n",
      "581000\n",
      "[-9.11809]\n",
      "[9627.194]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.52144122 -0.33999774  0.69635031  0.22894399 -0.49335137  0.22932108]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 580 : 804.0609625562302\n",
      "581000\n",
      "[-5.473508]\n",
      "[9586.768]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.5226359  -0.32784593  0.69071269  0.22461366 -0.48825096  0.21733764]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 580 : 780.3228458862259\n",
      "581000\n",
      "[-9.963549]\n",
      "[9206.585]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.51922383 -0.33484074  0.69820039  0.22426879 -0.49121618  0.22592607]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 580 : 765.6191365498926\n",
      "581000\n",
      "[-1.2744946]\n",
      "[8062.175]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.5018791  -0.31639136  0.70804079  0.22788763 -0.49511438  0.25215957]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 590 : 829.9950678893498\n",
      "591000\n",
      "[-16.407137]\n",
      "[9396.035]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.48527367 -0.30803901  0.67131109  0.22498872 -0.47898228  0.22072492]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 590 : 719.1671594522089\n",
      "591000\n",
      "[-25.50763]\n",
      "[7044.343]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.49234542 -0.32067713  0.68610885  0.22306866 -0.48066585  0.23006902]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 590 : 702.4264643729143\n",
      "591000\n",
      "[-9.913578]\n",
      "[8121.94]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.49257142 -0.30913857  0.70690708  0.24027188 -0.4917877   0.24991115]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 590 : 836.3301975647606\n",
      "591000\n",
      "[-26.722065]\n",
      "[12596.917]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.47003736 -0.30752241  0.69770239  0.22617292 -0.47671353  0.24795836]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 600 : 769.0045871945753\n",
      "601000\n",
      "[-21.080322]\n",
      "[12504.239]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.47274713 -0.31143091  0.69901521  0.23683468 -0.47832287  0.25553264]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 600 : 864.1297985290574\n",
      "601000\n",
      "[-14.84758]\n",
      "[11857.01]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4719529  -0.31173294  0.71413419  0.23020937 -0.47543315  0.26219102]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 600 : 848.0038405808851\n",
      "601000\n",
      "[-14.081061]\n",
      "[13070.775]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.47379502 -0.31483541  0.70765033  0.23790864 -0.48570488  0.25088162]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 600 : 797.2043310361859\n",
      "601000\n",
      "[-21.300919]\n",
      "[7503.663]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.45263131 -0.3072168   0.68804175  0.22958955 -0.47484355  0.2218706 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 610 : 723.7079421109804\n",
      "611000\n",
      "[-14.857159]\n",
      "[6504.981]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.45209006 -0.30395634  0.70489587  0.23501358 -0.47937715  0.25412487]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 610 : 805.1756182302231\n",
      "611000\n",
      "[-12.943003]\n",
      "[4999.427]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.44809291 -0.30265327  0.6914211   0.23031832 -0.46748162  0.2435588 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 610 : 795.6705644322066\n",
      "611000\n",
      "[-6.322045]\n",
      "[4774.0503]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.46189335 -0.31379815  0.71246313  0.24759001 -0.47707055  0.24393679]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 610 : 863.9264956165583\n",
      "611000\n",
      "[-4.739686]\n",
      "[8039.824]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.43660595 -0.28460385  0.71154859  0.2339891  -0.46586963  0.27352473]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 620 : 897.6796401342987\n",
      "621000\n",
      "[-11.49184]\n",
      "[6574.6763]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.43621315 -0.28774539  0.69572328  0.24801131 -0.4541181   0.25385401]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 620 : 852.2270180235306\n",
      "621000\n",
      "[-19.135517]\n",
      "[7036.0615]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.43130769 -0.2896968   0.67591825  0.23642238 -0.44996932  0.23480641]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 620 : 711.5682063275108\n",
      "621000\n",
      "[-4.859394]\n",
      "[6062.2725]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4302566  -0.2839444   0.70554241  0.23726966 -0.45906382  0.26047899]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 620 : 850.3116001396426\n",
      "621000\n",
      "[-10.011336]\n",
      "[3457.9255]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42340412 -0.29123642  0.6952495   0.23935257 -0.44372962  0.24831492]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 630 : 741.1625224070591\n",
      "631000\n",
      "[-0.14276886]\n",
      "[3082.2222]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42668339 -0.29543401  0.70794716  0.25329904 -0.44812243  0.26039012]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 630 : 859.2678991128489\n",
      "631000\n",
      "[-14.634609]\n",
      "[4895.083]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41609227 -0.27931234  0.68008108  0.24214305 -0.44310098  0.23625277]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 630 : 736.287298646993\n",
      "631000\n",
      "[-28.12064]\n",
      "[3988.853]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42754055 -0.29432317  0.65532669  0.24064101 -0.4357198   0.2118425 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 630 : 578.1297478301701\n",
      "631000\n",
      "[-4.447045]\n",
      "[5599.912]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40272008 -0.29764501  0.68351318  0.23077964 -0.4288637   0.24797247]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 640 : 778.7847181008062\n",
      "641000\n",
      "[-14.200939]\n",
      "[4241.4336]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40110786 -0.29956604  0.66504699  0.22921348 -0.41736016  0.22740984]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 640 : 651.3843418360362\n",
      "641000\n",
      "[-15.679482]\n",
      "[5485.448]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41073915 -0.30637216  0.67468094  0.22799071 -0.42794781  0.24219833]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 640 : 666.424788412003\n",
      "641000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.807461]\n",
      "[4665.3633]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40438909 -0.30325901  0.70626009  0.24020069 -0.44243184  0.26220234]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 640 : 892.9474781408152\n",
      "641000\n",
      "[-9.398168]\n",
      "[3651.619]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39420915 -0.29102968  0.65954848  0.22336491 -0.42885195  0.21575819]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 650 : 705.4235878785514\n",
      "651000\n",
      "[-18.008152]\n",
      "[3704.3213]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39633859 -0.29854067  0.6583804   0.2188137  -0.41698319  0.22367702]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 650 : 626.2082999436303\n",
      "651000\n",
      "[-7.0917153]\n",
      "[2891.646]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39907683 -0.29039206  0.69018137  0.22203959 -0.42255461  0.24491946]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 650 : 728.4783488162002\n",
      "651000\n",
      "[-12.587494]\n",
      "[4181.847]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40032597 -0.29032731  0.68185462  0.2214215  -0.42426136  0.23775441]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 650 : 684.754105558812\n",
      "651000\n",
      "[-17.221975]\n",
      "[8795.782]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38893605 -0.28090228  0.67811304  0.21015239 -0.42276025  0.24608912]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 660 : 735.9084106946326\n",
      "661000\n",
      "[-9.451669]\n",
      "[7325.6646]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40125341 -0.28568243  0.69394733  0.20673144 -0.43886161  0.25234319]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 660 : 857.8293444517516\n",
      "661000\n",
      "[-14.972738]\n",
      "[6901.33]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40136073 -0.29543988  0.68607048  0.21599512 -0.42085744  0.2485781 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 660 : 725.2060205945224\n",
      "661000\n",
      "[-11.388448]\n",
      "[8081.3755]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39612731 -0.2975935   0.68737111  0.21071637 -0.42433007  0.26123091]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 660 : 749.0688204634802\n",
      "661000\n",
      "[-23.795757]\n",
      "[8379.2705]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40667586 -0.28566274  0.67518084  0.21039198 -0.40173566  0.24093067]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 670 : 648.993080618092\n",
      "671000\n",
      "[-9.034327]\n",
      "[10330.922]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40045343 -0.28607955  0.67980589  0.21277026 -0.41466343  0.24403715]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 670 : 800.4241089496442\n",
      "671000\n",
      "[-20.725887]\n",
      "[8283.088]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40424241 -0.2819157   0.68838911  0.21079926 -0.41392395  0.24762918]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 670 : 763.0335225800638\n",
      "671000\n",
      "[-2.7557993]\n",
      "[7888.506]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40678756 -0.28120325  0.68313569  0.2129172  -0.40731754  0.2344269 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 670 : 855.8041642345481\n",
      "671000\n",
      "[-30.088892]\n",
      "[9290.661]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40414917 -0.28635842  0.66038462  0.20868142 -0.38771634  0.23252263]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 680 : 619.822475245493\n",
      "681000\n",
      "[-18.240252]\n",
      "[7207.21]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40052114 -0.28479934  0.65624224  0.2077514  -0.38117772  0.23683193]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 680 : 707.5144666082695\n",
      "681000\n",
      "[-11.923125]\n",
      "[9719.866]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40479991 -0.28998103  0.68890486  0.22119832 -0.38895966  0.24988092]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 680 : 871.1361711226945\n",
      "681000\n",
      "[-13.678769]\n",
      "[8628.532]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39625417 -0.28544221  0.68208462  0.21149741 -0.38683454  0.26169916]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 680 : 772.8633855302437\n",
      "681000\n",
      "[-13.651412]\n",
      "[6972.1333]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40704954 -0.30147073  0.67236904  0.22051318 -0.37722488  0.24882001]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 690 : 767.0403782119602\n",
      "691000\n",
      "[-10.781804]\n",
      "[7645.0566]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40158157 -0.30031443  0.67643426  0.23369206 -0.38623989  0.24804992]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 690 : 788.4060712029635\n",
      "691000\n",
      "[-16.437866]\n",
      "[7437.9087]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.401546   -0.29877464  0.67245807  0.22103705 -0.37784779  0.24485975]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 690 : 709.5554615430398\n",
      "691000\n",
      "[4.271989]\n",
      "[7052.9463]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38883109 -0.28945192  0.67979849  0.21683491 -0.3777693   0.25644851]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 690 : 895.1913999237082\n",
      "691000\n",
      "[-18.062042]\n",
      "[8923.086]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40039253 -0.29153383  0.67304143  0.21996856 -0.37172947  0.26827727]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 700 : 692.3452819932883\n",
      "701000\n",
      "[-13.0383415]\n",
      "[9867.503]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39393884 -0.2853469   0.67032455  0.23402845 -0.3733946   0.2629036 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 700 : 846.5236336851715\n",
      "701000\n",
      "[-13.143439]\n",
      "[9140.517]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39285309 -0.28560663  0.67728159  0.22818136 -0.37954033  0.26840519]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 700 : 722.6767491549253\n",
      "701000\n",
      "[-16.396488]\n",
      "[6574.4043]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3903847  -0.28823962  0.66068505  0.22517782 -0.36032587  0.25407397]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 700 : 703.565662904259\n",
      "701000\n",
      "[-16.83033]\n",
      "[4536.431]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37073645 -0.26897081  0.65657568  0.224502   -0.3598156   0.25789633]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 710 : 647.6317104564605\n",
      "711000\n",
      "[-9.197632]\n",
      "[3747.5266]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37659608 -0.27510558  0.67003296  0.22123802 -0.37205651  0.26672445]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 710 : 765.1154411007767\n",
      "711000\n",
      "[-12.057934]\n",
      "[4223.991]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37914927 -0.27202117  0.66035583  0.22123074 -0.36878801  0.26474275]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 710 : 658.8873645569103\n",
      "711000\n",
      "[-12.504403]\n",
      "[4572.7905]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37850811 -0.27724602  0.67134482  0.23320979 -0.37667254  0.26385125]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 710 : 713.548354206162\n",
      "711000\n",
      "[-1.7561092]\n",
      "[9087.216]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38190638 -0.25967203  0.68675547  0.23378571 -0.37165986  0.28211025]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 720 : 866.0791295428259\n",
      "721000\n",
      "[-24.080683]\n",
      "[9283.482]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37300444 -0.25696653  0.68469248  0.22350113 -0.36764467  0.29163199]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 720 : 780.6968917794023\n",
      "721000\n",
      "[-16.69466]\n",
      "[7200.583]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.379797   -0.26946988  0.67266859  0.22559652 -0.37374217  0.28209147]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 720 : 774.7347764775844\n",
      "721000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-12.661844]\n",
      "[6662.9272]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39131181 -0.27497577  0.67969802  0.23971704 -0.36703662  0.28289108]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 720 : 774.7133189877086\n",
      "721000\n",
      "[-18.409348]\n",
      "[7265.1133]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37689961 -0.25785915  0.66665265  0.22065613 -0.34782566  0.27902133]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 730 : 695.3855436825643\n",
      "731000\n",
      "[-12.983357]\n",
      "[7867.17]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37675862 -0.25855498  0.68511923  0.22472151 -0.35147843  0.29293022]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 730 : 827.3694362945457\n",
      "731000\n",
      "[-1.4414997]\n",
      "[6274.752]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37956215 -0.26010454  0.70446396  0.23902674 -0.35572692  0.30956262]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 730 : 942.8993010405569\n",
      "731000\n",
      "[-13.231513]\n",
      "[5603.427]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38279857 -0.26312862  0.66800895  0.23447032 -0.3418074   0.27463623]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 730 : 820.1058409490615\n",
      "731000\n",
      "[-8.459665]\n",
      "[5426.345]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35848256 -0.24969966  0.67986526  0.22597447 -0.33867936  0.27886108]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 740 : 750.0597336227138\n",
      "741000\n",
      "[-14.946173]\n",
      "[7865.4756]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36655027 -0.25956561  0.66756475  0.21551698 -0.33980353  0.26158024]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 740 : 687.2456145593828\n",
      "741000\n",
      "[-2.0267391]\n",
      "[7236.8804]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37555906 -0.25988126  0.69529316  0.23256421 -0.34878794  0.28699158]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 740 : 852.2453748729399\n",
      "741000\n",
      "[-16.44236]\n",
      "[5741.787]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36625212 -0.25600842  0.67780987  0.21521074 -0.33944039  0.27845689]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 740 : 679.7353691802443\n",
      "741000\n",
      "[-13.49968]\n",
      "[8711.193]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35530237 -0.26860237  0.68717323  0.22592541 -0.32199788  0.29903057]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 750 : 812.8970416882188\n",
      "751000\n",
      "[-7.9795837]\n",
      "[7312.521]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36568448 -0.27446729  0.67123107  0.23245452 -0.33148741  0.27762652]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 750 : 745.5276125595029\n",
      "751000\n",
      "[-26.573832]\n",
      "[7827.2437]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3671783  -0.27091284  0.67484901  0.2249754  -0.33613067  0.27678217]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 750 : 691.5172281002316\n",
      "751000\n",
      "[-7.286384]\n",
      "[6825.3633]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3516656  -0.25338451  0.67984694  0.20953209 -0.33862599  0.2861041 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 750 : 816.1601432270002\n",
      "751000\n",
      "[-5.5715346]\n",
      "[8203.63]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35637295 -0.24780562  0.68544076  0.22846074 -0.32947297  0.29084634]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 760 : 854.8313989166011\n",
      "761000\n",
      "[-16.630697]\n",
      "[8090.3843]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37164927 -0.26320003  0.68861956  0.23046241 -0.33825346  0.29780567]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 760 : 773.0296345084082\n",
      "761000\n",
      "[-12.594458]\n",
      "[10524.819]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35910628 -0.24839811  0.67267187  0.22047977 -0.33105307  0.28083897]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 760 : 762.0272646867835\n",
      "761000\n",
      "[-15.535985]\n",
      "[8294.431]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35669132 -0.23999984  0.66831779  0.2138325  -0.32619278  0.27961155]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 760 : 736.6081780054985\n",
      "761000\n",
      "[-15.328831]\n",
      "[3875.4783]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34324727 -0.25279747  0.67331953  0.20800676 -0.32598688  0.28324865]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 770 : 758.6083264137711\n",
      "771000\n",
      "[-17.775799]\n",
      "[4829.156]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35326687 -0.2568136   0.68112398  0.20965035 -0.3310245   0.28273875]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 770 : 689.61881187914\n",
      "771000\n",
      "[-15.058529]\n",
      "[4452.27]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34068931 -0.24358106  0.66957445  0.20394244 -0.32463012  0.27427217]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 770 : 721.1012945618235\n",
      "771000\n",
      "[-10.503098]\n",
      "[6022.204]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34334093 -0.24880928  0.67760413  0.21886279 -0.32636456  0.2652501 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 770 : 783.3919700213614\n",
      "771000\n",
      "[-15.334506]\n",
      "[4960.491]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3417293  -0.2545233   0.65876508  0.21958305 -0.32716965  0.2658242 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 780 : 673.5812311402874\n",
      "781000\n",
      "[-10.764834]\n",
      "[6614.0376]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33720879 -0.24325897  0.6759427   0.21421658 -0.33818573  0.27959435]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 780 : 764.9190223201326\n",
      "781000\n",
      "[-23.717339]\n",
      "[6692.8594]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33068695 -0.2382847   0.66998409  0.19918763 -0.33532814  0.27582367]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 780 : 654.9599150640275\n",
      "781000\n",
      "[-3.058072]\n",
      "[5475.056]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34651917 -0.24893374  0.67231446  0.22582625 -0.33636575  0.27281393]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 780 : 830.2090098922654\n",
      "781000\n",
      "[-14.615807]\n",
      "[7940.4395]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33791757 -0.23976668  0.6843491   0.22277506 -0.33130169  0.30007663]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 790 : 826.0276610646868\n",
      "791000\n",
      "[-28.104027]\n",
      "[7083.4253]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32805016 -0.22982407  0.67346392  0.20113763 -0.32206483  0.28230396]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 790 : 605.4159512804323\n",
      "791000\n",
      "[-7.4377427]\n",
      "[8484.519]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32955256 -0.23381568  0.67742993  0.2157981  -0.32803182  0.29262074]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 790 : 822.2196413337618\n",
      "791000\n",
      "[-9.46168]\n",
      "[9453.918]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34148816 -0.23965366  0.68419228  0.21647317 -0.33446126  0.28674743]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 790 : 795.2956138252912\n",
      "791000\n",
      "[-17.100677]\n",
      "[8363.985]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3408376  -0.24080441  0.67747194  0.20041515 -0.32835709  0.29954124]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 800 : 699.902675060906\n",
      "801000\n",
      "[-7.2868824]\n",
      "[6629.444]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32852401 -0.23081434  0.68701897  0.20090772 -0.33040051  0.31435219]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 800 : 804.4456340995617\n",
      "801000\n",
      "[-15.266629]\n",
      "[6143.5835]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34184827 -0.24879653  0.67695095  0.21164653 -0.32689396  0.28910181]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 800 : 763.837551067259\n",
      "801000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-17.728573]\n",
      "[7663.9434]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33024441 -0.23134315  0.69398901  0.2065834  -0.33238479  0.31751515]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 800 : 741.1953701063276\n",
      "801000\n",
      "[-25.923695]\n",
      "[6029.872]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33094567 -0.24554027  0.65715601  0.22549718 -0.30713765  0.28463678]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 810 : 694.2771831483565\n",
      "811000\n",
      "[-1.716721]\n",
      "[4378.4287]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32575192 -0.2367828   0.66965403  0.23232558 -0.30575553  0.28859193]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 810 : 855.8748845756058\n",
      "811000\n",
      "[-15.974846]\n",
      "[6689.1333]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3336394  -0.24117645  0.66972985  0.22747057 -0.31887078  0.28602826]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 810 : 774.2314283429838\n",
      "811000\n",
      "[-10.785188]\n",
      "[3768.1213]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33600747 -0.24716043  0.67868309  0.23224754 -0.31397523  0.29245454]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 810 : 762.6811762879537\n",
      "811000\n",
      "[-4.1580744]\n",
      "[3992.3896]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34320481 -0.25035999  0.68581374  0.24002928 -0.31901828  0.31756854]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 820 : 904.8283468626245\n",
      "821000\n",
      "[-13.062807]\n",
      "[5618.6094]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33168339 -0.2323701   0.68039891  0.22248623 -0.3239224   0.31706835]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 820 : 766.3415026200191\n",
      "821000\n",
      "[-21.787964]\n",
      "[6740.6963]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33434905 -0.2387934   0.65955749  0.22032265 -0.32119562  0.29012921]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 820 : 700.611840230556\n",
      "821000\n",
      "[-17.636625]\n",
      "[3539.976]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33736101 -0.23399871  0.65228805  0.22684806 -0.31575956  0.28870842]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 820 : 709.8574710935629\n",
      "821000\n",
      "[-26.309126]\n",
      "[7493.034]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33565316 -0.23884697  0.65403477  0.20755723 -0.30225683  0.293802  ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 830 : 592.8084287421943\n",
      "831000\n",
      "[-21.954807]\n",
      "[10989.069]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33548855 -0.22642114  0.68455782  0.22367683 -0.30083     0.32981863]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 830 : 793.0606514498066\n",
      "831000\n",
      "[-9.416674]\n",
      "[8948.874]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33284059 -0.23614461  0.67152645  0.22772124 -0.30610089  0.32121509]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 830 : 815.2203285443447\n",
      "831000\n",
      "[-4.217687]\n",
      "[9681.51]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32934595 -0.22933474  0.67216607  0.22650281 -0.30480132  0.32509233]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 830 : 840.2660394631577\n",
      "831000\n",
      "[-13.838156]\n",
      "[6065.6245]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31933173 -0.22418093  0.66757255  0.23654377 -0.2874187   0.31312859]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 840 : 813.8058222074859\n",
      "841000\n",
      "[-18.303917]\n",
      "[8926.717]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32511406 -0.2334074   0.68095379  0.24695531 -0.29114448  0.32115789]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 840 : 877.9317342906185\n",
      "841000\n",
      "[-17.974115]\n",
      "[5902.5947]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32510623 -0.22326539  0.66813502  0.23898834 -0.28111852  0.30200073]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 840 : 795.4557588352473\n",
      "841000\n",
      "[-12.6663265]\n",
      "[8889.674]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32328154 -0.22993398  0.67786896  0.24590167 -0.28615207  0.31330867]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 840 : 837.1852423558547\n",
      "841000\n",
      "[-5.8652472]\n",
      "[7949.008]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32531236 -0.23769728  0.67418089  0.2349006  -0.26287196  0.32478472]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 850 : 793.1387285111607\n",
      "851000\n",
      "[-2.186926]\n",
      "[9597.846]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33272082 -0.24229754  0.67561668  0.23851129 -0.27056073  0.31095122]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 850 : 797.9322870276452\n",
      "851000\n",
      "[-3.571114]\n",
      "[10340.301]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33106691 -0.23000514  0.6774493   0.22438741 -0.27297732  0.31855766]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 850 : 774.7757966047276\n",
      "851000\n",
      "[-21.156721]\n",
      "[7139.3013]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32538818 -0.23238115  0.68021706  0.2112178  -0.26959483  0.31274075]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 850 : 637.1183715311039\n",
      "851000\n",
      "[-10.868513]\n",
      "[10394.336]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3228906  -0.24712778  0.66556247  0.26056818 -0.2461996   0.32450828]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 860 : 891.8778903313843\n",
      "861000\n",
      "[-9.622985]\n",
      "[9819.33]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31651176 -0.24334366  0.68385953  0.25509831 -0.26019673  0.33715438]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 860 : 827.507753364558\n",
      "861000\n",
      "[-18.403343]\n",
      "[10441.313]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31841097 -0.2415807   0.66602008  0.24630683 -0.25715168  0.3133939 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 860 : 756.8951191254832\n",
      "861000\n",
      "[-14.3162565]\n",
      "[10083.069]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32655911 -0.24749471  0.67384039  0.25310453 -0.25861234  0.31484705]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 860 : 798.2508685455197\n",
      "861000\n",
      "[-1.211545]\n",
      "[9024.188]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30213488 -0.24115656  0.66241391  0.25476545 -0.23472156  0.32244793]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 870 : 858.3560416466872\n",
      "871000\n",
      "[-10.06202]\n",
      "[9564.715]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31405374 -0.24476158  0.66995568  0.26344984 -0.24438852  0.31451125]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 870 : 862.0315308987446\n",
      "871000\n",
      "[-23.498283]\n",
      "[11023.133]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30143484 -0.23512953  0.66288466  0.25172558 -0.24415749  0.31520839]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 870 : 769.2104890654787\n",
      "871000\n",
      "[-16.735676]\n",
      "[9842.685]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31432676 -0.23870596  0.65326892  0.25492099 -0.24262646  0.30125718]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 870 : 769.6815468135326\n",
      "871000\n",
      "[-17.662552]\n",
      "[7589.0854]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30127006 -0.23745179  0.66946305  0.26255967 -0.25136051  0.32709153]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 880 : 774.0794556661583\n",
      "881000\n",
      "[-15.872945]\n",
      "[8757.679]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.29493909 -0.23500883  0.65504614  0.26320923 -0.23677529  0.31710241]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 880 : 791.3409343288962\n",
      "881000\n",
      "[-6.3891373]\n",
      "[6712.146]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30994057 -0.24672033  0.65831789  0.28299526 -0.23607847  0.31697545]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 880 : 879.954730813306\n",
      "881000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-24.847425]\n",
      "[7674.4834]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.29688435 -0.23850265  0.66091938  0.24890334 -0.25053269  0.32401916]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 880 : 600.646877677323\n",
      "881000\n",
      "[-15.568248]\n",
      "[4374.163]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3142057  -0.24233458  0.68107002  0.2863803  -0.23914638  0.33736327]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 890 : 813.2409033703884\n",
      "891000\n",
      "[-13.483866]\n",
      "[3160.3074]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30947728 -0.24404789  0.68029151  0.28528436 -0.2464824   0.34641466]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 890 : 776.5719825358303\n",
      "891000\n",
      "[-14.751941]\n",
      "[3150.8923]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31890301 -0.23630361  0.67109821  0.27928504 -0.2422694   0.33623964]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 890 : 817.1141696860759\n",
      "891000\n",
      "[-8.843971]\n",
      "[3198.9722]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31528176 -0.24077537  0.68462994  0.28510711 -0.23860842  0.34824374]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 890 : 818.4666817323246\n",
      "891000\n",
      "[-17.559126]\n",
      "[9645.887]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30671335 -0.23270319  0.66521672  0.27520461 -0.23453196  0.32166779]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 900 : 789.9233599881109\n",
      "901000\n",
      "[-11.625183]\n",
      "[6882.084]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31326769 -0.24964258  0.67827682  0.282638   -0.23267345  0.32711186]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 900 : 809.8920240578117\n",
      "901000\n",
      "[-19.391798]\n",
      "[6899.3774]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30376177 -0.23988388  0.66251731  0.27811943 -0.22826327  0.3310304 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 900 : 779.631134433843\n",
      "901000\n",
      "[2.0169106]\n",
      "[5714.3755]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.2992763  -0.23953085  0.67119753  0.28941873 -0.22448317  0.33701907]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 900 : 955.0506570790241\n",
      "901000\n",
      "[-7.746151]\n",
      "[9072.096]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31002479 -0.23918713  0.68525038  0.2845012  -0.23271156  0.32216623]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 910 : 838.337529145715\n",
      "911000\n",
      "[-3.2575722]\n",
      "[6779.819]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30476744 -0.2341566   0.68089688  0.28002329 -0.21647872  0.33114919]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 910 : 853.910403611141\n",
      "911000\n",
      "[-4.959874]\n",
      "[8404.834]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32598665 -0.25968609  0.67941591  0.29920788 -0.21957272  0.3216368 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 910 : 849.639199588753\n",
      "911000\n",
      "[-14.192334]\n",
      "[6926.6104]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3133596  -0.23643038  0.67294792  0.27459893 -0.22844245  0.31628571]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 910 : 772.1866320677397\n",
      "911000\n",
      "[-3.2403288]\n",
      "[7225.119]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31064825 -0.26171865  0.68796459  0.28438641 -0.20317958  0.3393174 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 920 : 858.4344778237819\n",
      "921000\n",
      "[-8.768962]\n",
      "[8500.92]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.29224884 -0.23434335  0.68068183  0.26531472 -0.21640233  0.34335469]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 920 : 777.5298894161366\n",
      "921000\n",
      "[-19.191353]\n",
      "[6462.237]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30225001 -0.24054448  0.65738503  0.25927648 -0.20388757  0.31138853]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 920 : 721.6333943040207\n",
      "921000\n",
      "[-27.924648]\n",
      "[5870.601]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31423898 -0.25077867  0.68582169  0.26626503 -0.21096294  0.33496189]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 920 : 713.6245994675094\n",
      "921000\n",
      "[-12.621877]\n",
      "[9904.303]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31202424 -0.24926992  0.67245891  0.27795473 -0.19376664  0.3273889 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 930 : 881.8304377151017\n",
      "931000\n",
      "[-28.742363]\n",
      "[8374.03]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31067332 -0.24829867  0.66869111  0.25939382 -0.20200212  0.33683688]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 930 : 746.223491911938\n",
      "931000\n",
      "[-24.077143]\n",
      "[11810.542]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30853858 -0.23829909  0.66482293  0.25187559 -0.2031736   0.32418708]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 930 : 750.1231570137617\n",
      "931000\n",
      "[-27.334806]\n",
      "[10220.544]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30741813 -0.24297226  0.6696069   0.25512782 -0.20214646  0.33797217]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 930 : 755.3554063077722\n",
      "931000\n",
      "[-7.0783215]\n",
      "[6329.5884]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31706197 -0.25025012  0.68029883  0.27834375 -0.19527382  0.33364109]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 940 : 890.9786462888696\n",
      "941000\n",
      "[-9.0389]\n",
      "[7357.766]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32439101 -0.24769417  0.6746242   0.27656831 -0.18898086  0.32908805]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 940 : 863.8075495708165\n",
      "941000\n",
      "[-27.41819]\n",
      "[8783.702]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.30999293 -0.23608468  0.66241101  0.25747812 -0.19989989  0.31927242]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 940 : 673.3704490408893\n",
      "941000\n",
      "[-5.745782]\n",
      "[7725.4604]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3133353  -0.24736086  0.6793704   0.27253373 -0.19109001  0.34173545]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 940 : 879.4113461292014\n",
      "941000\n",
      "[-10.598679]\n",
      "[5798.055]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32258169 -0.24832839  0.67488392  0.28366093 -0.18894104  0.32634999]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 950 : 795.5685198792434\n",
      "951000\n",
      "[-1.913516]\n",
      "[6685.923]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31949387 -0.25090663  0.69051716  0.29510007 -0.17946255  0.3491073 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 950 : 961.1522557211828\n",
      "951000\n",
      "[-12.031642]\n",
      "[5500.9556]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31542824 -0.23813152  0.6664882   0.27981983 -0.18939576  0.32117746]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 950 : 791.3151405455679\n",
      "951000\n",
      "[-7.990452]\n",
      "[6217.9775]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31642895 -0.2400019   0.68422858  0.28236671 -0.18932619  0.34131641]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 950 : 906.7732048012803\n",
      "951000\n",
      "[-20.971409]\n",
      "[6958.5967]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32288636 -0.23919181  0.65120682  0.27537489 -0.19222713  0.30086178]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 960 : 708.132726024365\n",
      "961000\n",
      "[-5.728966]\n",
      "[5574.2397]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32900612 -0.25187844  0.67246911  0.29333768 -0.19016346  0.31735252]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 960 : 834.1915642716514\n",
      "961000\n",
      "[-9.540489]\n",
      "[5911.0776]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32037988 -0.23531232  0.67792545  0.28663273 -0.19470051  0.32721654]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 960 : 809.7465224519468\n",
      "961000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.026659]\n",
      "[3776.0134]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32429601 -0.2450157   0.66753806  0.29814856 -0.17624763  0.32049353]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 960 : 846.2397080709491\n",
      "961000\n",
      "[-10.87229]\n",
      "[6063.9883]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31456139 -0.22791547  0.67119062  0.28692001 -0.18812746  0.32212472]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 970 : 776.8764926116105\n",
      "971000\n",
      "[-3.9567852]\n",
      "[6521.2476]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32032085 -0.23070785  0.67862446  0.3014843  -0.17091514  0.32828237]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 970 : 888.7610964934157\n",
      "971000\n",
      "[-6.1222763]\n",
      "[4516.026]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33096615 -0.24428457  0.66749976  0.29120804 -0.17876399  0.30283059]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 970 : 805.8405900997464\n",
      "971000\n",
      "[-13.635912]\n",
      "[4942.553]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32794049 -0.24428762  0.66822137  0.29759286 -0.17442415  0.30341922]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 970 : 779.5035055946418\n",
      "971000\n",
      "[-14.243645]\n",
      "[8082.9424]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34641285 -0.25367435  0.68376431  0.31869075 -0.15509345  0.32000091]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 980 : 928.021324894236\n",
      "981000\n",
      "[-9.450756]\n",
      "[9000.14]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32885699 -0.24155945  0.69825746  0.30549658 -0.15813796  0.3413148 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 980 : 927.892396213861\n",
      "981000\n",
      "[-12.732452]\n",
      "[5781.15]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34020668 -0.24388052  0.67339312  0.30002807 -0.16097725  0.31378784]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 980 : 835.995180977557\n",
      "981000\n",
      "[-4.8066254]\n",
      "[6383.3086]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32802099 -0.2351491   0.68077453  0.29572536 -0.16227061  0.32349478]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 980 : 885.8701752621491\n",
      "981000\n",
      "[-13.902025]\n",
      "[8440.6875]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33447085 -0.23520649  0.66648468  0.29553805 -0.15230279  0.30738047]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 990 : 824.9432736255847\n",
      "991000\n",
      "[-18.178501]\n",
      "[6762.6987]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34175655 -0.25514326  0.67448539  0.30526773 -0.14786554  0.30685096]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 990 : 789.2971360191968\n",
      "991000\n",
      "[-7.102991]\n",
      "[6839.2666]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32685012 -0.24241776  0.66996969  0.31202565 -0.14214354  0.31315804]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 990 : 929.1485372032859\n",
      "991000\n",
      "[-15.919649]\n",
      "[7582.09]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33791893 -0.24389258  0.66776156  0.30159756 -0.16167206  0.29899154]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 990 : 784.5485902656752\n",
      "991000\n",
      "[-18.683329]\n",
      "[2985.4478]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33427349 -0.24576192  0.66509454  0.30307344 -0.14744423  0.29049161]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1000 : 686.3111590155233\n",
      "1001000\n",
      "[-4.823394]\n",
      "[4500.5356]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32386204 -0.23581697  0.66633694  0.30024218 -0.14127928  0.3047396 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1000 : 842.4284031583712\n",
      "1001000\n",
      "[-3.971655]\n",
      "[2437.878]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34124318 -0.24726576  0.66809285  0.31415794 -0.14607661  0.3007665 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1000 : 908.334567512586\n",
      "1001000\n",
      "[-15.383809]\n",
      "[2380.762]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34050545 -0.25038708  0.67537361  0.31231571 -0.14709888  0.30673611]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1000 : 745.1506504117534\n",
      "1001000\n",
      "[-16.59673]\n",
      "[12467.86]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33690249 -0.2400589   0.67286837  0.31348496 -0.13376271  0.32121585]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1010 : 910.3630180703844\n",
      "1011000\n",
      "[-6.8755426]\n",
      "[12410.442]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33326102 -0.24068327  0.67647307  0.30973601 -0.12952104  0.31769916]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1010 : 930.3621535578754\n",
      "1011000\n",
      "[-20.499758]\n",
      "[11563.6455]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33556091 -0.24178399  0.66841997  0.29508883 -0.12826831  0.30367426]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1010 : 753.2052740674645\n",
      "1011000\n",
      "[-17.63587]\n",
      "[10839.275]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33816733 -0.23588032  0.67817938  0.29585722 -0.14150942  0.3201088 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1010 : 771.6041520676628\n",
      "1011000\n",
      "[-8.041953]\n",
      "[7501.2163]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33039558 -0.22860022  0.67446698  0.30721515 -0.12963895  0.3097139 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1020 : 831.5448384306393\n",
      "1021000\n",
      "[-12.06587]\n",
      "[4306.474]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34059602 -0.23428166  0.67846442  0.30431852 -0.13928534  0.31725519]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1020 : 757.8571388248033\n",
      "1021000\n",
      "[-24.153524]\n",
      "[7638.6885]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33315684 -0.23304343  0.64925178  0.29659698 -0.14063148  0.28278338]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1020 : 619.6310782679202\n",
      "1021000\n",
      "[-11.803478]\n",
      "[4998.09]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.31804753 -0.2210345   0.66000103  0.29638062 -0.14242066  0.30376728]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1020 : 790.2491727990672\n",
      "1021000\n",
      "[-20.503569]\n",
      "[2241.7292]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32688339 -0.22494518  0.65518116  0.2883373  -0.12548565  0.31831775]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1030 : 610.9833131032593\n",
      "1031000\n",
      "[0.09812212]\n",
      "[2030.4081]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33077361 -0.23490351  0.66781961  0.3150188  -0.11547247  0.32240825]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1030 : 768.6896466059322\n",
      "1031000\n",
      "[-8.434044]\n",
      "[2809.2515]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33281284 -0.23265599  0.66468782  0.30043822 -0.11973692  0.3178023 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1030 : 708.4652550822311\n",
      "1031000\n",
      "[-2.23027]\n",
      "[3009.8718]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33035692 -0.22854079  0.67223684  0.31040056 -0.12496076  0.32122838]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1030 : 783.4218893162747\n",
      "1031000\n",
      "[-13.103788]\n",
      "[5116.4893]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34799602 -0.24364114  0.66926025  0.3187183  -0.10901438  0.32484853]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1040 : 813.7204005205014\n",
      "1041000\n",
      "[-1.3385677]\n",
      "[5119.349]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33207106 -0.22233864  0.68696528  0.31501107 -0.10044003  0.34190662]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1040 : 950.887828637724\n",
      "1041000\n",
      "[-9.620576]\n",
      "[4346.267]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34759068 -0.24225406  0.66957974  0.31729437 -0.10914324  0.32150641]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1040 : 803.3161196094989\n",
      "1041000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.483972]\n",
      "[3578.4795]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33028687 -0.22673658  0.6746314   0.31261649 -0.10068023  0.34081799]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1040 : 842.7844970627473\n",
      "1041000\n",
      "[-12.518311]\n",
      "[8265.067]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33553219 -0.2164467   0.67033969  0.30376296 -0.10902564  0.32273467]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1050 : 771.7520324168283\n",
      "1051000\n",
      "[-7.0954456]\n",
      "[5844.0845]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3436911  -0.2300489   0.67515911  0.31378164 -0.09666733  0.33536926]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1050 : 870.0246189599594\n",
      "1051000\n",
      "[-22.334475]\n",
      "[6187.906]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34072902 -0.22798952  0.66737858  0.3038884  -0.10481315  0.32075312]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1050 : 680.354001483208\n",
      "1051000\n",
      "[-13.183244]\n",
      "[7097.3076]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34114911 -0.22791585  0.66684285  0.30677277 -0.10602615  0.32569509]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1050 : 782.2240100882293\n",
      "1051000\n",
      "[-6.1817174]\n",
      "[3191.0918]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34591772 -0.22297805  0.67376607  0.32580672 -0.09205735  0.33686669]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1060 : 799.031853500301\n",
      "1061000\n",
      "[-4.995248]\n",
      "[1889.3716]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34672916 -0.23217077  0.65942781  0.31737222 -0.08209171  0.31396851]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1060 : 787.1339377293299\n",
      "1061000\n",
      "[-14.6694765]\n",
      "[2815.3286]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35010241 -0.23843963  0.65459562  0.31786452 -0.09073308  0.32425077]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1060 : 706.9030601406034\n",
      "1061000\n",
      "[-6.204775]\n",
      "[3541.9797]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34764151 -0.22970404  0.66000016  0.31776177 -0.09893404  0.31785379]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1060 : 753.6219494115385\n",
      "1061000\n",
      "[-7.146428]\n",
      "[3276.4084]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33197304 -0.22011252  0.65577817  0.31447139 -0.07968442  0.32729604]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1070 : 743.8398859065344\n",
      "1071000\n",
      "[-13.998113]\n",
      "[5411.704]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33999566 -0.22395903  0.63555052  0.30802372 -0.09030484  0.29475525]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1070 : 650.8760628603023\n",
      "1071000\n",
      "[-28.54794]\n",
      "[4029.76]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33494472 -0.22318854  0.63670592  0.30916493 -0.08883612  0.30469918]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1070 : 631.3696582530497\n",
      "1071000\n",
      "[4.537107]\n",
      "[5899.7026]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33449576 -0.2204524   0.66255342  0.32464249 -0.08383367  0.3319775 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1070 : 808.5658741588189\n",
      "1071000\n",
      "[-7.478798]\n",
      "[6746.1074]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34240016 -0.24631594  0.65004299  0.32464785 -0.0697332   0.3183923 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1080 : 788.6979445445905\n",
      "1081000\n",
      "[-10.007763]\n",
      "[5183.271]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33098658 -0.22965969  0.66023443  0.32249149 -0.06789485  0.33477819]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1080 : 794.7713880356894\n",
      "1081000\n",
      "[-12.453498]\n",
      "[5364.6743]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3348196  -0.23170515  0.64811787  0.31232918 -0.07867739  0.31511363]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1080 : 780.9535519085556\n",
      "1081000\n",
      "[-14.560877]\n",
      "[4685.419]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3319982  -0.2192774   0.64455429  0.3126141  -0.08859194  0.31792979]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1080 : 748.7311970119022\n",
      "1081000\n",
      "[-13.186564]\n",
      "[6272.631]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.32992588 -0.21836903  0.63867865  0.30218143 -0.07653679  0.29795614]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1090 : 732.0752717927274\n",
      "1091000\n",
      "[-0.03782463]\n",
      "[5333.7803]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.33762344 -0.22697064  0.66263989  0.31938513 -0.07226639  0.32245565]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1090 : 852.3944549725071\n",
      "1091000\n",
      "[-2.1015558]\n",
      "[4502.475]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34015329 -0.23316169  0.65881244  0.32106838 -0.0600946   0.32407388]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1090 : 781.3597509546258\n",
      "1091000\n",
      "[-18.012444]\n",
      "[3787.2725]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35063558 -0.24213592  0.64072005  0.31911265 -0.06481425  0.29720877]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1090 : 661.6891133626406\n",
      "1091000\n",
      "[-12.425467]\n",
      "[6365.8193]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34480813 -0.23426964  0.65678787  0.31302041 -0.06547508  0.31283352]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1100 : 833.0179319526933\n",
      "1101000\n",
      "[-42.998306]\n",
      "[6254.14]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34004923 -0.22749505  0.63785282  0.28195134 -0.10014059  0.28563635]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1100 : 457.97809022771753\n",
      "1101000\n",
      "[-8.970081]\n",
      "[3598.4617]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34478087 -0.23223258  0.65696373  0.32129173 -0.06079675  0.32740153]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1100 : 806.4404874809388\n",
      "1101000\n",
      "[1.980031]\n",
      "[4998.752]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34301102 -0.22294319  0.65095661  0.31103388 -0.08023379  0.30314198]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1100 : 823.6892291763082\n",
      "1101000\n",
      "[-5.379531]\n",
      "[4239.6743]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34952332 -0.22249379  0.64823304  0.29871794 -0.06646851  0.28592701]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1110 : 782.8634919926519\n",
      "1111000\n",
      "[-13.428813]\n",
      "[6676.5195]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35446891 -0.22684422  0.6575428   0.29324226 -0.07741068  0.28831313]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1110 : 706.8272923097309\n",
      "1111000\n",
      "[-9.900728]\n",
      "[4739.3447]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34535744 -0.22099376  0.64927948  0.28803346 -0.06478378  0.28337028]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1110 : 687.9609483056604\n",
      "1111000\n",
      "[-3.7278633]\n",
      "[4975.0522]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34241106 -0.22623536  0.66603345  0.30180443 -0.07206518  0.30426765]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1110 : 760.4050746917281\n",
      "1111000\n",
      "[-7.8015285]\n",
      "[4569.1025]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35226475 -0.22692413  0.65861917  0.30897143 -0.05652589  0.29368656]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1120 : 758.1214268366393\n",
      "1121000\n",
      "[-21.655983]\n",
      "[4482.697]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35659728 -0.23214073  0.65140954  0.29580448 -0.06667823  0.29318283]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1120 : 657.5656257224699\n",
      "1121000\n",
      "[-13.793964]\n",
      "[2253.948]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35841794 -0.23008181  0.6527833   0.30267103 -0.0556146   0.29042285]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1120 : 683.9796019184981\n",
      "1121000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.018897]\n",
      "[1788.0371]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34878676 -0.22799168  0.66557522  0.31475852 -0.04842286  0.31095627]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1120 : 826.5851338617067\n",
      "1121000\n",
      "[-0.49510288]\n",
      "[1383.3868]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34528014 -0.21915175  0.6576375   0.31093758 -0.05575808  0.29653624]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1130 : 788.8684101581484\n",
      "1131000\n",
      "[-14.972229]\n",
      "[2197.1865]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34341082 -0.20512516  0.6471273   0.2894603  -0.06876611  0.28135064]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1130 : 661.6537029350484\n",
      "1131000\n",
      "[-4.826847]\n",
      "[1843.679]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34927751 -0.22054628  0.6650265   0.31760168 -0.0620992   0.30682997]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1130 : 759.5930388339756\n",
      "1131000\n",
      "[-8.481981]\n",
      "[1540.3293]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34836788 -0.21998809  0.66120394  0.31138033 -0.06706507  0.29757098]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1130 : 707.9391516965068\n",
      "1131000\n",
      "[-3.20837]\n",
      "[1038.1376]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34581752 -0.21025799  0.67637958  0.30386798 -0.06077201  0.30041929]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1140 : 835.1893643660646\n",
      "1141000\n",
      "[-23.727804]\n",
      "[2364.5186]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3571114  -0.22250683  0.63671034  0.28753874 -0.07027944  0.26701665]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1140 : 659.8795469658432\n",
      "1141000\n",
      "[1.8598809]\n",
      "[629.06335]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35925521 -0.22273438  0.67193314  0.31305241 -0.05302775  0.30636512]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1140 : 874.0399392054501\n",
      "1141000\n",
      "[-5.9973407]\n",
      "[1446.4602]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.34865582 -0.21519755  0.64621396  0.29874079 -0.05332654  0.28190049]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1140 : 764.8540495304125\n",
      "1141000\n",
      "[-6.579674]\n",
      "[6729.0747]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37415508 -0.21993614  0.67444336  0.2996304  -0.06562755  0.29218029]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1150 : 822.5891217893463\n",
      "1151000\n",
      "[-1.9341297]\n",
      "[7301.5522]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36685468 -0.21180257  0.66989893  0.2948399  -0.07000403  0.28176993]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1150 : 857.6358442141127\n",
      "1151000\n",
      "[-10.382892]\n",
      "[4911.052]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36603056 -0.22791475  0.67733012  0.30448051 -0.05678175  0.28943712]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1150 : 812.2580195221024\n",
      "1151000\n",
      "[-18.13058]\n",
      "[6762.9536]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35902029 -0.21136637  0.65202353  0.2847585  -0.07658573  0.26733669]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1150 : 699.1736290543515\n",
      "1151000\n",
      "[-2.6115184]\n",
      "[2494.0322]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35399253 -0.21339093  0.67076317  0.29206052 -0.0609741   0.27485057]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1160 : 923.8891927889299\n",
      "1161000\n",
      "[-0.8675771]\n",
      "[2002.333]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36352449 -0.22534363  0.66230613  0.28176677 -0.06302545  0.2707223 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1160 : 879.1078093320742\n",
      "1161000\n",
      "[-27.025852]\n",
      "[5404.9927]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35775409 -0.21074599  0.63779968  0.27276685 -0.08375469  0.24163438]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1160 : 722.3940852493095\n",
      "1161000\n",
      "[-6.4550433]\n",
      "[3358.518]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36457247 -0.21773116  0.68177591  0.29697851 -0.06082652  0.28041157]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1160 : 864.0940427510315\n",
      "1161000\n",
      "[-12.970828]\n",
      "[8447.496]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36313382 -0.21589113  0.660225    0.27884674 -0.07069383  0.27938184]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1170 : 766.2421561515931\n",
      "1171000\n",
      "[-16.663101]\n",
      "[8998.348]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3613119  -0.21171782  0.6766068   0.29005899 -0.06802309  0.28967063]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1170 : 815.2391629227849\n",
      "1171000\n",
      "[-17.88404]\n",
      "[8146.4214]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36940055 -0.21541999  0.65709199  0.28763038 -0.06145463  0.28427388]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1170 : 842.1280394447656\n",
      "1171000\n",
      "[5.897871]\n",
      "[8667.657]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36934289 -0.21682178  0.66610218  0.30341034 -0.04900203  0.28647375]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1170 : 975.4887001207558\n",
      "1171000\n",
      "[-23.307358]\n",
      "[10058.809]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36062205 -0.20394914  0.66440599  0.27892952 -0.07340828  0.2737144 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1180 : 723.1045513687706\n",
      "1181000\n",
      "[-4.498748]\n",
      "[4660.1426]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36591897 -0.21807697  0.66335909  0.29569239 -0.04306082  0.26578474]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1180 : 916.3292203192118\n",
      "1181000\n",
      "[-13.339461]\n",
      "[6565.761]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36878219 -0.20988859  0.66664579  0.28532449 -0.05577146  0.26175478]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1180 : 798.4154807684305\n",
      "1181000\n",
      "[-5.972178]\n",
      "[6739.448]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35654212 -0.19322134  0.66256824  0.28426629 -0.06170482  0.27657416]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1180 : 877.5512724238683\n",
      "1181000\n",
      "[-25.086908]\n",
      "[4997.7505]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35141455 -0.20208226  0.66639431  0.27104042 -0.06129044  0.26629413]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1190 : 648.1787124533193\n",
      "1191000\n",
      "[-11.00274]\n",
      "[3862.7593]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35609557 -0.20793038  0.67643815  0.27649697 -0.04978631  0.28051704]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1190 : 779.9199659281952\n",
      "1191000\n",
      "[0.8975754]\n",
      "[4404.616]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35323354 -0.21128247  0.66308443  0.28795026 -0.04271427  0.26837467]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1190 : 890.5579284814725\n",
      "1191000\n",
      "[-22.711063]\n",
      "[4285.7915]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35494678 -0.21153033  0.67002542  0.26956263 -0.05786002  0.27466855]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1190 : 684.7273067488105\n",
      "1191000\n",
      "[-5.859039]\n",
      "[5223.0234]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3592026  -0.20623729  0.64948705  0.27250339 -0.03811388  0.24682984]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1200 : 793.1799654795324\n",
      "1201000\n",
      "[-22.268642]\n",
      "[6177.634]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.35354442 -0.19626849  0.65575156  0.26340132 -0.05117622  0.26055646]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1200 : 693.5525167795248\n",
      "1201000\n",
      "[2.0835052]\n",
      "[5173.612]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37199825 -0.21050202  0.66389695  0.28040974 -0.0485899   0.25170948]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1200 : 820.7336196521842\n",
      "1201000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-16.95741]\n",
      "[5290.281]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3617039  -0.20562167  0.66328188  0.27379536 -0.05213337  0.26183205]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1200 : 668.7407036214696\n",
      "1201000\n",
      "[-9.715607]\n",
      "[4009.062]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37556175 -0.21584457  0.66607926  0.2811981  -0.03623842  0.25578865]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1210 : 813.3386605463256\n",
      "1211000\n",
      "[-11.180105]\n",
      "[6198.7734]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37535362 -0.20813349  0.66594786  0.27539708 -0.03479861  0.244898  ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1210 : 755.4059262192519\n",
      "1211000\n",
      "[-3.1219273]\n",
      "[7297.4487]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37631843 -0.2121814   0.67782426  0.28427072 -0.03649258  0.26112637]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1210 : 803.9157002511826\n",
      "1211000\n",
      "[-6.085589]\n",
      "[6310.5776]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36853181 -0.20512857  0.66734892  0.27881578 -0.03984204  0.26291229]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1210 : 812.0039502708515\n",
      "1211000\n",
      "[-33.872475]\n",
      "[10253.11]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36403951 -0.19934061  0.66209973  0.27153504 -0.04369497  0.26063927]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1220 : 736.1419047924498\n",
      "1221000\n",
      "[-1.2779493]\n",
      "[6644.883]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36882839 -0.19925272  0.6840666   0.28654212 -0.00801805  0.28285735]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1220 : 961.3882214405415\n",
      "1221000\n",
      "[-4.4325852]\n",
      "[6453.214]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37746277 -0.2066755   0.67093197  0.28017494 -0.03075582  0.26701564]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1220 : 898.3339339186472\n",
      "1221000\n",
      "[7.48662]\n",
      "[5925.5444]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37164745 -0.20406117  0.69564726  0.29906694 -0.01759798  0.28885982]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1220 : 984.7474878994083\n",
      "1221000\n",
      "[-20.051369]\n",
      "[7210.029]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37696714 -0.21316029  0.66694585  0.27628818 -0.02865932  0.27263056]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1230 : 826.7639097915345\n",
      "1231000\n",
      "[-20.908485]\n",
      "[8126.15]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36879342 -0.20501274  0.66487686  0.28685808 -0.04130613  0.27901286]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1230 : 802.7900524342942\n",
      "1231000\n",
      "[-16.584553]\n",
      "[8436.388]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37210691 -0.20841526  0.68335377  0.28344832 -0.02699847  0.28062768]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1230 : 813.1464301279896\n",
      "1231000\n",
      "[-4.467003]\n",
      "[5760.6313]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36840117 -0.21195171  0.66425709  0.29291113 -0.01693184  0.2744976 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1230 : 994.1193020478133\n",
      "1231000\n",
      "[-13.940632]\n",
      "[6971.808]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38338593 -0.21771076  0.67721758  0.28558032 -0.03098373  0.29257817]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1240 : 826.6178718759835\n",
      "1241000\n",
      "[-10.011659]\n",
      "[9559.482]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37470782 -0.20944235  0.67109007  0.27766803 -0.02255258  0.27086734]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1240 : 813.2602595783476\n",
      "1241000\n",
      "[-7.717807]\n",
      "[6337.96]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38212791 -0.21101554  0.66123521  0.28076033 -0.03702645  0.26561583]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1240 : 879.652861770039\n",
      "1241000\n",
      "[-4.1698794]\n",
      "[9361.993]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36519703 -0.20603693  0.67155848  0.28630556 -0.02543939  0.27969122]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1240 : 881.0972884958899\n",
      "1241000\n",
      "[-1.3419461]\n",
      "[2668.4773]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37467868 -0.20309674  0.66201989  0.26938583 -0.02495     0.25719031]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1250 : 775.7651230730502\n",
      "1251000\n",
      "[-10.57071]\n",
      "[4909.3623]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36736914 -0.20248976  0.65176487  0.26241793 -0.03553541  0.24515163]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1250 : 720.4553327889037\n",
      "1251000\n",
      "[-9.745892]\n",
      "[4446.4956]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37593246 -0.2031335   0.66368688  0.27024038 -0.03308227  0.25828027]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1250 : 720.7954777651804\n",
      "1251000\n",
      "[-0.7208338]\n",
      "[3593.0352]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38014736 -0.20975494  0.66987527  0.27654581 -0.01535435  0.25439013]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1250 : 796.8840472160038\n",
      "1251000\n",
      "[-13.787005]\n",
      "[6468.991]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3758144  -0.22264471  0.67325897  0.28193688 -0.02054109  0.26323428]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1260 : 807.5614067204766\n",
      "1261000\n",
      "[-7.9226723]\n",
      "[9172.694]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37985126 -0.20948815  0.67368196  0.2838306  -0.02375339  0.26961962]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1260 : 912.9508209354246\n",
      "1261000\n",
      "[-15.414977]\n",
      "[7264.688]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37718363 -0.21328153  0.65486207  0.27181311 -0.02586056  0.25229158]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1260 : 760.5954489287977\n",
      "1261000\n",
      "[-11.988421]\n",
      "[6454.276]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37939062 -0.20859467  0.67283018  0.27265275 -0.02284756  0.25476459]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1260 : 848.7313654634534\n",
      "1261000\n",
      "[-7.1663036]\n",
      "[4771.9263]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36394769 -0.19593314  0.68245466  0.27422983 -0.02377179  0.27898034]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1270 : 873.8188119334095\n",
      "1271000\n",
      "[-11.39192]\n",
      "[5117.5005]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37174584 -0.19838296  0.66298136  0.26260721 -0.02920722  0.25226884]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1270 : 799.1542411690434\n",
      "1271000\n",
      "[-9.722129]\n",
      "[5392.]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36728083 -0.19616219  0.65653156  0.25983816 -0.0354248   0.25444411]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1270 : 752.9611466614025\n",
      "1271000\n",
      "[-14.197261]\n",
      "[2685.3245]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37112345 -0.20279158  0.6726617   0.2618061  -0.02851198  0.26617292]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1270 : 767.6583724471154\n",
      "1271000\n",
      "[-3.5178032]\n",
      "[8869.89]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36589858 -0.19439963  0.66158891  0.26497111 -0.02944766  0.27034967]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1280 : 870.1687154436266\n",
      "1281000\n",
      "[-20.619677]\n",
      "[5516.656]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36812371 -0.19284001  0.65012101  0.26105089 -0.04337579  0.25548221]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1280 : 747.0691828452804\n",
      "1281000\n",
      "[-16.69629]\n",
      "[5871.2427]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3669615  -0.19944059  0.65042178  0.26554479 -0.02302172  0.249999  ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1280 : 751.1831087466394\n",
      "1281000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.611701]\n",
      "[5625.026]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36590827 -0.19039472  0.67156368  0.26838301 -0.02746344  0.27207337]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1280 : 801.510237217245\n",
      "1281000\n",
      "[-6.287322]\n",
      "[4508.9756]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3652417  -0.19562482  0.67305557  0.28028259 -0.01415897  0.26920604]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1290 : 940.7978879226713\n",
      "1291000\n",
      "[-15.184275]\n",
      "[3816.423]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37482279 -0.20495055  0.67497843  0.28239927 -0.01661121  0.25558772]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1290 : 799.1419593210503\n",
      "1291000\n",
      "[1.3838778]\n",
      "[3306.1833]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37133989 -0.1972484   0.6723335   0.28666295 -0.01091744  0.26308639]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1290 : 944.7850158702927\n",
      "1291000\n",
      "[-15.149532]\n",
      "[3245.7239]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36277773 -0.19377832  0.66074276  0.26829217 -0.02832881  0.25298912]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1290 : 803.7497810448009\n",
      "1291000\n",
      "[-15.718743]\n",
      "[2311.1274]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37326524 -0.19615167  0.66647006  0.26801331 -0.03832531  0.25794773]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1300 : 654.4115433194027\n",
      "1301000\n",
      "[2.793776]\n",
      "[2434.6545]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36151783 -0.1953683   0.67414887  0.28879671 -0.02334623  0.26149046]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1300 : 804.8614034862733\n",
      "1301000\n",
      "[4.788598]\n",
      "[1215.0066]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37110394 -0.18913444  0.68363884  0.27763466 -0.02708383  0.26972254]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1300 : 849.7340457480944\n",
      "1301000\n",
      "[-19.951416]\n",
      "[3317.981]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36269639 -0.19137409  0.66281729  0.26854119 -0.03226919  0.26026163]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1300 : 655.8693312815088\n",
      "1301000\n",
      "[-6.002667]\n",
      "[6625.2817]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37583459 -0.20497542  0.67812391  0.28263391 -0.01607258  0.2698821 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1310 : 789.1565175819395\n",
      "1311000\n",
      "[-12.268793]\n",
      "[7592.1807]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38166916 -0.20349911  0.67855557  0.28767672 -0.02390544  0.26780999]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1310 : 849.8841285458785\n",
      "1311000\n",
      "[-13.970235]\n",
      "[6973.064]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37322564 -0.20600062  0.66975891  0.271576   -0.03079284  0.25609264]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1310 : 730.5208712044839\n",
      "1311000\n",
      "[-6.6216526]\n",
      "[6380.755]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36516522 -0.19805054  0.68116794  0.29186934 -0.0091546   0.27296727]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1310 : 871.7543398700873\n",
      "1311000\n",
      "[-11.53136]\n",
      "[5272.3037]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37330863 -0.19735328  0.66663964  0.28290566 -0.00782639  0.26396904]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1320 : 883.9619535669074\n",
      "1321000\n",
      "[-1.229249]\n",
      "[5993.3286]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37705696 -0.19366652  0.67146415  0.2901682  -0.00671303  0.26197602]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1320 : 960.754337802716\n",
      "1321000\n",
      "[-17.675266]\n",
      "[7544.6636]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37340491 -0.19065122  0.66185628  0.27214881 -0.01740099  0.25349169]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1320 : 803.4140517339317\n",
      "1321000\n",
      "[-9.053643]\n",
      "[4113.972]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38065234 -0.19652185  0.68502001  0.28767099 -0.01129081  0.27130751]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1320 : 870.5440669770807\n",
      "1321000\n",
      "[-15.323826]\n",
      "[5072.556]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38323841 -0.20508975  0.65669297  0.27940498 -0.01046677  0.24397271]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1330 : 596.1957436638828\n",
      "1331000\n",
      "[-9.922421]\n",
      "[3250.9646]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3885843  -0.21559005  0.66700929  0.28574075 -0.02095482  0.25935197]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1330 : 664.9573693015801\n",
      "1331000\n",
      "[-24.072395]\n",
      "[3530.3604]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38039219 -0.21274876  0.65874729  0.27520372 -0.00951975  0.24176752]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1330 : 601.1851449520541\n",
      "1331000\n",
      "[14.0945215]\n",
      "[2157.9465]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38777076 -0.21245142  0.68613048  0.30329056  0.01021734  0.27023906]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1330 : 879.0701894670203\n",
      "1331000\n",
      "[-18.486452]\n",
      "[2032.7539]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38125597 -0.20135873  0.66800807  0.28169071 -0.00365547  0.25417566]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1340 : 656.9087930843223\n",
      "1341000\n",
      "[-4.3134084]\n",
      "[1821.5372]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37753966 -0.20338383  0.67718194  0.28552864 -0.00335048  0.2610399 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1340 : 765.7491970796747\n",
      "1341000\n",
      "[-5.566191]\n",
      "[2387.7231]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37376522 -0.20791089  0.67855781  0.29589198  0.00455699  0.27075722]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1340 : 819.2605453761777\n",
      "1341000\n",
      "[-10.010901]\n",
      "[2282.3174]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38213    -0.21321339  0.66215956  0.29052026 -0.0047395   0.25051711]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1340 : 776.193717776521\n",
      "1341000\n",
      "[-0.23772144]\n",
      "[4896.807]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37562141 -0.20349939  0.68058408  0.29384754  0.01091705  0.27448652]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1350 : 816.779935869983\n",
      "1351000\n",
      "[-13.672246]\n",
      "[7630.718]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36966826 -0.19447727  0.6703371   0.27683504  0.00197711  0.26469472]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1350 : 770.1981460139997\n",
      "1351000\n",
      "[-2.1619024]\n",
      "[3939.7915]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37840036 -0.20837377  0.670707    0.29257455  0.01831039  0.25106005]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1350 : 808.9813095124546\n",
      "1351000\n",
      "[-24.906906]\n",
      "[6026.0405]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37208861 -0.19577635  0.67017036  0.27101766 -0.00513614  0.25184397]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1350 : 680.719690945197\n",
      "1351000\n",
      "[5.708465]\n",
      "[1304.3461]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3794375  -0.20876471  0.67923568  0.29126777  0.01880357  0.2610245 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1360 : 858.7943130480378\n",
      "1361000\n",
      "[-7.249095]\n",
      "[1107.7115]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37450559 -0.20923874  0.65890892  0.28693946  0.013896    0.24476805]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1360 : 734.7340513595623\n",
      "1361000\n",
      "[-4.7744613]\n",
      "[2181.2844]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38066082 -0.21278532  0.65649248  0.29044986  0.01923127  0.2419629 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1360 : 722.7387234601853\n",
      "1361000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.187634]\n",
      "[779.16895]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3713221  -0.20280445  0.66334701  0.28683078  0.01422092  0.25002268]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1360 : 789.038067800318\n",
      "1361000\n",
      "[-16.14071]\n",
      "[3705.7903]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36832583 -0.20897149  0.65781816  0.28377309  0.01072646  0.24369174]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1370 : 700.8346771333798\n",
      "1371000\n",
      "[-1.6268792]\n",
      "[1311.8542]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38218377 -0.21428114  0.66335433  0.29632632  0.02097834  0.24338477]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1370 : 791.1575109630114\n",
      "1371000\n",
      "[-19.782522]\n",
      "[1893.0099]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37906433 -0.20852039  0.65563107  0.28252113  0.01304084  0.23823533]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1370 : 675.6194080072853\n",
      "1371000\n",
      "[-9.613132]\n",
      "[1919.2051]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37385415 -0.20979523  0.68168137  0.29118733  0.01383883  0.26303447]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1370 : 682.1689752760979\n",
      "1371000\n",
      "[-34.44723]\n",
      "[6376.1343]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36346278 -0.19910013  0.65841441  0.26541378  0.00148674  0.24476458]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1380 : 568.3309264088144\n",
      "1381000\n",
      "[-3.9497442]\n",
      "[2591.837]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37273274 -0.21722201  0.67104278  0.28023063  0.02845376  0.2569496 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1380 : 771.8151545806965\n",
      "1381000\n",
      "[-5.531809]\n",
      "[4654.0366]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37341879 -0.20884757  0.68203497  0.28562822  0.02612081  0.2618195 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1380 : 768.7927744046814\n",
      "1381000\n",
      "[-2.6731896]\n",
      "[2495.1746]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36406399 -0.19704504  0.68219519  0.28335294  0.01468369  0.26348377]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1380 : 807.8255255041104\n",
      "1381000\n",
      "[-19.053726]\n",
      "[3018.6958]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36861604 -0.21021744  0.66161396  0.2761489   0.02968927  0.2405932 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1390 : 684.0413249138745\n",
      "1391000\n",
      "[-4.8630095]\n",
      "[2275.9158]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3745643  -0.20570735  0.66693319  0.28050243  0.02341795  0.24987123]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1390 : 791.9639714058574\n",
      "1391000\n",
      "[-14.641411]\n",
      "[1920.0417]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37164704 -0.21069219  0.6607934   0.27471273  0.02920147  0.24259053]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1390 : 661.2967076215465\n",
      "1391000\n",
      "[-6.0269346]\n",
      "[2783.1223]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37237269 -0.21345475  0.66426763  0.27455971  0.02625219  0.24515912]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1390 : 740.0778523075903\n",
      "1391000\n",
      "[-9.164963]\n",
      "[1447.3809]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38330336 -0.21851332  0.65950283  0.27037411  0.01756704  0.23077575]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1400 : 657.1730480420498\n",
      "1401000\n",
      "[-2.60949]\n",
      "[1594.115]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37371391 -0.20334838  0.6631272   0.28183584  0.02335824  0.23565252]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1400 : 701.5446611891194\n",
      "1401000\n",
      "[-6.02661]\n",
      "[1769.6047]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36722044 -0.20402702  0.64839726  0.27319066  0.02019579  0.23762662]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1400 : 698.5068986725337\n",
      "1401000\n",
      "[-10.919347]\n",
      "[830.6262]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37009609 -0.21328459  0.66121224  0.27459362  0.02431597  0.24720058]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1400 : 624.7424300772968\n",
      "1401000\n",
      "[-6.59042]\n",
      "[2374.0195]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37395241 -0.21416476  0.66905882  0.27987663  0.03914654  0.2573336 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1410 : 779.4846115242938\n",
      "1411000\n",
      "[-4.97765]\n",
      "[3208.6174]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36623917 -0.2114575   0.66255296  0.27323903  0.03311414  0.24848296]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1410 : 764.1576265163776\n",
      "1411000\n",
      "[7.5514503]\n",
      "[1007.5386]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.36789829 -0.20705834  0.68001304  0.28874353  0.04087775  0.26747166]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1410 : 867.5632860543302\n",
      "1411000\n",
      "[-14.224617]\n",
      "[2008.5265]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37141615 -0.21231791  0.66641097  0.27238412  0.02446257  0.25103337]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1410 : 684.5883817044332\n",
      "1411000\n",
      "[-13.373394]\n",
      "[4037.7185]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38067509 -0.21689841  0.65843128  0.28662762  0.02025886  0.23851387]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1420 : 837.9436331485734\n",
      "1421000\n",
      "[-2.7500262]\n",
      "[3926.0847]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37972278 -0.22466767  0.66829014  0.29015767  0.04153132  0.25236036]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1420 : 855.199536681082\n",
      "1421000\n",
      "[-16.777925]\n",
      "[7925.397]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37294169 -0.21199218  0.66427435  0.28350701  0.02810341  0.25224282]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1420 : 779.972954450984\n",
      "1421000\n",
      "[-6.4657364]\n",
      "[3613.0942]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37716945 -0.22174313  0.66020128  0.29139056  0.03577839  0.24843312]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1420 : 880.4603222198637\n",
      "1421000\n",
      "[-16.35619]\n",
      "[8027.7246]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37570998 -0.21385147  0.6543131   0.27750678  0.0216407   0.23827069]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1430 : 752.0273868429446\n",
      "1431000\n",
      "[-14.431943]\n",
      "[4138.488]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38924155 -0.22727651  0.66592141  0.29144763  0.03097591  0.23377735]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1430 : 765.1985965922538\n",
      "1431000\n",
      "[-6.2934084]\n",
      "[3731.312]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37188265 -0.20966362  0.67270958  0.29057154  0.0443028   0.25375708]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1430 : 849.247704086933\n",
      "1431000\n",
      "[-5.6474657]\n",
      "[3332.7559]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37405186 -0.21106948  0.67676041  0.29234443  0.03692853  0.27023476]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1430 : 871.526141766845\n",
      "1431000\n",
      "[-20.246185]\n",
      "[4016.6584]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38248191 -0.22092715  0.66129783  0.27230245  0.01669334  0.2280527 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1440 : 683.8939617224527\n",
      "1441000\n",
      "[-13.544198]\n",
      "[3642.4253]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38946598 -0.22443295  0.65747808  0.27889808  0.02284525  0.23090392]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1440 : 719.45354243777\n",
      "1441000\n",
      "[2.7299929]\n",
      "[2853.5693]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38237768 -0.21214024  0.66488021  0.28527086  0.03118399  0.23230124]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1440 : 884.6386426578804\n",
      "1441000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.189275]\n",
      "[3537.335]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3877158  -0.21326522  0.67782236  0.27914256  0.03359035  0.24410152]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1440 : 750.1754391780576\n",
      "1441000\n",
      "[-4.3784695]\n",
      "[1743.6914]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3885732  -0.23565676  0.66256272  0.29454624  0.02055262  0.22082236]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1450 : 713.056701025584\n",
      "1451000\n",
      "[-15.987735]\n",
      "[1378.614]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37883088 -0.21747457  0.6617594   0.27197597  0.02853804  0.2274156 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1450 : 594.7291585110064\n",
      "1451000\n",
      "[0.41944742]\n",
      "[1276.0449]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38545901 -0.2217032   0.67412044  0.28444325  0.02782734  0.23571487]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1450 : 749.600307689956\n",
      "1451000\n",
      "[-13.906793]\n",
      "[1379.0245]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37975532 -0.22510186  0.64522842  0.27694642  0.02923155  0.21062187]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1450 : 619.7567658950842\n",
      "1451000\n",
      "[-10.8047905]\n",
      "[4700.3525]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37870777 -0.22182012  0.66739248  0.29716073  0.03602526  0.23089818]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1460 : 842.4530501198342\n",
      "1461000\n",
      "[2.5637002]\n",
      "[2832.8281]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37318984 -0.21835591  0.67059058  0.29116662  0.04896672  0.23236508]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1460 : 874.9290402863086\n",
      "1461000\n",
      "[-0.01387596]\n",
      "[1857.0776]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37872664 -0.21869678  0.68288432  0.29619085  0.05340133  0.24554328]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1460 : 853.4192569252502\n",
      "1461000\n",
      "[-17.480423]\n",
      "[4510.6294]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38026452 -0.21649776  0.67236639  0.28195519  0.02966038  0.23878113]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1460 : 744.0189306512908\n",
      "1461000\n",
      "[-7.2050037]\n",
      "[2853.5884]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38159136 -0.22116424  0.6586282   0.29334765  0.028929    0.22491063]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1470 : 741.8489300103765\n",
      "1471000\n",
      "[-1.1463509]\n",
      "[3424.6138]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38264775 -0.22153266  0.67989939  0.29778844  0.03698687  0.25150315]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1470 : 849.724905326772\n",
      "1471000\n",
      "[-36.897358]\n",
      "[4234.724]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38115063 -0.21611259  0.66269034  0.27940127  0.02273016  0.23743008]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1470 : 542.9528532780394\n",
      "1471000\n",
      "[0.85344744]\n",
      "[2048.249]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38730931 -0.22437829  0.67857062  0.29904573  0.0470598   0.25321614]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1470 : 831.366633169458\n",
      "1471000\n",
      "[-22.43314]\n",
      "[4010.6836]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39232066 -0.21428424  0.66943382  0.28938827  0.03357556  0.22755777]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1480 : 682.3679322738931\n",
      "1481000\n",
      "[-8.495666]\n",
      "[4531.9966]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3787179  -0.2009197   0.65362185  0.28126936  0.03655848  0.22442336]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1480 : 790.795415973269\n",
      "1481000\n",
      "[6.100418]\n",
      "[3642.8557]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38146077 -0.20756926  0.67451843  0.30533828  0.05187671  0.23569972]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1480 : 927.3994127871279\n",
      "1481000\n",
      "[-10.313623]\n",
      "[2999.193]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37916478 -0.20660793  0.68275005  0.28842723  0.04312408  0.24583017]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1480 : 752.8376913734369\n",
      "1481000\n",
      "[-17.700043]\n",
      "[4310.814]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39162308 -0.21559556  0.67176544  0.29074683  0.03693659  0.24088654]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1490 : 716.0589940733772\n",
      "1491000\n",
      "[-9.327322]\n",
      "[5382.8174]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.387029   -0.21157195  0.66953477  0.29621859  0.0363819   0.23303651]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1490 : 812.5444623325137\n",
      "1491000\n",
      "[-7.942683]\n",
      "[5399.6216]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.37962288 -0.20626179  0.67410452  0.29169699  0.03628637  0.25192436]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1490 : 742.1411792959673\n",
      "1491000\n",
      "[-0.71896076]\n",
      "[3165.1318]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39469655 -0.21249402  0.68484339  0.29553146  0.05381276  0.24782689]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1490 : 839.5618925192425\n",
      "1491000\n",
      "[-0.08603954]\n",
      "[2608.4382]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39060597 -0.20068583  0.67333116  0.29694756  0.03984396  0.24132021]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1500 : 792.7814567743882\n",
      "1501000\n",
      "[-26.828468]\n",
      "[4639.2646]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39216846 -0.20066169  0.67103264  0.28197869  0.01419236  0.23282964]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1500 : 650.8672063575759\n",
      "1501000\n",
      "[-5.4549766]\n",
      "[2640.0227]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3915047  -0.20981686  0.67323742  0.29416089  0.04395747  0.24427519]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1500 : 776.4460904320782\n",
      "1501000\n",
      "[-2.273705]\n",
      "[2690.9336]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39992008 -0.20982265  0.67819624  0.2983301   0.04871062  0.23721937]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1500 : 771.9440353318785\n",
      "1501000\n",
      "[-17.353264]\n",
      "[4212.976]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39807733 -0.20611478  0.67294671  0.28525832  0.03144007  0.24518351]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1510 : 671.0813235045512\n",
      "1511000\n",
      "[-8.816543]\n",
      "[4831.778]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39735975 -0.21706742  0.65819783  0.27932801  0.04150337  0.21779152]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1510 : 685.2279502016967\n",
      "1511000\n",
      "[-6.885398]\n",
      "[4351.05]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39372107 -0.19377626  0.67644146  0.28800989  0.04558269  0.23807804]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1510 : 706.65074924437\n",
      "1511000\n",
      "[10.076045]\n",
      "[2742.2104]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3898275  -0.20643821  0.66731497  0.30264407  0.05663301  0.23391595]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1510 : 879.2052615726906\n",
      "1511000\n",
      "[-8.036279]\n",
      "[2613.5896]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39918518 -0.20962435  0.67322191  0.29307382  0.04765794  0.23705056]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1520 : 715.9724162199258\n",
      "1521000\n",
      "[-14.501593]\n",
      "[4731.0596]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3983066  -0.2153808   0.67481707  0.3031355   0.03912405  0.244851  ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1520 : 757.6557819707376\n",
      "1521000\n",
      "[2.7793474]\n",
      "[3595.687]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39199031 -0.20482591  0.68351649  0.31076171  0.04567612  0.26154937]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1520 : 845.1076121698519\n",
      "1521000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.5057716]\n",
      "[4406.1313]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38708029 -0.1991573   0.68246171  0.30040948  0.04114428  0.25363753]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1520 : 830.7105186470294\n",
      "1521000\n",
      "[2.7105818]\n",
      "[3306.5725]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38728635 -0.19527328  0.67715688  0.29928788  0.03991314  0.2585428 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1530 : 789.2007785646871\n",
      "1531000\n",
      "[-8.445955]\n",
      "[5853.8594]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38808458 -0.20064676  0.66304183  0.2957546   0.03471369  0.24605763]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1530 : 701.2658241761952\n",
      "1531000\n",
      "[-1.2515535]\n",
      "[2690.1304]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38974952 -0.20130663  0.67364363  0.30066952  0.03919184  0.24448219]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1530 : 759.8353660557352\n",
      "1531000\n",
      "[-22.681477]\n",
      "[4530.011]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3864739  -0.20456308  0.67357655  0.28713938  0.02429491  0.24444507]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1530 : 561.8457353930633\n",
      "1531000\n",
      "[3.1775026]\n",
      "[3313.9414]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39106826 -0.21287592  0.68669116  0.31826659  0.04966489  0.26658222]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1540 : 870.4061089210944\n",
      "1541000\n",
      "[-7.606225]\n",
      "[4590.792]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3870388  -0.2028998   0.67284116  0.30940764  0.04141263  0.24603379]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1540 : 776.9343108584053\n",
      "1541000\n",
      "[-10.379198]\n",
      "[3641.0266]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38993898 -0.20185484  0.65512103  0.31175499  0.04359911  0.22624879]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1540 : 761.7472155085123\n",
      "1541000\n",
      "[-5.508024]\n",
      "[3561.363]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3942266  -0.21070706  0.66706299  0.30688872  0.05013105  0.24043166]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1540 : 787.3925257499642\n",
      "1541000\n",
      "[-18.29526]\n",
      "[6527.662]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39219405 -0.20322379  0.65761085  0.30473666  0.03346488  0.23168536]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1550 : 667.9336199717101\n",
      "1551000\n",
      "[6.9402347]\n",
      "[2917.2554]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39507681 -0.19578748  0.68920411  0.32786469  0.05114664  0.25765342]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1550 : 865.4645033263138\n",
      "1551000\n",
      "[-7.593604]\n",
      "[3415.7764]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38488328 -0.19248369  0.66993625  0.30774428  0.03533879  0.24692435]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1550 : 770.379405725836\n",
      "1551000\n",
      "[-3.2979808]\n",
      "[2610.3381]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39159486 -0.20531421  0.66852572  0.31615578  0.05876977  0.23941514]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1550 : 769.2403086928196\n",
      "1551000\n",
      "[-21.958714]\n",
      "[3222.572]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39847248 -0.20676081  0.65634079  0.29556333  0.03533817  0.21970129]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1560 : 603.8249841261004\n",
      "1561000\n",
      "[-1.8650064]\n",
      "[3523.6038]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39230483 -0.19989613  0.66902983  0.31274118  0.04024286  0.24403541]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1560 : 823.8581290675604\n",
      "1561000\n",
      "[-12.711148]\n",
      "[2943.2883]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39075486 -0.19578255  0.66297926  0.29939279  0.03451833  0.24423972]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1560 : 705.2107653141483\n",
      "1561000\n",
      "[2.040598]\n",
      "[3119.6426]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39472894 -0.19506179  0.68141447  0.30689528  0.04799246  0.25841129]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1560 : 823.9067511947655\n",
      "1561000\n",
      "[13.343063]\n",
      "[1297.8734]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39171483 -0.19023286  0.68617344  0.31379214  0.05567381  0.2612746 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1570 : 918.0529708732477\n",
      "1571000\n",
      "[-15.126743]\n",
      "[4303.324]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3942757  -0.18847722  0.66719484  0.2977135   0.03776082  0.2362785 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1570 : 702.3879854145671\n",
      "1571000\n",
      "[-9.140316]\n",
      "[2244.0557]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38375751 -0.19167491  0.67515252  0.30138895  0.04807047  0.26056575]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1570 : 735.4681847531222\n",
      "1571000\n",
      "[-4.9905066]\n",
      "[2182.5461]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39253993 -0.19340764  0.65888775  0.29814333  0.04188791  0.23747589]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1570 : 764.5656040187563\n",
      "1571000\n",
      "[-7.176646]\n",
      "[3372.8381]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39820375 -0.18753539  0.67740367  0.31416064  0.05305625  0.2497337 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1580 : 813.3020477177919\n",
      "1581000\n",
      "[-8.246822]\n",
      "[3064.1235]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39300649 -0.18921124  0.66893486  0.30381426  0.04188293  0.23777547]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1580 : 747.9351456284395\n",
      "1581000\n",
      "[-26.371399]\n",
      "[2974.2969]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40267686 -0.19279456  0.67658314  0.30479417  0.03514953  0.23751889]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1580 : 656.0040799379481\n",
      "1581000\n",
      "[-6.4156117]\n",
      "[2933.903]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.401508   -0.19480486  0.67772814  0.30995726  0.04129077  0.24123384]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1580 : 739.3836698291748\n",
      "1581000\n",
      "[-9.193937]\n",
      "[5470.0166]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3934969  -0.17884589  0.67892311  0.31378619  0.05148918  0.25002204]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1590 : 807.7172731297995\n",
      "1591000\n",
      "[-18.107632]\n",
      "[4798.55]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39182389 -0.17865588  0.68426825  0.31293622  0.02857258  0.25875849]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1590 : 730.9082842865699\n",
      "1591000\n",
      "[-5.9594517]\n",
      "[3766.8108]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3958171  -0.17939277  0.67937931  0.32035886  0.0509008   0.25692096]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1590 : 803.8829587310152\n",
      "1591000\n",
      "[-6.245936]\n",
      "[3697.5923]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39594773 -0.19307284  0.68381582  0.32346076  0.04905964  0.25749621]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1590 : 802.8180347075902\n",
      "1591000\n",
      "[0.8548336]\n",
      "[4000.0686]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.38744409 -0.17487708  0.67408114  0.32027529  0.05000783  0.24254534]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1600 : 807.8096352210505\n",
      "1601000\n",
      "[-2.2696571]\n",
      "[2165.5752]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4008707  -0.1866114   0.67239213  0.31493275  0.05483547  0.23501988]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1600 : 815.9892180358532\n",
      "1601000\n",
      "[-0.32156038]\n",
      "[1788.3274]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39753159 -0.19076146  0.6748413   0.31934823  0.05022549  0.24716768]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1600 : 779.7244624177195\n",
      "1601000\n",
      "[-11.219107]\n",
      "[1881.7073]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40180137 -0.18372108  0.68393486  0.31117651  0.04833476  0.25343108]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1600 : 757.6126859935835\n",
      "1601000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.7322326]\n",
      "[1875.0508]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39960713 -0.18539657  0.67114285  0.31707137  0.05132621  0.23485286]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1610 : 828.8567312081938\n",
      "1611000\n",
      "[-18.405205]\n",
      "[2521.3623]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40599639 -0.19576197  0.66802932  0.3160465   0.04231834  0.21963663]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1610 : 733.9216140201704\n",
      "1611000\n",
      "[-10.188034]\n",
      "[2110.2744]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39375126 -0.18068394  0.67694242  0.32053193  0.05069581  0.23994799]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1610 : 796.1940943019875\n",
      "1611000\n",
      "[11.527647]\n",
      "[1105.5177]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40160143 -0.18199827  0.69620049  0.33141573  0.06110852  0.25561203]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1610 : 941.8249916285747\n",
      "1611000\n",
      "[-0.00637436]\n",
      "[3451.7764]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40604826 -0.18952716  0.69095559  0.31661088  0.05473631  0.25898712]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1620 : 814.3436416335181\n",
      "1621000\n",
      "[-12.394955]\n",
      "[3989.6685]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40167171 -0.18878239  0.66332884  0.31105327  0.03941784  0.22939492]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1620 : 714.0041689951161\n",
      "1621000\n",
      "[-9.470163]\n",
      "[4167.4644]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40062009 -0.18098485  0.67832076  0.31366697  0.0399869   0.25004796]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1620 : 762.618087473497\n",
      "1621000\n",
      "[-14.437046]\n",
      "[4245.8184]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40308468 -0.1813568   0.6828204   0.31947414  0.04163761  0.2511238 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1620 : 755.1445825849655\n",
      "1621000\n",
      "[-5.1671367]\n",
      "[3090.875]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39861161 -0.18799746  0.67961172  0.31835036  0.04561929  0.23994786]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1630 : 772.6196197792501\n",
      "1631000\n",
      "[-12.407963]\n",
      "[3166.9082]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40339322 -0.18280463  0.6721507   0.3150707   0.06055701  0.23999088]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1630 : 736.2199693336628\n",
      "1631000\n",
      "[-3.845123]\n",
      "[2641.4768]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40472075 -0.18227811  0.68563793  0.3234587   0.05287545  0.25164244]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1630 : 794.5120657217659\n",
      "1631000\n",
      "[-3.6218772]\n",
      "[2387.1704]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4026929  -0.18429274  0.67399584  0.31386385  0.04525609  0.23823995]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1630 : 798.2260368853092\n",
      "1631000\n",
      "[-20.201908]\n",
      "[2010.3984]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39209578 -0.17319662  0.65873016  0.30643195  0.04476494  0.23098531]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1640 : 654.4780644017226\n",
      "1641000\n",
      "[-14.362323]\n",
      "[1436.8121]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40615098 -0.18703185  0.67179162  0.31511579  0.04735136  0.22824029]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1640 : 673.9741344597314\n",
      "1641000\n",
      "[-13.36956]\n",
      "[2840.3484]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40429968 -0.17886477  0.66736346  0.31509903  0.04969669  0.22955989]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1640 : 698.9925878249022\n",
      "1641000\n",
      "[10.077991]\n",
      "[894.0636]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40473072 -0.18458559  0.68634855  0.32171461  0.06061692  0.25171028]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1640 : 890.6202355241826\n",
      "1641000\n",
      "[-1.7224789]\n",
      "[2237.2783]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39950989 -0.16486314  0.68668478  0.31578214  0.0388945   0.24943074]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1650 : 806.7032477160582\n",
      "1651000\n",
      "[-13.904033]\n",
      "[1962.6915]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39694931 -0.17868371  0.67148145  0.31397121  0.03031406  0.24731891]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1650 : 662.6194787794108\n",
      "1651000\n",
      "[-15.201012]\n",
      "[4078.8164]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40182085 -0.18075077  0.67075032  0.30886323  0.03351659  0.23069616]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1650 : 642.697211962245\n",
      "1651000\n",
      "[-5.787153]\n",
      "[2096.7476]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40767746 -0.17758704  0.67125643  0.31396061  0.04339738  0.23008113]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1650 : 713.7300809159973\n",
      "1651000\n",
      "[-2.986187]\n",
      "[3971.772]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4006836  -0.17483752  0.69300892  0.33306224  0.04810535  0.26712622]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1660 : 854.1054473963659\n",
      "1661000\n",
      "[-17.729198]\n",
      "[4473.1406]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39981326 -0.17005976  0.67555508  0.31881816  0.04284944  0.24014518]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1660 : 756.8766341531463\n",
      "1661000\n",
      "[-18.896818]\n",
      "[4967.827]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39996678 -0.17815613  0.67469558  0.32218775  0.03214065  0.24250763]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1660 : 728.5021148199351\n",
      "1661000\n",
      "[-11.056294]\n",
      "[3734.715]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3989527  -0.17573901  0.67383591  0.32785315  0.04190493  0.24248558]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1660 : 816.5432076094119\n",
      "1661000\n",
      "[-7.285956]\n",
      "[2610.7073]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40313032 -0.18716581  0.66451428  0.31879237  0.03799065  0.22630852]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1670 : 690.5260666959621\n",
      "1671000\n",
      "[-18.75579]\n",
      "[3669.9539]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41205986 -0.18715141  0.67454204  0.32151937  0.03700067  0.22885166]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1670 : 612.6317805309731\n",
      "1671000\n",
      "[-5.131479]\n",
      "[1913.4916]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40312531 -0.19446433  0.66875776  0.32206002  0.04359225  0.23526922]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1670 : 693.6794227566106\n",
      "1671000\n",
      "[12.344472]\n",
      "[1790.9883]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39987242 -0.18382307  0.66638918  0.32951543  0.05242479  0.23126067]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1670 : 842.3202743123402\n",
      "1671000\n",
      "[-4.132938]\n",
      "[2997.1409]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40188989 -0.17765988  0.67407194  0.33716539  0.05223194  0.23481792]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1680 : 848.4187240489058\n",
      "1681000\n",
      "[-10.278303]\n",
      "[3697.7837]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39979202 -0.17801039  0.68037333  0.33216101  0.05076742  0.248116  ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1680 : 784.391417383069\n",
      "1681000\n",
      "[-3.75345]\n",
      "[3890.8958]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39792786 -0.17946018  0.6731996   0.33026934  0.05084221  0.24466077]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1680 : 852.839757058516\n",
      "1681000\n",
      "[-18.281292]\n",
      "[2677.157]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40492315 -0.18540437  0.67073199  0.32419006  0.04543112  0.24064329]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1680 : 723.6151928002856\n",
      "1681000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.424969]\n",
      "[3344.1348]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41132767 -0.18787109  0.68039011  0.34150282  0.0500725   0.24087001]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1690 : 756.3095715808731\n",
      "1691000\n",
      "[-1.0441203]\n",
      "[1856.9407]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39958065 -0.18173264  0.67649094  0.33558578  0.06820313  0.23866348]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1690 : 786.8842269867569\n",
      "1691000\n",
      "[-13.0144415]\n",
      "[3006.6738]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40365547 -0.17525565  0.67795519  0.3218707   0.04673353  0.24378576]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1690 : 761.1701331432209\n",
      "1691000\n",
      "[-5.248006]\n",
      "[2042.9789]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40619262 -0.19221246  0.67252976  0.32759763  0.05499077  0.24038136]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1690 : 795.0079896112259\n",
      "1691000\n",
      "[-1.1075597]\n",
      "[3305.6313]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40147124 -0.18236197  0.66775284  0.34514239  0.06254547  0.2410592 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1700 : 784.4551112199376\n",
      "1701000\n",
      "[-13.700856]\n",
      "[4492.3877]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40447989 -0.18640316  0.67144846  0.33392288  0.04331161  0.23964611]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1700 : 720.41219336756\n",
      "1701000\n",
      "[-28.606968]\n",
      "[4510.5103]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41216041 -0.19129112  0.65512289  0.32584673  0.02882718  0.22221317]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1700 : 627.197395923502\n",
      "1701000\n",
      "[7.2016854]\n",
      "[2402.2085]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40109936 -0.18638093  0.67325132  0.34794789  0.06353608  0.24267636]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1700 : 853.6031219941128\n",
      "1701000\n",
      "[-10.722366]\n",
      "[2083.9456]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40655875 -0.17739721  0.67372793  0.33976622  0.05526685  0.2378351 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1710 : 718.3418418823306\n",
      "1711000\n",
      "[0.32031155]\n",
      "[2487.3042]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40646163 -0.1765304   0.68116966  0.35406034  0.07181293  0.24504744]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1710 : 824.1841345862151\n",
      "1711000\n",
      "[-4.266389]\n",
      "[1139.43]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41389662 -0.18561728  0.67984548  0.34992335  0.05748078  0.23586988]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1710 : 761.0967509915996\n",
      "1711000\n",
      "[-4.8678594]\n",
      "[2645.2234]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40920142 -0.18145467  0.66612383  0.34334864  0.06092744  0.23552714]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1710 : 791.6750064318497\n",
      "1711000\n",
      "[-12.499548]\n",
      "[3020.131]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4128228  -0.17941591  0.67908316  0.34619867  0.05678479  0.22900011]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1720 : 693.3240918566687\n",
      "1721000\n",
      "[-7.723242]\n",
      "[2984.7424]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41782121 -0.18819236  0.68451703  0.34596028  0.04242612  0.23867648]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1720 : 726.1803977691978\n",
      "1721000\n",
      "[-0.78893185]\n",
      "[2679.1597]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40669431 -0.18016099  0.67317985  0.34658294  0.05813084  0.23083494]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1720 : 759.0317447249804\n",
      "1721000\n",
      "[-23.496904]\n",
      "[4546.223]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40847941 -0.17934644  0.66405204  0.32789815  0.04469731  0.22394203]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1720 : 650.1010863687651\n",
      "1721000\n",
      "[-8.012468]\n",
      "[1066.5067]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41227476 -0.182342    0.68066496  0.36258167  0.05809732  0.24210643]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1730 : 744.1572624377537\n",
      "1731000\n",
      "[7.9996653]\n",
      "[300.02206]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40628938 -0.17540898  0.68315782  0.35907242  0.07081084  0.23899833]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1730 : 835.1054890589584\n",
      "1731000\n",
      "[-10.371298]\n",
      "[1371.2058]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40134322 -0.17587049  0.67085557  0.34943945  0.05430384  0.22776312]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1730 : 643.9191379393827\n",
      "1731000\n",
      "[4.375441]\n",
      "[370.54196]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41160581 -0.17818332  0.6641574   0.35084417  0.06396084  0.21614308]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1730 : 791.4232826737853\n",
      "1731000\n",
      "[-10.607632]\n",
      "[7212.0283]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39891007 -0.17429583  0.64381142  0.33850854  0.04560551  0.20334944]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1740 : 735.015639412617\n",
      "1741000\n",
      "[-13.659168]\n",
      "[4570.444]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39272671 -0.1683747   0.68574845  0.35644769  0.06269423  0.24718466]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1740 : 784.6911891592674\n",
      "1741000\n",
      "[-4.2531986]\n",
      "[3021.0635]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41195878 -0.17671259  0.6861715   0.36141248  0.0658433   0.24665592]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1740 : 801.5200517825579\n",
      "1741000\n",
      "[-24.08859]\n",
      "[3726.3032]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42068892 -0.18938366  0.67734909  0.34536884  0.05658427  0.23379825]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1740 : 639.0681368545837\n",
      "1741000\n",
      "[-11.76776]\n",
      "[2464.2957]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40611856 -0.17678536  0.67636877  0.35730623  0.06095893  0.24161086]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1750 : 771.0391155791336\n",
      "1751000\n",
      "[-6.6552086]\n",
      "[4970.4155]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40276898 -0.18470505  0.68199914  0.35744411  0.06894679  0.24607903]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1750 : 756.0550933314937\n",
      "1751000\n",
      "[0.48661423]\n",
      "[3607.5833]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39542552 -0.17011667  0.68131801  0.35816019  0.07160102  0.2472497 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1750 : 866.1764724662773\n",
      "1751000\n",
      "[1.2565813]\n",
      "[2918.522]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40326471 -0.18471111  0.6789377   0.36489456  0.07525479  0.24906974]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1750 : 882.739323347232\n",
      "1751000\n",
      "[-3.445753]\n",
      "[4690.16]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41094839 -0.18342619  0.66744265  0.3559602   0.07255736  0.22506051]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1760 : 791.8315079099967\n",
      "1761000\n",
      "[-4.720557]\n",
      "[4504.9097]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40186226 -0.1776757   0.67954597  0.36482196  0.06902147  0.24179876]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1760 : 805.8828839650077\n",
      "1761000\n",
      "[-3.363781]\n",
      "[4606.1367]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39750196 -0.17763003  0.6775199   0.36605723  0.07204707  0.24594746]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1760 : 830.8942283219334\n",
      "1761000\n",
      "[-5.3520346]\n",
      "[4962.592]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40919911 -0.18415521  0.68099851  0.36593829  0.06418578  0.23952493]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1760 : 813.7168104348536\n",
      "1761000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-16.157307]\n",
      "[4297.8696]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4007902  -0.17864738  0.6938182   0.37550348  0.06859593  0.26133608]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1770 : 756.9995322860494\n",
      "1771000\n",
      "[5.3301463]\n",
      "[1582.1307]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40887794 -0.17639781  0.69404735  0.37746508  0.07508965  0.25957043]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1770 : 914.6655343756695\n",
      "1771000\n",
      "[-6.34264]\n",
      "[2468.5884]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40394542 -0.17871442  0.68852632  0.36031445  0.06089827  0.24814708]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1770 : 812.1148037889066\n",
      "1771000\n",
      "[-17.472008]\n",
      "[3609.0852]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41830971 -0.18500316  0.68626777  0.36215418  0.05433857  0.25069865]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1770 : 706.0992709502451\n",
      "1771000\n",
      "[-26.655949]\n",
      "[4867.186]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41197454 -0.17995684  0.66230611  0.3477771   0.05893784  0.2227966 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1780 : 662.1870296647135\n",
      "1781000\n",
      "[-3.6236153]\n",
      "[3922.8184]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41203537 -0.17467559  0.68850051  0.36378087  0.06579242  0.25421949]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1780 : 795.8666119369009\n",
      "1781000\n",
      "[-16.850735]\n",
      "[6322.906]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39926871 -0.17251721  0.6532903   0.35400493  0.06254098  0.21996539]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1780 : 736.1776415017025\n",
      "1781000\n",
      "[0.0300827]\n",
      "[4902.745]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40694137 -0.16914068  0.68225662  0.373915    0.07398636  0.24285433]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1780 : 820.4275013094918\n",
      "1781000\n",
      "[-12.684892]\n",
      "[3455.098]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40239284 -0.16617429  0.67043299  0.36689438  0.06608966  0.24339312]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1790 : 774.1355714612225\n",
      "1791000\n",
      "[-2.418457]\n",
      "[2817.4814]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41895548 -0.18173309  0.68199464  0.37949817  0.07193618  0.2492295 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1790 : 831.6238793995416\n",
      "1791000\n",
      "[-18.542276]\n",
      "[4363.536]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4139838  -0.17351668  0.67346329  0.35420836  0.05007721  0.23491511]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1790 : 714.2341092784766\n",
      "1791000\n",
      "[-3.6394925]\n",
      "[2873.6233]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40353323 -0.16647616  0.67632126  0.37143153  0.06868188  0.24208385]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1790 : 843.8054323828621\n",
      "1791000\n",
      "[9.10243]\n",
      "[979.8356]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41147733 -0.1655471   0.69192097  0.37886367  0.07328687  0.25966625]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1800 : 833.914403889452\n",
      "1801000\n",
      "[-14.03221]\n",
      "[1972.1494]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40616904 -0.17547367  0.65978526  0.36322522  0.04630772  0.22516344]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1800 : 648.3492833490169\n",
      "1801000\n",
      "[-23.096453]\n",
      "[3156.008]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41814366 -0.18722435  0.67827195  0.36546998  0.04805723  0.23646441]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1800 : 544.4693397874076\n",
      "1801000\n",
      "[-0.32421637]\n",
      "[1033.7996]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41679013 -0.17552834  0.66930278  0.36847966  0.06042442  0.23336957]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1800 : 720.8206009003736\n",
      "1801000\n",
      "[-7.468552]\n",
      "[1330.4722]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41602263 -0.18042755  0.66730594  0.36402015  0.05186853  0.2319574 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1810 : 668.7014044438838\n",
      "1811000\n",
      "[-1.3862283]\n",
      "[587.5945]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41444498 -0.17677101  0.68056799  0.36934522  0.05831785  0.23579968]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1810 : 685.8217945186639\n",
      "1811000\n",
      "[7.9643626]\n",
      "[660.6149]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41202289 -0.17712656  0.69137011  0.37526533  0.06315601  0.24647758]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1810 : 747.2760851081345\n",
      "1811000\n",
      "[-4.089368]\n",
      "[606.74963]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41067549 -0.18116023  0.67653148  0.36354112  0.05552144  0.24670703]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1810 : 697.7175340410837\n",
      "1811000\n",
      "[-25.018574]\n",
      "[3171.514]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4222602  -0.18778813  0.65564381  0.35640111  0.04618268  0.21470188]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1820 : 566.7911524658198\n",
      "1821000\n",
      "[-2.790546]\n",
      "[3280.835]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40740024 -0.1782394   0.67750246  0.36988504  0.05319188  0.24863223]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1820 : 701.7193576353276\n",
      "1821000\n",
      "[-10.153822]\n",
      "[2906.103]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41216532 -0.1801277   0.65567277  0.36693748  0.05800628  0.22105671]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1820 : 647.6918017176436\n",
      "1821000\n",
      "[7.6443615]\n",
      "[3976.177]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40764932 -0.17400855  0.67984053  0.37982953  0.05243083  0.24358479]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1820 : 809.7583218340774\n",
      "1821000\n",
      "[4.516576]\n",
      "[2956.8586]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41484604 -0.17622017  0.68456739  0.39331454  0.07270033  0.24645559]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1830 : 898.2590298559301\n",
      "1831000\n",
      "[-26.838722]\n",
      "[3500.267]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41074798 -0.18629641  0.66842083  0.35739875  0.04809114  0.23400123]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1830 : 575.2120083603464\n",
      "1831000\n",
      "[-1.1784301]\n",
      "[1445.5951]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41273686 -0.17397632  0.67972381  0.38194097  0.06275906  0.24873934]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1830 : 791.6701690556995\n",
      "1831000\n",
      "[-11.50276]\n",
      "[1602.2183]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41261509 -0.18265008  0.68792021  0.38195467  0.06209658  0.25111788]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1830 : 699.2837931435388\n",
      "1831000\n",
      "[-14.582029]\n",
      "[5421.4736]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40869665 -0.18120095  0.66587214  0.37048884  0.0530084   0.22862801]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1840 : 700.6478062952796\n",
      "1841000\n",
      "[4.495885]\n",
      "[2102.296]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41166244 -0.18124546  0.68193846  0.39431059  0.07927471  0.2453945 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1840 : 899.8606550038377\n",
      "1841000\n",
      "[-9.246054]\n",
      "[2558.8481]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41173904 -0.17843937  0.66967385  0.37339725  0.04930082  0.22898032]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1840 : 787.6033104642565\n",
      "1841000\n",
      "[-16.008144]\n",
      "[2417.37]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41897236 -0.17683798  0.67676344  0.37299598  0.05507946  0.23699718]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1840 : 730.1259930629749\n",
      "1841000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.4273357]\n",
      "[4959.5347]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40559988 -0.18082698  0.66805143  0.37615176  0.05850706  0.23631976]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1850 : 747.318526274889\n",
      "1851000\n",
      "[-8.994814]\n",
      "[4080.731]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40931611 -0.18224698  0.67304374  0.3798988   0.06400032  0.23469365]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1850 : 792.0328194133942\n",
      "1851000\n",
      "[-9.248274]\n",
      "[5101.2183]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41313609 -0.18027245  0.67342968  0.37394961  0.05832984  0.23254881]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1850 : 723.8739592767532\n",
      "1851000\n",
      "[-10.097621]\n",
      "[3454.9492]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41345202 -0.18675284  0.67719676  0.3705936   0.05068615  0.24099981]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1850 : 760.4455895421256\n",
      "1851000\n",
      "[-12.556322]\n",
      "[5867.72]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40465713 -0.17264295  0.68033849  0.37282327  0.05846388  0.24508135]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1860 : 742.2639563134961\n",
      "1861000\n",
      "[-2.5691934]\n",
      "[3705.5503]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40353076 -0.17573004  0.6736471   0.3813103   0.06098853  0.23982521]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1860 : 813.7773394610695\n",
      "1861000\n",
      "[5.560993]\n",
      "[3576.5618]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41508613 -0.18504346  0.68898078  0.39100026  0.07595147  0.25033669]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1860 : 857.7309270073833\n",
      "1861000\n",
      "[-15.83643]\n",
      "[5827.3843]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40802515 -0.17812511  0.67463031  0.3691484   0.04916935  0.23679973]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1860 : 663.756626288689\n",
      "1861000\n",
      "[-20.29905]\n",
      "[4532.1294]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41806919 -0.18611915  0.66492567  0.37591811  0.05383184  0.23118984]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1870 : 663.6512311773604\n",
      "1871000\n",
      "[-31.85418]\n",
      "[5080.9736]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40830632 -0.18366278  0.64692479  0.34988879  0.03511616  0.20286886]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1870 : 454.0087008357214\n",
      "1871000\n",
      "[-17.103569]\n",
      "[3541.6448]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40444001 -0.17915077  0.67161626  0.37664087  0.0583565   0.23211541]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1870 : 705.7875330024766\n",
      "1871000\n",
      "[-4.20068]\n",
      "[2566.878]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4079778  -0.17392305  0.67415206  0.38168184  0.06606739  0.22957784]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1870 : 780.583845328934\n",
      "1871000\n",
      "[-6.031326]\n",
      "[4190.457]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40540759 -0.17138931  0.67038484  0.37983699  0.04949474  0.23003495]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1880 : 741.6829524293801\n",
      "1881000\n",
      "[-12.842997]\n",
      "[3210.6396]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40609599 -0.17377319  0.66400209  0.37650522  0.05296267  0.23017645]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1880 : 668.4324732605253\n",
      "1881000\n",
      "[-10.997252]\n",
      "[3292.53]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.3994257  -0.17451264  0.67163108  0.37067998  0.04797386  0.23725634]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1880 : 700.6823958324532\n",
      "1881000\n",
      "[-16.848568]\n",
      "[2650.5593]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41505186 -0.17961898  0.66592875  0.37360054  0.03525984  0.22168134]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1880 : 647.1553776208126\n",
      "1881000\n",
      "[3.5620012]\n",
      "[2908.7576]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40957257 -0.16941037  0.66589101  0.38547187  0.06097928  0.23568663]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1890 : 836.2729234699881\n",
      "1891000\n",
      "[-14.368955]\n",
      "[4531.595]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41390933 -0.18228845  0.6630998   0.37329095  0.05247395  0.22925685]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1890 : 697.2879766704536\n",
      "1891000\n",
      "[-7.7390738]\n",
      "[3112.6182]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40508283 -0.17495784  0.67266597  0.38060668  0.04748019  0.2410294 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1890 : 790.1622730761135\n",
      "1891000\n",
      "[-20.896315]\n",
      "[2836.133]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41825193 -0.1828805   0.67625465  0.37021017  0.0401663   0.23233829]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1890 : 626.7270817143672\n",
      "1891000\n",
      "[-20.093151]\n",
      "[4497.0737]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40490243 -0.17488777  0.67302457  0.37385088  0.03061603  0.22992769]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1900 : 623.0986009719059\n",
      "1901000\n",
      "[-9.192581]\n",
      "[4802.396]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39929657 -0.16740039  0.66653983  0.38318241  0.05323235  0.23076069]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1900 : 708.0791151903302\n",
      "1901000\n",
      "[11.875777]\n",
      "[2849.0498]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39541627 -0.16178928  0.68649866  0.40042421  0.06138153  0.26118209]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1900 : 904.5183415802167\n",
      "1901000\n",
      "[-12.488251]\n",
      "[3327.8142]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4042719  -0.16649086  0.68236542  0.38466611  0.05393801  0.24628782]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1900 : 745.5261447976433\n",
      "1901000\n",
      "[-2.8653588]\n",
      "[3605.3262]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40492677 -0.16509349  0.68402313  0.39134056  0.05740449  0.24559346]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1910 : 819.507700143054\n",
      "1911000\n",
      "[-31.691118]\n",
      "[5267.2686]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41081888 -0.17160941  0.67704377  0.3806151   0.03461986  0.23778829]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1910 : 649.0414856048687\n",
      "1911000\n",
      "[-5.6764116]\n",
      "[4988.409]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4090023  -0.16729427  0.68909999  0.3924602   0.04819098  0.25010283]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1910 : 773.9268169853789\n",
      "1911000\n",
      "[-16.799665]\n",
      "[4969.4697]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40445446 -0.17702628  0.68216153  0.38296214  0.04511535  0.24794662]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1910 : 735.5552175057479\n",
      "1911000\n",
      "[-17.736292]\n",
      "[4872.6]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39943477 -0.16309353  0.67062841  0.37962363  0.0375863   0.22882452]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1920 : 715.9941302770245\n",
      "1921000\n",
      "[13.123912]\n",
      "[3150.4578]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40523916 -0.16261941  0.67598287  0.39478631  0.05676705  0.22984091]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1920 : 951.0085563407931\n",
      "1921000\n",
      "[-27.872177]\n",
      "[7413.4985]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4143634  -0.16960503  0.68525593  0.38399686  0.03106966  0.23202812]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1920 : 635.0047007396657\n",
      "1921000\n",
      "[-4.7738132]\n",
      "[2765.6536]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40534692 -0.17694157  0.6682874   0.38794333  0.04206804  0.22177669]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1920 : 796.094507697873\n",
      "1921000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-27.52935]\n",
      "[4244.9463]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40867447 -0.18100076  0.66347559  0.37364129  0.03767408  0.21666007]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1930 : 583.8992045097887\n",
      "1931000\n",
      "[-14.684152]\n",
      "[4223.3267]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40817661 -0.17398785  0.66936863  0.38118437  0.04892374  0.22408381]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1930 : 681.349638171294\n",
      "1931000\n",
      "[4.442377]\n",
      "[3939.3345]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40403778 -0.16516272  0.67397144  0.39603005  0.04943396  0.24128809]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1930 : 845.3821727332734\n",
      "1931000\n",
      "[3.6000223]\n",
      "[3901.9355]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4032908  -0.16667569  0.68430922  0.40041178  0.05381305  0.23945861]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1930 : 860.0423548540699\n",
      "1931000\n",
      "[-11.958521]\n",
      "[3212.9902]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40773078 -0.17748654  0.6661483   0.37909909  0.04863377  0.21768321]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1940 : 666.1897600249521\n",
      "1941000\n",
      "[2.453311]\n",
      "[2721.0713]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41007774 -0.17107462  0.67613645  0.39274905  0.05228835  0.22794946]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1940 : 761.2881861003029\n",
      "1941000\n",
      "[3.534162]\n",
      "[1932.9525]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41372005 -0.16330783  0.68656281  0.40040963  0.05719377  0.23528984]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1940 : 822.4116679965288\n",
      "1941000\n",
      "[-22.446472]\n",
      "[4019.5083]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40727828 -0.17522688  0.669148    0.38382999  0.04608877  0.21937506]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1940 : 633.5852415316825\n",
      "1941000\n",
      "[-11.646501]\n",
      "[5018.586]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40965192 -0.17032329  0.67940432  0.39366937  0.04239496  0.22617752]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1950 : 702.9656247747442\n",
      "1951000\n",
      "[-13.193277]\n",
      "[3701.7568]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40977559 -0.17034347  0.67505529  0.39296711  0.04488696  0.23041518]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1950 : 714.6091914965758\n",
      "1951000\n",
      "[3.9404488]\n",
      "[3350.4092]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40553528 -0.17284766  0.67505929  0.39845376  0.05486047  0.23324047]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1950 : 829.2534015067343\n",
      "1951000\n",
      "[-5.0338902]\n",
      "[3503.1528]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41000566 -0.17242623  0.67625674  0.39683591  0.05918099  0.22917723]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1950 : 788.5608826519573\n",
      "1951000\n",
      "[-16.906034]\n",
      "[4405.389]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40978604 -0.17110197  0.65628109  0.37959293  0.03448587  0.20661892]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1960 : 652.396986629186\n",
      "1961000\n",
      "[-7.370748]\n",
      "[4957.123]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41170239 -0.16964911  0.67017579  0.39807403  0.04906493  0.22344138]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1960 : 755.7080676904617\n",
      "1961000\n",
      "[-13.622654]\n",
      "[4980.362]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40666304 -0.16790451  0.66568514  0.38681099  0.04262302  0.22823397]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1960 : 723.7479708003309\n",
      "1961000\n",
      "[-10.877726]\n",
      "[3961.2026]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41336604 -0.17146323  0.67194757  0.40081705  0.05129918  0.21777457]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1960 : 713.9414640067464\n",
      "1961000\n",
      "[-7.268403]\n",
      "[3874.165]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40733274 -0.15916605  0.67357457  0.39903452  0.03813915  0.23124757]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1970 : 700.5488429014595\n",
      "1971000\n",
      "[-18.974766]\n",
      "[5421.136]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40962647 -0.15949424  0.67741606  0.39762359  0.03894896  0.2249142 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1970 : 633.0502167658742\n",
      "1971000\n",
      "[-0.0212841]\n",
      "[4071.53]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4138443  -0.16464312  0.68740555  0.41141173  0.0591256   0.24444979]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1970 : 780.5873582305779\n",
      "1971000\n",
      "[-2.6153264]\n",
      "[2392.6877]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4146662  -0.16899205  0.68456969  0.40558192  0.06133375  0.23747355]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1970 : 770.1852669813996\n",
      "1971000\n",
      "[-19.520107]\n",
      "[3948.6536]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40678282 -0.16860234  0.67097011  0.38774283  0.04278489  0.22229465]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1980 : 615.0019307888628\n",
      "1981000\n",
      "[-11.82477]\n",
      "[3780.0476]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41095362 -0.16911332  0.67768577  0.39734848  0.04353868  0.22193253]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1980 : 704.3344399767819\n",
      "1981000\n",
      "[1.9600205]\n",
      "[1661.5084]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40522328 -0.16712087  0.68843672  0.41160404  0.05985169  0.2284378 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1980 : 750.5947932624559\n",
      "1981000\n",
      "[-2.371252]\n",
      "[2446.9978]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40617104 -0.17163277  0.67428612  0.40272456  0.04655095  0.21796559]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1980 : 756.9143144962795\n",
      "1981000\n",
      "[-9.16855]\n",
      "[1832.7316]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40597836 -0.17273921  0.66265563  0.39677358  0.03905933  0.21492958]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 1990 : 687.5182986275898\n",
      "1991000\n",
      "[-0.6787329]\n",
      "[1812.7601]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40917556 -0.16996225  0.67118003  0.40414463  0.05105019  0.22513963]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 1990 : 794.797628676786\n",
      "1991000\n",
      "[-7.8866663]\n",
      "[2473.5884]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41658127 -0.17682544  0.68065751  0.40355276  0.04156028  0.22008556]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 1990 : 690.9855903243875\n",
      "1991000\n",
      "[-11.97624]\n",
      "[3176.2615]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41113706 -0.17630216  0.6827677   0.40672375  0.04279008  0.22517207]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 1990 : 651.392949726691\n",
      "1991000\n",
      "[-9.781447]\n",
      "[3151.1057]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41980384 -0.17387199  0.67567098  0.40162234  0.04534506  0.20917138]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2000 : 744.5167783442173\n",
      "2001000\n",
      "[-17.363197]\n",
      "[4743.782]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40234402 -0.17803891  0.67315545  0.4030111   0.04250483  0.21306458]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2000 : 681.902186226791\n",
      "2001000\n",
      "[0.2685976]\n",
      "[2672.921]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40292128 -0.16408996  0.68119581  0.41427213  0.04673574  0.23783187]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2000 : 836.3336183811039\n",
      "2001000\n",
      "[-8.112364]\n",
      "[2678.0823]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41298912 -0.17199468  0.67234739  0.41049427  0.05185684  0.21541761]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2000 : 769.6369796712997\n",
      "2001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-35.57728]\n",
      "[5747.5083]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41387778 -0.16934159  0.66874524  0.39423593  0.02981614  0.21047725]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2010 : 581.804504888342\n",
      "2011000\n",
      "[-10.178117]\n",
      "[3617.1533]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40979639 -0.17102811  0.68006745  0.40349405  0.05143739  0.22389827]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2010 : 734.2497806334252\n",
      "2011000\n",
      "[-1.7859664]\n",
      "[2298.5183]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4174527  -0.17086221  0.69500144  0.41837966  0.04965607  0.23202447]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2010 : 836.371143252291\n",
      "2011000\n",
      "[3.0627341]\n",
      "[1718.863]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41991265 -0.17623223  0.68898559  0.41874071  0.05737449  0.22456528]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2010 : 821.0544481914629\n",
      "2011000\n",
      "[-5.185261]\n",
      "[4450.419]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41507308 -0.1686378   0.67700017  0.41438868  0.06017227  0.21458001]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2020 : 825.6874619763119\n",
      "2021000\n",
      "[-13.013598]\n",
      "[4914.0977]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41095274 -0.1600125   0.67737847  0.40422481  0.04643737  0.23179069]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2020 : 739.7267746570764\n",
      "2021000\n",
      "[-25.650585]\n",
      "[4078.5552]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41965367 -0.17250718  0.68022259  0.40673266  0.03632823  0.21781848]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2020 : 607.5809366439048\n",
      "2021000\n",
      "[-8.608498]\n",
      "[3147.8901]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4129964  -0.16779023  0.68137888  0.41255865  0.04562479  0.21697613]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2020 : 784.932188968862\n",
      "2021000\n",
      "[-24.588268]\n",
      "[4660.452]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42337925 -0.1871939   0.67405624  0.39405822  0.02115286  0.20825048]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2030 : 541.7829878661751\n",
      "2031000\n",
      "[-2.3620756]\n",
      "[3684.34]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4109841  -0.17248113  0.67669598  0.41333574  0.0447142   0.21141408]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2030 : 712.8260374104038\n",
      "2031000\n",
      "[-7.677271]\n",
      "[5445.874]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41004818 -0.16972915  0.6747606   0.40881752  0.03109327  0.21689932]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2030 : 706.7738964932049\n",
      "2031000\n",
      "[-6.9266233]\n",
      "[3951.0264]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41242793 -0.17649543  0.67673557  0.41450358  0.05309618  0.22119201]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2030 : 719.7152246836023\n",
      "2031000\n",
      "[-5.0365505]\n",
      "[1930.9786]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42138401 -0.17181224  0.68294321  0.41840502  0.05308866  0.21807242]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2040 : 737.9669873092693\n",
      "2041000\n",
      "[11.588476]\n",
      "[1429.026]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40980554 -0.17594188  0.69341921  0.43216142  0.05755156  0.23802601]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2040 : 864.359804256081\n",
      "2041000\n",
      "[-22.702366]\n",
      "[2559.2856]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41891258 -0.17817226  0.67236916  0.41034931  0.03029528  0.21548321]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2040 : 615.3077604245698\n",
      "2041000\n",
      "[-9.238721]\n",
      "[1675.164]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41835228 -0.17762033  0.66798208  0.40715451  0.04613901  0.2121266 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2040 : 696.6029539249787\n",
      "2041000\n",
      "[-16.46159]\n",
      "[6435.3755]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41144708 -0.17648006  0.68376784  0.41254814  0.04834568  0.22584584]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2050 : 667.150192726208\n",
      "2051000\n",
      "[-2.2014775]\n",
      "[2930.4946]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40880077 -0.16923462  0.67457724  0.41701103  0.04449253  0.22104791]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2050 : 798.038507489827\n",
      "2051000\n",
      "[-7.672856]\n",
      "[4310.717]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41767876 -0.16905877  0.68637659  0.41499098  0.03599471  0.22837253]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2050 : 728.1376605177059\n",
      "2051000\n",
      "[-8.478426]\n",
      "[4875.477]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41083231 -0.17338209  0.68306617  0.42028724  0.0622252   0.23006609]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2050 : 748.1740605195141\n",
      "2051000\n",
      "[-9.413511]\n",
      "[5188.727]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40202314 -0.15843563  0.68466025  0.42657574  0.04784287  0.23212189]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2060 : 762.0509033889684\n",
      "2061000\n",
      "[-0.5035267]\n",
      "[3780.6655]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40559072 -0.16624816  0.68504232  0.42891044  0.05828195  0.24080704]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2060 : 792.1083324840157\n",
      "2061000\n",
      "[-16.4998]\n",
      "[3591.1516]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41409884 -0.18390784  0.6719642   0.41144133  0.04744551  0.21878157]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2060 : 661.4973813517605\n",
      "2061000\n",
      "[-26.770348]\n",
      "[4498.035]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41272817 -0.17981289  0.67719752  0.40041732  0.02854753  0.21401932]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2060 : 512.9679588337206\n",
      "2061000\n",
      "[3.1478329]\n",
      "[2813.875]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40731295 -0.16756993  0.6883304   0.43184183  0.0621722   0.23583918]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2070 : 875.1165112881519\n",
      "2071000\n",
      "[-25.06285]\n",
      "[4604.513]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41317373 -0.17739465  0.68617161  0.41635656  0.04045771  0.23663122]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2070 : 684.8553386725455\n",
      "2071000\n",
      "[-1.2551074]\n",
      "[2487.4805]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.39944583 -0.16387103  0.67177697  0.41682487  0.05889306  0.22481017]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2070 : 826.5321801094516\n",
      "2071000\n",
      "[-12.91891]\n",
      "[4526.6187]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4186725  -0.1797222   0.69386618  0.42298841  0.0449775   0.23370221]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2070 : 729.4834126584825\n",
      "2071000\n",
      "[9.681326]\n",
      "[3109.982]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40910147 -0.16689465  0.6826369   0.43255619  0.06277003  0.22188435]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2080 : 850.0316052089307\n",
      "2081000\n",
      "[-3.3007925]\n",
      "[2087.3367]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4036144  -0.16808779  0.67591657  0.42022097  0.05259869  0.23059923]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2080 : 774.8437605176659\n",
      "2081000\n",
      "[-9.095039]\n",
      "[2083.7302]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41545509 -0.17695226  0.67389739  0.42270043  0.05228484  0.21418989]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2080 : 727.1181279321153\n",
      "2081000\n",
      "[-21.35606]\n",
      "[3920.3347]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41589077 -0.17470215  0.68309053  0.42206319  0.0448152   0.23087369]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2080 : 612.1309762876068\n",
      "2081000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.0213323]\n",
      "[4525.005]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40757618 -0.17051057  0.68275405  0.43168929  0.05936111  0.23693744]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2090 : 781.8034059804046\n",
      "2091000\n",
      "[-6.505791]\n",
      "[4717.8716]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40382018 -0.16383578  0.68045348  0.42933186  0.05073693  0.22906958]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2090 : 774.1082149229231\n",
      "2091000\n",
      "[-4.7872014]\n",
      "[5449.1753]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40901331 -0.16762924  0.68929763  0.43250218  0.04075119  0.23354488]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2090 : 791.1671731469465\n",
      "2091000\n",
      "[-11.525642]\n",
      "[4616.71]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4182639  -0.18109549  0.68990558  0.43544903  0.03545973  0.22459062]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2090 : 710.7821819430463\n",
      "2091000\n",
      "[1.1142836]\n",
      "[2144.7397]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41544614 -0.16751881  0.68755633  0.43602377  0.05972939  0.23085099]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2100 : 761.7890495277986\n",
      "2101000\n",
      "[-8.652407]\n",
      "[3601.3796]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.411653   -0.17233512  0.67451328  0.42156737  0.02939542  0.22340862]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2100 : 700.8216991824537\n",
      "2101000\n",
      "[-11.439962]\n",
      "[1549.4403]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41531146 -0.1805467   0.66760424  0.41809546  0.03742412  0.21321281]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2100 : 665.585486476731\n",
      "2101000\n",
      "[-8.911583]\n",
      "[1884.3406]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41716209 -0.18017385  0.67733881  0.43012086  0.04182178  0.21655365]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2100 : 685.8674524270212\n",
      "2101000\n",
      "[-5.464303]\n",
      "[2650.901]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40805633 -0.17427812  0.67843946  0.43120848  0.05706767  0.22845934]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2110 : 810.3239479349177\n",
      "2111000\n",
      "[-2.489417]\n",
      "[3819.9248]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40066606 -0.16240917  0.68653414  0.43879201  0.04873039  0.23968654]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2110 : 856.3815809505192\n",
      "2111000\n",
      "[-15.953342]\n",
      "[5944.7773]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41228364 -0.17595182  0.69243804  0.43124253  0.0456836   0.24031897]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2110 : 720.1178802798505\n",
      "2111000\n",
      "[-19.094883]\n",
      "[5827.3193]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41597482 -0.16926162  0.69948896  0.43951109  0.04440431  0.24176828]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2110 : 783.4357064627635\n",
      "2111000\n",
      "[-2.7638083]\n",
      "[3352.6216]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40995559 -0.16582338  0.68877914  0.43194127  0.042848    0.23746511]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2120 : 765.2439732795804\n",
      "2121000\n",
      "[-19.973051]\n",
      "[5323.724]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40249825 -0.16988673  0.6750512   0.42058393  0.03916782  0.22328164]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2120 : 656.8878355619353\n",
      "2121000\n",
      "[-12.816641]\n",
      "[2278.8652]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41795337 -0.18036038  0.6822606   0.42466328  0.03764477  0.22223042]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2120 : 688.2806223941634\n",
      "2121000\n",
      "[-0.54450274]\n",
      "[3599.0696]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40394057 -0.16560705  0.68444399  0.43339042  0.0467426   0.22921799]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2120 : 782.978035521363\n",
      "2121000\n",
      "[-14.899269]\n",
      "[7399.7534]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41790539 -0.16978011  0.68975773  0.42707861  0.02866364  0.22949597]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2130 : 705.8812424504392\n",
      "2131000\n",
      "[11.554446]\n",
      "[6027.2026]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40686002 -0.157859    0.67967111  0.43926121  0.04945019  0.23311193]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2130 : 893.587577990458\n",
      "2131000\n",
      "[-18.19394]\n",
      "[6027.049]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4080559  -0.17082024  0.65056366  0.4081661   0.02418471  0.1982298 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2130 : 643.1426425403492\n",
      "2131000\n",
      "[-4.9402676]\n",
      "[4807.2695]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40807415 -0.16499536  0.68281861  0.42755578  0.0492815   0.22918321]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2130 : 706.5695221099461\n",
      "2131000\n",
      "[-12.723935]\n",
      "[3508.8955]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40678482 -0.17062736  0.67151493  0.42369216  0.04259193  0.22304665]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2140 : 697.7980189974653\n",
      "2141000\n",
      "[-2.7922726]\n",
      "[3803.0684]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41238025 -0.17413331  0.68619888  0.44309072  0.05325048  0.22580943]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2140 : 809.4794710476111\n",
      "2141000\n",
      "[-7.7897167]\n",
      "[4576.4756]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41199122 -0.16700635  0.69391386  0.43992806  0.04627786  0.24040702]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2140 : 769.4376884953351\n",
      "2141000\n",
      "[-11.526096]\n",
      "[4051.4463]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40877749 -0.16559757  0.67560899  0.43168442  0.03685998  0.22761093]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2140 : 707.8700885851459\n",
      "2141000\n",
      "[-3.5294619]\n",
      "[3317.9534]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41800583 -0.17322217  0.68725116  0.4424663   0.04703101  0.22827608]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2150 : 778.1415655485367\n",
      "2151000\n",
      "[6.8521633]\n",
      "[2901.0837]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40703315 -0.16305286  0.68937974  0.44766953  0.05767439  0.22896042]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2150 : 856.185193867133\n",
      "2151000\n",
      "[-10.569863]\n",
      "[3680.1646]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41346555 -0.16403542  0.69085059  0.43869154  0.03754843  0.2323817 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2150 : 716.1331004327272\n",
      "2151000\n",
      "[-12.572962]\n",
      "[4303.057]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40537655 -0.16920107  0.68028431  0.43575565  0.04074475  0.23038473]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2150 : 671.3176434104734\n",
      "2151000\n",
      "[-7.5692368]\n",
      "[2658.9512]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40985232 -0.17480687  0.68341473  0.44341169  0.04985043  0.22694783]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2160 : 701.8858381838164\n",
      "2161000\n",
      "[-6.7217507]\n",
      "[3481.4736]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41364574 -0.1708794   0.69723736  0.45461729  0.04494652  0.23139621]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2160 : 717.1336217703945\n",
      "2161000\n",
      "[-3.2077737]\n",
      "[3083.0042]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40900755 -0.16276155  0.67389414  0.43224275  0.03381992  0.20678037]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2160 : 772.8535418298641\n",
      "2161000\n",
      "[-0.761148]\n",
      "[2566.8108]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40653667 -0.16603774  0.68315674  0.44190706  0.03407297  0.23705789]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2160 : 791.0921324650302\n",
      "2161000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.346262]\n",
      "[1562.7507]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42095922 -0.16617116  0.69662586  0.4515508   0.04122417  0.2257593 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2170 : 784.4052144774992\n",
      "2171000\n",
      "[-0.7982235]\n",
      "[1985.3142]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40662616 -0.16260153  0.67011304  0.43350128  0.03906884  0.21430939]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2170 : 752.9648146165205\n",
      "2171000\n",
      "[-19.17224]\n",
      "[3553.5974]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4215458  -0.17748288  0.68366611  0.43961003  0.03324653  0.21663071]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2170 : 599.0193525445197\n",
      "2171000\n",
      "[-9.758286]\n",
      "[2103.7275]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40619935 -0.1725076   0.68263287  0.43908183  0.04026648  0.22165338]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2170 : 683.3096448654784\n",
      "2171000\n",
      "[-24.916943]\n",
      "[4211.5234]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42507888 -0.17840333  0.67629181  0.4351866   0.0289124   0.20682545]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2180 : 640.832689881003\n",
      "2181000\n",
      "[-10.224861]\n",
      "[3144.2493]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4143406  -0.18250985  0.67488628  0.44247955  0.03726914  0.21014937]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2180 : 686.0776894529885\n",
      "2181000\n",
      "[-1.6174588]\n",
      "[2478.9897]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42061599 -0.17929781  0.69537871  0.45071047  0.04986097  0.23272717]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2180 : 738.8668927060428\n",
      "2181000\n",
      "[-13.689583]\n",
      "[3456.7832]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42169073 -0.18128665  0.67753016  0.43578873  0.03903651  0.21209396]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2180 : 635.6900245650997\n",
      "2181000\n",
      "[-8.405197]\n",
      "[3360.6072]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41531886 -0.1747533   0.68156732  0.44330354  0.04150993  0.2158895 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2190 : 724.1722010462069\n",
      "2191000\n",
      "[-0.12326908]\n",
      "[3685.4434]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40944515 -0.16603979  0.67647008  0.44945743  0.05154717  0.2207424 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2190 : 797.0140562261796\n",
      "2191000\n",
      "[-1.6305065]\n",
      "[3226.7466]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41853905 -0.17211207  0.68902992  0.45857461  0.05517498  0.23028896]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2190 : 797.1741235140496\n",
      "2191000\n",
      "[12.916863]\n",
      "[3478.6375]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41067203 -0.16750485  0.69087078  0.46489449  0.05416207  0.23999648]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2190 : 913.5734011128189\n",
      "2191000\n",
      "[-3.6539161]\n",
      "[4702.8335]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41444096 -0.17261495  0.68384507  0.44880686  0.0528626   0.2253127 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2200 : 768.0298127530542\n",
      "2201000\n",
      "[-8.499705]\n",
      "[5109.3306]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41713906 -0.17380588  0.68263947  0.44732711  0.03589049  0.22591397]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2200 : 744.9496501258054\n",
      "2201000\n",
      "[-4.635297]\n",
      "[4503.055]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41815489 -0.16875059  0.69416209  0.45241946  0.0351217   0.23462447]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2200 : 812.3027100419695\n",
      "2201000\n",
      "[-17.16311]\n",
      "[3191.9392]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41576145 -0.17342644  0.68183097  0.43325213  0.02714199  0.22444556]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2200 : 654.9622372112543\n",
      "2201000\n",
      "[-18.404556]\n",
      "[5791.9277]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41727523 -0.16939353  0.68280722  0.44138511  0.03579947  0.21997747]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2210 : 704.3654730377334\n",
      "2211000\n",
      "[-13.3805065]\n",
      "[6379.756]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41837579 -0.17179098  0.68889079  0.45548369  0.04599015  0.22564545]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2210 : 791.0063994894281\n",
      "2211000\n",
      "[7.7052402]\n",
      "[5919.323]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41171798 -0.16322158  0.68708299  0.46195781  0.05628406  0.22331268]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2210 : 914.8676177564566\n",
      "2211000\n",
      "[-10.84217]\n",
      "[5268.9214]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41727902 -0.16892533  0.69423332  0.44338149  0.03214535  0.23190528]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2210 : 769.5182386525943\n",
      "2211000\n",
      "[-5.8606257]\n",
      "[2352.5645]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42718239 -0.18273593  0.69022576  0.45258026  0.03248455  0.22062071]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2220 : 735.3719800690477\n",
      "2221000\n",
      "[-8.451944]\n",
      "[2491.3784]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41931833 -0.17625333  0.68793073  0.45526024  0.03836224  0.22793543]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2220 : 717.3856137867349\n",
      "2221000\n",
      "[-1.6294165]\n",
      "[2759.8145]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41855428 -0.17356291  0.6886071   0.45662227  0.04784464  0.23604897]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2220 : 782.1512760051091\n",
      "2221000\n",
      "[-17.309868]\n",
      "[3115.0552]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41078669 -0.17594215  0.69198859  0.44526239  0.03919255  0.24186124]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2220 : 650.1643319972899\n",
      "2221000\n",
      "[-1.360929]\n",
      "[4145.187]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42880427 -0.17586047  0.70855734  0.46427264  0.04182424  0.23897392]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2230 : 797.1299346347893\n",
      "2231000\n",
      "[-6.059057]\n",
      "[5638.786]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42591999 -0.18242669  0.69674021  0.46204064  0.04599522  0.23045668]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2230 : 741.3185826731874\n",
      "2231000\n",
      "[-19.523829]\n",
      "[5348.298]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42077884 -0.17164808  0.6791684   0.44870333  0.03331791  0.21612588]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2230 : 660.1214735403094\n",
      "2231000\n",
      "[1.184659]\n",
      "[5048.6885]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41501993 -0.1735043   0.69176328  0.46062687  0.04735729  0.23343883]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2230 : 808.2895321674333\n",
      "2231000\n",
      "[-4.0887136]\n",
      "[2873.4849]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41495222 -0.17434853  0.69575878  0.46060821  0.0365462   0.24234105]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2240 : 729.291138240273\n",
      "2241000\n",
      "[-7.571411]\n",
      "[1925.8488]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4219695  -0.17593707  0.68034888  0.44326937  0.04163824  0.21196064]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2240 : 660.3942857580772\n",
      "2241000\n",
      "[0.3267498]\n",
      "[1438.2515]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41672352 -0.17385022  0.68735766  0.45522654  0.04005187  0.22892282]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2240 : 751.3639557060404\n",
      "2241000\n",
      "[-20.755148]\n",
      "[4176.135]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40913557 -0.1784043   0.67829975  0.44302111  0.03033379  0.2186836 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2240 : 557.968262050206\n",
      "2241000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.7930875]\n",
      "[5205.5166]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41354463 -0.17244049  0.68884481  0.45472056  0.02927151  0.23506734]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2250 : 745.4152940648672\n",
      "2251000\n",
      "[0.6249261]\n",
      "[3314.7375]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41981338 -0.17128873  0.69783894  0.46553762  0.04655236  0.23191077]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2250 : 817.4253445378097\n",
      "2251000\n",
      "[-20.433002]\n",
      "[3423.8606]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41811508 -0.17270236  0.68594287  0.45234706  0.03186268  0.22942127]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2250 : 691.6038675580685\n",
      "2251000\n",
      "[-15.006235]\n",
      "[4150.513]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42383521 -0.18057658  0.69074778  0.45445535  0.03961741  0.23066095]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2250 : 660.5257657770014\n",
      "2251000\n",
      "[-7.9610987]\n",
      "[3772.1582]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41830623 -0.17421619  0.68070229  0.45484193  0.03980481  0.21947812]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2260 : 723.6943453171822\n",
      "2261000\n",
      "[-12.500373]\n",
      "[2174.3376]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41484321 -0.17619289  0.67779574  0.44746272  0.02396062  0.22625732]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2260 : 680.1731794639496\n",
      "2261000\n",
      "[-21.055286]\n",
      "[3030.1768]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42906871 -0.18634765  0.6869873   0.44880834  0.03528869  0.21859341]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2260 : 587.1220548150959\n",
      "2261000\n",
      "[3.2680588]\n",
      "[2313.7078]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41128167 -0.17073709  0.69706978  0.46882265  0.04535992  0.23564358]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2260 : 837.3002882843771\n",
      "2261000\n",
      "[-15.346323]\n",
      "[6407.7764]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41838724 -0.1685933   0.68761831  0.45572064  0.03423555  0.22187966]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2270 : 684.8136610081792\n",
      "2271000\n",
      "[-2.3382025]\n",
      "[5123.38]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4119228  -0.170852    0.68835566  0.45833514  0.05060215  0.24023696]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2270 : 866.2583064761916\n",
      "2271000\n",
      "[-8.361932]\n",
      "[4685.161]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41716655 -0.16739789  0.69427336  0.46626457  0.0411878   0.23552179]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2270 : 793.199670889616\n",
      "2271000\n",
      "[-6.541864]\n",
      "[4553.587]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42157539 -0.17615525  0.68436447  0.46177815  0.0484143   0.22676127]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2270 : 820.1640846762698\n",
      "2271000\n",
      "[-17.417635]\n",
      "[5532.357]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42176421 -0.17447894  0.70305598  0.46989759  0.03481401  0.23934486]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2280 : 718.5258878952052\n",
      "2281000\n",
      "[8.209727]\n",
      "[4122.661]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41421257 -0.17413403  0.69340132  0.47425465  0.04794569  0.23770021]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2280 : 909.5243641960458\n",
      "2281000\n",
      "[-12.284225]\n",
      "[2059.2095]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42873908 -0.18326846  0.68955904  0.46126799  0.0359525   0.22409598]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2280 : 660.832238270618\n",
      "2281000\n",
      "[-15.753157]\n",
      "[3736.8528]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41944088 -0.17465111  0.67049116  0.4365055   0.02636717  0.20467543]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2280 : 596.9554453480255\n",
      "2281000\n",
      "[12.324007]\n",
      "[2056.8176]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42317827 -0.17997708  0.7015729   0.47972397  0.05604228  0.23948036]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2290 : 866.1523542781914\n",
      "2291000\n",
      "[4.627923]\n",
      "[1857.1809]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41576392 -0.16399187  0.69523691  0.47088182  0.04946554  0.24170369]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2290 : 847.5027890022242\n",
      "2291000\n",
      "[-3.6033406]\n",
      "[1701.3975]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42027205 -0.17227926  0.6979196   0.46990226  0.04475951  0.23999562]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2290 : 763.0096821258371\n",
      "2291000\n",
      "[-26.991024]\n",
      "[3281.1921]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42611849 -0.178398    0.68435131  0.45554872  0.02241053  0.22109397]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2290 : 562.6360116940572\n",
      "2291000\n",
      "[-17.178596]\n",
      "[6485.1235]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41392533 -0.17621878  0.68928956  0.4571463   0.02672613  0.22805847]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2300 : 674.6380806300916\n",
      "2301000\n",
      "[-8.107025]\n",
      "[4259.801]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42502308 -0.18582465  0.69753431  0.47126661  0.04111267  0.23365463]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2300 : 744.2236691347388\n",
      "2301000\n",
      "[-13.2785]\n",
      "[5415.958]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41727824 -0.17336811  0.68042425  0.45254669  0.04275611  0.22501045]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2300 : 714.626437508873\n",
      "2301000\n",
      "[-23.428448]\n",
      "[5623.5166]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42227428 -0.17793446  0.67007826  0.4435555   0.02771897  0.21041908]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2300 : 646.0353533939951\n",
      "2301000\n",
      "[-6.296274]\n",
      "[3371.9487]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4222051  -0.17296933  0.68040229  0.45822248  0.04239245  0.22070185]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2310 : 748.084786592381\n",
      "2311000\n",
      "[-4.9002743]\n",
      "[4973.6016]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41859269 -0.17975981  0.68816282  0.46570477  0.04630104  0.22910736]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2310 : 737.9492120667185\n",
      "2311000\n",
      "[-34.600563]\n",
      "[5477.9434]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4249288  -0.18835059  0.67424749  0.44051625  0.02628586  0.20644936]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2310 : 461.3037179647396\n",
      "2311000\n",
      "[1.3626423]\n",
      "[2963.078]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42589427 -0.17817854  0.68951974  0.46739338  0.05488023  0.22659559]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2310 : 780.997712211978\n",
      "2311000\n",
      "[-12.04752]\n",
      "[3283.742]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.417302   -0.17611269  0.67412184  0.45233804  0.04015343  0.20791027]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2320 : 626.098239904856\n",
      "2321000\n",
      "[-6.9279766]\n",
      "[2490.9512]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4219232  -0.17883034  0.67996218  0.45474798  0.04442284  0.21309902]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2320 : 718.9614552823857\n",
      "2321000\n",
      "[-17.268948]\n",
      "[3714.4392]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41610503 -0.1760156   0.67689658  0.44177256  0.02684242  0.21329232]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2320 : 579.1746751455614\n",
      "2321000\n",
      "[-9.446162]\n",
      "[1980.5841]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41627983 -0.17635334  0.68770134  0.45578667  0.04026312  0.22684616]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2320 : 653.7841889368373\n",
      "2321000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-31.706455]\n",
      "[3895.6545]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42427407 -0.18356842  0.69644797  0.45659255  0.023697    0.22783069]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2330 : 500.2045997129585\n",
      "2331000\n",
      "[9.170728]\n",
      "[2267.1738]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41772054 -0.169908    0.69947737  0.47147468  0.05266257  0.23818586]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2330 : 775.0306529229878\n",
      "2331000\n",
      "[-23.478722]\n",
      "[4305.4854]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4168325  -0.18814336  0.6697808   0.44107528  0.03232775  0.20770889]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2330 : 531.8453364135886\n",
      "2331000\n",
      "[-4.480445]\n",
      "[2128.4404]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42225969 -0.18816892  0.67739967  0.45927277  0.04095982  0.20670323]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2330 : 693.991721310308\n",
      "2331000\n",
      "[0.14580965]\n",
      "[4282.0806]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42401882 -0.17963307  0.69651829  0.47402257  0.05107042  0.22987621]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2340 : 730.2440727080311\n",
      "2341000\n",
      "[10.581505]\n",
      "[3075.9304]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42116798 -0.18315139  0.69771777  0.48248607  0.06713319  0.23415259]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2340 : 844.2300604029689\n",
      "2341000\n",
      "[-1.480197]\n",
      "[3906.329]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41760206 -0.18059903  0.69328115  0.4720244   0.04314595  0.22606244]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2340 : 725.0963940427722\n",
      "2341000\n",
      "[-6.643454]\n",
      "[3738.9146]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41324439 -0.1762614   0.6802146   0.46861814  0.04819929  0.22159864]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2340 : 758.4084890011933\n",
      "2341000\n",
      "[-13.262228]\n",
      "[4407.9673]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41474998 -0.18369501  0.69022554  0.46905339  0.0449223   0.23196798]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2350 : 704.4264769369115\n",
      "2351000\n",
      "[-28.148449]\n",
      "[5544.1016]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41412508 -0.18117797  0.68418321  0.45793984  0.04044938  0.22533996]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2350 : 622.0884714515112\n",
      "2351000\n",
      "[15.336088]\n",
      "[4238.0547]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4084898  -0.16958845  0.70041625  0.48688774  0.06029498  0.23856344]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2350 : 883.9043112892225\n",
      "2351000\n",
      "[-13.755233]\n",
      "[4334.7393]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40944835 -0.17177838  0.68110053  0.4590704   0.03475323  0.22372243]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2350 : 682.4039503468198\n",
      "2351000\n",
      "[-9.819319]\n",
      "[2158.0835]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41449031 -0.18133701  0.69014734  0.46981701  0.05689959  0.22098275]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2360 : 757.897478354255\n",
      "2361000\n",
      "[0.07595062]\n",
      "[2585.9604]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.4218791  -0.1768562   0.70624423  0.48147397  0.05878967  0.23860379]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2360 : 851.7881345144325\n",
      "2361000\n",
      "[1.106091]\n",
      "[2004.5132]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42007865 -0.17866386  0.70112256  0.48160772  0.05230067  0.233982  ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2360 : 836.3790289620857\n",
      "2361000\n",
      "[-12.636534]\n",
      "[2296.8452]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.421582   -0.18947263  0.69102639  0.46523058  0.04942525  0.20926809]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2360 : 734.5628696787509\n",
      "2361000\n",
      "[6.3914795]\n",
      "[4100.405]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41234794 -0.17177292  0.69049285  0.48362235  0.0557423   0.22769378]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2370 : 867.0394203647353\n",
      "2371000\n",
      "[-3.3697202]\n",
      "[2162.1724]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42302693 -0.17900347  0.68835271  0.4749184   0.04603495  0.22281847]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2370 : 763.7476872198097\n",
      "2371000\n",
      "[-19.45297]\n",
      "[3776.3433]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41355581 -0.17386077  0.68117734  0.46389343  0.03540294  0.21097206]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2370 : 675.2290255772226\n",
      "2371000\n",
      "[-20.839167]\n",
      "[3029.003]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42124986 -0.1831544   0.68847753  0.46930446  0.0430944   0.22367959]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2370 : 674.539725000889\n",
      "2371000\n",
      "[-11.378362]\n",
      "[4211.8374]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42524869 -0.19394188  0.69438096  0.47307884  0.0488125   0.22964846]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2380 : 715.2220094724057\n",
      "2381000\n",
      "[0.16546631]\n",
      "[2397.739]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41549239 -0.174396    0.68627795  0.47733255  0.05797178  0.21745839]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2380 : 814.9495567028798\n",
      "2381000\n",
      "[-2.8358183]\n",
      "[2697.581]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41989376 -0.18074973  0.69411935  0.47673822  0.05793037  0.23601425]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2380 : 789.7531614315385\n",
      "2381000\n",
      "[-25.722687]\n",
      "[4030.1797]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41322736 -0.17489002  0.69485307  0.47047302  0.04797994  0.23569536]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2380 : 698.349046635853\n",
      "2381000\n",
      "[-13.649453]\n",
      "[2260.9216]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42152152 -0.18354837  0.67538754  0.46170092  0.03929718  0.2120256 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2390 : 688.0799326638515\n",
      "2391000\n",
      "[-15.100807]\n",
      "[3461.912]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42537024 -0.18996592  0.69669735  0.47622156  0.05748187  0.22833906]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2390 : 664.186547055482\n",
      "2391000\n",
      "[-3.618008]\n",
      "[1940.3901]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41114364 -0.18191352  0.6817899   0.46905845  0.06204863  0.22022378]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2390 : 736.9228139258876\n",
      "2391000\n",
      "[-11.980692]\n",
      "[3104.5525]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41210257 -0.17539553  0.68712749  0.47441201  0.04733119  0.2251006 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2390 : 725.0746378207748\n",
      "2391000\n",
      "[-10.492564]\n",
      "[3541.1653]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42302031 -0.18145     0.69124328  0.48021662  0.05478593  0.22210928]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2400 : 730.9733398800254\n",
      "2401000\n",
      "[-19.738613]\n",
      "[4217.406]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42171384 -0.18937098  0.688453    0.47458742  0.05206296  0.21833305]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2400 : 625.1951731597543\n",
      "2401000\n",
      "[-4.510927]\n",
      "[3541.4792]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41215986 -0.17589986  0.68659618  0.47792671  0.0572531   0.22774134]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2400 : 801.9548778984774\n",
      "2401000\n",
      "[-0.8639879]\n",
      "[2767.0518]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42946062 -0.18286655  0.68811996  0.48454412  0.06905106  0.22126471]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2400 : 843.283280276832\n",
      "2401000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-14.844516]\n",
      "[4727.7993]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41462995 -0.17502775  0.68365865  0.46913992  0.04731015  0.22227107]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2410 : 696.3553857792378\n",
      "2411000\n",
      "[-2.52244]\n",
      "[2962.1628]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42624367 -0.18169262  0.69648013  0.48022966  0.05423084  0.23136881]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2410 : 791.6917062980308\n",
      "2411000\n",
      "[-3.3445065]\n",
      "[3268.9385]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42668274 -0.18112919  0.69522664  0.48210605  0.04766277  0.21825804]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2410 : 718.0973884852606\n",
      "2411000\n",
      "[-14.94601]\n",
      "[4425.623]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41719025 -0.18788946  0.68602334  0.47257605  0.04099939  0.22496245]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2410 : 702.6920655898813\n",
      "2411000\n",
      "[8.337731]\n",
      "[2431.0242]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42314315 -0.18126122  0.69421155  0.4927643   0.06815979  0.2265749 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2420 : 838.3512087597933\n",
      "2421000\n",
      "[-8.346371]\n",
      "[2956.9429]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41703947 -0.17616067  0.67930081  0.46583982  0.04925302  0.20892922]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2420 : 712.6014947040435\n",
      "2421000\n",
      "[-17.104652]\n",
      "[3153.7554]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42310126 -0.18601183  0.67065149  0.45938907  0.04768096  0.2009057 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2420 : 643.4806849896053\n",
      "2421000\n",
      "[0.84381485]\n",
      "[3151.2275]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41707176 -0.1801413   0.68659392  0.47319812  0.0458809   0.2252474 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2420 : 800.6373052233923\n",
      "2421000\n",
      "[-14.832294]\n",
      "[3712.7961]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41477977 -0.17113423  0.68436864  0.46651857  0.03914288  0.21596589]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2430 : 713.0090635939932\n",
      "2431000\n",
      "[-13.323584]\n",
      "[4924.698]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41377208 -0.17316402  0.69086361  0.47731756  0.05279462  0.2309238 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2430 : 738.9508347607407\n",
      "2431000\n",
      "[-6.5610766]\n",
      "[4517.9136]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41966193 -0.17508375  0.69597449  0.47826354  0.0614255   0.2271427 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2430 : 737.6248277223721\n",
      "2431000\n",
      "[-12.687602]\n",
      "[2536.451]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41288565 -0.17371846  0.69235277  0.47860637  0.06520131  0.22801882]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2430 : 713.4373447754263\n",
      "2431000\n",
      "[-13.7561035]\n",
      "[2453.435]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42365055 -0.1826132   0.6845866   0.46767009  0.05109513  0.20781074]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2440 : 671.2420357199005\n",
      "2441000\n",
      "[-28.480064]\n",
      "[3014.8784]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42695302 -0.18532333  0.6872335   0.46617541  0.04338916  0.21427339]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2440 : 575.8691222919864\n",
      "2441000\n",
      "[-9.317241]\n",
      "[2778.9685]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41443772 -0.1712196   0.69434421  0.48043136  0.05691407  0.23443646]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2440 : 732.868068933337\n",
      "2441000\n",
      "[4.9272733]\n",
      "[2255.3643]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.40980194 -0.16713242  0.69438553  0.48254843  0.06419193  0.23690652]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2440 : 806.0399773062148\n",
      "2441000\n",
      "[1.6292429]\n",
      "[2535.6704]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.43210651 -0.18016347  0.69643277  0.47992447  0.05592907  0.2162543 ]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2450 : 735.7363380073064\n",
      "2451000\n",
      "[-10.223326]\n",
      "[3011.5732]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42769062 -0.18156892  0.68624144  0.47331187  0.03206436  0.21286106]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2450 : 653.094771696146\n",
      "2451000\n",
      "[-1.3925016]\n",
      "[1554.4436]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.43362215 -0.1887053   0.69306987  0.48243108  0.04920217  0.21603567]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2450 : 705.2179325008676\n",
      "2451000\n",
      "[-2.7119472]\n",
      "[3375.5652]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42407314 -0.16765885  0.69312952  0.48129492  0.05219016  0.22772834]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2450 : 715.188507708184\n",
      "2451000\n",
      "[-12.936926]\n",
      "[3278.9497]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42480062 -0.18295618  0.69490671  0.4753479   0.05441938  0.22090612]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2460 : 624.7091884358416\n",
      "2461000\n",
      "[4.6662765]\n",
      "[1639.8706]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42902858 -0.17623455  0.69824375  0.49113629  0.06378594  0.22467243]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2460 : 759.081133484675\n",
      "2461000\n",
      "[-7.994069]\n",
      "[2451.8477]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41507925 -0.17184914  0.68901664  0.47439737  0.04590897  0.22363137]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2460 : 687.821933682304\n",
      "2461000\n",
      "[-12.564959]\n",
      "[3538.5085]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42266448 -0.17982628  0.68211017  0.46711053  0.04787033  0.20654938]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2460 : 630.3488427691705\n",
      "2461000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-8d9fb66c3c5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0mth4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m \u001b[0mth1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0mth2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0mth3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/spinningup/lib/python3.6/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#multihtread\n",
    "num_actions = 6\n",
    "p_net_shared = policy_net(20,num_actions)\n",
    "v_net_shared = value_net(20)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "_lock = threading.Lock()\n",
    "\n",
    "reward_plot = [0 for i in range(5000)]\n",
    "\n",
    "def training(idx):\n",
    "    t_max = 5\n",
    "    gamma = 0.99\n",
    "    learning_rate = 0.001\n",
    "    beta = 0\n",
    "    step = 0\n",
    "    state = []\n",
    "    \n",
    "\n",
    "\n",
    "    global p_net_shared\n",
    "    global v_net_shared\n",
    "    global reward_plot\n",
    "    \n",
    "    for iteration in range(5000):\n",
    "        \n",
    "        p_optimizer = optim.Adam(p_net_shared.parameters(), lr=learning_rate/1000)\n",
    "        v_optimizer = optim.Adam(v_net_shared.parameters(), lr=learning_rate)\n",
    "\n",
    "        done = False\n",
    "        env = gym.make('DobroHalfCheetah-v0')\n",
    "        env.unwrapped.initialize(is_render=False)\n",
    "        observation = env.reset()\n",
    "        state = observation\n",
    "        \n",
    "        p_net = policy_net(20,num_actions)\n",
    "        v_net = value_net(20)\n",
    "    \n",
    "        p_net.zero_grad()\n",
    "        v_net.zero_grad()\n",
    "        \n",
    "        t_update = 0\n",
    "        #beta -= 0.0002\n",
    "        #learning_rate -= 0.0009/2000\n",
    "        if(beta<=0):\n",
    "            beta = 0\n",
    "        reward_stack = []\n",
    "        prob_stack = []\n",
    "        value_stack = []\n",
    "        action_stack = []\n",
    "        entropy = 0\n",
    "        reward_sum = 0\n",
    "        policy_loss_sum=0\n",
    "        value_loss_sum = 0\n",
    "        entropy_sum = 0\n",
    "        \n",
    "        \n",
    "        mean_average = np.zeros(num_actions)\n",
    "        variance_average = np.zeros(num_actions)\n",
    "        \n",
    "        \n",
    "        for t in range(10000):\n",
    "\n",
    "            step = step+1\n",
    "\n",
    "            mean, variance= p_net(torch.Tensor(state))\n",
    "            value = v_net(torch.Tensor(state))            \n",
    "            \n",
    "            mean_average += mean.detach().numpy()\n",
    "            variance_average += variance.detach().numpy()\n",
    "            \n",
    "            action = get_action(mean,variance,num_actions)\n",
    "            \n",
    "            next_state , reward, done, info = env.step(action)\n",
    "            #reward /= 16.2736044\n",
    "            reward_sum += reward\n",
    "            t_update += 1\n",
    "\n",
    "            reward_stack.append(reward)\n",
    "            value_stack.append(value)\n",
    "            prob_stack.append((mean,variance))\n",
    "            action_stack.append(action)\n",
    "            \n",
    "            for i in range(num_actions):\n",
    "                entropy += -(torch.log(torch.clamp(2*math.pi*variance[i]*variance[i] , min = 1e-6)) + 1)/2\n",
    "\n",
    "            if(t_update >= t_max or done):\n",
    "                if(done):\n",
    "                    R=0\n",
    "                else:\n",
    "                    R = v_net(torch.Tensor(next_state))\n",
    "                policy_loss = 0\n",
    "                value_loss = 0\n",
    "                \n",
    "\n",
    "                for i in range(t_update):\n",
    "                    R = R*gamma + reward_stack.pop()\n",
    "                    value_temp = value_stack.pop()\n",
    "                    mu , var = prob_stack.pop()\n",
    "                    action_i = action_stack.pop()\n",
    "                    advantage = (R-value_temp).detach()\n",
    "                    for j in range(num_actions):\n",
    "                        policy_loss += ( (( (action_i[j] - mu[j]) )**2)/2 ) * advantage\n",
    "                    value_loss += (R-value_temp) * (R-value_temp)\n",
    "\n",
    "                entropy_sum += entropy / t_max\n",
    "                entropy = -entropy * beta\n",
    "                policy_loss = policy_loss + entropy \n",
    "                policy_loss = policy_loss / t_max\n",
    "                value_loss = value_loss /t_max\n",
    "\n",
    "                _lock.acquire()\n",
    "                \n",
    "                policy_loss.backward(retain_graph=True)\n",
    "                value_loss.backward()\n",
    "                policy_loss_sum += policy_loss.detach().numpy()\n",
    "                value_loss_sum += value_loss.detach().numpy()\n",
    "                \n",
    "                for p_param , s_p_param in zip(p_net.parameters(), p_net_shared.parameters()):\n",
    "                    s_p_param._grad = p_param.grad.detach()\n",
    "                    if((s_p_param != s_p_param).any()):\n",
    "                        print(\"explode !!!! \")\n",
    "                        \n",
    "                        \n",
    "                for v_param , s_v_param in zip(v_net.parameters(), v_net_shared.parameters()):\n",
    "                    s_v_param._grad = v_param.grad.detach()\n",
    "                    if((s_v_param != s_v_param).any()):\n",
    "                        print(\"explode !!!! \")\n",
    "                \n",
    "                p_optimizer.step()\n",
    "                v_optimizer.step()\n",
    "                p_net_shared.zero_grad()\n",
    "                v_net_shared.zero_grad()\n",
    "\n",
    "                _lock.release()\n",
    "                \n",
    "                \n",
    "                \n",
    "                p_net = policy_net(20,num_actions)\n",
    "                v_net = value_net(20)    \n",
    "\n",
    "                p_net.load_state_dict(p_net_shared.state_dict())\n",
    "                v_net.load_state_dict(v_net_shared.state_dict())\n",
    "                R=0\n",
    "                entropy = 0\n",
    "                t_update = 0\n",
    "            if(done):\n",
    "                mean_average /= t + 1\n",
    "                variance_average /= t+1\n",
    "                break\n",
    "\n",
    "            #env.render()\n",
    "            state = next_state[:]\n",
    "        reward_plot[iteration] += reward_sum\n",
    "        env.close()\n",
    "        if(iteration%10 ==0):\n",
    "            print(policy_loss_sum)\n",
    "            print(value_loss_sum)\n",
    "            print(entropy_sum)\n",
    "            print(\"mean_average : {}\".format(mean_average))\n",
    "            print(\"variance_average : {}\".format(variance_average))\n",
    "            print(\"training idx {} actor true_reward at iteration {} : {}\".format(idx,iteration, reward_sum))\n",
    "            print(step)\n",
    "            beta = beta * 0.99\n",
    "            learning_rate = learning_rate * 0.99\n",
    "th1 = threading.Thread(target = training , args = (1,))\n",
    "th2 = threading.Thread(target = training , args = (2,))\n",
    "th3 = threading.Thread(target = training , args = (3,))\n",
    "th4 = threading.Thread(target = training , args = (4,))\n",
    "\n",
    "th1.start()\n",
    "th2.start()\n",
    "th3.start()\n",
    "th4.start()\n",
    "\n",
    "th1.join()\n",
    "th2.join()\n",
    "th3.join()\n",
    "th4.join()\n",
    "\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'reward')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5081582]\n",
      "[89.75523]\n",
      "tensor(-39.1731)\n",
      "mean_average : [-0.50640523 -0.62242595  0.9679677   0.90467709  0.38059821  0.80147466]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 280 : 37.6251369320111\n",
      "281000\n",
      "[-0.54233056]\n",
      "[86.40703]\n",
      "tensor(-39.1731)\n",
      "mean_average : [-0.49266385 -0.60641742  0.96801707  0.90131261  0.38492766  0.79737826]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 280 : 23.097752221510355\n",
      "281000\n",
      "[-1.499681]\n",
      "[61.598125]\n",
      "tensor(-39.1731)\n",
      "mean_average : [-0.48326331 -0.60888806  0.96815962  0.90383189  0.35293652  0.78592281]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 280 : 30.270807031074998\n",
      "281000\n",
      "[-3.0493608]\n",
      "[63.070644]\n",
      "tensor(-39.1731)\n",
      "mean_average : [-0.50536101 -0.61235621  0.96793374  0.90509004  0.38825313  0.80278091]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 280 : 0.8918827862566137\n",
      "281000\n"
     ]
    }
   ],
   "source": [
    "reward_np = np.array(reward_plot[:270])  /4\n",
    "fig, axe = plt.subplots(1, figsize = (15,15))\n",
    "axe.plot(list(range(len(reward_np))),reward_np, lw = 1, label = 'reward', color = 'blue')\n",
    "axe.set_title('reward', fontsize = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reward 670.9209412279608\n"
     ]
    }
   ],
   "source": [
    "#test\n",
    "state = []\n",
    "done = False\n",
    "reward_sum=0\n",
    "env = gym.make('DobroHalfCheetah-v0')\n",
    "env.unwrapped.initialize(is_render=True)\n",
    "\n",
    "observation = env.reset()\n",
    "\n",
    "state = observation\n",
    "\n",
    "for t in range(10000):\n",
    "    env.render()\n",
    "    \n",
    "    mean, variance= p_net_shared(torch.Tensor(state))\n",
    "    value = v_net_shared(torch.Tensor(state))\n",
    "\n",
    "    action = get_action(mean,variance,num_actions)\n",
    "    \n",
    "    obs , reward, done, info = env.step(action)\n",
    "    \n",
    "    \n",
    "    reward_sum = reward_sum + reward\n",
    "    state=obs\n",
    "    if done:\n",
    "        break\n",
    "    \n",
    "print(\"reward {}\".format(reward_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.4883375]\n",
      "[2791.6648]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41689503 -0.17811496  0.68862949  0.48441959  0.08041583  0.21579783]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 4 actor true_reward at iteration 2480 : 742.7555145054702\n",
      "2481000\n",
      "[4.580019]\n",
      "[2590.9663]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.41663202 -0.16778445  0.68326773  0.47837469  0.06268778  0.21767246]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 2 actor true_reward at iteration 2480 : 777.8593909629967\n",
      "2481000\n",
      "[-1.5122318]\n",
      "[2234.2854]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42227361 -0.18333763  0.68958244  0.47382023  0.06338541  0.21766604]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 3 actor true_reward at iteration 2480 : 748.9084506806155\n",
      "2481000\n",
      "[-21.234827]\n",
      "[3756.0498]\n",
      "tensor(-39.1731)\n",
      "mean_average : [ 0.42636718 -0.17341977  0.69237174  0.47419842  0.05387983  0.21901845]\n",
      "variance_average : [0.25 0.25 0.25 0.25 0.25 0.25]\n",
      "training idx 1 actor true_reward at iteration 2480 : 634.8232315599574\n",
      "2481000\n"
     ]
    }
   ],
   "source": [
    "torch.save(p_net_shared.state_dict() , './A3C_Model/DobroHalfCheetah_policy_model_seed_{}.pth'.format(0))\n",
    "torch.save(v_net_shared.state_dict() , './A3C_Model/DobroHalfCheetah_value_model_seed_{}.pth'.format(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'reward')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "reward_np = np.array(reward_plot[:2400])  / 4\n",
    "fig, axe = plt.subplots(1, figsize = (15,15))\n",
    "axe.plot(list(range(len(reward_np))),reward_np, lw = 1, label = 'reward', color = 'blue')\n",
    "axe.set_title('reward', fontsize = 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6_spinningup",
   "language": "python",
   "name": "spinningup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
