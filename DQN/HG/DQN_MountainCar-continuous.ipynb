{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_NAME = 'MountainCarContinuous-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hogun/anaconda2/envs/gym/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "action_dim = 2\n",
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_list = [env.action_space.low[0], env.action_space.high[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "max_buff_size = 5000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "\n",
    "update_freq = 5000\n",
    "print_freq = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(q_net, inputs, epsilon, action_dim=3):\n",
    "    # randomly choose\n",
    "    if random.random() <= epsilon:\n",
    "        action_idx = random.randint(0, action_dim-1)\n",
    "    else:\n",
    "        q_value = q_net(inputs).tolist()\n",
    "        action_idx = np.argmax(q_value)\n",
    "    \n",
    "    return action_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNet(nn.Module):\n",
    "    def __init__(self, input_dim=2, action_dim=3):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, action_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(minibatch, gamma=0.99, cuda=False):\n",
    "    rewards = torch.tensor((minibatch[:, 2]).astype(np.float32))\n",
    "    done = torch.tensor((1-minibatch[:, 4]).astype(np.float32))\n",
    "    next_q = target_net(torch.tensor(np.concatenate(minibatch[:,3], axis=0).reshape(-1, input_dim), dtype=torch.float32))\n",
    "    next_q_max = next_q[torch.arange(batch_size), next_q.max(1)[1]]\n",
    "    y_target = rewards + gamma * done * next_q_max\n",
    "    #print('y target:', y_target)\n",
    "    \n",
    "    pre_obs = torch.tensor(np.concatenate(minibatch[:,0], axis=0).reshape(-1, input_dim), dtype=torch.float32)\n",
    "    if cuda:\n",
    "        y_target = y_target.cuda()\n",
    "        pre_obs = pre_obs.cuda()\n",
    "    \n",
    "    q_values = q_net(pre_obs)\n",
    "    actions = minibatch[:, 1].astype(np.int32)\n",
    "    max_q = q_values[torch.arange(batch_size), actions]\n",
    "    #print('q:', max_q)\n",
    "    loss = criterion(y_target, max_q)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 step average loss: 0.005249139919906156\n",
      "2000 step average loss: 0.03910052082852053\n",
      "3000 step average loss: 0.04274629194680892\n",
      "4000 step average loss: 2.3801667232392503\n",
      "5000 step average loss: 3.887019426566083\n",
      "6000 step average loss: 4.746083925120533\n",
      "7000 step average loss: 1.9463472854942083\n",
      "8000 step average loss: 1.5646575100272895\n",
      "9000 step average loss: 0.7959038783162832\n",
      "10000 step average loss: 0.47596411349624396\n",
      "11000 step average loss: 0.4243933352679014\n",
      "12000 step average loss: 0.38082261064648626\n",
      "13000 step average loss: 0.531771592579782\n",
      "14000 step average loss: 0.45777800238877536\n",
      "15000 step average loss: 0.6970184894800187\n",
      "16000 step average loss: 0.8870736328065395\n",
      "17000 step average loss: 0.7228013489246369\n",
      "18000 step average loss: 0.46052476853132246\n",
      "19000 step average loss: 0.37173819380253553\n",
      "20000 step average loss: 0.3475290470793843\n",
      "21000 step average loss: 0.39468723184242843\n",
      "22000 step average loss: 7.702227892786264\n",
      "23000 step average loss: 1.7247831845283508\n",
      "24000 step average loss: 3.28249607026577\n",
      "25000 step average loss: 3.386116319477558\n",
      "26000 step average loss: 4.464009960651397\n",
      "27000 step average loss: 4.399479124605656\n",
      "28000 step average loss: 3.940718303054571\n",
      "29000 step average loss: 2.6375902341008186\n",
      "30000 step average loss: 2.8349181940555574\n",
      "31000 step average loss: 2.1257434947788716\n",
      "32000 step average loss: 1.5578810712695121\n",
      "33000 step average loss: 1.166975881755352\n",
      "34000 step average loss: 1.2901676051616668\n",
      "35000 step average loss: 1.283498508363962\n",
      "36000 step average loss: 1.2725261237174272\n",
      "37000 step average loss: 1.248651026070118\n",
      "38000 step average loss: 1.1971292822360993\n",
      "39000 step average loss: 1.1888001581281424\n",
      "40000 step average loss: 1.2309430373311043\n",
      "41000 step average loss: 1.352456934452057\n",
      "42000 step average loss: 1.9737324475049973\n",
      "43000 step average loss: 1.717343678623438\n",
      "44000 step average loss: 1.2833145576119422\n",
      "45000 step average loss: 1.255632817864418\n",
      "46000 step average loss: 1.406745646893978\n",
      "47000 step average loss: 1.4581450161635876\n",
      "48000 step average loss: 1.284594189763069\n",
      "49000 step average loss: 1.186375463142991\n",
      "50000 step average loss: 0.871585475564003\n",
      "51000 step average loss: 0.7131499787047505\n",
      "52000 step average loss: 0.7259123875573278\n",
      "53000 step average loss: 0.8388112827315927\n",
      "54000 step average loss: 1.2963402474075556\n",
      "55000 step average loss: 1.1509040360748768\n",
      "56000 step average loss: 1.5355354272723198\n",
      "57000 step average loss: 1.4937608386725187\n",
      "58000 step average loss: 1.6450932278186083\n",
      "59000 step average loss: 2.3855369223058225\n",
      "60000 step average loss: 2.361794290423393\n",
      "61000 step average loss: 1.8528565828353167\n",
      "62000 step average loss: 1.554229514196515\n",
      "63000 step average loss: 1.1555768993347884\n",
      "64000 step average loss: 0.8199876474440098\n",
      "65000 step average loss: 0.5954503307119012\n",
      "66000 step average loss: 0.5797501292973757\n",
      "67000 step average loss: 0.6823429730907082\n",
      "68000 step average loss: 0.7511722879633308\n",
      "69000 step average loss: 1.0112342249006032\n",
      "70000 step average loss: 1.079482537008822\n",
      "71000 step average loss: 0.953285350933671\n",
      "72000 step average loss: 1.4096036865115165\n",
      "73000 step average loss: 1.0940790822952986\n",
      "74000 step average loss: 1.7803767330795526\n",
      "75000 step average loss: 1.5693636253923178\n",
      "76000 step average loss: 1.1422109351754188\n",
      "77000 step average loss: 1.2306970482617616\n",
      "78000 step average loss: 1.1105900681614875\n",
      "79000 step average loss: 1.1181653304174541\n",
      "80000 step average loss: 1.2391457566693425\n",
      "81000 step average loss: 0.9496296992152929\n",
      "82000 step average loss: 1.1246932309418918\n",
      "83000 step average loss: 1.068369074627757\n",
      "84000 step average loss: 1.2928928503841162\n",
      "85000 step average loss: 1.0990996398180723\n",
      "86000 step average loss: 0.9903986770808697\n",
      "87000 step average loss: 1.1564227874577044\n",
      "88000 step average loss: 1.487956079542637\n",
      "89000 step average loss: 1.2486524641662835\n",
      "90000 step average loss: 1.4854134718030692\n",
      "91000 step average loss: 1.0495373211354018\n",
      "92000 step average loss: 0.9613147098720074\n",
      "93000 step average loss: 1.0951336562857032\n",
      "94000 step average loss: 0.8616674017459154\n",
      "95000 step average loss: 0.813065429776907\n",
      "96000 step average loss: 0.9678943786397576\n",
      "97000 step average loss: 0.8391399464011192\n",
      "98000 step average loss: 1.0759777444154024\n",
      "99000 step average loss: 1.2671584364920854\n",
      "100000 step average loss: 1.2633382174819707\n",
      "101000 step average loss: 1.2335901333540678\n",
      "102000 step average loss: 1.386348924010992\n",
      "103000 step average loss: 1.2750690724030138\n",
      "104000 step average loss: 1.3099277782440186\n",
      "105000 step average loss: 0.9987688204199076\n",
      "106000 step average loss: 3.5372829994410275\n",
      "107000 step average loss: 1.3787216792851686\n",
      "108000 step average loss: 0.9653108683228493\n",
      "109000 step average loss: 1.0906209594011307\n",
      "110000 step average loss: 0.7106049868315458\n",
      "111000 step average loss: 0.8387251116335392\n",
      "112000 step average loss: 0.6148898024559021\n",
      "113000 step average loss: 0.8982823936790227\n",
      "114000 step average loss: 0.7236749331355095\n",
      "115000 step average loss: 0.6086305469349027\n",
      "116000 step average loss: 0.9049879031479359\n",
      "117000 step average loss: 0.8103708886951209\n",
      "118000 step average loss: 0.5323609900251031\n",
      "119000 step average loss: 0.5907131459712982\n",
      "120000 step average loss: 1.0290636417865753\n",
      "121000 step average loss: 1.62510280187428\n",
      "122000 step average loss: 0.95941982036829\n",
      "123000 step average loss: 1.0037859033495187\n",
      "124000 step average loss: 0.7392752919048071\n",
      "125000 step average loss: 0.6416418298184872\n",
      "126000 step average loss: 0.6504608105793596\n",
      "127000 step average loss: 0.8443168128803372\n",
      "128000 step average loss: 0.9750133992880583\n",
      "129000 step average loss: 1.0011502681672573\n",
      "130000 step average loss: 1.3599107779413462\n",
      "131000 step average loss: 1.024430812418461\n",
      "132000 step average loss: 0.9605611520335078\n",
      "133000 step average loss: 0.634407482624054\n",
      "134000 step average loss: 0.498125358350575\n",
      "135000 step average loss: 0.37717085709422826\n",
      "136000 step average loss: 0.4162708630636334\n",
      "137000 step average loss: 0.3689456579312682\n",
      "138000 step average loss: 0.3975087069310248\n",
      "139000 step average loss: 0.5051625312305987\n",
      "140000 step average loss: 0.5463977763801813\n",
      "141000 step average loss: 0.5945327902287245\n",
      "142000 step average loss: 0.5014279312640428\n",
      "143000 step average loss: 0.5475390863865613\n",
      "144000 step average loss: 0.6107360993772745\n",
      "145000 step average loss: 0.6750962239131332\n",
      "146000 step average loss: 0.6196598334088922\n",
      "147000 step average loss: 0.6912958847805858\n",
      "148000 step average loss: 0.7482466602623463\n",
      "149000 step average loss: 0.7536789325550198\n",
      "150000 step average loss: 0.749247556656599\n",
      "151000 step average loss: 9.077630077056586\n",
      "152000 step average loss: 12.539394007265567\n",
      "153000 step average loss: 6.266965365558863\n",
      "154000 step average loss: 2.6328104596436024\n",
      "155000 step average loss: 2.0081120828837156\n",
      "156000 step average loss: 4.3743149083256725\n",
      "157000 step average loss: 14.191982750445604\n",
      "158000 step average loss: 5.242803670227528\n",
      "159000 step average loss: 3.107354638785124\n",
      "160000 step average loss: 2.297860366821289\n",
      "161000 step average loss: 2.0065668890476225\n",
      "162000 step average loss: 1.8753060218393802\n",
      "163000 step average loss: 2.021161712795496\n",
      "164000 step average loss: 2.8003291446566583\n",
      "165000 step average loss: 1.44134024938941\n",
      "166000 step average loss: 1.4957857209295033\n",
      "167000 step average loss: 1.3066521714031696\n",
      "168000 step average loss: 1.32793673568964\n",
      "169000 step average loss: 1.1269585199356078\n",
      "170000 step average loss: 1.316457143843174\n",
      "171000 step average loss: 1.6405993423163892\n",
      "172000 step average loss: 1.52872733476758\n",
      "173000 step average loss: 2.2602406983971597\n",
      "174000 step average loss: 1.9582206513881684\n",
      "175000 step average loss: 1.6994070584475993\n",
      "176000 step average loss: 0.8450006549209357\n",
      "177000 step average loss: 1.1243950273394585\n",
      "178000 step average loss: 0.9792685248851776\n",
      "179000 step average loss: 1.0460548488050698\n",
      "180000 step average loss: 1.014849299684167\n",
      "181000 step average loss: 0.7907083601653576\n",
      "182000 step average loss: 0.8910560701489448\n",
      "183000 step average loss: 1.0427990210205316\n",
      "184000 step average loss: 0.6370024877339602\n",
      "185000 step average loss: 0.5307078162580728\n",
      "186000 step average loss: 0.4416537806466222\n",
      "187000 step average loss: 0.3378754278421402\n",
      "188000 step average loss: 0.4294952531605959\n",
      "189000 step average loss: 0.39436795668303964\n",
      "190000 step average loss: 0.5921528950408101\n",
      "191000 step average loss: 0.5283982054740191\n",
      "192000 step average loss: 0.7378398791700601\n",
      "193000 step average loss: 0.6560392116233706\n",
      "194000 step average loss: 0.5764076756983996\n",
      "195000 step average loss: 0.46049787604063747\n",
      "196000 step average loss: 0.49184537302702663\n",
      "197000 step average loss: 0.5447028806507588\n",
      "198000 step average loss: 0.6666302921921015\n",
      "199000 step average loss: 0.6180043073520064\n",
      "200000 step average loss: 0.5375138240903616\n",
      "201000 step average loss: 1.131088558986783\n",
      "202000 step average loss: 1.6444419939219952\n",
      "203000 step average loss: 1.7232032829225064\n",
      "204000 step average loss: 1.6500534517168999\n",
      "205000 step average loss: 1.4715459967255593\n",
      "206000 step average loss: 1.170440399736166\n",
      "207000 step average loss: 0.9320758464634419\n",
      "208000 step average loss: 0.9066242889761925\n",
      "209000 step average loss: 0.711763816550374\n",
      "210000 step average loss: 0.5545480945855379\n",
      "211000 step average loss: 0.6657970089167357\n",
      "212000 step average loss: 0.47865748207271097\n",
      "213000 step average loss: 0.4964822472780943\n",
      "214000 step average loss: 0.5098558999449014\n",
      "215000 step average loss: 0.4653813931569457\n",
      "216000 step average loss: 0.6671752458736301\n",
      "217000 step average loss: 0.8795396188646555\n",
      "218000 step average loss: 0.9149368765950203\n",
      "219000 step average loss: 0.7122198080867529\n",
      "220000 step average loss: 0.7708820781856776\n",
      "221000 step average loss: 0.6404711343795061\n",
      "222000 step average loss: 0.5532717509642243\n",
      "223000 step average loss: 0.5885561829134822\n",
      "224000 step average loss: 0.5255603322461248\n",
      "225000 step average loss: 0.5200254683718085\n",
      "226000 step average loss: 0.5663834841102362\n",
      "227000 step average loss: 0.5539710768312216\n",
      "228000 step average loss: 0.6709542024731636\n",
      "229000 step average loss: 0.5560058591887355\n",
      "230000 step average loss: 0.6725833993107081\n",
      "231000 step average loss: 0.7400372964590788\n",
      "232000 step average loss: 1.078429943844676\n",
      "233000 step average loss: 1.1242865533232689\n",
      "234000 step average loss: 1.0211449214816093\n",
      "235000 step average loss: 0.6941774166971445\n",
      "236000 step average loss: 0.5942997193858027\n",
      "237000 step average loss: 0.6865300419554115\n",
      "238000 step average loss: 1.1338779624700546\n",
      "239000 step average loss: 0.7201496478542686\n",
      "240000 step average loss: 0.7842245065942407\n",
      "241000 step average loss: 0.8801319011747837\n",
      "242000 step average loss: 0.6814167700409889\n",
      "243000 step average loss: 0.6735796365588903\n",
      "244000 step average loss: 0.5880019717216491\n",
      "245000 step average loss: 0.5831157514452934\n",
      "246000 step average loss: 0.6347291971072555\n",
      "247000 step average loss: 0.759945160806179\n",
      "248000 step average loss: 0.729419600367546\n",
      "249000 step average loss: 0.6983325331062078\n",
      "250000 step average loss: 1.2896867863088846\n",
      "251000 step average loss: 0.9922059978246689\n",
      "252000 step average loss: 1.012213419958949\n",
      "253000 step average loss: 0.93359613224864\n",
      "254000 step average loss: 1.0710366659760475\n",
      "255000 step average loss: 0.9721024882346392\n",
      "256000 step average loss: 0.8444595495611429\n",
      "257000 step average loss: 0.813101471543312\n",
      "258000 step average loss: 0.7360692047253251\n",
      "259000 step average loss: 0.8552879706844687\n",
      "260000 step average loss: 0.9672317997664213\n",
      "261000 step average loss: 0.7964376964271068\n",
      "262000 step average loss: 0.8705477042794227\n",
      "263000 step average loss: 0.9428910406678915\n",
      "264000 step average loss: 0.8443175248354673\n",
      "265000 step average loss: 0.8553195786774158\n",
      "266000 step average loss: 0.6980432418435812\n",
      "267000 step average loss: 0.76241984269768\n",
      "268000 step average loss: 0.7897494061514735\n",
      "269000 step average loss: 0.6599081664681434\n",
      "270000 step average loss: 0.5205876951441168\n",
      "271000 step average loss: 0.6024800123274326\n",
      "272000 step average loss: 0.6381381120979785\n",
      "273000 step average loss: 0.5774403807148337\n",
      "274000 step average loss: 0.6216592147126794\n",
      "275000 step average loss: 0.47433408608287575\n",
      "276000 step average loss: 0.45594937479496\n",
      "277000 step average loss: 0.5479898255988955\n",
      "278000 step average loss: 0.7963686786144972\n",
      "279000 step average loss: 0.7059903798550368\n",
      "280000 step average loss: 0.8038839644044637\n",
      "281000 step average loss: 0.8025768555253744\n",
      "282000 step average loss: 0.9996916637867689\n",
      "283000 step average loss: 1.2780406407415867\n",
      "284000 step average loss: 1.460872685432434\n",
      "285000 step average loss: 1.5671001172959804\n",
      "286000 step average loss: 1.1921645343005658\n",
      "287000 step average loss: 0.7547352011650801\n",
      "288000 step average loss: 0.8482335544377565\n",
      "289000 step average loss: 0.7325665086060762\n",
      "290000 step average loss: 0.7190113628953695\n",
      "291000 step average loss: 0.6338446185141802\n",
      "292000 step average loss: 0.9669365761727094\n",
      "293000 step average loss: 1.0738341417610646\n",
      "294000 step average loss: 0.6759152600765228\n",
      "295000 step average loss: 0.6160232357382774\n",
      "296000 step average loss: 0.6647467632293701\n",
      "297000 step average loss: 0.659822009332478\n",
      "298000 step average loss: 0.5852821147143841\n",
      "299000 step average loss: 0.6459036073833704\n",
      "300000 step average loss: 0.5808233079984784\n",
      "301000 step average loss: 0.7175235601365566\n",
      "302000 step average loss: 0.6567356503009796\n",
      "303000 step average loss: 0.7648659171760083\n",
      "304000 step average loss: 0.8621234085708857\n",
      "305000 step average loss: 0.9496349223256111\n",
      "306000 step average loss: 0.9959633581340313\n",
      "307000 step average loss: 0.9891184450984001\n",
      "308000 step average loss: 0.941813134983182\n",
      "309000 step average loss: 1.124561437830329\n",
      "310000 step average loss: 1.0493861493468284\n",
      "311000 step average loss: 1.3528634576499463\n",
      "312000 step average loss: 1.29129881092906\n",
      "313000 step average loss: 1.6183773074299097\n",
      "314000 step average loss: 1.3190182372629642\n",
      "315000 step average loss: 1.3541101941913367\n",
      "316000 step average loss: 1.3934803903251887\n",
      "317000 step average loss: 1.7467426660954952\n",
      "318000 step average loss: 1.1589961005747318\n",
      "319000 step average loss: 1.2291697123497725\n",
      "320000 step average loss: 1.1649269210994244\n",
      "321000 step average loss: 1.021843612894416\n",
      "322000 step average loss: 0.8246133218407631\n",
      "323000 step average loss: 0.7373525842726231\n",
      "324000 step average loss: 0.8169406691640615\n",
      "325000 step average loss: 0.7359182697981596\n",
      "326000 step average loss: 0.7490059082359075\n",
      "327000 step average loss: 0.711966718584299\n",
      "328000 step average loss: 0.7607862080335617\n",
      "329000 step average loss: 0.7555100942254066\n",
      "330000 step average loss: 0.8503585885837674\n",
      "331000 step average loss: 0.9978974485993385\n",
      "332000 step average loss: 0.9737807966321707\n",
      "333000 step average loss: 0.8178479619175195\n",
      "334000 step average loss: 0.96938159891963\n",
      "335000 step average loss: 1.0672613467127086\n",
      "336000 step average loss: 1.180162396788597\n",
      "337000 step average loss: 1.0845122336745263\n",
      "338000 step average loss: 0.9850965185314416\n",
      "339000 step average loss: 0.7665087690353394\n",
      "340000 step average loss: 0.7258417425453663\n",
      "341000 step average loss: 0.7213349673002958\n",
      "342000 step average loss: 0.7278291540443897\n",
      "343000 step average loss: 0.6695661036819219\n",
      "344000 step average loss: 0.6124566153287888\n",
      "345000 step average loss: 0.5014105408936739\n",
      "346000 step average loss: 0.42408887527137995\n",
      "347000 step average loss: 0.9271894529312849\n",
      "348000 step average loss: 0.358557650513947\n",
      "349000 step average loss: 0.335421066224575\n",
      "350000 step average loss: 0.3594360854327679\n",
      "351000 step average loss: 0.33356208526343106\n",
      "352000 step average loss: 0.3223552454188466\n",
      "353000 step average loss: 0.3772261913344264\n",
      "354000 step average loss: 0.3898553866147995\n",
      "355000 step average loss: 0.3634070262759924\n",
      "356000 step average loss: 0.4413645487129688\n",
      "357000 step average loss: 0.3558561491146684\n",
      "358000 step average loss: 0.33736515034362674\n",
      "359000 step average loss: 0.30320437901094555\n",
      "360000 step average loss: 0.2713026967719197\n",
      "361000 step average loss: 1.1471171245872975\n",
      "362000 step average loss: 0.7894193647652864\n",
      "363000 step average loss: 0.6366921295970678\n",
      "364000 step average loss: 0.5115236004143954\n",
      "365000 step average loss: 0.7502963301837444\n",
      "366000 step average loss: 0.6619661310240627\n",
      "367000 step average loss: 0.8140514786690474\n",
      "368000 step average loss: 0.7676156440228223\n",
      "369000 step average loss: 0.9350370496362448\n",
      "370000 step average loss: 0.5826772557497024\n",
      "371000 step average loss: 0.5406853626295924\n",
      "372000 step average loss: 0.47588290966302155\n",
      "373000 step average loss: 0.4864034416899085\n",
      "374000 step average loss: 0.4708673825338483\n",
      "375000 step average loss: 0.34965642148256304\n",
      "376000 step average loss: 0.5616416928619147\n",
      "377000 step average loss: 0.5977640200704336\n",
      "378000 step average loss: 0.5694880833029747\n",
      "379000 step average loss: 0.6323071198761463\n",
      "380000 step average loss: 0.6649442294090986\n",
      "381000 step average loss: 0.5677490180283785\n",
      "382000 step average loss: 0.7332518115192652\n",
      "383000 step average loss: 0.5783184355869889\n",
      "384000 step average loss: 0.5966319978162646\n",
      "385000 step average loss: 0.5452408282011747\n",
      "386000 step average loss: 0.6172707958966493\n",
      "387000 step average loss: 0.4399551481604576\n",
      "388000 step average loss: 0.44081433963030575\n",
      "389000 step average loss: 0.49475991221517324\n",
      "390000 step average loss: 0.437138783402741\n",
      "391000 step average loss: 0.4212707600519061\n",
      "392000 step average loss: 0.5002442389130592\n",
      "393000 step average loss: 0.5535697308182717\n",
      "394000 step average loss: 0.65353457903862\n",
      "395000 step average loss: 0.5686736615523696\n",
      "396000 step average loss: 0.5999454876855016\n",
      "397000 step average loss: 0.5112451468706131\n",
      "398000 step average loss: 0.6367418538928032\n",
      "399000 step average loss: 0.4959070034176111\n",
      "400000 step average loss: 0.3972307075932622\n",
      "401000 step average loss: 0.3566426933631301\n",
      "402000 step average loss: 0.39486278559267524\n",
      "403000 step average loss: 0.47470971520990135\n",
      "404000 step average loss: 0.6165952380374073\n",
      "405000 step average loss: 0.653988702133298\n",
      "406000 step average loss: 0.6281336292028427\n",
      "407000 step average loss: 0.6525613439083099\n",
      "408000 step average loss: 0.5815229767598212\n",
      "409000 step average loss: 0.47729011850059033\n",
      "410000 step average loss: 0.3452492863982916\n",
      "411000 step average loss: 0.41205494190752506\n",
      "412000 step average loss: 0.594170011408627\n",
      "413000 step average loss: 0.7058750237748027\n",
      "414000 step average loss: 0.7091079981252552\n",
      "415000 step average loss: 0.8497566037923098\n",
      "416000 step average loss: 0.8330929019749165\n",
      "417000 step average loss: 0.81796597404778\n",
      "418000 step average loss: 0.9682529576420784\n",
      "419000 step average loss: 0.9399843155443668\n",
      "420000 step average loss: 0.9856997905671596\n",
      "421000 step average loss: 0.9397915852963924\n",
      "422000 step average loss: 0.9206887270957231\n",
      "423000 step average loss: 0.7599771017283201\n",
      "424000 step average loss: 1.0754883390963077\n",
      "425000 step average loss: 1.0520783989727498\n",
      "426000 step average loss: 1.117450609654188\n",
      "427000 step average loss: 1.392622505158186\n",
      "428000 step average loss: 1.168933892071247\n",
      "429000 step average loss: 0.9228173791766167\n",
      "430000 step average loss: 0.9838735522776842\n",
      "431000 step average loss: 0.8289825901538134\n",
      "432000 step average loss: 0.7452150767892599\n",
      "433000 step average loss: 0.6879377615898847\n",
      "434000 step average loss: 0.7201135686784983\n",
      "435000 step average loss: 0.6970368215292693\n",
      "436000 step average loss: 0.6716787168085575\n",
      "437000 step average loss: 0.6067092693895102\n",
      "438000 step average loss: 0.4274384992867708\n",
      "439000 step average loss: 0.5222792668268085\n",
      "440000 step average loss: 0.755612817004323\n",
      "441000 step average loss: 0.6789977090656757\n",
      "442000 step average loss: 0.5693711143657565\n",
      "443000 step average loss: 0.5642333110123873\n",
      "444000 step average loss: 0.5756416838392615\n",
      "445000 step average loss: 0.5456915502250195\n",
      "446000 step average loss: 0.5730768656209111\n",
      "447000 step average loss: 0.7548620478063822\n",
      "448000 step average loss: 0.7007497048005462\n",
      "449000 step average loss: 0.5209968826621771\n",
      "450000 step average loss: 0.5269694070667028\n",
      "451000 step average loss: 0.4852581698894501\n",
      "452000 step average loss: 0.48987965358793734\n",
      "453000 step average loss: 0.4087140919715166\n",
      "454000 step average loss: 0.3967927599772811\n",
      "455000 step average loss: 0.4975089561343193\n",
      "456000 step average loss: 0.5489346452653409\n",
      "457000 step average loss: 0.46630386492609976\n",
      "458000 step average loss: 0.45162013528496026\n",
      "459000 step average loss: 0.544069139122963\n",
      "460000 step average loss: 0.5042899430766702\n",
      "461000 step average loss: 0.47022360292077064\n",
      "462000 step average loss: 0.4648641931191087\n",
      "463000 step average loss: 0.4339280596598983\n",
      "464000 step average loss: 0.4408286849483848\n",
      "465000 step average loss: 0.49801966116577384\n",
      "466000 step average loss: 0.4006566977202892\n",
      "467000 step average loss: 0.42957267739623783\n",
      "468000 step average loss: 0.4046519980877638\n",
      "469000 step average loss: 0.4544793797507882\n",
      "470000 step average loss: 0.5480747867003083\n",
      "471000 step average loss: 0.688951814815402\n",
      "472000 step average loss: 0.6228670080378652\n",
      "473000 step average loss: 0.6781307166367769\n",
      "474000 step average loss: 0.731694838181138\n",
      "475000 step average loss: 0.6821973047703505\n",
      "476000 step average loss: 0.6425481667369604\n",
      "477000 step average loss: 0.532254125572741\n",
      "478000 step average loss: 0.5025235923975706\n",
      "479000 step average loss: 0.4609861405417323\n",
      "480000 step average loss: 0.42139988926053046\n",
      "481000 step average loss: 0.3009993209950626\n",
      "482000 step average loss: 0.3078417766727507\n",
      "483000 step average loss: 0.2117014801762998\n",
      "484000 step average loss: 0.614581692226231\n",
      "485000 step average loss: 1.004709169909358\n",
      "486000 step average loss: 1.1628720151633025\n",
      "487000 step average loss: 1.1260841597467661\n",
      "488000 step average loss: 1.0647493409961462\n",
      "489000 step average loss: 0.7126439556702971\n",
      "490000 step average loss: 0.6904957528412342\n",
      "491000 step average loss: 0.6236731782481074\n",
      "492000 step average loss: 1.0149089448451996\n",
      "493000 step average loss: 1.0400838790461422\n",
      "494000 step average loss: 1.1454809226840734\n",
      "495000 step average loss: 1.1448529098927975\n",
      "496000 step average loss: 1.096972147643566\n",
      "497000 step average loss: 1.491206002548337\n",
      "498000 step average loss: 2.287152403563261\n",
      "499000 step average loss: 1.4065275444239378\n",
      "500000 step average loss: 1.39374482986331\n"
     ]
    }
   ],
   "source": [
    "q_net = QNet(input_dim, action_dim)\n",
    "target_net = QNet(input_dim, action_dim)\n",
    "\n",
    "if cuda:\n",
    "    q_net = q_net.cuda()\n",
    "\n",
    "target_net.load_state_dict(q_net.state_dict())\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "#optimizer = optim.SGD(q_net.parameters(), lr=1e-6, momentum=0.95)\n",
    "optimizer = optim.Adam(q_net.parameters(), lr=learning_rate)\n",
    "\n",
    "epsilon = 1.0\n",
    "min_epsilon = 0.01\n",
    "\n",
    "replay_buffer = []\n",
    "log_returns = []\n",
    "log_average_loss = []\n",
    "log_minibatch_loss = []\n",
    "\n",
    "done = False\n",
    "t_step = 0\n",
    "ridx = 0\n",
    "episode_reward = 0\n",
    "running_loss = 0\n",
    "observation = env.reset()\n",
    "\n",
    "while t_step<500000:\n",
    "    #env.render()\n",
    "    pre_obs = observation\n",
    "    input_state = torch.tensor([observation], dtype=torch.float32)\n",
    "    if cuda:\n",
    "        input_state = input_state.cuda()\n",
    "    action_idx = get_action(q_net, input_state, epsilon, action_dim)\n",
    "    observation, reward, done, info = env.step([action_list[action_idx]])\n",
    "    \n",
    "#     if observation[0] >= 0.5:\n",
    "#         reward += 10\n",
    "    \n",
    "    epsilon = max(0.999*epsilon, min_epsilon)\n",
    "\n",
    "    episode_reward += reward\n",
    "    if done:\n",
    "        #print('new episode.')\n",
    "        log_returns.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        observation = env.reset()\n",
    "\n",
    "    if len(replay_buffer)<max_buff_size:\n",
    "        replay_buffer.append([pre_obs, action_idx, reward, observation, done])\n",
    "        if len(replay_buffer)<batch_size:\n",
    "            continue\n",
    "    else:\n",
    "        replay_buffer[ridx%max_buff_size] = [pre_obs, action_idx, reward, observation, done]\n",
    "        ridx += 1\n",
    "\n",
    "    minibatch = np.array(random.sample(replay_buffer, batch_size))\n",
    "    loss = calculate_loss(minibatch).cpu()\n",
    "    running_loss += loss.data.numpy()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (t_step+1)%print_freq==0:\n",
    "        print(t_step+1, 'step average loss:', running_loss/print_freq)\n",
    "        log_average_loss.append(running_loss/print_freq)\n",
    "        running_loss = 0\n",
    "    log_minibatch_loss.append(loss.data.numpy())\n",
    "\n",
    "    if (t_step+1)%update_freq:\n",
    "        target_net.load_state_dict(q_net.state_dict())\n",
    "\n",
    "    t_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = ['Episode Returns', 'Average Loss', 'Minibatch Loss']\n",
    "colors = ['red', 'blue', 'green']\n",
    "\n",
    "fig, axes = plt.subplots(3)\n",
    "axes[0].plot(log_returns, color=colors[0])\n",
    "axes[1].plot(log_average_loss, color=colors[1])\n",
    "axes[2].plot(log_minibatch_loss, color=colors[2])\n",
    "for i in range(3):\n",
    "    axes[i].set_title(labels[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
