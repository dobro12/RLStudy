{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "REPLAY_BUFFER_SIZE = 50000\n",
    "BATCH_SIZE = 32\n",
    "STATE_SHAPE = 3\n",
    "ACTION_NUMBER = 11\n",
    "GAMMA = 0.99\n",
    "EPSILON_DECAY_TIME = 400000\n",
    "TRAIN_STARTING_POINT = 5000\n",
    "TARGET_UPDATE_FREQ = 4000\n",
    "MAX_STEP = 500000\n",
    "EVALUATION_FREQ = 10000\n",
    "EVALUATION_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REPLAY BUFFER\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.history = deque([], maxlen = REPLAY_BUFFER_SIZE)\n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        buffer = (state, action, reward, next_state, done)\n",
    "        self.history.append(buffer)\n",
    "        \n",
    "    def sample_batch(self):\n",
    "        batch = random.sample(self.history, BATCH_SIZE)\n",
    "        return batch\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_eval= 0.05\n",
    "        self.final_epsilon = 0.1\n",
    "        self.epsilon_decay = (1.0 - self.final_epsilon) / (EPSILON_DECAY_TIME - REPLAY_BUFFER_SIZE)\n",
    "        self.replay = ReplayBuffer()\n",
    "        self.input_state = tf.placeholder(shape=(None, STATE_SHAPE), dtype=tf.float32)\n",
    "        self.actions = tf.placeholder(shape=(None,), dtype=tf.int32)\n",
    "        with tf.variable_scope('online'):\n",
    "            self.online_q_values = self._build_network()\n",
    "            print('online build')\n",
    "        with tf.variable_scope('target'):\n",
    "            self.target_q_values = self._build_network()\n",
    "            print('target build')\n",
    "        self.online_parameters = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'online')\n",
    "        self.target_parameters = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'target')\n",
    "        \n",
    "        self.target_values = tf.placeholder(shape=(None, ACTION_NUMBER), dtype=tf.float32)\n",
    "        self.loss = tf.reduce_sum(tf.square(self.target_values - self.online_q_values))\n",
    "     \n",
    "        self.gradient = tf.gradients(self.loss, self.online_parameters)\n",
    "        self.apply_grad = Optimizer.apply_gradients(zip(self.gradient, self.online_parameters))\n",
    "        \n",
    "        \n",
    "        self.sync_ops = self._sync_network_op()\n",
    "        \n",
    "    def _build_network(self):       \n",
    "        hidden_1 = tf.layers.dense(inputs = self.input_state, units = 64, activation=tf.nn.relu, use_bias=True, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        hidden_2 = tf.layers.dense(inputs = hidden_1, units = 64, activation=tf.nn.relu, use_bias=True, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        q_value = tf.layers.dense(inputs = hidden_2, units = ACTION_NUMBER, use_bias=True, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "        \n",
    "        return q_value\n",
    "    def _sync_network_op(self):\n",
    "        ops = []\n",
    "        for online, target in zip(self.online_parameters, self.target_parameters):\n",
    "            op = target.assign(online)\n",
    "            ops.append(op)\n",
    "        return ops\n",
    "\n",
    "    def sync_network(self):\n",
    "        for op in self.sync_ops:\n",
    "            sess.run(op)        \n",
    "        \n",
    "    def train(self):\n",
    "        batches = self.replay.sample_batch()\n",
    "        states, actions, rewards, next_states, dones = [],[],[],[],[]\n",
    "        \n",
    "        for batch in batches:\n",
    "            states.append(batch[0])\n",
    "            actions.append(batch[1])\n",
    "            rewards.append(batch[2])\n",
    "            next_states.append(batch[3])\n",
    "            dones.append(batch[4])\n",
    "        target_values = sess.run(self.online_q_values, feed_dict={self.input_state:states})\n",
    "        target_q_values = sess.run(self.target_q_values, feed_dict={self.input_state: next_states})\n",
    "        for i in range(BATCH_SIZE):\n",
    "            if dones[i]==False:\n",
    "                target_values[i,actions[i]] = rewards[i] + GAMMA * np.max(target_q_values[i])\n",
    "            elif dones[i]==True:\n",
    "                target_values[i,actions[i]] = rewards[i]\n",
    "            else:\n",
    "                print('wrong')\n",
    "        \n",
    "    \n",
    "        loss, _ = sess.run([self.loss, self.apply_grad], feed_dict={self.target_values:target_values, self.input_state:states})\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    def epsilon_decayer(self):\n",
    "        if len(self.replay.history)==REPLAY_BUFFER_SIZE and self.epsilon>self.final_epsilon:\n",
    "            self.epsilon -= self.epsilon_decay\n",
    "            \n",
    "    \n",
    "    def action_sample(self, state, evaluate=False):\n",
    "        if evaluate==False: epsilon=self.epsilon\n",
    "        else: epsilon=self.epsilon_eval\n",
    "        if random.random()>epsilon:\n",
    "            q_values = sess.run(self.online_q_values, feed_dict={self.input_state:state})\n",
    "            action = np.argmax(q_values[0])\n",
    "        else:\n",
    "            action = random.randint(0, ACTION_NUMBER-1)\n",
    "            q_values=[[0]]\n",
    "            \n",
    "        \n",
    "        return action, q_values[0]\n",
    "    \n",
    "    def evaluate(self, env):\n",
    "        print('Evaluation Start')\n",
    "\n",
    "        scores = []\n",
    "        for episode in range(EVALUATION_LENGTH):\n",
    "            score=0\n",
    "            state = env.reset()\n",
    "            while True:\n",
    "                action, _ = self.action_sample([state], evaluate=True)\n",
    "                normed_action = [-2.0 + action*4.0/(ACTION_NUMBER - 1.0)]\n",
    "                next_state, reward, done, _ = env.step(normed_action)\n",
    "                score += reward\n",
    "                if done==True:\n",
    "                    scores.append(score)\n",
    "                    break\n",
    "                state = next_state\n",
    "        print('Evaluation End, mean score:', np.mean(scores))\n",
    "        \n",
    "        return np.mean(scores)\n",
    "        \n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd80cd2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd80cd2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd80cd2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd80cd2e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd818b940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd818b940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd818b940>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dd818b940>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec2288d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec2288d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec2288d0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec2288d0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "online build\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec228ba8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec262550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec262550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec262550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f9dec262550>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "target build\n",
      "DONE EPISODE: 10 reward: -980.4567740257922 step: 2000 epsilon: 1.0 loss: None action: [-1.6] q: [0]\n",
      "DONE EPISODE: 20 reward: -1349.4260538140056 step: 4000 epsilon: 1.0 loss: None action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 30 reward: -1204.795060799544 step: 6000 epsilon: 1.0 loss: 197.37936 action: [-2.0] q: [0]\n",
      "DONE EPISODE: 40 reward: -1292.6515316843934 step: 8000 epsilon: 1.0 loss: 29.590227 action: [2.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1563.3916730699075\n",
      "DONE EPISODE: 50 reward: -1290.0000697785722 step: 10000 epsilon: 1.0 loss: 16.470428 action: [1.6] q: [0]\n",
      "DONE EPISODE: 60 reward: -1447.0045107647863 step: 12000 epsilon: 1.0 loss: 7.1882463 action: [1.6] q: [0]\n",
      "DONE EPISODE: 70 reward: -1300.516124367386 step: 14000 epsilon: 1.0 loss: 10.873401 action: [-1.2] q: [0]\n",
      "DONE EPISODE: 80 reward: -1298.8131261839258 step: 16000 epsilon: 1.0 loss: 4.0924315 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 90 reward: -1151.5705268440374 step: 18000 epsilon: 1.0 loss: 14.8141 action: [0.7999999999999998] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1507.9183693710265\n",
      "DONE EPISODE: 100 reward: -1269.571565997106 step: 20000 epsilon: 1.0 loss: 6.0625176 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 110 reward: -1220.9840907599248 step: 22000 epsilon: 1.0 loss: 713.1194 action: [0.0] q: [0]\n",
      "DONE EPISODE: 120 reward: -1063.870353995041 step: 24000 epsilon: 1.0 loss: 9.825907 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 130 reward: -1216.1803666287124 step: 26000 epsilon: 1.0 loss: 45.607628 action: [1.6] q: [0]\n",
      "DONE EPISODE: 140 reward: -1361.90056164442 step: 28000 epsilon: 1.0 loss: 13.171862 action: [-0.3999999999999999] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1310.3923082363326\n",
      "DONE EPISODE: 150 reward: -1209.4108121327222 step: 30000 epsilon: 1.0 loss: 14.191086 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 160 reward: -1275.5882428671775 step: 32000 epsilon: 1.0 loss: 14.578087 action: [0.7999999999999998] q: [0]\n",
      "DONE EPISODE: 170 reward: -1192.563911755115 step: 34000 epsilon: 1.0 loss: 18.272789 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 180 reward: -1275.546984048246 step: 36000 epsilon: 1.0 loss: 52.054626 action: [2.0] q: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE EPISODE: 190 reward: -1251.3031816665457 step: 38000 epsilon: 1.0 loss: 26.845863 action: [2.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -977.2478290074174\n",
      "DONE EPISODE: 200 reward: -1259.1137611042855 step: 40000 epsilon: 1.0 loss: 19.886517 action: [1.6] q: [0]\n",
      "DONE EPISODE: 210 reward: -1169.3747201182027 step: 42000 epsilon: 1.0 loss: 19.574818 action: [-2.0] q: [0]\n",
      "DONE EPISODE: 220 reward: -1143.844578213892 step: 44000 epsilon: 1.0 loss: 50.447403 action: [1.6] q: [0]\n",
      "DONE EPISODE: 230 reward: -1362.5343539632047 step: 46000 epsilon: 1.0 loss: 71.90036 action: [0.0] q: [0]\n",
      "DONE EPISODE: 240 reward: -1231.661771093183 step: 48000 epsilon: 1.0 loss: 2855.6394 action: [0.3999999999999999] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1071.3618628619347\n",
      "DONE EPISODE: 250 reward: -1286.614364962869 step: 50000 epsilon: 0.9999974285714286 loss: 95.89625 action: [0.0] q: [0]\n",
      "DONE EPISODE: 260 reward: -1182.2869566953375 step: 52000 epsilon: 0.9948545714286139 loss: 63.786102 action: [-2.0] q: [0]\n",
      "DONE EPISODE: 270 reward: -1255.5670836712497 step: 54000 epsilon: 0.9897117142857992 loss: 33.49137 action: [0.7999999999999998] q: [0]\n",
      "DONE EPISODE: 280 reward: -1181.1348857654261 step: 56000 epsilon: 0.9845688571429845 loss: 74.94587 action: [-0.8] q: [0]\n",
      "DONE EPISODE: 290 reward: -1346.788649308147 step: 58000 epsilon: 0.9794260000001698 loss: 170.37521 action: [1.2000000000000002] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1167.7593498744056\n",
      "DONE EPISODE: 300 reward: -1171.3030936761763 step: 60000 epsilon: 0.9742831428573551 loss: 70.97482 action: [0.0] q: [0]\n",
      "DONE EPISODE: 310 reward: -1059.7084667039426 step: 62000 epsilon: 0.9691402857145404 loss: 127.26032 action: [0.0] q: [0]\n",
      "DONE EPISODE: 320 reward: -1191.841996020836 step: 64000 epsilon: 0.9639974285717257 loss: 61.70643 action: [-2.0] q: [0]\n",
      "DONE EPISODE: 330 reward: -1370.468670549802 step: 66000 epsilon: 0.958854571428911 loss: 106.93143 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 340 reward: -1145.967338177897 step: 68000 epsilon: 0.9537117142860962 loss: 59.7219 action: [-1.2] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1368.7510550255463\n",
      "DONE EPISODE: 350 reward: -1188.0018612857236 step: 70000 epsilon: 0.9485688571432815 loss: 126.51738 action: [-1.2] q: [0]\n",
      "DONE EPISODE: 360 reward: -1175.4346635964662 step: 72000 epsilon: 0.9434260000004668 loss: 51.5982 action: [2.0] q: [0]\n",
      "DONE EPISODE: 370 reward: -1216.2072982771688 step: 74000 epsilon: 0.9382831428576521 loss: 192.46692 action: [2.0] q: [0]\n",
      "DONE EPISODE: 380 reward: -1229.5784884397635 step: 76000 epsilon: 0.9331402857148374 loss: 4599.895 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 390 reward: -1138.5860782387558 step: 78000 epsilon: 0.9279974285720227 loss: 100.340775 action: [0.7999999999999998] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1227.6499841705395\n",
      "DONE EPISODE: 400 reward: -1169.1600997771623 step: 80000 epsilon: 0.922854571429208 loss: 66.588455 action: [-1.2] q: [0]\n",
      "DONE EPISODE: 410 reward: -1111.7300144131311 step: 82000 epsilon: 0.9177117142863933 loss: 128.38551 action: [-1.6] q: [0]\n",
      "DONE EPISODE: 420 reward: -1120.616242537998 step: 84000 epsilon: 0.9125688571435786 loss: 16271.416 action: [0.0] q: [0]\n",
      "DONE EPISODE: 430 reward: -1240.3003782501805 step: 86000 epsilon: 0.9074260000007639 loss: 153.91177 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 440 reward: -1025.0254717843275 step: 88000 epsilon: 0.9022831428579492 loss: 78.10735 action: [-2.0] q: [-79.32144 -81.39446 -79.99469 -80.99075 -79.89752 -80.1026  -80.38132\n",
      " -80.15263 -80.48212 -79.79537 -79.46216]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -1372.3878734568702\n",
      "DONE EPISODE: 450 reward: -1045.5198207489 step: 90000 epsilon: 0.8971402857151345 loss: 132.99896 action: [-2.0] q: [-36.41307  -37.134743 -38.669315 -37.31052  -38.38803  -36.799316\n",
      " -37.682053 -36.69415  -39.27672  -39.302605 -38.20759 ]\n",
      "DONE EPISODE: 460 reward: -1047.697988763537 step: 92000 epsilon: 0.8919974285723198 loss: 128.27368 action: [-0.8] q: [0]\n",
      "DONE EPISODE: 470 reward: -970.3769274637323 step: 94000 epsilon: 0.8868545714295051 loss: 146.78491 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 480 reward: -1174.0433102748389 step: 96000 epsilon: 0.8817117142866904 loss: 121.98399 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 490 reward: -1055.950671307323 step: 98000 epsilon: 0.8765688571438757 loss: 182.83472 action: [-2.0] q: [-93.94111  -94.57049  -95.11902  -94.95714  -96.308334 -94.49286\n",
      " -95.54441  -95.2535   -97.18546  -96.34963  -96.43638 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -802.9010098279998\n",
      "DONE EPISODE: 500 reward: -1132.025213449666 step: 100000 epsilon: 0.871426000001061 loss: 133.90616 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 510 reward: -1135.174933856339 step: 102000 epsilon: 0.8662831428582463 loss: 247.4011 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 520 reward: -1136.3460162049807 step: 104000 epsilon: 0.8611402857154316 loss: 6872.053 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 530 reward: -1096.874785941102 step: 106000 epsilon: 0.8559974285726168 loss: 209.6172 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 540 reward: -1064.1326289323438 step: 108000 epsilon: 0.8508545714298021 loss: 8115.188 action: [1.6] q: [-76.34523  -77.13902  -76.419044 -76.88697  -76.541595 -75.86303\n",
      " -75.48249  -74.32348  -73.64392  -73.04855  -73.37955 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -472.244913861348\n",
      "DONE EPISODE: 550 reward: -1007.6385704925575 step: 110000 epsilon: 0.8457117142869874 loss: 198.35837 action: [-2.0] q: [-97.47859  -98.012726 -98.14534  -98.211494 -98.5477   -97.85488\n",
      " -98.57626  -98.260994 -99.27749  -99.006905 -98.64211 ]\n",
      "DONE EPISODE: 560 reward: -1059.9937855798457 step: 112000 epsilon: 0.8405688571441727 loss: 96.68904 action: [-0.8] q: [0]\n",
      "DONE EPISODE: 570 reward: -1057.1962424385586 step: 114000 epsilon: 0.835426000001358 loss: 222.07541 action: [2.0] q: [-129.49461  -128.69211  -127.934875 -126.849556 -126.89201  -125.34453\n",
      " -125.01821  -125.36603  -124.753654 -123.821754 -123.17954 ]\n",
      "DONE EPISODE: 580 reward: -1066.294418184646 step: 116000 epsilon: 0.8302831428585433 loss: 140.5423 action: [2.0] q: [0]\n",
      "DONE EPISODE: 590 reward: -1090.1756412842005 step: 118000 epsilon: 0.8251402857157286 loss: 208.91818 action: [0.7999999999999998] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -782.5761763200004\n",
      "DONE EPISODE: 600 reward: -1022.6823488024977 step: 120000 epsilon: 0.8199974285729139 loss: 224.94463 action: [2.0] q: [-70.83295  -70.78559  -70.86718  -70.877815 -68.19045  -68.816895\n",
      " -68.52617  -68.91793  -67.99308  -67.482796 -66.11493 ]\n",
      "DONE EPISODE: 610 reward: -920.2879899103385 step: 122000 epsilon: 0.8148545714300992 loss: 285.34375 action: [-1.6] q: [0]\n",
      "DONE EPISODE: 620 reward: -967.0600631192053 step: 124000 epsilon: 0.8097117142872845 loss: 266.64178 action: [0.0] q: [0]\n",
      "DONE EPISODE: 630 reward: -1020.6138863116973 step: 126000 epsilon: 0.8045688571444698 loss: 321.05286 action: [2.0] q: [0]\n",
      "DONE EPISODE: 640 reward: -966.8386718734153 step: 128000 epsilon: 0.7994260000016551 loss: 10189.4 action: [-0.3999999999999999] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -806.1970205863142\n",
      "DONE EPISODE: 650 reward: -1054.031526806752 step: 130000 epsilon: 0.7942831428588404 loss: 216.38121 action: [-0.8] q: [0]\n",
      "DONE EPISODE: 660 reward: -925.4858795890656 step: 132000 epsilon: 0.7891402857160257 loss: 209.80649 action: [1.6] q: [-110.01504  -111.61563  -110.04441  -110.94417  -110.93291  -110.53286\n",
      " -110.43564  -110.12405  -109.66     -108.947945 -109.35559 ]\n",
      "DONE EPISODE: 670 reward: -1024.162755232698 step: 134000 epsilon: 0.783997428573211 loss: 187.64474 action: [1.6] q: [0]\n",
      "DONE EPISODE: 680 reward: -1003.4499127952546 step: 136000 epsilon: 0.7788545714303963 loss: 170.51546 action: [2.0] q: [-100.96089  -100.68325  -101.44368  -100.83843  -100.51049   -99.920204\n",
      " -100.03362   -99.520966  -99.64252   -98.95264   -98.485535]\n",
      "DONE EPISODE: 690 reward: -1019.2929508259916 step: 138000 epsilon: 0.7737117142875816 loss: 8250.37 action: [2.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -847.4259026855258\n",
      "DONE EPISODE: 700 reward: -962.9376496051487 step: 140000 epsilon: 0.7685688571447669 loss: 69.853134 action: [-0.3999999999999999] q: [-54.6744   -55.08961  -54.708195 -54.84445  -54.241066 -55.174587\n",
      " -55.41664  -55.516514 -54.977734 -55.48444  -56.18701 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE EPISODE: 710 reward: -937.8646490984536 step: 142000 epsilon: 0.7634260000019522 loss: 12040.806 action: [1.6] q: [0]\n",
      "DONE EPISODE: 720 reward: -977.4885400159741 step: 144000 epsilon: 0.7582831428591374 loss: 307.92337 action: [0.0] q: [0]\n",
      "DONE EPISODE: 730 reward: -932.7677855701019 step: 146000 epsilon: 0.7531402857163227 loss: 180.92361 action: [-2.0] q: [-120.046196 -121.47334  -120.20054  -120.77123  -121.589096 -121.72254\n",
      " -121.371864 -121.504234 -120.820854 -120.956375 -121.47655 ]\n",
      "DONE EPISODE: 740 reward: -955.8435681039928 step: 148000 epsilon: 0.747997428573508 loss: 143.42397 action: [1.6] q: [-92.568054 -92.770485 -92.065956 -91.864044 -91.26128  -90.65246\n",
      " -90.12267  -89.575806 -87.74696  -87.16662  -87.377846]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -190.16947766867935\n",
      "DONE EPISODE: 750 reward: -919.9229481903207 step: 150000 epsilon: 0.7428545714306933 loss: 175.60439 action: [-1.6] q: [0]\n",
      "DONE EPISODE: 760 reward: -1013.5065687393104 step: 152000 epsilon: 0.7377117142878786 loss: 177.80893 action: [-2.0] q: [-73.96811  -74.25503  -74.185165 -74.57924  -74.603455 -74.81618\n",
      " -74.31645  -74.388054 -74.55465  -75.13726  -75.60148 ]\n",
      "DONE EPISODE: 770 reward: -985.8701189870787 step: 154000 epsilon: 0.7325688571450639 loss: 278.78125 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 780 reward: -926.2092261072596 step: 156000 epsilon: 0.7274260000022492 loss: 5730.695 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 790 reward: -988.289975803061 step: 158000 epsilon: 0.7222831428594345 loss: 236.50092 action: [-1.2] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -579.9448397376655\n",
      "DONE EPISODE: 800 reward: -948.6669897117338 step: 160000 epsilon: 0.7171402857166198 loss: 155.01634 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 810 reward: -928.6170748951608 step: 162000 epsilon: 0.7119974285738051 loss: 14316.428 action: [0.0] q: [0]\n",
      "DONE EPISODE: 820 reward: -940.047071925817 step: 164000 epsilon: 0.7068545714309904 loss: 169.76813 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 830 reward: -921.998077295405 step: 166000 epsilon: 0.7017117142881757 loss: 311.72824 action: [1.6] q: [0]\n",
      "DONE EPISODE: 840 reward: -898.6516844572313 step: 168000 epsilon: 0.696568857145361 loss: 160.26245 action: [1.6] q: [-118.96061  -118.4233   -117.03338  -117.10146  -117.12021  -115.70521\n",
      " -114.976524 -115.822624 -115.70323  -114.28308  -115.53024 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -224.55971911417487\n",
      "DONE EPISODE: 850 reward: -775.7598039329365 step: 170000 epsilon: 0.6914260000025463 loss: 240.11273 action: [1.6] q: [0]\n",
      "DONE EPISODE: 860 reward: -848.4482367314511 step: 172000 epsilon: 0.6862831428597316 loss: 114.89986 action: [2.0] q: [0]\n",
      "DONE EPISODE: 870 reward: -798.666150175917 step: 174000 epsilon: 0.6811402857169169 loss: 180.24992 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 880 reward: -808.7199232607734 step: 176000 epsilon: 0.6759974285741022 loss: 182.9314 action: [-2.0] q: [0]\n",
      "DONE EPISODE: 890 reward: -770.8508631873177 step: 178000 epsilon: 0.6708545714312875 loss: 152.14822 action: [0.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -176.99527651062368\n",
      "DONE EPISODE: 900 reward: -815.8565175084747 step: 180000 epsilon: 0.6657117142884728 loss: 137.88376 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 910 reward: -813.5524430841526 step: 182000 epsilon: 0.660568857145658 loss: 162.36246 action: [-1.6] q: [0]\n",
      "DONE EPISODE: 920 reward: -732.8978904222446 step: 184000 epsilon: 0.6554260000028433 loss: 135.64722 action: [-1.2] q: [0]\n",
      "DONE EPISODE: 930 reward: -756.9879931199886 step: 186000 epsilon: 0.6502831428600286 loss: 248.06668 action: [2.0] q: [0]\n",
      "DONE EPISODE: 940 reward: -742.2814733808423 step: 188000 epsilon: 0.6451402857172139 loss: 120.20191 action: [2.0] q: [-109.55087  -109.69983  -108.88847  -107.816    -107.57889  -106.263596\n",
      " -105.52413  -104.265656 -102.467255 -102.482254 -102.234146]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -126.03176837968203\n",
      "DONE EPISODE: 950 reward: -805.1463245370361 step: 190000 epsilon: 0.6399974285743992 loss: 8946.605 action: [-1.6] q: [0]\n",
      "DONE EPISODE: 960 reward: -715.5363363365113 step: 192000 epsilon: 0.6348545714315845 loss: 128.05478 action: [-0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 970 reward: -734.5313111911748 step: 194000 epsilon: 0.6297117142887698 loss: 18367.186 action: [-1.2] q: [0]\n",
      "DONE EPISODE: 980 reward: -690.9630463151973 step: 196000 epsilon: 0.6245688571459551 loss: 124.56991 action: [0.7999999999999998] q: [-77.79289  -79.04577  -78.38958  -77.84495  -77.333275 -76.871216\n",
      " -75.87655  -75.32514  -76.211845 -76.07342  -75.61828 ]\n",
      "DONE EPISODE: 990 reward: -704.791815496371 step: 198000 epsilon: 0.6194260000031404 loss: 224.48326 action: [-2.0] q: [-42.652138 -45.190716 -44.33574  -44.798187 -44.2965   -44.7679\n",
      " -44.733727 -44.482998 -44.171017 -45.676964 -46.345997]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -125.20367710468142\n",
      "DONE EPISODE: 1000 reward: -718.5633873197303 step: 200000 epsilon: 0.6142831428603257 loss: 190.33754 action: [-0.8] q: [0]\n",
      "DONE EPISODE: 1010 reward: -762.2459230971992 step: 202000 epsilon: 0.609140285717511 loss: 208.38358 action: [2.0] q: [-80.353165 -80.53238  -78.76081  -78.494514 -77.290565 -76.34986\n",
      " -75.10163  -73.640816 -71.44533  -72.422134 -71.31961 ]\n",
      "DONE EPISODE: 1020 reward: -680.9861951040461 step: 204000 epsilon: 0.6039974285746963 loss: 146.8162 action: [-2.0] q: [-109.674446 -110.54926  -111.16338  -111.69435  -112.5644   -113.88066\n",
      " -113.20363  -115.07868  -116.52594  -116.81365  -118.45431 ]\n",
      "DONE EPISODE: 1030 reward: -713.8902450610937 step: 206000 epsilon: 0.5988545714318816 loss: 312.8914 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 1040 reward: -792.1476803454923 step: 208000 epsilon: 0.5937117142890669 loss: 7088.183 action: [0.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -123.6378411394331\n",
      "DONE EPISODE: 1050 reward: -703.2642128725174 step: 210000 epsilon: 0.5885688571462522 loss: 145.87979 action: [0.7999999999999998] q: [0]\n",
      "DONE EPISODE: 1060 reward: -653.2593717722132 step: 212000 epsilon: 0.5834260000034375 loss: 1789.2113 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 1070 reward: -619.8201877495268 step: 214000 epsilon: 0.5782831428606228 loss: 160.30267 action: [2.0] q: [0]\n",
      "DONE EPISODE: 1080 reward: -721.7298547580551 step: 216000 epsilon: 0.5731402857178081 loss: 190.0125 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 1090 reward: -663.2338322790213 step: 218000 epsilon: 0.5679974285749934 loss: 341.39368 action: [-0.3999999999999999] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -100.06582460695215\n",
      "DONE EPISODE: 1100 reward: -663.965591305561 step: 220000 epsilon: 0.5628545714321787 loss: 235.6709 action: [1.2000000000000002] q: [-42.317944 -44.89113  -43.694828 -43.866093 -42.973377 -42.152054\n",
      " -42.9482   -42.879547 -41.335236 -43.575268 -43.890503]\n",
      "DONE EPISODE: 1110 reward: -636.3121069195048 step: 222000 epsilon: 0.557711714289364 loss: 240.27756 action: [-0.8] q: [0]\n",
      "DONE EPISODE: 1120 reward: -611.1510827285804 step: 224000 epsilon: 0.5525688571465492 loss: 266.22144 action: [2.0] q: [0]\n",
      "DONE EPISODE: 1130 reward: -656.2643865072939 step: 226000 epsilon: 0.5474260000037345 loss: 298.87042 action: [-2.0] q: [-79.04253  -81.33011  -80.22361  -80.42978  -80.75294  -81.286934\n",
      " -80.66143  -80.50662  -79.40046  -80.326065 -80.01077 ]\n",
      "DONE EPISODE: 1140 reward: -565.5468793418337 step: 228000 epsilon: 0.5422831428609198 loss: 202.1589 action: [-0.3999999999999999] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -191.27780737289413\n",
      "DONE EPISODE: 1150 reward: -587.5523079659466 step: 230000 epsilon: 0.5371402857181051 loss: 376.74255 action: [0.7999999999999998] q: [0]\n",
      "DONE EPISODE: 1160 reward: -522.0438621094784 step: 232000 epsilon: 0.5319974285752904 loss: 132.61133 action: [1.2000000000000002] q: [-34.453278 -37.028316 -35.187046 -35.116364 -34.327576 -33.540863\n",
      " -33.80945  -33.822956 -32.28607  -33.80655  -33.84434 ]\n",
      "DONE EPISODE: 1170 reward: -576.9422711883175 step: 234000 epsilon: 0.5268545714324757 loss: 233.75157 action: [0.7999999999999998] q: [0]\n",
      "DONE EPISODE: 1180 reward: -507.45431804409856 step: 236000 epsilon: 0.521711714289661 loss: 125.55754 action: [0.0] q: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE EPISODE: 1190 reward: -568.9833183113581 step: 238000 epsilon: 0.5165688571468463 loss: 372.62018 action: [0.3999999999999999] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -118.74973419970402\n",
      "DONE EPISODE: 1200 reward: -550.8227493223434 step: 240000 epsilon: 0.5114260000040316 loss: 299.43887 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 1210 reward: -570.4999534397373 step: 242000 epsilon: 0.5062831428612169 loss: 4551.272 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 1220 reward: -546.8844545523341 step: 244000 epsilon: 0.5011402857184022 loss: 1165.7301 action: [1.2000000000000002] q: [-33.031937 -35.352802 -32.710026 -32.271595 -31.114494 -30.158731\n",
      " -30.17122  -29.862164 -28.305185 -29.365986 -28.914572]\n",
      "DONE EPISODE: 1230 reward: -425.5153366760716 step: 246000 epsilon: 0.4959974285755875 loss: 376.5675 action: [1.2000000000000002] q: [-29.062695 -32.07826  -29.367977 -29.234394 -28.487743 -27.936954\n",
      " -28.354748 -28.056036 -27.366436 -27.78903  -27.806826]\n",
      "DONE EPISODE: 1240 reward: -470.56872400829644 step: 248000 epsilon: 0.4908545714327728 loss: 173.30746 action: [-2.0] q: [-37.284416 -40.38768  -39.02619  -39.581795 -39.815617 -41.99841\n",
      " -43.407413 -43.373714 -45.83298  -45.50623  -46.214294]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -147.07870467845999\n",
      "DONE EPISODE: 1250 reward: -434.3105455449243 step: 250000 epsilon: 0.4857117142899581 loss: 407.45804 action: [2.0] q: [-32.242867 -33.810497 -31.557663 -30.951654 -29.621513 -28.956303\n",
      " -27.877377 -28.078308 -27.111935 -27.300709 -26.638222]\n",
      "DONE EPISODE: 1260 reward: -425.40571272746183 step: 252000 epsilon: 0.48056885714714337 loss: 210.49316 action: [-2.0] q: [-42.928577 -45.537464 -46.04703  -46.408848 -48.121273 -49.896484\n",
      " -51.99768  -53.746708 -55.66686  -57.159603 -58.29563 ]\n",
      "DONE EPISODE: 1270 reward: -407.0468151343678 step: 254000 epsilon: 0.47542600000432866 loss: 466.70746 action: [-2.0] q: [0]\n",
      "DONE EPISODE: 1280 reward: -439.4345597368641 step: 256000 epsilon: 0.47028314286151396 loss: 235.36658 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 1290 reward: -572.2857395339737 step: 258000 epsilon: 0.46514028571869925 loss: 216.9437 action: [-2.0] q: [-22.75722  -25.387884 -23.454334 -24.095915 -24.211025 -24.866861\n",
      " -25.987854 -26.165232 -27.002731 -27.148027 -28.231558]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -145.43944747584072\n",
      "DONE EPISODE: 1300 reward: -524.4589727977464 step: 260000 epsilon: 0.45999742857588455 loss: 190.675 action: [-2.0] q: [-76.39371  -77.14054  -79.01014  -79.24449  -81.06145  -82.15367\n",
      " -85.387115 -88.28444  -90.18157  -92.12041  -93.52732 ]\n",
      "DONE EPISODE: 1310 reward: -440.2124948284557 step: 262000 epsilon: 0.45485457143306984 loss: 264.99365 action: [-0.3999999999999999] q: [-22.506588 -23.812998 -22.271511 -22.39745  -22.089392 -22.26923\n",
      " -22.593967 -22.811401 -23.13228  -23.337862 -23.964836]\n",
      "DONE EPISODE: 1320 reward: -385.18448352062336 step: 264000 epsilon: 0.44971171429025514 loss: 244.857 action: [0.0] q: [-134.50363 -133.8541  -133.77841 -133.87378 -134.06677 -132.68568\n",
      " -135.36832 -136.0497  -136.4773  -136.20432 -137.23143]\n",
      "DONE EPISODE: 1330 reward: -369.3466790518641 step: 266000 epsilon: 0.44456885714744043 loss: 370.5371 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 1340 reward: -484.65329952511166 step: 268000 epsilon: 0.4394260000046257 loss: 275.97388 action: [2.0] q: [-25.233446 -25.077356 -23.404137 -22.937466 -21.402666 -21.08795\n",
      " -20.300608 -20.261736 -19.529896 -19.546682 -19.324451]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -168.62629092098885\n",
      "DONE EPISODE: 1350 reward: -418.56695344869115 step: 270000 epsilon: 0.434283142861811 loss: 272.9648 action: [-2.0] q: [-23.40026  -25.89898  -25.653364 -27.347462 -29.12863  -31.193413\n",
      " -33.38429  -34.869297 -37.610306 -38.55932  -41.504868]\n",
      "DONE EPISODE: 1360 reward: -391.5206584235896 step: 272000 epsilon: 0.4291402857189963 loss: 237.70972 action: [0.7999999999999998] q: [-21.002943 -20.931267 -19.83343  -19.344543 -19.0151   -19.263319\n",
      " -19.078197 -18.701551 -19.088287 -19.129112 -19.865067]\n",
      "DONE EPISODE: 1370 reward: -417.3656355612478 step: 274000 epsilon: 0.4239974285761816 loss: 674.6302 action: [-1.6] q: [0]\n",
      "DONE EPISODE: 1380 reward: -416.95557505967247 step: 276000 epsilon: 0.4188545714333669 loss: 620.1491 action: [0.0] q: [-26.16048  -25.485329 -24.808077 -24.629087 -24.878948 -24.352037\n",
      " -24.814436 -24.747654 -25.050364 -25.964417 -26.705929]\n",
      "DONE EPISODE: 1390 reward: -449.49541490485655 step: 278000 epsilon: 0.4137117142905522 loss: 284.48907 action: [2.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -123.59433004148545\n",
      "DONE EPISODE: 1400 reward: -505.5160329464112 step: 280000 epsilon: 0.4085688571477375 loss: 144.85617 action: [2.0] q: [-64.281075 -59.107597 -56.625103 -52.624622 -49.1308   -45.476906\n",
      " -41.877705 -39.672363 -34.355953 -34.773197 -29.390934]\n",
      "DONE EPISODE: 1410 reward: -477.36833739494267 step: 282000 epsilon: 0.4034260000049228 loss: 17162.375 action: [-1.2] q: [-16.903801 -16.33797  -15.974977 -16.17851  -16.56674  -16.501749\n",
      " -16.911737 -17.06541  -17.58565  -17.690416 -19.380993]\n",
      "DONE EPISODE: 1420 reward: -375.6224932521747 step: 284000 epsilon: 0.3982831428621081 loss: 345.13898 action: [2.0] q: [-23.814154 -21.39108  -20.412657 -19.303719 -18.201506 -17.234978\n",
      " -16.317818 -15.740475 -14.731539 -14.549966 -14.130613]\n",
      "DONE EPISODE: 1430 reward: -552.9359881784039 step: 286000 epsilon: 0.3931402857192934 loss: 464.5052 action: [-0.3999999999999999] q: [-16.378653 -15.477134 -14.758354 -14.667984 -14.447999 -14.528513\n",
      " -14.49655  -14.482726 -14.867329 -14.902887 -15.975724]\n",
      "DONE EPISODE: 1440 reward: -369.1994623559291 step: 288000 epsilon: 0.3879974285764787 loss: 417.62753 action: [-1.2] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -94.80770363870226\n",
      "DONE EPISODE: 1450 reward: -503.6511561318971 step: 290000 epsilon: 0.38285457143366397 loss: 377.75208 action: [0.7999999999999998] q: [0]\n",
      "DONE EPISODE: 1460 reward: -354.1627056104714 step: 292000 epsilon: 0.37771171429084927 loss: 379.4426 action: [2.0] q: [-41.785038 -37.13133  -34.539776 -31.792246 -28.200651 -25.592867\n",
      " -22.429302 -20.268576 -16.453102 -16.35928  -11.839213]\n",
      "DONE EPISODE: 1470 reward: -397.8882532540362 step: 294000 epsilon: 0.37256885714803456 loss: 303.5442 action: [-0.8] q: [-14.3021    -12.852593  -12.658122  -12.611424  -12.6932335 -12.791091\n",
      " -13.069704  -13.304397  -13.597205  -13.793109  -14.977885 ]\n",
      "DONE EPISODE: 1480 reward: -451.19447061716255 step: 296000 epsilon: 0.36742600000521985 loss: 653.5212 action: [-0.8] q: [0]\n",
      "DONE EPISODE: 1490 reward: -453.9253367108434 step: 298000 epsilon: 0.36228314286240515 loss: 261.42227 action: [0.0] q: [-12.944514 -11.870434 -11.690441 -11.630384 -11.541147 -11.516079\n",
      " -11.863859 -11.656847 -12.24079  -12.195236 -13.633247]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -142.64941833894335\n",
      "DONE EPISODE: 1500 reward: -321.61454716547485 step: 300000 epsilon: 0.35714028571959044 loss: 302.2848 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 1510 reward: -349.0858040613497 step: 302000 epsilon: 0.35199742857677574 loss: 111.30235 action: [2.0] q: [-78.56338  -73.998215 -69.59323  -66.302414 -62.550247 -57.97346\n",
      " -54.821686 -50.669308 -45.840767 -45.56065  -39.383286]\n",
      "DONE EPISODE: 1520 reward: -398.1050902046949 step: 304000 epsilon: 0.34685457143396103 loss: 265.74673 action: [2.0] q: [-34.38437  -31.217129 -28.7964   -26.802128 -23.963493 -22.004694\n",
      " -19.954748 -18.724766 -15.871528 -16.205132 -12.579014]\n",
      "DONE EPISODE: 1530 reward: -278.9325956978291 step: 306000 epsilon: 0.34171171429114633 loss: 308.52023 action: [1.2000000000000002] q: [-11.849333  -10.4676    -10.212477  -10.0091     -9.59251    -9.458698\n",
      "  -9.35379    -9.267583   -9.231869   -9.7153635 -10.113799 ]\n",
      "DONE EPISODE: 1540 reward: -321.9620287349703 step: 308000 epsilon: 0.3365688571483316 loss: 341.8344 action: [-0.3999999999999999] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -194.7610026894031\n",
      "DONE EPISODE: 1550 reward: -391.3363250337449 step: 310000 epsilon: 0.3314260000055169 loss: 392.20297 action: [-0.8] q: [-10.132011  -9.473953  -9.374942  -9.048837  -9.059993  -9.187217\n",
      "  -9.35555   -9.548217  -9.600923 -10.022132 -11.378426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE EPISODE: 1560 reward: -367.77626545174155 step: 312000 epsilon: 0.3262831428627022 loss: 362.0715 action: [1.2000000000000002] q: [-12.325175  -11.13454   -10.487428   -9.434895   -9.016539   -8.757685\n",
      "  -8.396348   -7.9745564  -7.598117   -8.057368   -8.382342 ]\n",
      "DONE EPISODE: 1570 reward: -342.88846443153346 step: 314000 epsilon: 0.3211402857198875 loss: 256.903 action: [1.6] q: [0]\n",
      "DONE EPISODE: 1580 reward: -326.71343266701945 step: 316000 epsilon: 0.3159974285770728 loss: 448.08258 action: [2.0] q: [-47.67572  -43.44996  -38.683502 -35.60421  -31.363268 -27.613317\n",
      " -24.070944 -21.41684  -16.92184  -16.194666  -8.847649]\n",
      "DONE EPISODE: 1590 reward: -410.6150557519669 step: 318000 epsilon: 0.3108545714342581 loss: 580.4149 action: [-2.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -144.25225444409492\n",
      "DONE EPISODE: 1600 reward: -307.71300224447094 step: 320000 epsilon: 0.3057117142914434 loss: 480.02667 action: [0.3999999999999999] q: [-9.405392  -8.792209  -7.919698  -7.791963  -7.388605  -6.8602643\n",
      " -6.689596  -6.850413  -6.8804197 -6.822666  -7.7549024]\n",
      "DONE EPISODE: 1610 reward: -298.27916042605636 step: 322000 epsilon: 0.3005688571486287 loss: 313.18573 action: [-2.0] q: [ -6.483364  -8.061728  -9.845281 -11.581158 -13.650926 -15.631166\n",
      " -17.676666 -19.374548 -21.033342 -23.287352 -28.429913]\n",
      "DONE EPISODE: 1620 reward: -344.62921944202765 step: 324000 epsilon: 0.295426000005814 loss: 458.94073 action: [0.7999999999999998] q: [-8.013958  -7.3673162 -6.834957  -6.0693507 -5.8530006 -5.7344146\n",
      " -5.675968  -5.5183563 -5.7074404 -5.741776  -6.6280355]\n",
      "DONE EPISODE: 1630 reward: -307.26638885924257 step: 326000 epsilon: 0.2902831428629993 loss: 274.15964 action: [0.3999999999999999] q: [-6.8898335 -6.410925  -6.247828  -5.8540096 -5.5780754 -5.539972\n",
      " -5.43208   -5.854362  -5.8141165 -6.165982  -7.7083793]\n",
      "DONE EPISODE: 1640 reward: -345.4030302021441 step: 328000 epsilon: 0.28514028572018457 loss: 244.6913 action: [1.2000000000000002] q: [-8.998854  -8.423848  -7.5503693 -7.241435  -6.687648  -5.9792476\n",
      " -5.922526  -6.010595  -5.761817  -6.05462   -6.6252227]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -215.0455487901137\n",
      "DONE EPISODE: 1650 reward: -253.74365199524578 step: 330000 epsilon: 0.27999742857736987 loss: 424.00714 action: [1.6] q: [-8.955602  -8.230413  -7.024723  -6.163402  -5.345422  -4.8949184\n",
      " -4.3871427 -3.816847  -3.5867    -3.3267605 -3.535322 ]\n",
      "DONE EPISODE: 1660 reward: -303.57288209164653 step: 332000 epsilon: 0.27485457143455516 loss: 495.05252 action: [-0.3999999999999999] q: [-5.128404  -4.76042   -4.8178463 -4.8130164 -4.7563996 -4.985519\n",
      " -5.3181524 -5.4615974 -5.753333  -6.0369377 -7.7994723]\n",
      "DONE EPISODE: 1670 reward: -316.5349538321287 step: 334000 epsilon: 0.26971171429174046 loss: 223.62178 action: [-0.3999999999999999] q: [-4.743113  -4.9107084 -4.2994547 -4.1476874 -3.9685392 -4.3803883\n",
      " -4.2105517 -4.249309  -4.7351966 -4.88772   -6.3232465]\n",
      "DONE EPISODE: 1680 reward: -263.0193802377621 step: 336000 epsilon: 0.26456885714892575 loss: 328.07025 action: [-0.3999999999999999] q: [-4.718678  -4.9464855 -4.249454  -4.31677   -4.05276   -4.1002264\n",
      " -4.223929  -4.2888803 -4.582778  -4.8098474 -5.9975853]\n",
      "DONE EPISODE: 1690 reward: -342.24449924870305 step: 338000 epsilon: 0.25942600000611105 loss: 315.7274 action: [2.0] q: [-62.32652  -56.556305 -50.898346 -46.34311  -41.6114   -36.059555\n",
      " -32.25497  -27.36441  -22.246979 -20.603699  -9.455995]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -170.2464035161299\n",
      "DONE EPISODE: 1700 reward: -289.4862614510666 step: 340000 epsilon: 0.25428314286329634 loss: 12010.414 action: [0.3999999999999999] q: [-4.942209  -4.356094  -4.0463753 -3.8215384 -3.5222874 -3.4032328\n",
      " -3.2883775 -3.2892728 -3.345552  -3.6470304 -4.4491415]\n",
      "DONE EPISODE: 1710 reward: -301.91855873181646 step: 342000 epsilon: 0.24914028572047234 loss: 178.14037 action: [-0.8] q: [-88.74309  -88.97103  -90.02155  -88.68839  -90.055855 -91.771614\n",
      " -89.22037  -90.545425 -89.44173  -92.130455 -91.93224 ]\n",
      "DONE EPISODE: 1720 reward: -286.35013548812736 step: 344000 epsilon: 0.24399742857760212 loss: 209.1069 action: [1.2000000000000002] q: [-4.585682  -3.86031   -3.116388  -2.7977896 -2.644317  -2.6535757\n",
      " -2.558461  -2.4622154 -2.4071007 -2.5901823 -3.5561247]\n",
      "DONE EPISODE: 1730 reward: -211.23515404856803 step: 346000 epsilon: 0.2388545714347319 loss: 404.61737 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 1740 reward: -236.89058793556575 step: 348000 epsilon: 0.2337117142918617 loss: 177.35825 action: [1.6] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -190.68739879154543\n",
      "DONE EPISODE: 1750 reward: -219.96729119652247 step: 350000 epsilon: 0.22856885714899147 loss: 92.26434 action: [0.7999999999999998] q: [-3.571123  -2.8557935 -2.1790183 -1.882856  -1.5460742 -1.4080741\n",
      " -1.2252479 -1.2086564 -1.3449125 -1.4022439 -2.4456947]\n",
      "DONE EPISODE: 1760 reward: -350.97357494277406 step: 352000 epsilon: 0.22342600000612126 loss: 252.28719 action: [0.0] q: [-109.553955 -108.99837  -109.31114  -109.427956 -110.747284 -107.39209\n",
      " -109.73667  -108.16339  -109.42277  -109.06663  -113.18729 ]\n",
      "DONE EPISODE: 1770 reward: -321.18249605365565 step: 354000 epsilon: 0.21828314286325104 loss: 161.89008 action: [2.0] q: [-20.692389  -18.003897  -15.399453  -13.368651  -11.370573   -9.19023\n",
      "  -7.3563156  -5.6552153  -3.8004751  -3.151521    0.6909167]\n",
      "DONE EPISODE: 1780 reward: -207.09657301354514 step: 356000 epsilon: 0.21314028572038082 loss: 157.76344 action: [1.6] q: [-3.8928514  -2.8493261  -2.069925   -1.9422529  -1.4545774  -1.1297095\n",
      " -0.7984569  -0.54061997 -0.66640687 -0.32670975 -1.4991041 ]\n",
      "DONE EPISODE: 1790 reward: -323.6830441870819 step: 358000 epsilon: 0.2079974285775106 loss: 65.77785 action: [0.7999999999999998] q: [-2.6341138  -1.5447583  -1.026628   -0.5800104  -0.5053154  -0.30108118\n",
      " -0.08799636 -0.03860867 -0.08312953 -0.09458353 -0.99321294]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -188.1128410988234\n",
      "DONE EPISODE: 1800 reward: -240.05291213363617 step: 360000 epsilon: 0.2028545714346404 loss: 110.72576 action: [-2.0] q: [0]\n",
      "DONE EPISODE: 1810 reward: -253.20160330308107 step: 362000 epsilon: 0.19771171429177017 loss: 150.34006 action: [0.3999999999999999] q: [-1.7938586  -0.74475116 -0.4078449   0.05416362  0.16334885  0.24007493\n",
      "  0.26160243  0.18473433  0.09947498 -0.10171108 -1.4313786 ]\n",
      "DONE EPISODE: 1820 reward: -242.0395584145111 step: 364000 epsilon: 0.19256885714889996 loss: 176.78459 action: [2.0] q: [-93.53893  -87.698494 -82.34438  -77.61803  -74.87733  -67.84123\n",
      " -65.003395 -57.920406 -53.047867 -51.14501  -41.10246 ]\n",
      "DONE EPISODE: 1830 reward: -263.55993836328213 step: 366000 epsilon: 0.18742600000602974 loss: 49.397003 action: [1.2000000000000002] q: [-2.6953664  -1.5120662  -0.82645905 -0.18375531  0.0658457   0.42019337\n",
      "  0.5384309   0.8596205   1.0819825   0.72144437  0.15178141]\n",
      "DONE EPISODE: 1840 reward: -337.97721900142153 step: 368000 epsilon: 0.18228314286315953 loss: 185.44333 action: [1.6] q: [-1.7267704  -0.6293516  -0.390091    0.32115304  0.42895648  0.8403742\n",
      "  1.0930507   0.9553323   1.0857975   1.1350561   0.1913996 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -127.31127464567138\n",
      "DONE EPISODE: 1850 reward: -352.2888513316196 step: 370000 epsilon: 0.1771402857202893 loss: 61.239677 action: [-1.2] q: [-1.4507817  -0.20168582  0.29381448  0.2729102  -0.20428795 -0.54821056\n",
      " -0.3101742  -0.5564759  -0.8077413  -0.9534048  -2.8552067 ]\n",
      "DONE EPISODE: 1860 reward: -296.1685551866907 step: 372000 epsilon: 0.1719974285774191 loss: 163.55789 action: [1.2000000000000002] q: [0]\n",
      "DONE EPISODE: 1870 reward: -231.3160385029299 step: 374000 epsilon: 0.16685457143454888 loss: 87.70951 action: [2.0] q: [-5.012925   -3.7378097  -2.6012278  -0.8913456  -0.96730125  0.29879546\n",
      "  0.93769085  1.5302378   1.9073523   2.150261    2.4713778 ]\n",
      "DONE EPISODE: 1880 reward: -238.29174738805258 step: 376000 epsilon: 0.16171171429167866 loss: 136.03467 action: [0.7999999999999998] q: [-0.66551316  0.28976893  1.1382079   1.5131695   1.5971047   1.8867202\n",
      "  1.970135    2.046924    1.9505593   1.8248128   0.8240544 ]\n",
      "DONE EPISODE: 1890 reward: -323.1212734267831 step: 378000 epsilon: 0.15656885714880844 loss: 28.686563 action: [-1.2] q: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Start\n",
      "Evaluation End, mean score: -80.15619489877545\n",
      "DONE EPISODE: 1900 reward: -244.2647675687224 step: 380000 epsilon: 0.15142600000593823 loss: 110.5238 action: [0.0] q: [-3.3789215  -3.0180612  -2.078789   -1.9780495  -1.1943942  -0.6535103\n",
      " -0.7431948  -0.7827184  -0.75483155 -1.3128207  -1.7283335 ]\n",
      "DONE EPISODE: 1910 reward: -224.86189992159962 step: 382000 epsilon: 0.146283142863068 loss: 312.66254 action: [0.3999999999999999] q: [1.6041511  1.8941798  2.3766685  2.6777484  2.6580765  2.6502855\n",
      " 2.7553747  2.489505   2.6711807  2.2400863  0.24562024]\n",
      "DONE EPISODE: 1920 reward: -324.84032089064533 step: 384000 epsilon: 0.1411402857201978 loss: 222.24994 action: [0.7999999999999998] q: [-0.27934074  0.34647644  1.6054912   1.99652     2.3183975   2.5519009\n",
      "  2.631122    3.003826    2.9193459   2.8723955   1.9415936 ]\n",
      "DONE EPISODE: 1930 reward: -213.61156502716813 step: 386000 epsilon: 0.13599742857732758 loss: 88.76692 action: [2.0] q: [-10.038965    -8.452625    -7.099177    -5.1172557   -3.7540324\n",
      "  -2.0238633   -1.1657534    0.07043275   1.2116867    1.5856354\n",
      "   3.7856288 ]\n",
      "DONE EPISODE: 1940 reward: -139.81669898965424 step: 388000 epsilon: 0.13085457143445736 loss: 41.48449 action: [-1.2] q: [-88.807976 -89.31643  -86.39776  -89.52988  -89.82088  -89.986534\n",
      " -90.98426  -92.54005  -90.34061  -92.41961  -94.496994]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -245.12029809668337\n",
      "DONE EPISODE: 1950 reward: -195.6612877227801 step: 390000 epsilon: 0.12571171429158715 loss: 73.82359 action: [2.0] q: [-4.34323    -3.2136152  -2.1266837  -0.6726425   0.12147543  0.7439201\n",
      "  1.7877452   2.106095    2.743566    2.9424565   3.55102   ]\n",
      "DONE EPISODE: 1960 reward: -258.54762731010476 step: 392000 epsilon: 0.12056885714871693 loss: 248.36212 action: [0.3999999999999999] q: [0.797167  1.4738663 2.2207432 2.8894029 2.942525  3.0515742 3.5278575\n",
      " 3.364484  3.3710394 3.279688  2.022602 ]\n",
      "DONE EPISODE: 1970 reward: -268.2394688718876 step: 394000 epsilon: 0.11542600000584671 loss: 167.3307 action: [-0.3999999999999999] q: [2.3214822 2.7704525 3.0219285 3.7195706 3.7327116 3.6066504 3.6555398\n",
      " 3.6057532 3.4807377 3.3088396 1.5800161]\n",
      "DONE EPISODE: 1980 reward: -264.87094667737085 step: 396000 epsilon: 0.1102831428629765 loss: 171.84955 action: [2.0] q: [-103.894554  -99.74126   -95.25765   -90.176315  -86.62224   -80.645035\n",
      "  -77.754906  -70.81316   -67.31992   -64.45079   -56.76047 ]\n",
      "DONE EPISODE: 1990 reward: -175.84082130198527 step: 398000 epsilon: 0.10514028572010628 loss: 56.682175 action: [1.2000000000000002] q: [0.6696004 1.2509987 2.10411   2.9091759 3.4561038 3.6249049 3.981715\n",
      " 4.146139  4.2759156 4.183468  3.1403203]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -189.95365958809492\n",
      "DONE EPISODE: 2000 reward: -227.404970505258 step: 400000 epsilon: 0.09999742857723606 loss: 5323.2925 action: [0.7999999999999998] q: [1.9555852 2.6779985 2.9869514 3.7339542 3.4425204 3.7427533 3.7985125\n",
      " 3.9008873 3.888722  3.7390828 2.4053452]\n",
      "DONE EPISODE: 2010 reward: -255.52905513993483 step: 402000 epsilon: 0.09999742857723606 loss: 52.820957 action: [0.7999999999999998] q: [1.7099211 2.22762   2.6560981 3.6964138 3.5268059 3.8105063 4.2600694\n",
      " 4.466021  4.3320446 4.2255607 3.2025692]\n",
      "DONE EPISODE: 2020 reward: -197.66754761965964 step: 404000 epsilon: 0.09999742857723606 loss: 224.6582 action: [0.0] q: [0]\n",
      "DONE EPISODE: 2030 reward: -169.65096619279072 step: 406000 epsilon: 0.09999742857723606 loss: 766.6825 action: [1.6] q: [1.1903781 1.885925  2.4480393 3.2198675 3.849229  4.002867  4.6977444\n",
      " 4.7063    4.8701944 4.9467893 4.095997 ]\n",
      "DONE EPISODE: 2040 reward: -148.4643014444544 step: 408000 epsilon: 0.09999742857723606 loss: 128.47906 action: [1.2000000000000002] q: [2.5123649 2.5687804 3.4704666 3.9849477 4.2701507 4.385171  4.4753194\n",
      " 4.475433  4.5321093 4.2498155 2.993625 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -128.6408117527056\n",
      "DONE EPISODE: 2050 reward: -212.30006102209813 step: 410000 epsilon: 0.09999742857723606 loss: 533.2611 action: [1.6] q: [-0.25535062  0.82440805  1.5655854   2.640439    3.2008097   3.457999\n",
      "  4.2625623   4.4168997   4.549433    4.665462    4.510641  ]\n",
      "DONE EPISODE: 2060 reward: -250.4197546480862 step: 412000 epsilon: 0.09999742857723606 loss: 418.05518 action: [0.7999999999999998] q: [2.7594512 3.4631922 3.630975  4.234859  4.63731   4.6433573 4.724857\n",
      " 4.752565  4.7315383 4.469643  3.4093223]\n",
      "DONE EPISODE: 2070 reward: -218.8539199375855 step: 414000 epsilon: 0.09999742857723606 loss: 55.119076 action: [2.0] q: [-39.63748   -35.081913  -31.653183  -25.666803  -21.827948  -17.536041\n",
      " -13.53494   -10.018091   -6.744751   -4.619948    5.7098727]\n",
      "DONE EPISODE: 2080 reward: -313.63390883686725 step: 416000 epsilon: 0.09999742857723606 loss: 76.53823 action: [0.3999999999999999] q: [2.7816188 3.4268675 4.035001  4.5469184 4.898832  4.966321  5.1856575\n",
      " 5.126748  5.101167  5.0454497 3.8361785]\n",
      "DONE EPISODE: 2090 reward: -241.84337264337643 step: 418000 epsilon: 0.09999742857723606 loss: 41.08893 action: [0.7999999999999998] q: [3.3993578 3.774303  4.226462  4.8319964 4.9679427 5.0530887 5.043361\n",
      " 5.247135  5.136672  5.1773286 3.5045238]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -246.2597119061903\n",
      "DONE EPISODE: 2100 reward: -259.51550668763304 step: 420000 epsilon: 0.09999742857723606 loss: 8890.604 action: [0.0] q: [4.1425447 4.3605337 4.8402457 5.0337625 5.3138757 5.3377533 5.3001533\n",
      " 5.2071333 5.1998444 5.011468  3.623803 ]\n",
      "DONE EPISODE: 2110 reward: -287.908524243746 step: 422000 epsilon: 0.09999742857723606 loss: 102.87659 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 2120 reward: -178.6837871004217 step: 424000 epsilon: 0.09999742857723606 loss: 31.466465 action: [0.3999999999999999] q: [2.6597848 3.826794  4.2489924 4.8104405 5.0004735 5.1032543 5.787393\n",
      " 5.535015  5.6329427 5.7214775 4.6428556]\n",
      "DONE EPISODE: 2130 reward: -222.89364262787498 step: 426000 epsilon: 0.09999742857723606 loss: 86.37753 action: [1.2000000000000002] q: [3.162438  3.8624427 4.6325364 5.238801  5.338213  5.6306863 5.718207\n",
      " 5.5275135 5.747618  5.6210093 4.3181844]\n",
      "DONE EPISODE: 2140 reward: -235.80996220875795 step: 428000 epsilon: 0.09999742857723606 loss: 28.087193 action: [1.6] q: [2.6228857 3.8134184 4.185257  4.4808865 5.103508  5.2606235 5.6342883\n",
      " 5.804258  5.917077  5.9707665 5.392584 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -203.82053214789318\n",
      "DONE EPISODE: 2150 reward: -181.4692839497753 step: 430000 epsilon: 0.09999742857723606 loss: 133.82397 action: [2.0] q: [0.8876449 2.0974553 2.925397  3.7695918 4.6003036 4.934396  5.4422846\n",
      " 5.673375  6.029769  6.106088  6.1168504]\n",
      "DONE EPISODE: 2160 reward: -209.2210596143199 step: 432000 epsilon: 0.09999742857723606 loss: 243.08871 action: [2.0] q: [-0.02661955  0.9323225   1.796881    2.9598513   3.9970393   4.3146186\n",
      "  4.8181095   5.1570306   5.4951897   5.647628    5.8326263 ]\n",
      "DONE EPISODE: 2170 reward: -178.01326149010225 step: 434000 epsilon: 0.09999742857723606 loss: 78.083 action: [1.6] q: [0.33218563 1.6328691  2.0214148  3.348258   4.0906935  4.5837483\n",
      " 5.3081985  5.571168   5.7980065  6.096135   6.0414143 ]\n",
      "DONE EPISODE: 2180 reward: -246.94404654507167 step: 436000 epsilon: 0.09999742857723606 loss: 54.848923 action: [1.2000000000000002] q: [5.329612  5.851036  6.038875  5.985921  5.9850125 6.0338855 6.022181\n",
      " 5.7296247 6.069843  5.6268754 3.9746659]\n",
      "DONE EPISODE: 2190 reward: -288.40426387534023 step: 438000 epsilon: 0.09999742857723606 loss: 36.299862 action: [0.3999999999999999] q: [4.56765   5.2727733 5.30809   6.2818675 6.237591  6.3859    6.4657245\n",
      " 6.3696904 6.442382  6.3032975 5.144818 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -174.2697666756895\n",
      "DONE EPISODE: 2200 reward: -184.2793677000729 step: 440000 epsilon: 0.09999742857723606 loss: 90.04143 action: [1.2000000000000002] q: [3.452148  4.3573904 5.0036883 5.4531283 6.0415497 5.947431  6.2550216\n",
      " 6.1579094 6.2720904 6.160685  5.29116  ]\n",
      "DONE EPISODE: 2210 reward: -266.600866166723 step: 442000 epsilon: 0.09999742857723606 loss: 22.381664 action: [0.7999999999999998] q: [3.5638702 4.1776733 5.06011   5.34407   5.844979  5.995611  6.2186737\n",
      " 6.4573493 6.3607407 6.3940682 5.3514047]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE EPISODE: 2220 reward: -158.76875883182353 step: 444000 epsilon: 0.09999742857723606 loss: 57.05952 action: [1.2000000000000002] q: [1.8727707 2.9734297 4.002194  4.950953  5.037006  5.4016647 5.815142\n",
      " 5.869127  6.064716  6.0173793 5.4282923]\n",
      "DONE EPISODE: 2230 reward: -211.38019571586602 step: 446000 epsilon: 0.09999742857723606 loss: 355.52853 action: [1.6] q: [3.0403576 3.9989705 4.934718  5.336644  5.5644016 5.9690933 6.201616\n",
      " 6.16664   6.305435  6.3180223 5.3056445]\n",
      "DONE EPISODE: 2240 reward: -186.12615019685146 step: 448000 epsilon: 0.09999742857723606 loss: 190.02725 action: [0.0] q: [0]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -153.46996548078786\n",
      "DONE EPISODE: 2250 reward: -225.7078337838895 step: 450000 epsilon: 0.09999742857723606 loss: 427.4615 action: [0.3999999999999999] q: [0]\n",
      "DONE EPISODE: 2260 reward: -241.2163268563758 step: 452000 epsilon: 0.09999742857723606 loss: 77.882576 action: [2.0] q: [-3.7193723  -2.3906617  -1.2534246   0.32219985  1.8097942   2.4341648\n",
      "  3.533273    4.044164    4.6264744   5.0529346   6.3133082 ]\n",
      "DONE EPISODE: 2270 reward: -227.20967935683834 step: 454000 epsilon: 0.09999742857723606 loss: 325.4563 action: [1.2000000000000002] q: [-102.57923  -103.41607  -101.92923   -99.63742   -96.31628   -93.21333\n",
      "  -92.97408   -90.587814  -88.647865  -89.68562   -91.81164 ]\n",
      "DONE EPISODE: 2280 reward: -295.1894032916761 step: 456000 epsilon: 0.09999742857723606 loss: 130.11708 action: [1.2000000000000002] q: [3.436951  4.14484   4.9545107 5.4859915 5.8034186 6.079361  6.0257382\n",
      " 6.1325016 6.397304  6.1501694 5.1777935]\n",
      "DONE EPISODE: 2290 reward: -204.99481692833297 step: 458000 epsilon: 0.09999742857723606 loss: 113.33133 action: [1.6] q: [-85.75662  -84.84931  -84.17867  -82.575294 -86.639305 -87.94062\n",
      " -83.43041  -88.98284  -84.50776  -82.33772  -85.836006]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -148.6460760148872\n",
      "DONE EPISODE: 2300 reward: -221.66224572186928 step: 460000 epsilon: 0.09999742857723606 loss: 42.38508 action: [0.3999999999999999] q: [3.9738655 4.747925  5.7817554 5.743068  6.2067323 6.2530956 6.474838\n",
      " 6.3634615 6.4447703 6.3130364 5.1761274]\n",
      "DONE EPISODE: 2310 reward: -261.1368200569553 step: 462000 epsilon: 0.09999742857723606 loss: 1137.1787 action: [0.3999999999999999] q: [3.6480608 4.492913  5.243245  5.752151  6.182199  6.274151  6.542617\n",
      " 6.3418036 6.4110446 6.3384895 5.4872985]\n",
      "DONE EPISODE: 2320 reward: -285.8548061849666 step: 464000 epsilon: 0.09999742857723606 loss: 10.131287 action: [2.0] q: [-66.78223   -61.516697  -54.898727  -45.855976  -38.37546   -32.56465\n",
      " -25.347399  -21.03661   -15.131833  -12.599434    5.9316344]\n",
      "DONE EPISODE: 2330 reward: -215.2516369500376 step: 466000 epsilon: 0.09999742857723606 loss: 338.55072 action: [1.2000000000000002] q: [3.4354568 4.209148  5.4072847 5.923498  6.2904596 6.503165  6.3202915\n",
      " 6.455353  6.5739584 6.4506106 5.4567432]\n",
      "DONE EPISODE: 2340 reward: -284.84623900315233 step: 468000 epsilon: 0.09999742857723606 loss: 6625.34 action: [0.7999999999999998] q: [2.2573533 3.8092597 4.818706  5.224101  6.065893  5.9658213 6.2682576\n",
      " 6.5192885 6.512827  6.467602  5.646558 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -180.46183391879003\n",
      "DONE EPISODE: 2350 reward: -178.86689737571973 step: 470000 epsilon: 0.09999742857723606 loss: 67.993965 action: [1.2000000000000002] q: [3.0293577 4.545927  5.188993  5.6341367 6.2153125 6.4454236 6.1358314\n",
      " 6.4793057 6.4850116 6.4180107 5.430337 ]\n",
      "DONE EPISODE: 2360 reward: -240.24872867593353 step: 472000 epsilon: 0.09999742857723606 loss: 177.48021 action: [-1.2] q: [-88.91011  -90.12685  -86.98142  -88.74354  -91.97711  -90.26031\n",
      " -93.50938  -92.472496 -92.65886  -92.40165  -99.50823 ]\n",
      "DONE EPISODE: 2370 reward: -186.3957866649151 step: 474000 epsilon: 0.09999742857723606 loss: 114.45413 action: [-2.0] q: [-41.02661  -43.233265 -42.499657 -42.495056 -41.980904 -45.558086\n",
      " -43.333218 -45.87699  -45.71348  -45.36853  -41.367092]\n",
      "DONE EPISODE: 2380 reward: -227.47245564855342 step: 476000 epsilon: 0.09999742857723606 loss: 329.1135 action: [0.7999999999999998] q: [1.7789264 2.9735253 4.048349  5.030648  5.9974246 5.9070277 6.2611775\n",
      " 6.636654  6.462976  6.5863705 6.1380053]\n",
      "DONE EPISODE: 2390 reward: -269.9007845299028 step: 478000 epsilon: 0.09999742857723606 loss: 109.9524 action: [0.0] q: [ -98.05825   -96.26223   -98.324234  -97.04103   -98.14635   -95.720116\n",
      "  -97.70856   -97.55332   -99.222404  -98.650024 -105.60483 ]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -178.94831649151152\n",
      "DONE EPISODE: 2400 reward: -169.09026186298192 step: 480000 epsilon: 0.09999742857723606 loss: 67.42754 action: [2.0] q: [-13.59066   -11.02034    -8.339116   -5.983841   -3.326839   -2.3762438\n",
      "  -0.5129832   0.5755214   2.0949187   2.7538817   6.36695  ]\n",
      "DONE EPISODE: 2410 reward: -335.5023659397543 step: 482000 epsilon: 0.09999742857723606 loss: 196.06726 action: [1.2000000000000002] q: [2.5848236 4.2452536 5.1818156 6.030389  6.315926  6.515014  6.7820206\n",
      " 6.9180894 7.0075417 6.936167  5.646426 ]\n",
      "DONE EPISODE: 2420 reward: -168.42649713753403 step: 484000 epsilon: 0.09999742857723606 loss: 42.372272 action: [0.7999999999999998] q: [1.6132281 3.469407  4.151268  5.2375855 6.170019  6.5642295 6.544867\n",
      " 7.066809  6.8821893 6.942241  6.4847775]\n",
      "DONE EPISODE: 2430 reward: -322.49010826787816 step: 486000 epsilon: 0.09999742857723606 loss: 54.981552 action: [2.0] q: [-22.564234  -19.217949  -15.801392  -12.483866   -8.845962   -7.1264625\n",
      "  -4.0975833  -2.3885047  -0.6854463   0.716716    7.02987  ]\n",
      "DONE EPISODE: 2440 reward: -282.3562390287907 step: 488000 epsilon: 0.09999742857723606 loss: 81.54848 action: [-0.3999999999999999] q: [4.3134327 4.8751755 6.3286066 6.1433372 6.5798097 6.510568  5.9156694\n",
      " 6.164252  5.6789804 5.193912  3.4110782]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -176.62930252339987\n",
      "DONE EPISODE: 2450 reward: -261.853132834534 step: 490000 epsilon: 0.09999742857723606 loss: 46.903828 action: [2.0] q: [-22.7432     -19.51269    -16.304096   -12.668329    -9.281646\n",
      "  -7.3628473   -4.064855    -2.2837796   -0.56509954   0.4091701\n",
      "   6.823508  ]\n",
      "DONE EPISODE: 2460 reward: -196.00408774601735 step: 492000 epsilon: 0.09999742857723606 loss: 261.33365 action: [0.3999999999999999] q: [3.3423452 4.9407725 5.8373923 6.5681148 6.7480655 6.921311  7.0857553\n",
      " 6.790409  6.8647065 6.809947  5.6137137]\n",
      "DONE EPISODE: 2470 reward: -254.04950450090604 step: 494000 epsilon: 0.09999742857723606 loss: 46.65111 action: [-1.2] q: [0]\n",
      "DONE EPISODE: 2480 reward: -255.4828817161163 step: 496000 epsilon: 0.09999742857723606 loss: 176.90222 action: [-0.3999999999999999] q: [2.1981277 4.022539  5.406916  6.340039  7.0312285 6.952104  7.014646\n",
      " 6.8403873 6.841568  6.870391  5.880374 ]\n",
      "DONE EPISODE: 2490 reward: -246.67003680836393 step: 498000 epsilon: 0.09999742857723606 loss: 281.3966 action: [-1.6] q: [ 8.597606    9.124016    9.109239    8.59271     7.8543787   7.1459765\n",
      "  5.539435    5.4504843   4.6158466   3.2252684  -0.42353135]\n",
      "Evaluation Start\n",
      "Evaluation End, mean score: -181.62195435078533\n",
      "DONE EPISODE: 2500 reward: -299.6926618337624 step: 500000 epsilon: 0.09999742857723606 loss: 23.391674 action: [2.0] q: [-114.24321  -112.872314 -106.82915  -104.44685   -98.43877   -93.82729\n",
      "  -89.87285   -84.71926   -84.447105  -82.322426  -81.97167 ]\n",
      "MAX STEPS\n"
     ]
    }
   ],
   "source": [
    "trial_num=4\n",
    "tf.reset_default_graph()\n",
    "\n",
    "sess =tf.Session()\n",
    "SCORES = []\n",
    "Qvalues = []\n",
    "EVAL_SCORES = []\n",
    "\n",
    "Optimizer = tf.train.AdamOptimizer(learning_rate = 1e-4)\n",
    "agent=Agent()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "env = gym.make('Pendulum-v0')\n",
    "eval_env = gym.make('Pendulum-v0')\n",
    "\n",
    "step_count = 0\n",
    "episode_count = 0\n",
    "score_deque = deque([], maxlen=10)\n",
    "rendering=False\n",
    "loss = None\n",
    "while True:\n",
    "    if episode_count%500==0:\n",
    "        rendering=True\n",
    "    else:\n",
    "        rendering=False\n",
    "    state = env.reset()\n",
    "    episode_count += 1\n",
    "    score = 0\n",
    "    qvalues = []\n",
    "\n",
    "    while True:\n",
    "        action, q_values = agent.action_sample([state])\n",
    "\n",
    "        qvalues.append(np.max(q_values[0]))\n",
    "        normed_action = [-2.0 + action*4.0/(ACTION_NUMBER - 1.0)]\n",
    "        step_count += 1\n",
    "\n",
    "        next_state, reward, done, _ = env.step(normed_action)\n",
    "        if rendering==True:\n",
    "            env.render()\n",
    "            time.sleep(0.05)\n",
    "\n",
    "        score += reward\n",
    "        agent.replay.update(state,action,reward,next_state,done)\n",
    "        state = next_state\n",
    "\n",
    "        if len(agent.replay.history)>TRAIN_STARTING_POINT:\n",
    "            loss = agent.train()\n",
    "            agent.epsilon_decayer()\n",
    "        if step_count%TARGET_UPDATE_FREQ==0:\n",
    "            agent.sync_network()            \n",
    "        \n",
    "        if step_count%EVALUATION_FREQ==0:\n",
    "            eval_score = agent.evaluate(eval_env)\n",
    "            EVAL_SCORES.append(eval_score)\n",
    "        \n",
    "        if done:\n",
    "            score_deque.append(score)\n",
    "            if episode_count%10==0:\n",
    "                print('DONE EPISODE:', episode_count, 'reward:', np.mean(score_deque), 'step:', step_count, 'epsilon:', agent.epsilon, 'loss:', loss, 'action:', normed_action, 'q:', q_values)\n",
    "            if rendering==True:\n",
    "                rendering=False\n",
    "                env.close()\n",
    "            break\n",
    "    SCORES.append(score)\n",
    "    Qvalues.append(np.mean(qvalues))\n",
    "    if step_count>MAX_STEP:\n",
    "        score_deque.append(score)\n",
    "        print('MAX STEPS')\n",
    "        break\n",
    "        \n",
    "with open('./pendulum_eval_score_' + str(trial_num) + '.pickle', 'wb') as f:\n",
    "    pickle.dump(EVAL_SCORES, f)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1472.31102582 -1364.27989615 -1006.65926563  -794.98841765\n",
      "  -470.56693036  -564.48291079 -1252.3306112   -934.84100969\n",
      "  -925.78634221  -741.80645306  -780.99566808  -911.03934021\n",
      "  -830.72275699  -652.901882     -34.70781711  -229.64590673\n",
      "  -174.43288564  -103.72279565  -126.23997013  -137.79575752\n",
      "   -70.23371941   -91.54688444  -163.50533555   -74.69643844\n",
      "  -106.96212608  -112.43213282  -148.68445714  -115.66614398\n",
      "  -122.32582522  -116.53574203  -108.15517557  -114.87492453\n",
      "  -103.98925741  -162.63630474  -159.82277145   -99.35876549\n",
      "  -110.288826     -91.76367485  -137.29482203  -119.19005852\n",
      "  -122.58169712  -100.29478319  -148.49695449  -146.20993194\n",
      "  -150.04304895  -134.51846899  -105.58452363  -102.9741738\n",
      "  -113.72159925  -156.10054528]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(5):\n",
    "    with open('./pendulum_eval_score_' + str(i) + '.pickle', 'rb') as f:\n",
    "        a = pickle.load(f)\n",
    "        data.append(a)\n",
    "\n",
    "result = np.mean(data, axis=0)\n",
    "data = np.array(data)\n",
    "var = []\n",
    "for i in range(len(result)):\n",
    "    var.append(np.sqrt(np.var(data[:,i])))\n",
    "for i in range(len(result)):\n",
    "    var1 = result + var\n",
    "    var2 = result - var\n",
    "    \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(result)\n",
    "plt.fill_between(range(len(result)), var2, var1, color='skyblue')\n",
    "plt.xlabel('iteration(1e4)')\n",
    "plt.ylabel('Pendulum score')\n",
    "plt.grid()\n",
    "# print(var1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATARI_kernel",
   "language": "python",
   "name": "atari_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
