{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/lgm/JEONGHO/ATARI/lib/python3.5/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "###성공###\n",
    "import sys\n",
    "sys.path.append('/home/lgm/JEONGHO/RL스터디2020/')\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import gym\n",
    "import dobroEnv\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "# from halfCheetah import HalfCheetah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make('DobroHalfCheetah-v0')\n",
    "# env.unwrapped.initialize(is_render=True) # renderin하려면.\n",
    "GAME_NAME = 'Pendulum-v0'\n",
    "\n",
    "env = gym.make(GAME_NAME)\n",
    "eval_env = gym.make(GAME_NAME)\n",
    "\n",
    "MAX_EPISODE =100\n",
    "REPLAY_BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "ALPHA = 0.1\n",
    "BETA = 0.1\n",
    "SOFT_UPDATA_TAU = 0.001\n",
    "STATE_DIM = env.observation_space.shape[0]\n",
    "ACTION_DIM = env.action_space.shape[0]\n",
    "Policy_LR = 3e-4\n",
    "Qnet_LR = 3e-4\n",
    "MIN_REPLAY_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, buffer_size):\n",
    "        self.history = deque([], maxlen = buffer_size)\n",
    "    def update(self, state, action, reward, next_state, done):\n",
    "        buffer = (state, action, reward, next_state, done)\n",
    "        self.history.append(buffer)\n",
    "        \n",
    "    def sample_batch(self, batch_size):\n",
    "        batch = random.sample(self.history, batch_size)\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self):\n",
    "        self.replay = ReplayBuffer(REPLAY_BUFFER_SIZE)\n",
    "        self.gamma = GAMMA\n",
    "        self.alpha = ALPHA\n",
    "        self.betha = BETA \n",
    "        self.tau = SOFT_UPDATA_TAU\n",
    "        self.state_dim = STATE_DIM\n",
    "        self.action_dim = ACTION_DIM\n",
    "        self.batch_size = BATCH_SIZE\n",
    "        self.minimum_replay_size = MIN_REPLAY_SIZE\n",
    "        self.eval_count = 0\n",
    "        \n",
    "        self.PolicyOptimizer = tf.train.AdamOptimizer(learning_rate=Policy_LR)\n",
    "        self.QnetOptimizer = tf.train.AdamOptimizer(learning_rate=Qnet_LR)\n",
    "        \n",
    "        with tf.variable_scope('SACagent'):\n",
    "            self.state_ph = tf.placeholder(tf.float32, shape=(None, self.state_dim), name='state_ph')\n",
    "            self.action_ph = tf.placeholder(tf.float32, shape=(None, self.action_dim), name='action_ph')\n",
    "            self.sample_action_ph = tf.placeholder(tf.float32, shape=(None, self.action_dim), name='sample_action_ph')\n",
    "            self.action_eps_ph = tf.placeholder(tf.float32, shape=(None,self.action_dim), name='eps_ph')\n",
    "            self.action_std_ph = tf.placeholder(tf.float32, shape=(None,self.action_dim), name='std_ph')\n",
    "            \n",
    "            self._build_policy()\n",
    "            self._build_qnet()\n",
    "            \n",
    "            self.policy_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SACagent/policy')\n",
    "\n",
    "            self.qnet1_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SACagent/onlineq1')\n",
    "            self.qnet2_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SACagent/onlineq2')\n",
    "            self.qnet1_target_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SACagent/targetq1')\n",
    "            self.qnet2_target_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SACagent/targetq2')\n",
    "            self.qnet_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'SACagent/onlineq')\n",
    "            \n",
    "            self.q1_target_update_ops, self.q2_target_update_ops = self._build_q_target_update_ops()\n",
    "            \n",
    "\n",
    "            self.reward_ph = tf.placeholder(tf.float32, (None,1), name='reward_ph')\n",
    "            self.done_ph = tf.cast(tf.placeholder(tf.bool, (None,1), name='done_ph'), tf.float32)\n",
    "\n",
    "            \n",
    "            self.log_policy = - 0.5 * tf.log(1e-8+(2.*np.pi * self.action_std**2)) \\\n",
    "                                    - 0.5 * (self.action_eps_ph)**2 \\\n",
    "                                    - tf.expand_dims(tf.reduce_sum(tf.log(1e-8+1 - tf.square(self.action)),axis=1),1)#sampling된 액션1(from current state of buffer)\n",
    "\n",
    "            self.log_policy_next = - 0.5 * tf.log(1e-8+(2.*np.pi * self.action_std_ph**2)) \\\n",
    "                                            - 0.5 * (self.action_eps_ph)**2 \\\n",
    "                                            - tf.expand_dims(tf.reduce_sum(tf.log(1e-8+1 - tf.square(self.action_ph)),axis=1),1)#sampling 된 액션2 (from next_state of buffer)\n",
    "            \n",
    "            \n",
    "            self.qnet_target = self.reward_ph + self.gamma * (1 - self.done_ph) * (self.qmin_target - self.alpha * self.log_policy_next) # 전부 샘플링된 액션2 (from next_state of buffer)\n",
    "            self.qnet_target_ph = tf.placeholder(tf.float32, shape=(None, self.action_dim), name='qnet_target_ph')\n",
    "\n",
    "            # 폴리시 LOSS\n",
    "            self.policy_loss = tf.reduce_mean(self.alpha * self.log_policy - self.qmin_backprop)\n",
    "        \n",
    "            # q네트워크 LOSS\n",
    "            self.qnet1_loss = tf.reduce_mean(tf.square(self.q_value1 - self.qnet_target_ph)) # q_value1: buffer's current action, current state\n",
    "            self.qnet2_loss = tf.reduce_mean(tf.square(self.q_value2 - self.qnet_target_ph)) \n",
    "            self.qnet_loss = self.qnet1_loss + self.qnet2_loss\n",
    "\n",
    "            self.qnet_update = self.QnetOptimizer.minimize(self.qnet_loss, var_list=self.qnet_vars)\n",
    "            \n",
    "            self.policy_update = self.PolicyOptimizer.minimize(self.policy_loss, var_list=self.policy_vars)\n",
    "#         print('HHHHHHHHHHHHHHHHHHHHHHHHHHHHH')\n",
    "#         self.q_initial_sync()\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "    def _build_qnet(self):\n",
    "        LAYER_SIZE = 128\n",
    "        init_mu = 0.\n",
    "        init_std = 0.1\n",
    "        qnet_input = tf.concat([self.state_ph, self.action_ph], axis=1)\n",
    "        with tf.variable_scope('onlineq1'):\n",
    "            qnet_hid11 = tf.layers.dense(inputs=qnet_input, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q1_h1')\n",
    "            qnet_hid11 = tf.nn.relu(qnet_hid11)\n",
    "            qnet_hid12 = tf.layers.dense(inputs=qnet_hid11, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q1_h2')\n",
    "            qnet_hid12 = tf.nn.relu(qnet_hid12)\n",
    "\n",
    "            self.q_value1 = tf.layers.dense(inputs=qnet_hid12, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q1_h3')\n",
    "        \n",
    "        with tf.variable_scope('onlineq2'):\n",
    "            qnet_hid21 = tf.layers.dense(inputs=qnet_input, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q2_h1')\n",
    "            qnet_hid21 = tf.nn.relu(qnet_hid21)\n",
    "            qnet_hid22 = tf.layers.dense(inputs=qnet_hid21, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q2_h2')\n",
    "            qnet_hid22 = tf.nn.relu(qnet_hid22)\n",
    "\n",
    "            self.q_value2 = tf.layers.dense(inputs=qnet_hid22, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q2_h3')\n",
    "        self.qmin = tf.minimum(self.q_value1, self.q_value2)\n",
    "        \n",
    "        qnet_target_input = tf.concat([self.state_ph, self.sample_action_ph], axis=1)\n",
    "        with tf.variable_scope('targetq1'):\n",
    "            qnet_target_hid11 = tf.layers.dense(inputs=qnet_target_input, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='qt1_h1')\n",
    "            qnet_target_hid11 = tf.nn.relu(qnet_target_hid11)\n",
    "            qnet_target_hid12 = tf.layers.dense(inputs=qnet_target_hid11, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='qt1_h2')\n",
    "            qnet_target_hid12 = tf.nn.relu(qnet_target_hid12)\n",
    "\n",
    "            self.q_value1_target = tf.layers.dense(inputs=qnet_target_hid12, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='qt1_h3')\n",
    "        \n",
    "        with tf.variable_scope('targetq2'):\n",
    "            qnet_target_hid21 = tf.layers.dense(inputs=qnet_target_input, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='qt2_h1')\n",
    "            qnet_target_hid21 = tf.nn.relu(qnet_target_hid21)\n",
    "            qnet_target_hid22 = tf.layers.dense(inputs=qnet_target_hid21, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='qt2_h2')\n",
    "            qnet_target_hid22 = tf.nn.relu(qnet_target_hid22)\n",
    "\n",
    "            self.q_value2_target = tf.layers.dense(inputs=qnet_target_hid22, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='qt2_h3')\n",
    "        self.qmin_target = tf.minimum(self.q_value1_target, self.q_value2_target)\n",
    "        \n",
    "        #### q에 들어가는 action이 self.action이어서 grad가 back prop되는 q들\n",
    "        qnetg_input = tf.concat([self.state_ph, self.action], axis=1)\n",
    "        with tf.variable_scope('onlineq1', reuse=True):\n",
    "            qnetg_hid11 = tf.layers.dense(inputs=qnetg_input, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q1_h1')\n",
    "            qnetg_hid11 = tf.nn.relu(qnetg_hid11)\n",
    "            qnetg_hid12 = tf.layers.dense(inputs=qnetg_hid11, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q1_h2')\n",
    "            qnetg_hid12 = tf.nn.relu(qnetg_hid12)\n",
    "\n",
    "            self.q_value1_copy = tf.layers.dense(inputs=qnetg_hid12, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q1_h3')\n",
    "        with tf.variable_scope('onlineq2', reuse=True):\n",
    "            qnetg_hid21 = tf.layers.dense(inputs=qnetg_input, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q2_h1')\n",
    "            qnetg_hid21 = tf.nn.relu(qnetg_hid21)\n",
    "            qnetg_hid22 = tf.layers.dense(inputs=qnetg_hid21, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q2_h2')\n",
    "            qnetg_hid22 = tf.nn.relu(qnetg_hid22)\n",
    "\n",
    "            self.q_value2_copy = tf.layers.dense(inputs=qnetg_hid22, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std),name='q2_h3')\n",
    "        self.qmin_backprop = tf.minimum(self.q_value1_copy, self.q_value2_copy)\n",
    "        \n",
    "    def _build_policy(self):\n",
    "        LAYER_SIZE = 128\n",
    "        init_mu = 0.\n",
    "        init_std = 0.1\n",
    "        with tf.variable_scope('policy'):\n",
    "            policy_hid1 = tf.layers.dense(inputs=self.state_ph, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std))\n",
    "            policy_hid1 = tf.nn.relu(policy_hid1)\n",
    "            \n",
    "            policy_hid2 = tf.layers.dense(inputs=policy_hid1, units=LAYER_SIZE, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std))\n",
    "            policy_hid2 = tf.nn.relu(policy_hid2)\n",
    "            \n",
    "            self.action_mu = tf.layers.dense(inputs=policy_hid2, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std))\n",
    "            self.action_std = tf.layers.dense(inputs=policy_hid2, units=self.action_dim, kernel_initializer=tf.compat.v1.initializers.random_normal(init_mu,init_std), bias_initializer= tf.compat.v1.initializers.random_normal(init_mu,init_std))\n",
    "            self.action_std = tf.nn.softplus(self.action_std)\n",
    "\n",
    "\n",
    "            self.unbounded_action = self.action_mu + self.action_std * self.action_eps_ph\n",
    "            self.action = tf.nn.tanh(self.unbounded_action)\n",
    "\n",
    "\n",
    "\n",
    "    def q_initial_sync(self):\n",
    "        ops1 = []\n",
    "        for target_var, online_var in zip(self.qnet1_target_vars, self.qnet1_vars):\n",
    "            ops1.append(target_var.assign(online_var))\n",
    "        ops2 = []\n",
    "        for target_var, online_var in zip(self.qnet2_target_vars, self.qnet2_vars):\n",
    "            ops2.append(target_var.assign(online_var))\n",
    "        for op in ops1:\n",
    "            sess.run(op)\n",
    "        for op in ops2:\n",
    "            sess.run(op)\n",
    "        print('#########################\\nQ net initially sync done\\n#########################')\n",
    "        \n",
    "    def _build_q_target_update_ops(self):\n",
    "        ops1 = []\n",
    "        for target_var, online_var in zip(self.qnet1_target_vars, self.qnet1_vars):\n",
    "            ops1.append(target_var.assign(self.tau * online_var + (1-self.tau) * target_var))\n",
    "        ops2 = []\n",
    "        \n",
    "        for target_var, online_var in zip(self.qnet2_target_vars, self.qnet2_vars):\n",
    "            ops2.append(target_var.assign(self.tau * online_var + (1-self.tau) * target_var))\n",
    "        return ops1, ops2\n",
    "\n",
    "    \n",
    "    def q_target_update(self):\n",
    "        for op in self.q1_target_update_ops:\n",
    "            sess.run(op)\n",
    "        for op in self.q2_target_update_ops:\n",
    "            sess.run(op)\n",
    "    \n",
    "        \n",
    "    def sample_action(self, state, Train=False):\n",
    "        if Train:\n",
    "            eps = self.sample_action_eps(Train=True)\n",
    "            \n",
    "            action = sess.run(self.action, feed_dict={self.state_ph:state, self.action_eps_ph:eps})\n",
    "\n",
    "            return action, eps\n",
    "        else:\n",
    "            if len(self.replay.history) < self.minimum_replay_size:\n",
    "                action = [env.action_space.sample()]\n",
    "\n",
    "                ua = action\n",
    "            else:\n",
    "                eps = self.sample_action_eps()\n",
    "                action, ua = sess.run([self.action,self.unbounded_action], feed_dict={self.state_ph:[state], self.action_eps_ph:[eps]})\n",
    "\n",
    "            return action, ua\n",
    "    \n",
    "    def sample_action_eval(self, state):\n",
    "#         eps = self.sample_action_eps()\n",
    "        action = sess.run(self.action_mu, feed_dict={self.state_ph:[state]})\n",
    "    \n",
    "        return np.tanh(action)\n",
    "\n",
    "        \n",
    "    def sample_action_eps(self, Train=False):\n",
    "        if Train:\n",
    "            action_eps = np.random.normal(size=(self.batch_size, self.action_dim))\n",
    "#             print('예시', action_eps)\n",
    "        else:\n",
    "            action_eps = np.random.normal(size=self.action_dim) # shape 아마 틀릴듯\n",
    "        return action_eps\n",
    "    \n",
    "    def sample_batch(self):\n",
    "        batch = self.replay.sample_batch(self.batch_size)\n",
    "        return batch\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    def train_policy(self, states,actions,rewards,next_states,dones):\n",
    "\n",
    "        eps = self.sample_action_eps(Train=True)\n",
    "\n",
    "        feed_dict = {self.state_ph:states, self.action_eps_ph:eps}\n",
    "        _, ploss = sess.run([self.policy_update, self.policy_loss], feed_dict=feed_dict)\n",
    "\n",
    "        return ploss\n",
    "    \n",
    "    def train_qnet(self, states,actions,rewards,next_states,dones):\n",
    "\n",
    "        eps = self.sample_action_eps(Train=True)\n",
    "\n",
    "        next_actions, stds = sess.run([self.action, self.action_std], feed_dict={self.state_ph:next_states, self.action_eps_ph:eps})\n",
    "        targets = sess.run(self.qnet_target, feed_dict={self.reward_ph:rewards, self.done_ph: dones, self.state_ph:next_states, self.action_eps_ph:eps, self.sample_action_ph:next_actions, self.action_ph:next_actions, self.action_std_ph:stds})\n",
    "\n",
    "        _, qloss = sess.run([self.qnet_update, self.qnet_loss], feed_dict={self.state_ph:states, self.action_ph:actions, self.qnet_target_ph:targets})\n",
    "        self.q_target_update()\n",
    "\n",
    "        \n",
    "        return qloss\n",
    "        \n",
    "\n",
    "    def train(self):\n",
    "        if len(self.replay.history) < self.minimum_replay_size:\n",
    "            return 1,1\n",
    "        batches = self.sample_batch()\n",
    "        states, actions, rewards, next_states, dones = [],[],[],[],[]\n",
    "        for batch in batches:\n",
    "            states.append(batch[0])\n",
    "            actions.append(batch[1])\n",
    "            rewards.append(batch[2])\n",
    "            next_states.append(batch[3])\n",
    "\n",
    "            dones.append(batch[4])\n",
    "\n",
    "        qloss = self.train_qnet(states,actions,rewards,next_states,dones)\n",
    "        ploss = self.train_policy(states,actions,rewards,next_states,dones)\n",
    "#         ploss = 1\n",
    "        \n",
    "        return qloss, ploss\n",
    "    \n",
    "    def evaluate(self):\n",
    "        self.eval_count += 1\n",
    "        eval_s = eval_env.reset()\n",
    "        eval_score = 0\n",
    "        eval_step = 0\n",
    "        while True:\n",
    "            eval_step += 1\n",
    "            eval_a = self.sample_action_eval(eval_s)\n",
    "#             eval_a = self.sample_action(eval_s)\n",
    "            eval_ns, eval_r, eval_d, info = eval_env.step(eval_a[0])\n",
    "            eval_score += eval_r\n",
    "            eval_s = eval_ns\n",
    "            if eval_d:\n",
    "                print(self.eval_count, '-th evaluation done. score:' ,eval_score, 'step:', eval_step)\n",
    "                break\n",
    "        \n",
    "        return eval_score\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b06d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b06d780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b06d780>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b06d780>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d90b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d90b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d90b8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d90b8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337da0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b3380f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b3380f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b3380f0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b3380f0>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d9588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d9588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d9588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00055d9588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338128>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338128>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552c88>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552c88>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effef879588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effef879588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effef879588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effef879588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b337b70>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552a58>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa8552a58>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b338358>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b6bf588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b6bf588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b6bf588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f000b6bf588>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f00056499e8>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7effa86b6e80>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "#########################\n",
      "Q net initially sync done\n",
      "#########################\n",
      "step 200 score -1684.9861211438356 qloss 1 ploss 1\n",
      "ac [array([0.35596845], dtype=float32)] ua [array([0.35596845], dtype=float32)]\n",
      "1 -th evaluation done. score: -1622.0449003277895 step: 200\n",
      "step 200 score -1704.7423539111487 qloss 1 ploss 1\n",
      "ac [array([-0.6141543], dtype=float32)] ua [array([-0.6141543], dtype=float32)]\n",
      "2 -th evaluation done. score: -1309.911399458948 step: 200\n",
      "step 200 score -868.5525291126058 qloss 1 ploss 1\n",
      "ac [array([1.0767331], dtype=float32)] ua [array([1.0767331], dtype=float32)]\n",
      "3 -th evaluation done. score: -1839.2722197077103 step: 200\n",
      "step 200 score -883.602349052377 qloss 1 ploss 1\n",
      "ac [array([-1.4035326], dtype=float32)] ua [array([-1.4035326], dtype=float32)]\n",
      "4 -th evaluation done. score: -1328.3950942666258 step: 200\n",
      "step 200 score -758.5531608605866 qloss 110.807434 ploss 0.22996357\n",
      "ac [array([-1.828019], dtype=float32)] ua [array([-1.828019], dtype=float32)]\n",
      "5 -th evaluation done. score: -1847.5036225562044 step: 200\n",
      "step 200 score -1501.6165344029614 qloss 5.4547396 ploss 5.9141483\n",
      "ac [[0.0558961]] ua [[0.05595442]]\n",
      "6 -th evaluation done. score: -1157.9826355091932 step: 200\n",
      "step 200 score -1072.3366595665093 qloss 1.000632 ploss 7.209897\n",
      "ac [[-0.6648399]] ua [[-0.801438]]\n",
      "7 -th evaluation done. score: -1057.2823699617993 step: 200\n",
      "step 200 score -1628.8519841407797 qloss 0.57114804 ploss 8.403532\n",
      "ac [[0.18823196]] ua [[0.19050357]]\n",
      "8 -th evaluation done. score: -1934.6863106841197 step: 200\n",
      "step 200 score -1148.1809329859984 qloss 0.4349345 ploss 8.849819\n",
      "ac [[0.11096306]] ua [[0.11142188]]\n",
      "9 -th evaluation done. score: -1384.6963521406658 step: 200\n",
      "step 200 score -1080.9271509507473 qloss 0.42817056 ploss 9.852555\n",
      "ac [[0.8701424]] ua [[1.3336662]]\n",
      "10 -th evaluation done. score: -1118.3051023358025 step: 200\n",
      "step 200 score -1093.8608598307092 qloss 0.20089552 ploss 10.71319\n",
      "ac [[-0.25117606]] ua [[-0.2566677]]\n",
      "11 -th evaluation done. score: -1483.450392797167 step: 200\n",
      "step 200 score -1405.6414273123946 qloss 0.12752852 ploss 11.903913\n",
      "ac [[-0.39289698]] ua [[-0.41522127]]\n",
      "12 -th evaluation done. score: -1426.1375018523681 step: 200\n",
      "step 200 score -1491.6873221284966 qloss 0.13443391 ploss 13.3671875\n",
      "ac [[0.509926]] ua [[0.56262976]]\n",
      "13 -th evaluation done. score: -1958.127286927936 step: 200\n",
      "step 200 score -1617.1181495644341 qloss 0.07166368 ploss 13.35692\n",
      "ac [[0.5379016]] ua [[0.60119814]]\n",
      "14 -th evaluation done. score: -1628.6386806540206 step: 200\n",
      "step 200 score -1523.4030546521801 qloss 0.042488236 ploss 14.206228\n",
      "ac [[0.59512484]] ua [[0.6855643]]\n",
      "15 -th evaluation done. score: -1840.468658229951 step: 200\n",
      "step 200 score -1601.0094621861017 qloss 0.04570643 ploss 16.377064\n",
      "ac [[-0.29941174]] ua [[-0.3088733]]\n",
      "16 -th evaluation done. score: -1436.121280259945 step: 200\n",
      "step 200 score -1754.9318379026586 qloss 0.051084213 ploss 18.398556\n",
      "ac [[0.15186137]] ua [[0.1530452]]\n",
      "17 -th evaluation done. score: -1616.705870686195 step: 200\n",
      "step 200 score -1364.8967893825027 qloss 0.04447726 ploss 18.746586\n",
      "ac [[0.22531176]] ua [[0.22924496]]\n",
      "18 -th evaluation done. score: -1735.0415354931501 step: 200\n",
      "step 200 score -1412.244942360283 qloss 0.041382223 ploss 20.422234\n",
      "ac [[0.3812841]] ua [[0.40156135]]\n",
      "19 -th evaluation done. score: -1694.6436824018308 step: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200 score -1518.397738170781 qloss 0.05417601 ploss 22.522022\n",
      "ac [[0.9582867]] ua [[1.9245026]]\n",
      "20 -th evaluation done. score: -1537.768856595167 step: 200\n",
      "step 200 score -1845.5478594534484 qloss 0.035677887 ploss 21.024326\n",
      "ac [[0.93099755]] ua [[1.6658251]]\n",
      "21 -th evaluation done. score: -1803.9109222615027 step: 200\n",
      "step 200 score -1421.1642724269057 qloss 0.046903454 ploss 25.735188\n",
      "ac [[0.01077527]] ua [[0.01077569]]\n",
      "22 -th evaluation done. score: -1813.8422112363153 step: 200\n",
      "step 200 score -1447.5450466688383 qloss 0.026277207 ploss 25.711763\n",
      "ac [[0.59007967]] ua [[0.67778826]]\n",
      "23 -th evaluation done. score: -1457.748327360588 step: 200\n",
      "step 200 score -1628.361665055448 qloss 0.043167464 ploss 26.449863\n",
      "ac [[0.9459669]] ua [[1.7919581]]\n",
      "24 -th evaluation done. score: -1830.5925776042072 step: 200\n",
      "step 200 score -1698.0948956385641 qloss 0.04024783 ploss 26.715275\n",
      "ac [[0.8222689]] ua [[1.1637832]]\n",
      "25 -th evaluation done. score: -1671.5571623176982 step: 200\n",
      "step 200 score -1404.2972775645717 qloss 0.03880457 ploss 28.746143\n",
      "ac [[0.3953287]] ua [[0.41810012]]\n",
      "26 -th evaluation done. score: -1368.8178597294395 step: 200\n",
      "step 200 score -1593.3571327882405 qloss 0.036707807 ploss 29.685425\n",
      "ac [[-0.7592593]] ua [[-0.9944638]]\n",
      "27 -th evaluation done. score: -1178.7289000870364 step: 200\n",
      "step 200 score -1381.2172379082667 qloss 0.05965773 ploss 33.293022\n",
      "ac [[-0.7223562]] ua [[-0.9125546]]\n",
      "28 -th evaluation done. score: -1614.5988491386772 step: 200\n",
      "step 200 score -1583.9835243912942 qloss 0.053767893 ploss 34.4245\n",
      "ac [[0.7577523]] ua [[0.99091506]]\n",
      "29 -th evaluation done. score: -1698.406461883942 step: 200\n",
      "step 200 score -1474.8105095169224 qloss 0.03731015 ploss 34.881973\n",
      "ac [[-0.75699484]] ua [[-0.9891387]]\n",
      "30 -th evaluation done. score: -1620.0387791359046 step: 200\n",
      "step 200 score -1429.2297761847233 qloss 0.0518803 ploss 34.453033\n",
      "ac [[0.9734751]] ua [[2.1547346]]\n",
      "31 -th evaluation done. score: -1396.375898440805 step: 200\n",
      "step 200 score -1345.2686645877395 qloss 0.040503945 ploss 36.074265\n",
      "ac [[0.9463819]] ua [[1.7959218]]\n",
      "32 -th evaluation done. score: -1353.4114431033845 step: 200\n",
      "step 200 score -1549.3096959839445 qloss 0.039005823 ploss 35.669205\n",
      "ac [[0.7229187]] ua [[0.9137318]]\n",
      "33 -th evaluation done. score: -1306.622274135109 step: 200\n",
      "step 200 score -1178.9159796200424 qloss 0.05972863 ploss 39.89827\n",
      "ac [[-0.736731]] ua [[-0.9432918]]\n",
      "34 -th evaluation done. score: -1245.6527933416453 step: 200\n",
      "step 200 score -1302.3238735330722 qloss 0.09338841 ploss 41.82486\n",
      "ac [[-0.86171794]] ua [[-1.2999796]]\n",
      "35 -th evaluation done. score: -1277.8737584771184 step: 200\n",
      "step 200 score -1130.8547527217459 qloss 0.07193823 ploss 42.259094\n",
      "ac [[0.6495004]] ua [[0.77443403]]\n",
      "36 -th evaluation done. score: -1273.733351492033 step: 200\n",
      "step 200 score -1373.9858048104195 qloss 0.08260216 ploss 40.495567\n",
      "ac [[0.7917562]] ua [[1.076121]]\n",
      "37 -th evaluation done. score: -1315.9530653743725 step: 200\n",
      "step 200 score -1363.7595568113188 qloss 0.08075061 ploss 45.0188\n",
      "ac [[-0.94638336]] ua [[-1.7959355]]\n",
      "38 -th evaluation done. score: -1235.646094486397 step: 200\n",
      "step 200 score -1351.6963082466955 qloss 0.057157744 ploss 46.8644\n",
      "ac [[-0.98767275]] ua [[-2.541455]]\n",
      "39 -th evaluation done. score: -1228.6949993883347 step: 200\n",
      "step 200 score -1282.1270716264683 qloss 0.08384981 ploss 46.596394\n",
      "ac [[-0.4584461]] ua [[-0.49534214]]\n",
      "40 -th evaluation done. score: -1243.8236831678605 step: 200\n",
      "step 200 score -1265.293369637621 qloss 0.08751393 ploss 46.93151\n",
      "ac [[0.844513]] ua [[1.2367039]]\n",
      "41 -th evaluation done. score: -1168.7446664314662 step: 200\n",
      "step 200 score -1282.479121224468 qloss 0.07432462 ploss 49.105156\n",
      "ac [[-0.9469872]] ua [[-1.8017535]]\n",
      "42 -th evaluation done. score: -1116.631009485184 step: 200\n",
      "step 200 score -1205.7645038500932 qloss 0.07242988 ploss 49.87429\n",
      "ac [[0.04144081]] ua [[0.04146457]]\n",
      "43 -th evaluation done. score: -1264.9685162035223 step: 200\n",
      "step 200 score -1082.505762104885 qloss 0.089807235 ploss 51.728302\n",
      "ac [[-0.3141492]] ua [[-0.32514235]]\n",
      "44 -th evaluation done. score: -1238.7235503063184 step: 200\n",
      "step 200 score -1299.0020114148545 qloss 0.17553957 ploss 52.34436\n",
      "ac [[0.7427797]] ua [[0.9566518]]\n",
      "45 -th evaluation done. score: -1117.4612377323365 step: 200\n",
      "step 200 score -1177.7926619554048 qloss 0.113659695 ploss 51.832844\n",
      "ac [[0.41253015]] ua [[0.43865648]]\n",
      "46 -th evaluation done. score: -1106.7036278393507 step: 200\n",
      "step 200 score -1238.4470400879698 qloss 0.15870285 ploss 55.999508\n",
      "ac [[0.8314551]] ua [[1.192832]]\n",
      "47 -th evaluation done. score: -1100.627539980081 step: 200\n",
      "step 200 score -1329.3647932715198 qloss 0.10912434 ploss 55.776196\n",
      "ac [[-0.57940626]] ua [[-0.6615684]]\n",
      "48 -th evaluation done. score: -1187.2471140610735 step: 200\n",
      "step 200 score -1105.8515277216027 qloss 0.23015761 ploss 52.67038\n",
      "ac [[-0.9852546]] ua [[-2.4512835]]\n",
      "49 -th evaluation done. score: -1125.4507452433834 step: 200\n",
      "step 200 score -1101.4037887706065 qloss 0.08321695 ploss 58.727985\n",
      "ac [[0.90709025]] ua [[1.5108526]]\n",
      "50 -th evaluation done. score: -1079.9420995533096 step: 200\n",
      "step 200 score -1078.833927299484 qloss 0.08134622 ploss 56.24613\n",
      "ac [[-0.88181573]] ua [[-1.3838736]]\n",
      "51 -th evaluation done. score: -1008.0672295017383 step: 200\n",
      "step 200 score -728.1999680960563 qloss 0.20672235 ploss 58.863678\n",
      "ac [[0.9155247]] ua [[1.5606439]]\n",
      "52 -th evaluation done. score: -1004.7490657249335 step: 200\n",
      "step 200 score -743.1084594684291 qloss 0.052186288 ploss 60.025585\n",
      "ac [[-0.9515978]] ua [[-1.8484294]]\n",
      "53 -th evaluation done. score: -1018.7085506557933 step: 200\n",
      "step 200 score -1073.0912287174053 qloss 0.057697464 ploss 60.86345\n",
      "ac [[-0.8653361]] ua [[-1.3142073]]\n",
      "54 -th evaluation done. score: -1026.5251293875456 step: 200\n",
      "step 200 score -1004.9295042203937 qloss 0.04223209 ploss 59.815613\n",
      "ac [[0.9744719]] ua [[2.174138]]\n",
      "55 -th evaluation done. score: -1156.033395466489 step: 200\n",
      "step 200 score -1082.3314161202154 qloss 0.06153779 ploss 62.71785\n",
      "ac [[-0.5007381]] ua [[-0.55029076]]\n",
      "56 -th evaluation done. score: -980.9238899276183 step: 200\n",
      "step 200 score -1250.6516221667785 qloss 0.073048756 ploss 65.24135\n",
      "ac [[0.815741]] ua [[1.1439532]]\n",
      "57 -th evaluation done. score: -1153.9650666022417 step: 200\n",
      "step 200 score -1095.2964787368435 qloss 0.058826603 ploss 65.21714\n",
      "ac [[-0.93053275]] ua [[-1.6623484]]\n",
      "58 -th evaluation done. score: -872.4409963866111 step: 200\n",
      "step 200 score -1137.9604736791455 qloss 0.0681154 ploss 63.173893\n",
      "ac [[0.8636646]] ua [[1.307591]]\n",
      "59 -th evaluation done. score: -0.528719707881065 step: 200\n",
      "step 200 score -1143.8215221755065 qloss 0.079494506 ploss 70.99407\n",
      "ac [[-0.91529465]] ua [[-1.5592244]]\n",
      "60 -th evaluation done. score: -993.0789811696916 step: 200\n",
      "step 200 score -1000.1268835385963 qloss 0.064642094 ploss 68.05482\n",
      "ac [[-0.9571113]] ua [[-1.9103091]]\n",
      "61 -th evaluation done. score: -1012.7303970129051 step: 200\n",
      "step 200 score -1123.0457219359837 qloss 0.061578322 ploss 67.71351\n",
      "ac [[0.15063442]] ua [[0.15178955]]\n",
      "62 -th evaluation done. score: -870.9209512406999 step: 200\n",
      "step 200 score -997.779462338103 qloss 0.11983224 ploss 73.56683\n",
      "ac [[-0.9566635]] ua [[-1.9050007]]\n",
      "63 -th evaluation done. score: -763.2321246498435 step: 200\n",
      "step 200 score -377.19237817283897 qloss 0.08766414 ploss 71.19644\n",
      "ac [[-0.7974412]] ua [[-1.0915444]]\n",
      "64 -th evaluation done. score: -633.4641688864764 step: 200\n",
      "step 200 score -986.377108874259 qloss 0.07987425 ploss 71.45697\n",
      "ac [[-0.7435358]] ua [[-0.95834064]]\n",
      "65 -th evaluation done. score: -504.7200755724419 step: 200\n",
      "step 200 score -629.2003455315361 qloss 0.08710426 ploss 74.526505\n",
      "ac [[-0.5660176]] ua [[-0.6416435]]\n",
      "66 -th evaluation done. score: -625.3670772710119 step: 200\n",
      "step 200 score -984.2750624968653 qloss 0.09252831 ploss 70.98135\n",
      "ac [[-0.88847214]] ua [[-1.4146245]]\n",
      "67 -th evaluation done. score: -500.18424042213957 step: 200\n",
      "step 200 score -126.17203629651159 qloss 0.096163884 ploss 70.389786\n",
      "ac [[-0.01839049]] ua [[-0.01839256]]\n",
      "68 -th evaluation done. score: -634.7827594798849 step: 200\n",
      "step 200 score -126.67665422044048 qloss 0.11437072 ploss 68.14572\n",
      "ac [[-0.5272447]] ua [[-0.58632135]]\n",
      "69 -th evaluation done. score: -883.6394749060034 step: 200\n",
      "step 200 score -252.02352803312164 qloss 0.16492504 ploss 69.77102\n",
      "ac [[-0.7257548]] ua [[-0.91969836]]\n",
      "70 -th evaluation done. score: -750.982846172145 step: 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 200 score -634.7821738535188 qloss 0.12954415 ploss 70.763695\n",
      "ac [[-0.9012548]] ua [[-1.478863]]\n",
      "71 -th evaluation done. score: -0.382945154264151 step: 200\n",
      "step 200 score -1029.62054130281 qloss 0.12686649 ploss 68.23483\n",
      "ac [[0.4515727]] ua [[0.48667404]]\n",
      "72 -th evaluation done. score: -0.5185226983549517 step: 200\n",
      "step 200 score -635.2641721334304 qloss 0.12440968 ploss 73.7698\n",
      "ac [[-0.82458997]] ua [[-1.170992]]\n",
      "73 -th evaluation done. score: -642.6333219381486 step: 200\n",
      "step 200 score -851.4609396614145 qloss 0.14292163 ploss 76.07337\n",
      "ac [[0.6923136]] ua [[0.85238546]]\n",
      "74 -th evaluation done. score: -125.40723786357391 step: 200\n",
      "step 200 score -0.37416423817512845 qloss 0.14169343 ploss 68.25714\n",
      "ac [[0.23411469]] ua [[0.23853838]]\n",
      "75 -th evaluation done. score: -849.5019607463903 step: 200\n",
      "step 200 score -785.9276485090844 qloss 0.1135598 ploss 70.18631\n",
      "ac [[0.85349256]] ua [[1.2688752]]\n",
      "76 -th evaluation done. score: -366.5170614813033 step: 200\n",
      "step 200 score -1027.2285261148188 qloss 0.13719559 ploss 67.59927\n",
      "ac [[0.38677153]] ua [[0.40799806]]\n",
      "77 -th evaluation done. score: -772.3571584244063 step: 200\n",
      "step 200 score -377.3931470876606 qloss 0.15481919 ploss 67.16766\n",
      "ac [[-0.57376015]] ua [[-0.6531104]]\n",
      "78 -th evaluation done. score: -639.0594700998442 step: 200\n",
      "step 200 score -373.44860272999335 qloss 0.16429617 ploss 67.24982\n",
      "ac [[0.07727658]] ua [[0.07743096]]\n",
      "79 -th evaluation done. score: -884.5017370861243 step: 200\n",
      "step 200 score -749.8395873522161 qloss 0.20591092 ploss 65.11942\n",
      "ac [[0.11332556]] ua [[0.11381447]]\n",
      "80 -th evaluation done. score: -767.1433468369007 step: 200\n",
      "step 200 score -253.24120755082012 qloss 0.14996102 ploss 66.45599\n",
      "ac [[-0.71840256]] ua [[-0.90433586]]\n",
      "81 -th evaluation done. score: -763.9099405855386 step: 200\n",
      "step 200 score -125.5581972562319 qloss 0.17681624 ploss 62.506805\n",
      "ac [[-0.30521205]] ua [[-0.31525707]]\n",
      "82 -th evaluation done. score: -124.22139574022573 step: 200\n",
      "step 200 score -253.51266782496066 qloss 0.18148713 ploss 60.268444\n",
      "ac [[0.00156893]] ua [[0.00156894]]\n",
      "83 -th evaluation done. score: -124.5416418148638 step: 200\n",
      "step 200 score -633.4734658424468 qloss 0.18308714 ploss 62.70038\n",
      "ac [[0.07598977]] ua [[0.07613654]]\n",
      "84 -th evaluation done. score: -481.9120470101102 step: 200\n",
      "step 200 score -371.1164864197552 qloss 0.22342741 ploss 69.34845\n",
      "ac [[-0.34574145]] ua [[-0.36059892]]\n",
      "85 -th evaluation done. score: -786.1208581350878 step: 200\n",
      "step 200 score -493.94146883880194 qloss 0.19805136 ploss 66.07602\n",
      "ac [[0.05179888]] ua [[0.05184528]]\n",
      "86 -th evaluation done. score: -615.4956245708744 step: 200\n",
      "step 200 score -126.40220223480301 qloss 0.23109795 ploss 66.44678\n",
      "ac [[0.1402448]] ua [[0.14117528]]\n",
      "87 -th evaluation done. score: -123.70733399813432 step: 200\n",
      "step 200 score -480.5073108100124 qloss 0.27984834 ploss 65.436264\n",
      "ac [[-0.5677338]] ua [[-0.64417243]]\n",
      "88 -th evaluation done. score: -907.6450641588823 step: 200\n",
      "step 200 score -862.8362267706241 qloss 0.27448782 ploss 61.2173\n",
      "ac [[-0.4632942]] ua [[-0.50149775]]\n",
      "89 -th evaluation done. score: -126.03477453105707 step: 200\n",
      "step 200 score -1121.1550360429287 qloss 0.45542294 ploss 66.37918\n",
      "ac [[-0.69178647]] ua [[-0.8513737]]\n",
      "90 -th evaluation done. score: -775.57315480013 step: 200\n",
      "step 200 score -369.6353038948622 qloss 0.41710648 ploss 57.524242\n",
      "ac [[0.61567014]] ua [[0.71800196]]\n",
      "91 -th evaluation done. score: -127.44110460766132 step: 200\n",
      "step 200 score -845.6666918054008 qloss 0.2973847 ploss 64.69003\n",
      "ac [[-0.68575984]] ua [[-0.8399071]]\n",
      "92 -th evaluation done. score: -502.67333787886696 step: 200\n",
      "step 200 score -245.48154142382273 qloss 0.3829386 ploss 67.988846\n",
      "ac [[0.14127402]] ua [[0.14222533]]\n",
      "93 -th evaluation done. score: -252.72813125998533 step: 200\n",
      "step 200 score -533.471418542033 qloss 0.641885 ploss 61.983883\n",
      "ac [[-0.38222307]] ua [[-0.4026605]]\n",
      "94 -th evaluation done. score: -761.606388190449 step: 200\n",
      "step 200 score -252.8332024782809 qloss 0.46139356 ploss 55.381573\n",
      "ac [[-0.21577993]] ua [[-0.2192257]]\n",
      "95 -th evaluation done. score: -374.63879894955176 step: 200\n",
      "step 200 score -609.0042683097953 qloss 0.34147757 ploss 68.01942\n",
      "ac [[0.2664254]] ua [[0.27301216]]\n",
      "96 -th evaluation done. score: -365.0215890427588 step: 200\n",
      "step 200 score -725.3531947261889 qloss 0.4075105 ploss 56.802895\n",
      "ac [[-0.21721302]] ua [[-0.22072928]]\n",
      "97 -th evaluation done. score: -126.09372354276039 step: 200\n",
      "step 200 score -489.0779751529591 qloss 0.3812127 ploss 62.269722\n",
      "ac [[-0.9483924]] ua [[-1.8155453]]\n",
      "98 -th evaluation done. score: -124.43484124656085 step: 200\n",
      "step 200 score -369.59090806673277 qloss 0.5403036 ploss 56.75345\n",
      "ac [[0.01778013]] ua [[0.017782]]\n",
      "99 -th evaluation done. score: -366.0444781085198 step: 200\n",
      "step 200 score -484.65601582077227 qloss 0.45514637 ploss 56.621567\n",
      "ac [[-0.35104078]] ua [[-0.36663032]]\n",
      "100 -th evaluation done. score: -510.8291463118454 step: 200\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "agent = Agent()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "agent.q_initial_sync()\n",
    "## TRAIN ##\n",
    "eval_scores = []\n",
    "\n",
    "for episode in range(MAX_EPISODE):\n",
    "    state = env.reset()\n",
    "\n",
    "#     eps = [[np.random.normal(agent.action_dim)]]\n",
    "#     aa = sess.run(agent.action, feed_dict={agent.state_ph:[state], agent.action_eps_ph:eps})\n",
    "#     d=sess.run(agent.log_policy, feed_dict={agent.state_ph:[state], agent.action_ph:aa, agent.action_eps_ph:eps})\n",
    "#     print('d',d)\n",
    "#     print('sat',state)\n",
    "    score = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        action, ua = agent.sample_action(state)\n",
    "        \n",
    "        if episode%10==0:\n",
    "            env.render()\n",
    "            time.sleep(0.01)\n",
    "        next_state, reward, done, info = env.step(action[0])\n",
    "        fake_done = False\n",
    "#         env.render()\n",
    "#         time.sleep(0.01)\n",
    "        agent.replay.update(state, action[0], [reward], next_state, [fake_done])\n",
    "#         print('nn',next_state)\n",
    "        qloss, ploss = agent.train()\n",
    "\n",
    "\n",
    "        step += 1\n",
    "        score += reward\n",
    "        state = next_state\n",
    "        if done or step>2000:\n",
    "            print('step', step, 'score', score, 'qloss', qloss,'ploss',ploss)\n",
    "            print('ac', action, 'ua', ua)\n",
    "            print\n",
    "            break\n",
    "    \n",
    "    eval_score = agent.evaluate()\n",
    "    eval_scores.append(eval_score)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efff5b6bb00>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(eval_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ATARI_kernel",
   "language": "python",
   "name": "atari_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
